
<!doctype html>
<meta charset="utf-8">
<style>
body { margin: 20px; }
</style>
<script>
function toggle(arxiv) {
  let elt = document.getElementById(arxiv);
  console.log(elt, elt.style.display);
  if(elt.style.display == "block") {
    elt.style.display = "none";
  } else {
    elt.style.display = "block";
  }
}
</script>
<div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.14057v1")'>Left/Right Brain, human motor control and the implications for robotics</div>
<div id='2401.14057v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-25T10:29:07Z</div><div>Authors: Jarrad Rinaldo, Levin Kuhlmann, Jason Friedman, Gideon Kowadlo</div><div style='padding-top: 10px; width: 80ex'>Neural Network movement controllers promise a variety of advantages over
conventional control methods however they are not widely adopted due to their
inability to produce reliably precise movements. This research explores a
bilateral neural network architecture as a control system for motor tasks. We
aimed to achieve hemispheric specialisation similar to what is observed in
humans across different tasks; the dominant system (usually the right hand,
left hemisphere) excels at tasks involving coordination and efficiency of
movement, and the non-dominant system performs better at tasks requiring
positional stability. Specialisation was achieved by training the hemispheres
with different loss functions tailored toward the expected behaviour of the
respective hemispheres. We compared bilateral models with and without
specialised hemispheres, with and without inter-hemispheric connectivity
(representing the biological Corpus Callosum), and unilateral models with and
without specialisation. The models were trained and tested on two tasks common
in the human motor control literature: the random reach task, suited to the
dominant system, a model with better coordination, and the hold position task,
suited to the non-dominant system, a model with more stable movement. Each
system out-performed the non-favoured system in its preferred task. For both
tasks, a bilateral model outperforms the 'non-preferred' hand, and is as good
or better than the 'preferred' hand. The Corpus Callosum tends to improve
performance, but not always for the specialised models.</div><div><a href='http://arxiv.org/abs/2401.14057v1'>2401.14057v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.05164v1")'>Synthetic data generation for system identification: leveraging
  knowledge transfer from similar systems</div>
<div id='2403.05164v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-08T09:09:15Z</div><div>Authors: Dario Piga, Matteo Rufolo, Gabriele Maroni, Manas Mejari, Marco Forgione</div><div style='padding-top: 10px; width: 80ex'>This paper addresses the challenge of overfitting in the learning of
dynamical systems by introducing a novel approach for the generation of
synthetic data, aimed at enhancing model generalization and robustness in
scenarios characterized by data scarcity. Central to the proposed methodology
is the concept of knowledge transfer from systems within the same class.
Specifically, synthetic data is generated through a pre-trained meta-model that
describes a broad class of systems to which the system of interest is assumed
to belong. Training data serves a dual purpose: firstly, as input to the
pre-trained meta model to discern the system's dynamics, enabling the
prediction of its behavior and thereby generating synthetic output sequences
for new input sequences; secondly, in conjunction with synthetic data, to
define the loss function used for model estimation. A validation dataset is
used to tune a scalar hyper-parameter balancing the relative importance of
training and synthetic data in the definition of the loss function. The same
validation set can be also used for other purposes, such as early stopping
during the training, fundamental to avoid overfitting in case of small-size
training datasets. The efficacy of the approach is shown through a numerical
example that highlights the advantages of integrating synthetic data into the
system identification process.</div><div><a href='http://arxiv.org/abs/2403.05164v1'>2403.05164v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.19290v2")'>Estimation and Deconvolution of Second Order Cyclostationary Signals</div>
<div id='2402.19290v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T15:53:47Z</div><div>Authors: Igor Makienko, Michael Grebshtein, Eli Gildish</div><div style='padding-top: 10px; width: 80ex'>This method solves the dual problem of blind deconvolution and estimation of
the time waveform of noisy second-order cyclo-stationary (CS2) signals that
traverse a Transfer Function (TF) en route to a sensor. We have proven that the
deconvolution filter exists and eliminates the TF effect from signals whose
statistics vary over time. This method is blind, meaning it does not require
prior knowledge about the signals or TF. Simulations demonstrate the algorithm
high precision across various signal types, TFs, and Signal-to-Noise Ratios
(SNRs). In this study, the CS2 signals family is restricted to the product of a
deterministic periodic function and white noise. Furthermore, this method has
the potential to improve the training of Machine Learning models where the
aggregation of signals from identical systems but with different TFs is
required.</div><div><a href='http://arxiv.org/abs/2402.19290v2'>2402.19290v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.02007v1")'>Understanding Time Series Anomaly State Detection through One-Class
  Classification</div>
<div id='2402.02007v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-03T03:43:04Z</div><div>Authors: Hanxu Zhou, Yuan Zhang, Guangjie Leng, Ruofan Wang, Zhi-Qin John Xu</div><div style='padding-top: 10px; width: 80ex'>For a long time, research on time series anomaly detection has mainly focused
on finding outliers within a given time series. Admittedly, this is consistent
with some practical problems, but in other practical application scenarios,
people are concerned about: assuming a standard time series is given, how to
judge whether another test time series deviates from the standard time series,
which is more similar to the problem discussed in one-class classification
(OCC). Therefore, in this article, we try to re-understand and define the time
series anomaly detection problem through OCC, which we call 'time series
anomaly state detection problem'. We first use stochastic processes and
hypothesis testing to strictly define the 'time series anomaly state detection
problem', and its corresponding anomalies. Then, we use the time series
classification dataset to construct an artificial dataset corresponding to the
problem. We compile 38 anomaly detection algorithms and correct some of the
algorithms to adapt to handle this problem. Finally, through a large number of
experiments, we fairly compare the actual performance of various time series
anomaly detection algorithms, providing insights and directions for future
research by researchers.</div><div><a href='http://arxiv.org/abs/2402.02007v1'>2402.02007v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04429v1")'>Exploring the Influence of Dimensionality Reduction on Anomaly Detection
  Performance in Multivariate Time Series</div>
<div id='2403.04429v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T11:59:00Z</div><div>Authors: Mahsun Altin, Altan Cakir</div><div style='padding-top: 10px; width: 80ex'>This paper presents an extensive empirical study on the integration of
dimensionality reduction techniques with advanced unsupervised time series
anomaly detection models, focusing on the MUTANT and Anomaly-Transformer
models. The study involves a comprehensive evaluation across three different
datasets: MSL, SMAP, and SWaT. Each dataset poses unique challenges, allowing
for a robust assessment of the models' capabilities in varied contexts. The
dimensionality reduction techniques examined include PCA, UMAP, Random
Projection, and t-SNE, each offering distinct advantages in simplifying
high-dimensional data. Our findings reveal that dimensionality reduction not
only aids in reducing computational complexity but also significantly enhances
anomaly detection performance in certain scenarios. Moreover, a remarkable
reduction in training times was observed, with reductions by approximately
300\% and 650\% when dimensionality was halved and minimized to the lowest
dimensions, respectively. This efficiency gain underscores the dual benefit of
dimensionality reduction in both performance enhancement and operational
efficiency. The MUTANT model exhibits notable adaptability, especially with
UMAP reduction, while the Anomaly-Transformer demonstrates versatility across
various reduction techniques. These insights provide a deeper understanding of
the synergistic effects of dimensionality reduction and anomaly detection,
contributing valuable perspectives to the field of time series analysis. The
study underscores the importance of selecting appropriate dimensionality
reduction strategies based on specific model requirements and dataset
characteristics, paving the way for more efficient, accurate, and scalable
solutions in anomaly detection.</div><div><a href='http://arxiv.org/abs/2403.04429v1'>2403.04429v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.10802v2")'>TimeSeriesBench: An Industrial-Grade Benchmark for Time Series Anomaly
  Detection Models</div>
<div id='2402.10802v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-16T16:25:20Z</div><div>Authors: Haotian Si, Changhua Pei, Hang Cui, Jingwen Yang, Yongqian Sun, Shenglin Zhang, Jingjing Li, Haiming Zhang, Jing Han, Dan Pei, Jianhui Li, Gaogang Xie</div><div style='padding-top: 10px; width: 80ex'>Driven by the proliferation of real-world application scenarios and scales,
time series anomaly detection (TSAD) has attracted considerable scholarly and
industrial interest. However, existing algorithms exhibit a gap in terms of
training paradigm, online detection paradigm, and evaluation criteria when
compared to the actual needs of real-world industrial systems. Firstly, current
algorithms typically train a specific model for each individual time series. In
a large-scale online system with tens of thousands of curves, maintaining such
a multitude of models is impractical. The performance of using merely one
single unified model to detect anomalies remains unknown. Secondly, most TSAD
models are trained on the historical part of a time series and are tested on
its future segment. In distributed systems, however, there are frequent system
deployments and upgrades, with new, previously unseen time series emerging
daily. The performance of testing newly incoming unseen time series on current
TSAD algorithms remains unknown. Lastly, although some papers have conducted
detailed surveys, the absence of an online evaluation platform prevents
answering questions like "Who is the best at anomaly detection at the current
stage?" In this paper, we propose TimeSeriesBench, an industrial-grade
benchmark that we continuously maintain as a leaderboard. On this leaderboard,
we assess the performance of existing algorithms across more than 168
evaluation settings combining different training and testing paradigms,
evaluation metrics and datasets. Through our comprehensive analysis of the
results, we provide recommendations for the future design of anomaly detection
algorithms. To address known issues with existing public datasets, we release
an industrial dataset to the public together with TimeSeriesBench. All code,
data, and the online leaderboard have been made publicly available.</div><div><a href='http://arxiv.org/abs/2402.10802v2'>2402.10802v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07281v2")'>Can Tree Based Approaches Surpass Deep Learning in Anomaly Detection? A
  Benchmarking Study</div>
<div id='2402.07281v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-11T19:12:51Z</div><div>Authors: Santonu Sarkar, Shanay Mehta, Nicole Fernandes, Jyotirmoy Sarkar, Snehanshu Saha</div><div style='padding-top: 10px; width: 80ex'>Detection of anomalous situations for complex mission-critical systems holds
paramount importance when their service continuity needs to be ensured. A major
challenge in detecting anomalies from the operational data arises due to the
imbalanced class distribution problem since the anomalies are supposed to be
rare events. This paper evaluates a diverse array of machine learning-based
anomaly detection algorithms through a comprehensive benchmark study. The paper
contributes significantly by conducting an unbiased comparison of various
anomaly detection algorithms, spanning classical machine learning including
various tree-based approaches to deep learning and outlier detection methods.
The inclusion of 104 publicly available and a few proprietary industrial
systems datasets enhances the diversity of the study, allowing for a more
realistic evaluation of algorithm performance and emphasizing the importance of
adaptability to real-world scenarios. The paper dispels the deep learning myth,
demonstrating that though powerful, deep learning is not a universal solution
in this case. We observed that recently proposed tree-based evolutionary
algorithms outperform in many scenarios. We noticed that tree-based approaches
catch a singleton anomaly in a dataset where deep learning methods fail. On the
other hand, classical SVM performs the best on datasets with more than 10%
anomalies, implying that such scenarios can be best modeled as a classification
problem rather than anomaly detection. To our knowledge, such a study on a
large number of state-of-the-art algorithms using diverse data sets, with the
objective of guiding researchers and practitioners in making informed
algorithmic choices, has not been attempted earlier.</div><div><a href='http://arxiv.org/abs/2402.07281v2'>2402.07281v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.10085v1")'>Develop End-to-End Anomaly Detection System</div>
<div id='2402.10085v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T09:02:44Z</div><div>Authors: Emanuele Mengoli, Zhiyuan Yao, Wutao Wei</div><div style='padding-top: 10px; width: 80ex'>Anomaly detection plays a crucial role in ensuring network robustness.
However, implementing intelligent alerting systems becomes a challenge when
considering scenarios in which anomalies can be caused by both malicious and
non-malicious events, leading to the difficulty of determining anomaly
patterns. The lack of labeled data in the computer networking domain further
exacerbates this issue, impeding the development of robust models capable of
handling real-world scenarios. To address this challenge, in this paper, we
propose an end-to-end anomaly detection model development pipeline. This
framework makes it possible to consume user feedback and enable continuous
user-centric model performance evaluation and optimization. We demonstrate the
efficacy of the framework by way of introducing and bench-marking a new
forecasting model -- named \emph{Lachesis} -- on a real-world networking
problem. Experiments have demonstrated the robustness and effectiveness of the
two proposed versions of \emph{Lachesis} compared with other models proposed in
the literature. Our findings underscore the potential for improving the
performance of data-driven products over their life cycles through a harmonized
integration of user feedback and iterative development.</div><div><a href='http://arxiv.org/abs/2402.10085v1'>2402.10085v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09082v1")'>Detection Latencies of Anomaly Detectors: An Overlooked Perspective ?</div>
<div id='2402.09082v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T10:52:39Z</div><div>Authors: Tommaso Puccetti, Andrea Ceccarelli</div><div style='padding-top: 10px; width: 80ex'>The ever-evolving landscape of attacks, coupled with the growing complexity
of ICT systems, makes crafting anomaly-based intrusion detectors (ID) and error
detectors (ED) a difficult task: they must accurately detect attacks, and they
should promptly perform detections. Although improving and comparing the
detection capability is the focus of most research works, the timeliness of the
detection is less considered and often insufficiently evaluated or discussed.
In this paper, we argue the relevance of measuring the temporal latency of
attacks and errors, and we propose an evaluation approach for detectors to
ensure a pragmatic trade-off between correct and in-time detection. Briefly,
the approach relates the false positive rate with the temporal latency of
attacks and errors, and this ultimately leads to guidelines for configuring a
detector. We apply our approach by evaluating different ED and ID solutions in
two industrial cases: i) an embedded railway on-board system that optimizes
public mobility, and ii) an edge device for the Industrial Internet of Things.
Our results show that considering latency in addition to traditional metrics
like the false positive rate, precision, and coverage gives an additional
fundamental perspective on the actual performance of the detector and should be
considered when assessing and configuring anomaly detectors.</div><div><a href='http://arxiv.org/abs/2402.09082v1'>2402.09082v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.14041v4")'>E2USD: Efficient-yet-effective Unsupervised State Detection for
  Multivariate Time Series</div>
<div id='2402.14041v4' style='display: none; margin-left: 20px'><div>Date: 2024-02-21T10:16:57Z</div><div>Authors: Zhichen Lai, Huan Li, Dalin Zhang, Yan Zhao, Weizhu Qian, Christian S. Jensen</div><div style='padding-top: 10px; width: 80ex'>We propose E2USD that enables efficient-yet-accurate unsupervised MTS state
detection. E2USD exploits a Fast Fourier Transform-based Time Series Compressor
(FFTCompress) and a Decomposed Dual-view Embedding Module (DDEM) that together
encode input MTSs at low computational overhead. Additionally, we propose a
False Negative Cancellation Contrastive Learning method (FNCCLearning) to
counteract the effects of false negatives and to achieve more cluster-friendly
embedding spaces. To reduce computational overhead further in streaming
settings, we introduce Adaptive Threshold Detection (ADATD). Comprehensive
experiments with six baselines and six datasets offer evidence that E2USD is
capable of SOTA accuracy at significantly reduced computational overhead.</div><div><a href='http://arxiv.org/abs/2402.14041v4'>2402.14041v4</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.07892v1")'>Change Point Detection with Copula Entropy based Two-Sample Test</div>
<div id='2403.07892v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-03T20:36:48Z</div><div>Authors: Jian Ma</div><div style='padding-top: 10px; width: 80ex'>Change point detection is a typical task that aim to find changes in time
series and can be tackled with two-sample test. Copula Entropy is a
mathematical concept for measuring statistical independence and a two-sample
test based on it was introduced recently. In this paper we propose a
nonparametric multivariate method for multiple change point detection with the
copula entropy-based two-sample test. The single change point detection is
first proposed as a group of two-sample tests on every points of time series
data and the change point is considered as with the maximum of the test
statistics. The multiple change point detection is then proposed by combining
the single change point detection method with binary segmentation strategy. We
verified the effectiveness of our method and compared it with the other similar
methods on the simulated univariate and multivariate data and the Nile data.</div><div><a href='http://arxiv.org/abs/2403.07892v1'>2403.07892v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.08013v1")'>Supervised Time Series Classification for Anomaly Detection in Subsea
  Engineering</div>
<div id='2403.08013v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T18:25:10Z</div><div>Authors: Ergys Çokaj, Halvor Snersrud Gustad, Andrea Leone, Per Thomas Moe, Lasse Moldestad</div><div style='padding-top: 10px; width: 80ex'>Time series classification is of significant importance in monitoring
structural systems. In this work, we investigate the use of supervised machine
learning classification algorithms on simulated data based on a physical system
with two states: Intact and Broken. We provide a comprehensive discussion of
the preprocessing of temporal data, using measures of statistical dispersion
and dimension reduction techniques. We present an intuitive baseline method and
discuss its efficiency. We conclude with a comparison of the various methods
based on different performance metrics, showing the advantage of using machine
learning techniques as a tool in decision making.</div><div><a href='http://arxiv.org/abs/2403.08013v1'>2403.08013v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00803v1")'>Signal Quality Auditing for Time-series Data</div>
<div id='2402.00803v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T17:40:10Z</div><div>Authors: Chufan Gao, Nicholas Gisolfi, Artur Dubrawski</div><div style='padding-top: 10px; width: 80ex'>Signal quality assessment (SQA) is required for monitoring the reliability of
data acquisition systems, especially in AI-driven Predictive Maintenance (PMx)
application contexts. SQA is vital for addressing "silent failures" of data
acquisition hardware and software, which when unnoticed, misinform the users of
data, creating the risk for incorrect decisions with unintended or even
catastrophic consequences. We have developed an open-source software
implementation of signal quality indices (SQIs) for the analysis of time-series
data. We codify a range of SQIs, demonstrate them using established benchmark
data, and show that they can be effective for signal quality assessment. We
also study alternative approaches to denoising time-series data in an attempt
to improve the quality of the already degraded signal, and evaluate them
empirically on relevant real-world data. To our knowledge, our software toolkit
is the first to provide an open source implementation of a broad range of
signal quality assessment and improvement techniques validated on publicly
available benchmark data for ease of reproducibility. The generality of our
framework can be easily extended to assessing reliability of arbitrary
time-series measurements in complex systems, especially when morphological
patterns of the waveform shapes and signal periodicity are of key interest in
downstream analyses.</div><div><a href='http://arxiv.org/abs/2402.00803v1'>2402.00803v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15199v1")'>SCANIA Component X Dataset: A Real-World Multivariate Time Series
  Dataset for Predictive Maintenance</div>
<div id='2401.15199v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-26T20:51:55Z</div><div>Authors: Zahra Kharazian, Tony Lindgren, Sindri Magnússon, Olof Steinert, Oskar Andersson Reyna</div><div style='padding-top: 10px; width: 80ex'>This paper presents a description of a real-world, multivariate time series
dataset collected from an anonymized engine component (called Component X) of a
fleet of trucks from SCANIA, Sweden. This dataset includes diverse variables
capturing detailed operational data, repair records, and specifications of
trucks while maintaining confidentiality by anonymization. It is well-suited
for a range of machine learning applications, such as classification,
regression, survival analysis, and anomaly detection, particularly when applied
to predictive maintenance scenarios. The large population size and variety of
features in the format of histograms and numerical counters, along with the
inclusion of temporal information, make this real-world dataset unique in the
field. The objective of releasing this dataset is to give a broad range of
researchers the possibility of working with real-world data from an
internationally well-known company and introduce a standard benchmark to the
predictive maintenance field, fostering reproducible research.</div><div><a href='http://arxiv.org/abs/2401.15199v1'>2401.15199v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.19294v1")'>Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes</div>
<div id='2402.19294v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T15:57:09Z</div><div>Authors: Ying Fu, Ye Kwon Huh, Kaibo Liu</div><div style='padding-top: 10px; width: 80ex'>Operating units often experience various failure modes in complex systems,
leading to distinct degradation paths. Relying on a prognostic model trained on
a single failure mode may lead to poor generalization performance across
multiple failure modes. Therefore, accurately identifying the failure mode is
of critical importance. Current prognostic approaches either ignore failure
modes during degradation or assume known failure mode labels, which can be
challenging to acquire in practice. Moreover, the high dimensionality and
complex relations of sensor signals make it challenging to identify the failure
modes accurately. To address these issues, we propose a novel failure mode
diagnosis method that leverages a dimension reduction technique called UMAP
(Uniform Manifold Approximation and Projection) to project and visualize each
unit's degradation trajectory into a lower dimension. Then, using these
degradation trajectories, we develop a time series-based clustering method to
identify the training units' failure modes. Finally, we introduce a
monotonically constrained prognostic model to predict the failure mode labels
and RUL of the test units simultaneously using the obtained failure modes of
the training units. The proposed prognostic model provides failure
mode-specific RUL predictions while preserving the monotonic property of the
RUL predictions across consecutive time steps. We evaluate the proposed model
using a case study with the aircraft gas turbine engine dataset.</div><div><a href='http://arxiv.org/abs/2402.19294v1'>2402.19294v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.17802v1")'>Time Series Analysis in Compressor-Based Machines: A Survey</div>
<div id='2402.17802v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T08:34:48Z</div><div>Authors: Francesca Forbicini, Nicolò Oreste Pinciroli Vago, Piero Fraternali</div><div style='padding-top: 10px; width: 80ex'>In both industrial and residential contexts, compressor-based machines, such
as refrigerators, HVAC systems, heat pumps and chillers, are essential to
fulfil production and consumers' needs. The diffusion of sensors and IoT
connectivity supports the development of monitoring systems able to detect and
predict faults, identify behavioural shifts and forecast the operational status
of machines and of their components. The focus of this paper is to survey the
recent research on such tasks as Fault Detection, Fault Prediction, Forecasting
and Change Point Detection applied to multivariate time series characterizing
the operations of compressor-based machines. Specifically, Fault Detection
detects and diagnoses faults, Fault Prediction predicts such occurrences,
forecasting anticipates the future value of characteristic variables of
machines and Change Point Detection identifies significant variations in the
behaviour of the appliances, such as a change in the working regime. We
identify and classify the approaches to the above-mentioned tasks, compare the
algorithms employed, highlight the gaps in the current status of the art and
discuss the most promising future research directions in the field.</div><div><a href='http://arxiv.org/abs/2402.17802v1'>2402.17802v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.06942v1")'>Grid Monitoring and Protection with Continuous Point-on-Wave
  Measurements and Generative AI</div>
<div id='2403.06942v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-11T17:28:46Z</div><div>Authors: Lang Tong, Xinyi Wang, Qing Zhao</div><div style='padding-top: 10px; width: 80ex'>Purpose This article presents a case for a next-generation grid monitoring
and control system, leveraging recent advances in generative artificial
intelligence (AI), machine learning, and statistical inference. Advancing
beyond earlier generations of wide-area monitoring systems built upon
supervisory control and data acquisition (SCADA) and synchrophasor
technologies, we argue for a monitoring and control framework based on the
streaming of continuous point-on-wave (CPOW) measurements with AI-powered data
compression and fault detection.
  Methods and Results: The architecture of the proposed design originates from
the Wiener-Kallianpur innovation representation of a random process that
transforms causally a stationary random process into an innovation sequence
with independent and identically distributed random variables. This work
presents a generative AI approach that (i) learns an innovation autoencoder
that extracts innovation sequence from CPOW time series, (ii) compresses the
CPOW streaming data with innovation autoencoder and subband coding, and (iii)
detects unknown faults and novel trends via nonparametric sequential hypothesis
testing.
  Conclusion: This work argues that conventional monitoring using SCADA and
phasor measurement unit (PMU) technologies is ill-suited for a future grid with
deep penetration of inverter-based renewable generations and distributed energy
resources. A monitoring system based on CPOW data streaming and AI data
analytics should be the basic building blocks for situational awareness of a
highly dynamic future grid.</div><div><a href='http://arxiv.org/abs/2403.06942v1'>2403.06942v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.05664v1")'>Root Cause Analysis on Energy Efficiency with Transfer Entropy Flow</div>
<div id='2401.05664v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-11T04:54:52Z</div><div>Authors: Jian Ma</div><div style='padding-top: 10px; width: 80ex'>Energy efficiency is a big concern in industrial sectors. Finding the root
cause of anomaly state of energy efficiency can help to improve energy
efficiency of industrial systems and therefore save energy cost. In this
research, we propose to use transfer entropy (TE) for root cause analysis on
energy efficiency of industrial systems. A method, called TE flow, is proposed
in that a TE flow from physical measurements of each subsystem to the energy
efficiency indicator along timeline is considered as causal strength for
diagnosing root cause of anomaly states of energy efficiency of a system. The
copula entropy-based nonparametric TE estimator is used in the proposed method.
We conducted experiments on real data collected from a compressing air system
to verify the proposed method. Experimental results show that the TE flow
method successfully identified the root cause of the energy (in)efficiency of
the system.</div><div><a href='http://arxiv.org/abs/2401.05664v1'>2401.05664v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.01824v1")'>Identification of Cognitive Decline from Spoken Language through Feature
  Selection and the Bag of Acoustic Words Model</div>
<div id='2402.01824v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T17:06:03Z</div><div>Authors: Marko Niemelä, Mikaela von Bonsdorff, Sami Äyrämö, Tommi Kärkkäinen</div><div style='padding-top: 10px; width: 80ex'>Memory disorders are a central factor in the decline of functioning and daily
activities in elderly individuals. The confirmation of the illness, initiation
of medication to slow its progression, and the commencement of occupational
therapy aimed at maintaining and rehabilitating cognitive abilities require a
medical diagnosis. The early identification of symptoms of memory disorders,
especially the decline in cognitive abilities, plays a significant role in
ensuring the well-being of populations. Features related to speech production
are known to connect with the speaker's cognitive ability and changes. The lack
of standardized speech tests in clinical settings has led to a growing emphasis
on developing automatic machine learning techniques for analyzing naturally
spoken language. Non-lexical but acoustic properties of spoken language have
proven useful when fast, cost-effective, and scalable solutions are needed for
the rapid diagnosis of a disease. The work presents an approach related to
feature selection, allowing for the automatic selection of the essential
features required for diagnosis from the Geneva minimalistic acoustic parameter
set and relative speech pauses, intended for automatic paralinguistic and
clinical speech analysis. These features are refined into word histogram
features, in which machine learning classifiers are trained to classify control
subjects and dementia patients from the Dementia Bank's Pitt audio database.
The results show that achieving a 75% average classification accuracy with only
twenty-five features with the separate ADReSS 2020 competition test data and
the Leave-One-Subject-Out cross-validation of the entire competition data is
possible. The results rank at the top compared to international research, where
the same dataset and only acoustic features have been used to diagnose
patients.</div><div><a href='http://arxiv.org/abs/2402.01824v1'>2402.01824v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00897v1")'>Screening method for early dementia using sound objects as voice
  biomarkers</div>
<div id='2402.00897v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-31T19:20:08Z</div><div>Authors: Adam Pluta, Zbigniew Pioch, Jędrzej Kardach, Piotr Zioło, Tomasz Kręcicki, Elżbieta Trypka</div><div style='padding-top: 10px; width: 80ex'>Introduction: We present a screening method for early dementia using features
based on sound objects as voice biomarkers.
  Methods: The final dataset used for machine learning models consisted of 266
observations, with a distribution of 186 healthy individuals, 46 diagnosed with
Alzheimer's, and 34 with MCI. This method is based on six-second recordings of
the sustained vowel /a/ spoken by the subject. The main original contribution
of this work is the use of carefully crafted features based on sound objects.
This approach allows one to first represent the sound spectrum in a more
accurate way than the standard spectrum, and then build interpretable features
containing relevant information about subjects' control over their voice.
  Results: ROC AUC obtained in this work for distinguishing healthy subjects
from those with MCI was 0.85, while accuracy was 0.76. For distinguishing
between healthy subjects and those with either MCI or Alzheimer's the results
were 0.84, 0.77, respectively.
  Conclusion: The use of features based on sound objects enables screening for
early dementia even on very short recordings of language-independent voice
samples.</div><div><a href='http://arxiv.org/abs/2402.00897v1'>2402.00897v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.00854v1")'>Speaker-Independent Dysarthria Severity Classification using
  Self-Supervised Transformers and Multi-Task Learning</div>
<div id='2403.00854v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T18:30:52Z</div><div>Authors: Lauren Stumpf, Balasundaram Kadirvelu, Sigourney Waibel, A. Aldo Faisal</div><div style='padding-top: 10px; width: 80ex'>Dysarthria, a condition resulting from impaired control of the speech muscles
due to neurological disorders, significantly impacts the communication and
quality of life of patients. The condition's complexity, human scoring and
varied presentations make its assessment and management challenging. This study
presents a transformer-based framework for automatically assessing dysarthria
severity from raw speech data. It can offer an objective, repeatable,
accessible, standardised and cost-effective and compared to traditional methods
requiring human expert assessors. We develop a transformer framework, called
Speaker-Agnostic Latent Regularisation (SALR), incorporating a multi-task
learning objective and contrastive learning for speaker-independent multi-class
dysarthria severity classification. The multi-task framework is designed to
reduce reliance on speaker-specific characteristics and address the intrinsic
intra-class variability of dysarthric speech. We evaluated on the Universal
Access Speech dataset using leave-one-speaker-out cross-validation, our model
demonstrated superior performance over traditional machine learning approaches,
with an accuracy of $70.48\%$ and an F1 score of $59.23\%$. Our SALR model also
exceeded the previous benchmark for AI-based classification, which used support
vector machines, by $16.58\%$. We open the black box of our model by
visualising the latent space where we can observe how the model substantially
reduces speaker-specific cues and amplifies task-specific ones, thereby showing
its robustness. In conclusion, SALR establishes a new benchmark in
speaker-independent multi-class dysarthria severity classification using
generative AI. The potential implications of our findings for broader clinical
applications in automated dysarthria severity assessments.</div><div><a href='http://arxiv.org/abs/2403.00854v1'>2403.00854v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.13812v1")'>Voice-Driven Mortality Prediction in Hospitalized Heart Failure
  Patients: A Machine Learning Approach Enhanced with Diagnostic Biomarkers</div>
<div id='2402.13812v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-21T13:50:46Z</div><div>Authors: Nihat Ahmadli, Mehmet Ali Sarsil, Berk Mizrak, Kurtulus Karauzum, Ata Shaker, Erol Tulumen, Didar Mirzamidinov, Dilek Ural, Onur Ergen</div><div style='padding-top: 10px; width: 80ex'>Addressing heart failure (HF) as a prevalent global health concern poses
difficulties in implementing innovative approaches for enhanced patient care.
Predicting mortality rates in HF patients, in particular, is difficult yet
critical, necessitating individualized care, proactive management, and enabling
educated decision-making to enhance outcomes. Recently, the significance of
voice biomarkers coupled with Machine Learning (ML) has surged, demonstrating
remarkable efficacy, particularly in predicting heart failure. The synergy of
voice analysis and ML algorithms provides a non-invasive and easily accessible
means to evaluate patients' health. However, there is a lack of voice
biomarkers for predicting mortality rates among heart failure patients with
standardized speech protocols. Here, we demonstrate a powerful and effective ML
model for predicting mortality rates in hospitalized HF patients through the
utilization of voice biomarkers. By seamlessly integrating voice biomarkers
into routine patient monitoring, this strategy has the potential to improve
patient outcomes, optimize resource allocation, and advance patient-centered HF
management. In this study, a Machine Learning system, specifically a logistic
regression model, is trained to predict patients' 5-year mortality rates using
their speech as input. The model performs admirably and consistently, as
demonstrated by cross-validation and statistical approaches (p-value &lt; 0.001).
Furthermore, integrating NT-proBNP, a diagnostic biomarker in HF, improves the
model's predictive accuracy substantially.</div><div><a href='http://arxiv.org/abs/2402.13812v1'>2402.13812v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03369v1")'>Evaluation of Google's Voice Recognition and Sentence Classification for
  Health Care Applications</div>
<div id='2402.03369v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T03:13:09Z</div><div>Authors: Majbah Uddin, Nathan Huynh, Jose M Vidal, Kevin M Taaffe, Lawrence D Fredendall, Joel S Greenstein</div><div style='padding-top: 10px; width: 80ex'>This study examined the use of voice recognition technology in perioperative
services (Periop) to enable Periop staff to record workflow milestones using
mobile technology. The use of mobile technology to improve patient flow and
quality of care could be facilitated if such voice recognition technology could
be made robust. The goal of this experiment was to allow the Periop staff to
provide care without being interrupted with data entry and querying tasks.
However, the results are generalizable to other situations where an engineering
manager attempts to improve communication performance using mobile technology.
This study enhanced Google's voice recognition capability by using
post-processing classifiers (i.e., bag-of-sentences, support vector machine,
and maximum entropy). The experiments investigated three factors (original
phrasing, reduced phrasing, and personalized phrasing) at three levels (zero
training repetition, 5 training repetitions, and 10 training repetitions).
Results indicated that personal phrasing yielded the highest correctness and
that training the device to recognize an individual's voice improved
correctness as well. Although simplistic, the bag-of-sentences classifier
significantly improved voice recognition correctness. The classification
efficiency of the maximum entropy and support vector machine algorithms was
found to be nearly identical. These results suggest that engineering managers
could significantly enhance Google's voice recognition technology by using
post-processing techniques, which would facilitate its use in health care and
other applications.</div><div><a href='http://arxiv.org/abs/2402.03369v1'>2402.03369v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.08789v1")'>Leveraging cough sounds to optimize chest x-ray usage in low-resource
  settings</div>
<div id='2402.08789v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T20:54:55Z</div><div>Authors: Alexander Philip, Sanya Chawla, Lola Jover, George P. Kafentzis, Joe Brew, Vishakh Saraf, Shibu Vijayan, Peter Small, Carlos Chaccour</div><div style='padding-top: 10px; width: 80ex'>Chest X-ray is a commonly used tool during triage, diagnosis and management
of respiratory diseases. In resource-constricted settings, optimizing this
resource can lead to valuable cost savings for the health care system and the
patients as well as to and improvement in consult time. We used
prospectively-collected data from 137 patients referred for chest X-ray at the
Christian Medical Center and Hospital (CMCH) in Purnia, Bihar, India. Each
patient provided at least five coughs while awaiting radiography. Collected
cough sounds were analyzed using acoustic AI methods. Cross-validation was done
on temporal and spectral features on the cough sounds of each patient. Features
were summarized using standard statistical approaches. Three models were
developed, tested and compared in their capacity to predict an abnormal result
in the chest X-ray. All three methods yielded models that could discriminate to
some extent between normal and abnormal with the logistic regression performing
best with an area under the receiver operating characteristic curves ranging
from 0.7 to 0.78. Despite limitations and its relatively small sample size,
this study shows that AI-enabled algorithms can use cough sounds to predict
which individuals presenting for chest radiographic examination will have a
normal or abnormal results. These results call for expanding this research
given the potential optimization of limited health care resources in low- and
middle-income countries.</div><div><a href='http://arxiv.org/abs/2402.08789v1'>2402.08789v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.03522v2")'>Non-verbal information in spontaneous speech -- towards a new framework
  of analysis</div>
<div id='2403.03522v2' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T08:03:05Z</div><div>Authors: Tirza Biron, Moshe Barboy, Eran Ben-Artzy, Alona Golubchik, Yanir Marmor, Smadar Szekely, Yaron Winter, David Harel</div><div style='padding-top: 10px; width: 80ex'>Non-verbal signals in speech are encoded by prosody and carry information
that ranges from conversation action to attitude and emotion. Despite its
importance, the principles that govern prosodic structure are not yet
adequately understood. This paper offers an analytical schema and a
technological proof-of-concept for the categorization of prosodic signals and
their association with meaning. The schema interprets surface-representations
of multi-layered prosodic events. As a first step towards implementation, we
present a classification process that disentangles prosodic phenomena of three
orders. It relies on fine-tuning a pre-trained speech recognition model,
enabling the simultaneous multi-class/multi-label detection. It generalizes
over a large variety of spontaneous data, performing on a par with, or superior
to, human annotation. In addition to a standardized formalization of prosody,
disentangling prosodic patterns can direct a theory of communication and speech
organization. A welcome by-product is an interpretation of prosody that will
enhance speech- and language-related technologies.</div><div><a href='http://arxiv.org/abs/2403.03522v2'>2403.03522v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.07342v2")'>Who Said What? An Automated Approach to Analyzing Speech in Preschool
  Classrooms</div>
<div id='2401.07342v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-14T18:27:37Z</div><div>Authors: Anchen Sun, Juan J Londono, Batya Elbaum, Luis Estrada, Roberto Jose Lazo, Laura Vitale, Hugo Gonzalez Villasanti, Riccardo Fusaroli, Lynn K Perry, Daniel S Messinger</div><div style='padding-top: 10px; width: 80ex'>Young children spend substantial portions of their waking hours in noisy
preschool classrooms. In these environments, children's vocal interactions with
teachers are critical contributors to their language outcomes, but manually
transcribing these interactions is prohibitive. Using audio from child- and
teacher-worn recorders, we propose an automated framework that uses open source
software both to classify speakers (ALICE) and to transcribe their utterances
(Whisper). We compare results from our framework to those from a human expert
for 110 minutes of classroom recordings, including 85 minutes from child-word
microphones (n=4 children) and 25 minutes from teacher-worn microphones (n=2
teachers). The overall proportion of agreement, that is, the proportion of
correctly classified teacher and child utterances, was .76, with an
error-corrected kappa of .50 and a weighted F1 of .76. The word error rate for
both teacher and child transcriptions was .15, meaning that 15% of words would
need to be deleted, added, or changed to equate the Whisper and expert
transcriptions. Moreover, speech features such as the mean length of utterances
in words, the proportion of teacher and child utterances that were questions,
and the proportion of utterances that were responded to within 2.5 seconds were
similar when calculated separately from expert and automated transcriptions.
The results suggest substantial progress in analyzing classroom speech that may
support children's language development. Future research using natural language
processing is underway to improve speaker classification and to analyze results
from the application of the automated it framework to a larger dataset
containing classroom recordings from 13 children and 4 teachers observed on 17
occasions over one year.</div><div><a href='http://arxiv.org/abs/2401.07342v2'>2401.07342v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03269v1")'>ISPA: Inter-Species Phonetic Alphabet for Transcribing Animal Sounds</div>
<div id='2402.03269v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T18:27:27Z</div><div>Authors: Masato Hagiwara, Marius Miron, Jen-Yu Liu</div><div style='padding-top: 10px; width: 80ex'>Traditionally, bioacoustics has relied on spectrograms and continuous,
per-frame audio representations for the analysis of animal sounds, also serving
as input to machine learning models. Meanwhile, the International Phonetic
Alphabet (IPA) system has provided an interpretable, language-independent
method for transcribing human speech sounds. In this paper, we introduce ISPA
(Inter-Species Phonetic Alphabet), a precise, concise, and interpretable system
designed for transcribing animal sounds into text. We compare acoustics-based
and feature-based methods for transcribing and classifying animal sounds,
demonstrating their comparable performance with baseline methods utilizing
continuous, dense audio representations. By representing animal sounds with
text, we effectively treat them as a "foreign language," and we show that
established human language ML paradigms and models, such as language models,
can be successfully applied to improve performance.</div><div><a href='http://arxiv.org/abs/2402.03269v1'>2402.03269v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15985v1")'>Phonetic and Lexical Discovery of a Canine Language using HuBERT</div>
<div id='2402.15985v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-25T04:35:45Z</div><div>Authors: Xingyuan Li, Sinong Wang, Zeyu Xie, Mengyue Wu, Kenny Q. Zhu</div><div style='padding-top: 10px; width: 80ex'>This paper delves into the pioneering exploration of potential communication
patterns within dog vocalizations and transcends traditional linguistic
analysis barriers, which heavily relies on human priori knowledge on limited
datasets to find sound units in dog vocalization. We present a self-supervised
approach with HuBERT, enabling the accurate classification of phoneme labels
and the identification of vocal patterns that suggest a rudimentary vocabulary
within dog vocalizations. Our findings indicate a significant acoustic
consistency in these identified canine vocabulary, covering the entirety of
observed dog vocalization sequences. We further develop a web-based dog
vocalization labeling system. This system can highlight phoneme n-grams,
present in the vocabulary, in the dog audio uploaded by users.</div><div><a href='http://arxiv.org/abs/2402.15985v1'>2402.15985v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.16026v1")'>Feature Selection Based on Orthogonal Constraints and Polygon Area</div>
<div id='2402.16026v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-25T08:20:05Z</div><div>Authors: Zhenxing Zhang, Jun Ge, Zheng Wei, Chunjie Zhou, Yilei Wang</div><div style='padding-top: 10px; width: 80ex'>The goal of feature selection is to choose the optimal subset of features for
a recognition task by evaluating the importance of each feature, thereby
achieving effective dimensionality reduction. Currently, proposed feature
selection methods often overlook the discriminative dependencies between
features and labels. To address this problem, this paper introduces a novel
orthogonal regression model incorporating the area of a polygon. The model can
intuitively capture the discriminative dependencies between features and
labels. Additionally, this paper employs a hybrid non-monotone linear search
method to efficiently tackle the non-convex optimization challenge posed by
orthogonal constraints. Experimental results demonstrate that our approach not
only effectively captures discriminative dependency information but also
surpasses traditional methods in reducing feature dimensions and enhancing
classification performance.</div><div><a href='http://arxiv.org/abs/2402.16026v1'>2402.16026v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09281v1")'>Synergistic eigenanalysis of covariance and Hessian matrices for
  enhanced binary classification</div>
<div id='2402.09281v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T16:10:42Z</div><div>Authors: Agus Hartoyo, Jan Argasiński, Aleksandra Trenk, Kinga Przybylska, Anna Błasiak, Alessandro Crimi</div><div style='padding-top: 10px; width: 80ex'>Covariance and Hessian matrices have been analyzed separately in the
literature for classification problems. However, integrating these matrices has
the potential to enhance their combined power in improving classification
performance. We present a novel approach that combines the eigenanalysis of a
covariance matrix evaluated on a training set with a Hessian matrix evaluated
on a deep learning model to achieve optimal class separability in binary
classification tasks. Our approach is substantiated by formal proofs that
establish its capability to maximize between-class mean distance and minimize
within-class variances. By projecting data into the combined space of the most
relevant eigendirections from both matrices, we achieve optimal class
separability as per the linear discriminant analysis (LDA) criteria. Empirical
validation across neural and health datasets consistently supports our
theoretical framework and demonstrates that our method outperforms established
methods. Our method stands out by addressing both LDA criteria, unlike PCA and
the Hessian method, which predominantly emphasize one criterion each. This
comprehensive approach captures intricate patterns and relationships, enhancing
classification performance. Furthermore, through the utilization of both LDA
criteria, our method outperforms LDA itself by leveraging higher-dimensional
feature spaces, in accordance with Cover's theorem, which favors linear
separability in higher dimensions. Our method also surpasses kernel-based
methods and manifold learning techniques in performance. Additionally, our
approach sheds light on complex DNN decision-making, rendering them
comprehensible within a 2D space.</div><div><a href='http://arxiv.org/abs/2402.09281v1'>2402.09281v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.06048v1")'>Texture image retrieval using a classification and contourlet-based
  features</div>
<div id='2403.06048v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-10T00:07:47Z</div><div>Authors: Asal Rouhafzay, Nadia Baaziz, Mohand Said Allili</div><div style='padding-top: 10px; width: 80ex'>In this paper, we propose a new framework for improving Content Based Image
Retrieval (CBIR) for texture images. This is achieved by using a new image
representation based on the RCT-Plus transform which is a novel variant of the
Redundant Contourlet transform that extracts a richer directional information
in the image. Moreover, the process of image search is improved through a
learning-based approach where the images of the database are classified using
an adapted similarity metric to the statistical modeling of the RCT-Plus
transform. A query is then first classified to select the best texture class
after which the retained class images are ranked to select top ones. By this,
we have achieved significant improvements in the retrieval rates compared to
previous CBIR schemes.</div><div><a href='http://arxiv.org/abs/2403.06048v1'>2403.06048v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.03448v1")'>Kernel Correlation-Dissimilarity for Multiple Kernel k-Means Clustering</div>
<div id='2403.03448v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T04:24:43Z</div><div>Authors: Rina Su, Yu Guo, Caiying Wu, Qiyu Jin, Tieyong Zeng</div><div style='padding-top: 10px; width: 80ex'>The main objective of the Multiple Kernel k-Means (MKKM) algorithm is to
extract non-linear information and achieve optimal clustering by optimizing
base kernel matrices. Current methods enhance information diversity and reduce
redundancy by exploiting interdependencies among multiple kernels based on
correlations or dissimilarities. Nevertheless, relying solely on a single
metric, such as correlation or dissimilarity, to define kernel relationships
introduces bias and incomplete characterization. Consequently, this limitation
hinders efficient information extraction, ultimately compromising clustering
performance. To tackle this challenge, we introduce a novel method that
systematically integrates both kernel correlation and dissimilarity. Our
approach comprehensively captures kernel relationships, facilitating more
efficient classification information extraction and improving clustering
performance. By emphasizing the coherence between kernel correlation and
dissimilarity, our method offers a more objective and transparent strategy for
extracting non-linear information and significantly improving clustering
precision, supported by theoretical rationale. We assess the performance of our
algorithm on 13 challenging benchmark datasets, demonstrating its superiority
over contemporary state-of-the-art MKKM techniques.</div><div><a href='http://arxiv.org/abs/2403.03448v1'>2403.03448v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09529v1")'>The Manifold Density Function: An Intrinsic Method for the Validation of
  Manifold Learning</div>
<div id='2402.09529v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T19:09:23Z</div><div>Authors: Benjamin Holmgren, Eli Quist, Jordan Schupbach, Brittany Terese Fasy, Bastian Rieck</div><div style='padding-top: 10px; width: 80ex'>We introduce the manifold density function, which is an intrinsic method to
validate manifold learning techniques. Our approach adapts and extends Ripley's
$K$-function, and categorizes in an unsupervised setting the extent to which an
output of a manifold learning algorithm captures the structure of a latent
manifold. Our manifold density function generalizes to broad classes of
Riemannian manifolds. In particular, we extend the manifold density function to
general two-manifolds using the Gauss-Bonnet theorem, and demonstrate that the
manifold density function for hypersurfaces is well approximated using the
first Laplacian eigenvalue. We prove desirable convergence and robustness
properties.</div><div><a href='http://arxiv.org/abs/2402.09529v1'>2402.09529v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01514v1")'>Mapping the Multiverse of Latent Representations</div>
<div id='2402.01514v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T15:54:53Z</div><div>Authors: Jeremy Wayland, Corinna Coupette, Bastian Rieck</div><div style='padding-top: 10px; width: 80ex'>Echoing recent calls to counter reliability and robustness concerns in
machine learning via multiverse analysis, we present PRESTO, a principled
framework for mapping the multiverse of machine-learning models that rely on
latent representations. Although such models enjoy widespread adoption, the
variability in their embeddings remains poorly understood, resulting in
unnecessary complexity and untrustworthy representations. Our framework uses
persistent homology to characterize the latent spaces arising from different
combinations of diverse machine-learning methods, (hyper)parameter
configurations, and datasets, allowing us to measure their pairwise
(dis)similarity and statistically reason about their distributions. As we
demonstrate both theoretically and empirically, our pipeline preserves
desirable properties of collections of latent representations, and it can be
leveraged to perform sensitivity analysis, detect anomalous embeddings, or
efficiently and effectively navigate hyperparameter search spaces.</div><div><a href='http://arxiv.org/abs/2402.01514v1'>2402.01514v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.11404v2")'>Evaluating the Stability of Deep Learning Latent Feature Spaces</div>
<div id='2402.11404v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-17T23:41:15Z</div><div>Authors: Ademide O. Mabadeje, Michael J. Pyrcz</div><div style='padding-top: 10px; width: 80ex'>High-dimensional datasets present substantial challenges in statistical
modeling across various disciplines, necessitating effective dimensionality
reduction methods. Deep learning approaches, notable for their capacity to
distill essential features from complex data, facilitate modeling,
visualization, and compression through reduced dimensionality latent feature
spaces, have wide applications from bioinformatics to earth sciences. This
study introduces a novel workflow to evaluate the stability of these latent
spaces, ensuring consistency and reliability in subsequent analyses. Stability,
defined as the invariance of latent spaces to minor data, training
realizations, and parameter perturbations, is crucial yet often overlooked.
  Our proposed methodology delineates three stability types, sample,
structural, and inferential, within latent spaces, and introduces a suite of
metrics for comprehensive evaluation. We implement this workflow across 500
autoencoder realizations and three datasets, encompassing both synthetic and
real-world scenarios to explain latent space dynamics. Employing k-means
clustering and the modified Jonker-Volgenant algorithm for class alignment,
alongside anisotropy metrics and convex hull analysis, we introduce adjusted
stress and Jaccard dissimilarity as novel stability indicators.
  Our findings highlight inherent instabilities in latent feature spaces and
demonstrate the workflow's efficacy in quantifying and interpreting these
instabilities. This work advances the understanding of latent feature spaces,
promoting improved model interpretability and quality control for more informed
decision-making for diverse analytical workflows that leverage deep learning.</div><div><a href='http://arxiv.org/abs/2402.11404v2'>2402.11404v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15903v1")'>Toward the Identifiability of Comparative Deep Generative Models</div>
<div id='2401.15903v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T06:10:54Z</div><div>Authors: Romain Lopez, Jan-Christian Huetter, Ehsan Hajiramezanali, Jonathan Pritchard, Aviv Regev</div><div style='padding-top: 10px; width: 80ex'>Deep Generative Models (DGMs) are versatile tools for learning data
representations while adequately incorporating domain knowledge such as the
specification of conditional probability distributions. Recently proposed DGMs
tackle the important task of comparing data sets from different sources. One
such example is the setting of contrastive analysis that focuses on describing
patterns that are enriched in a target data set compared to a background data
set. The practical deployment of those models often assumes that DGMs naturally
infer interpretable and modular latent representations, which is known to be an
issue in practice. Consequently, existing methods often rely on ad-hoc
regularization schemes, although without any theoretical grounding. Here, we
propose a theory of identifiability for comparative DGMs by extending recent
advances in the field of non-linear independent component analysis. We show
that, while these models lack identifiability across a general class of mixing
functions, they surprisingly become identifiable when the mixing function is
piece-wise affine (e.g., parameterized by a ReLU neural network). We also
investigate the impact of model misspecification, and empirically show that
previously proposed regularization techniques for fitting comparative DGMs help
with identifiability when the number of latent variables is not known in
advance. Finally, we introduce a novel methodology for fitting comparative DGMs
that improves the treatment of multiple data sources via multi-objective
optimization and that helps adjust the hyperparameter for the regularization in
an interpretable manner, using constrained optimization. We empirically
validate our theory and new methodology using simulated data as well as a
recent data set of genetic perturbations in cells profiled via single-cell RNA
sequencing.</div><div><a href='http://arxiv.org/abs/2401.15903v1'>2401.15903v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.01078v1")'>$Γ$-VAE: Curvature regularized variational autoencoders for
  uncovering emergent low dimensional geometric structure in high dimensional
  data</div>
<div id='2403.01078v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-02T03:26:09Z</div><div>Authors: Jason Z. Kim, Nicolas Perrin-Gilbert, Erkan Narmanli, Paul Klein, Christopher R. Myers, Itai Cohen, Joshua J. Waterfall, James P. Sethna</div><div style='padding-top: 10px; width: 80ex'>Natural systems with emergent behaviors often organize along low-dimensional
subsets of high-dimensional spaces. For example, despite the tens of thousands
of genes in the human genome, the principled study of genomics is fruitful
because biological processes rely on coordinated organization that results in
lower dimensional phenotypes. To uncover this organization, many nonlinear
dimensionality reduction techniques have successfully embedded high-dimensional
data into low-dimensional spaces by preserving local similarities between data
points. However, the nonlinearities in these methods allow for too much
curvature to preserve general trends across multiple non-neighboring data
clusters, thereby limiting their interpretability and generalizability to
out-of-distribution data. Here, we address both of these limitations by
regularizing the curvature of manifolds generated by variational autoencoders,
a process we coin ``$\Gamma$-VAE''. We demonstrate its utility using two
example data sets: bulk RNA-seq from the The Cancer Genome Atlas (TCGA) and the
Genotype Tissue Expression (GTEx); and single cell RNA-seq from a lineage
tracing experiment in hematopoietic stem cell differentiation. We find that the
resulting regularized manifolds identify mesoscale structure associated with
different cancer cell types, and accurately re-embed tissues from completely
unseen, out-of distribution cancers as if they were originally trained on them.
Finally, we show that preserving long-range relationships to differentiated
cells separates undifferentiated cells -- which have not yet specialized --
according to their eventual fate. Broadly, we anticipate that regularizing the
curvature of generative models will enable more consistent, predictive, and
generalizable models in any high-dimensional system with emergent
low-dimensional behavior.</div><div><a href='http://arxiv.org/abs/2403.01078v1'>2403.01078v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.07486v1")'>XpertAI: uncovering model strategies for sub-manifolds</div>
<div id='2403.07486v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T10:21:31Z</div><div>Authors: Simon Letzgus, Klaus-Robert Müller, Grégoire Montavon</div><div style='padding-top: 10px; width: 80ex'>In recent years, Explainable AI (XAI) methods have facilitated profound
validation and knowledge extraction from ML models. While extensively studied
for classification, few XAI solutions have addressed the challenges specific to
regression models. In regression, explanations need to be precisely formulated
to address specific user queries (e.g.\ distinguishing between `Why is the
output above 0?' and `Why is the output above 50?'). They should furthermore
reflect the model's behavior on the relevant data sub-manifold. In this paper,
we introduce XpertAI, a framework that disentangles the prediction strategy
into multiple range-specific sub-strategies and allows the formulation of
precise queries about the model (the `explanandum') as a linear combination of
those sub-strategies. XpertAI is formulated generally to work alongside popular
XAI attribution techniques, based on occlusion, gradient integration, or
reverse propagation. Qualitative and quantitative results, demonstrate the
benefits of our approach.</div><div><a href='http://arxiv.org/abs/2403.07486v1'>2403.07486v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14139v1")'>Genetic Programming for Explainable Manifold Learning</div>
<div id='2403.14139v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T05:17:22Z</div><div>Authors: Ben Cravens, Andrew Lensen, Paula Maddigan, Bing Xue</div><div style='padding-top: 10px; width: 80ex'>Manifold learning techniques play a pivotal role in machine learning by
revealing lower-dimensional embeddings within high-dimensional data, thus
enhancing both the efficiency and interpretability of data analysis by
transforming the data into a lower-dimensional representation. However, a
notable challenge with current manifold learning methods is their lack of
explicit functional mappings, crucial for explainability in many real-world
applications. Genetic programming, known for its interpretable functional
tree-based models, has emerged as a promising approach to address this
challenge. Previous research leveraged multi-objective GP to balance manifold
quality against embedding dimensionality, producing functional mappings across
a range of embedding sizes. Yet, these mapping trees often became complex,
hindering explainability. In response, in this paper, we introduce Genetic
Programming for Explainable Manifold Learning (GP-EMaL), a novel approach that
directly penalises tree complexity. Our new method is able to maintain high
manifold quality while significantly enhancing explainability and also allows
customisation of complexity measures, such as symmetry balancing, scaling, and
node complexity, catering to diverse application needs. Our experimental
analysis demonstrates that GP-EMaL is able to match the performance of the
existing approach in most cases, while using simpler, smaller, and more
interpretable tree structures. This advancement marks a significant step
towards achieving interpretable manifold learning.</div><div><a href='http://arxiv.org/abs/2403.14139v1'>2403.14139v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03191v1")'>Isotropy, Clusters, and Classifiers</div>
<div id='2402.03191v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T16:57:24Z</div><div>Authors: Timothee Mickus, Stig-Arne Grönroos, Joseph Attieh</div><div style='padding-top: 10px; width: 80ex'>Whether embedding spaces use all their dimensions equally, i.e., whether they
are isotropic, has been a recent subject of discussion. Evidence has been
accrued both for and against enforcing isotropy in embedding spaces. In the
present paper, we stress that isotropy imposes requirements on the embedding
space that are not compatible with the presence of clusters -- which also
negatively impacts linear classification objectives. We demonstrate this fact
empirically and use it to shed light on previous results from the literature.</div><div><a href='http://arxiv.org/abs/2402.03191v1'>2402.03191v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.15038v1")'>Estimation of multiple mean vectors in high dimension</div>
<div id='2403.15038v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-22T08:42:41Z</div><div>Authors: Gilles Blanchard, Jean-Baptiste Fermanian, Hannah Marienwald</div><div style='padding-top: 10px; width: 80ex'>We endeavour to estimate numerous multi-dimensional means of various
probability distributions on a common space based on independent samples. Our
approach involves forming estimators through convex combinations of empirical
means derived from these samples. We introduce two strategies to find
appropriate data-dependent convex combination weights: a first one employing a
testing procedure to identify neighbouring means with low variance, which
results in a closed-form plug-in formula for the weights, and a second one
determining weights via minimization of an upper confidence bound on the
quadratic risk.Through theoretical analysis, we evaluate the improvement in
quadratic risk offered by our methods compared to the empirical means. Our
analysis focuses on a dimensional asymptotics perspective, showing that our
methods asymptotically approach an oracle (minimax) improvement as the
effective dimension of the data increases.We demonstrate the efficacy of our
methods in estimating multiple kernel mean embeddings through experiments on
both simulated and real-world datasets.</div><div><a href='http://arxiv.org/abs/2403.15038v1'>2403.15038v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.05226v1")'>Learning effective good variables from physical data</div>
<div id='2401.05226v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-10T15:52:35Z</div><div>Authors: Giulio Barletta, Giovanni Trezza, Eliodoro Chiavazzo</div><div style='padding-top: 10px; width: 80ex'>We assume that a sufficiently large database is available, where a physical
property of interest and a number of associated ruling primitive variables or
observables are stored. We introduce and test two machine learning approaches
to discover possible groups or combinations of primitive variables: The first
approach is based on regression models whereas the second on classification
models. The variable group (here referred to as the new effective good
variable) can be considered as successfully found, when the physical property
of interest is characterized by the following effective invariant behaviour: In
the first method, invariance of the group implies invariance of the property up
to a given accuracy; in the other method, upon partition of the physical
property values into two or more classes, invariance of the group implies
invariance of the class. For the sake of illustration, the two methods are
successfully applied to two popular empirical correlations describing the
convective heat transfer phenomenon and to the Newton's law of universal
gravitation.</div><div><a href='http://arxiv.org/abs/2401.05226v1'>2401.05226v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.12636v1")'>A Practical Guide to Statistical Distances for Evaluating Generative
  Models in Science</div>
<div id='2403.12636v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-19T11:16:14Z</div><div>Authors: Sebastian Bischoff, Alana Darcher, Michael Deistler, Richard Gao, Franziska Gerken, Manuel Gloeckler, Lisa Haxel, Jaivardhan Kapoor, Janne K Lappalainen, Jakob H Macke, Guy Moss, Matthijs Pals, Felix Pei, Rachel Rapp, A Erdem Sağtekin, Cornelius Schröder, Auguste Schulz, Zinovia Stefanidi, Shoji Toyota, Linda Ulmer, Julius Vetter</div><div style='padding-top: 10px; width: 80ex'>Generative models are invaluable in many fields of science because of their
ability to capture high-dimensional and complicated distributions, such as
photo-realistic images, protein structures, and connectomes. How do we evaluate
the samples these models generate? This work aims to provide an accessible
entry point to understanding popular notions of statistical distances,
requiring only foundational knowledge in mathematics and statistics. We focus
on four commonly used notions of statistical distances representing different
methodologies: Using low-dimensional projections (Sliced-Wasserstein; SW),
obtaining a distance using classifiers (Classifier Two-Sample Tests; C2ST),
using embeddings through kernels (Maximum Mean Discrepancy; MMD), or neural
networks (Fr\'echet Inception Distance; FID). We highlight the intuition behind
each distance and explain their merits, scalability, complexity, and pitfalls.
To demonstrate how these distances are used in practice, we evaluate generative
models from different scientific domains, namely a model of decision making and
a model generating medical images. We showcase that distinct distances can give
different results on similar data. Through this guide, we aim to help
researchers to use, interpret, and evaluate statistical distances for
generative models in science.</div><div><a href='http://arxiv.org/abs/2403.12636v1'>2403.12636v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14621v1")'>latrend: A Framework for Clustering Longitudinal Data</div>
<div id='2402.14621v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T15:09:13Z</div><div>Authors: Niek Den Teuling, Steffen Pauws, Edwin van den Heuvel</div><div style='padding-top: 10px; width: 80ex'>Clustering of longitudinal data is used to explore common trends among
subjects over time for a numeric measurement of interest. Various R packages
have been introduced throughout the years for identifying clusters of
longitudinal patterns, summarizing the variability in trajectories between
subject in terms of one or more trends. We introduce the R package "latrend" as
a framework for the unified application of methods for longitudinal clustering,
enabling comparisons between methods with minimal coding. The package also
serves as an interface to commonly used packages for clustering longitudinal
data, including "dtwclust", "flexmix", "kml", "lcmm", "mclust", "mixAK", and
"mixtools". This enables researchers to easily compare different approaches,
implementations, and method specifications. Furthermore, researchers can build
upon the standard tools provided by the framework to quickly implement new
cluster methods, enabling rapid prototyping. We demonstrate the functionality
and application of the latrend package on a synthetic dataset based on the
therapy adherence patterns of patients with sleep apnea.</div><div><a href='http://arxiv.org/abs/2402.14621v1'>2402.14621v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03414v1")'>Leveraging The Finite States of Emotion Processing to Study Late-Life
  Mental Health</div>
<div id='2403.03414v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T02:46:17Z</div><div>Authors: Yuanzhe Huang, Saurab Faruque, Minjie Wu, Akiko Mizuno, Eduardo Diniz, Shaolin Yang, George Dewitt Stetten, Noah Schweitzer, Hecheng Jin, Linghai Wang, Howard J. Aizenstein</div><div style='padding-top: 10px; width: 80ex'>Traditional approaches in mental health research apply General Linear Models
(GLM) to describe the longitudinal dynamics of observed psycho-behavioral
measurements (questionnaire summary scores). Similarly, GLMs are also applied
to characterize relationships between neurobiological measurements (regional
fMRI signals) and perceptual stimuli or other regional signals. While these
methods are useful for exploring linear correlations among the isolated signals
of those constructs (i.e., summary scores or fMRI signals), these classical
frameworks fall short in providing insights into the comprehensive system-level
dynamics underlying observable changes. Hidden Markov Models (HMM) are a
statistical model that enable us to describe the sequential relations among
multiple observable constructs, and when applied through the lens of Finite
State Automata (FSA), can provide a more integrated and intuitive framework for
modeling and understanding the underlying controller (the prescription for how
to respond to inputs) that fundamentally defines any system, as opposed to
linearly correlating output signals produced by the controller. We present a
simple and intuitive HMM processing pipeline vcHMM (See Preliminary Data) that
highlights FSA theory and is applicable for both behavioral analysis of
questionnaire data and fMRI data. HMMs offer theoretic promise as they are
computationally equivalent to the FSA, the control processor of a Turing
Machine (TM) The dynamic programming Viterbi algorithm is used to leverage the
HMM model. It efficiently identifies the most likely sequence of hidden states.
The vcHMM pipeline leverages this grammar to understand how behavior and neural
activity relate to depression.</div><div><a href='http://arxiv.org/abs/2403.03414v1'>2403.03414v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.09465v1")'>Outlier Robust Multivariate Polynomial Regression</div>
<div id='2403.09465v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T15:04:45Z</div><div>Authors: Vipul Arora, Arnab Bhattacharyya, Mathews Boban, Venkatesan Guruswami, Esty Kelman</div><div style='padding-top: 10px; width: 80ex'>We study the problem of robust multivariate polynomial regression: let
$p\colon\mathbb{R}^n\to\mathbb{R}$ be an unknown $n$-variate polynomial of
degree at most $d$ in each variable. We are given as input a set of random
samples $(\mathbf{x}_i,y_i) \in [-1,1]^n \times \mathbb{R}$ that are noisy
versions of $(\mathbf{x}_i,p(\mathbf{x}_i))$. More precisely, each
$\mathbf{x}_i$ is sampled independently from some distribution $\chi$ on
$[-1,1]^n$, and for each $i$ independently, $y_i$ is arbitrary (i.e., an
outlier) with probability at most $\rho &lt; 1/2$, and otherwise satisfies
$|y_i-p(\mathbf{x}_i)|\leq\sigma$. The goal is to output a polynomial
$\hat{p}$, of degree at most $d$ in each variable, within an
$\ell_\infty$-distance of at most $O(\sigma)$ from $p$.
  Kane, Karmalkar, and Price [FOCS'17] solved this problem for $n=1$. We
generalize their results to the $n$-variate setting, showing an algorithm that
achieves a sample complexity of $O_n(d^n\log d)$, where the hidden constant
depends on $n$, if $\chi$ is the $n$-dimensional Chebyshev distribution. The
sample complexity is $O_n(d^{2n}\log d)$, if the samples are drawn from the
uniform distribution instead. The approximation error is guaranteed to be at
most $O(\sigma)$, and the run-time depends on $\log(1/\sigma)$. In the setting
where each $\mathbf{x}_i$ and $y_i$ are known up to $N$ bits of precision, the
run-time's dependence on $N$ is linear. We also show that our sample
complexities are optimal in terms of $d^n$. Furthermore, we show that it is
possible to have the run-time be independent of $1/\sigma$, at the cost of a
higher sample complexity.</div><div><a href='http://arxiv.org/abs/2403.09465v1'>2403.09465v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13429v2")'>Detection of Correlated Random Vectors</div>
<div id='2401.13429v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T12:58:08Z</div><div>Authors: Dor Elimelech, Wasim Huleihel</div><div style='padding-top: 10px; width: 80ex'>In this paper, we investigate the problem of deciding whether two standard
normal random vectors $\mathsf{X}\in\mathbb{R}^{n}$ and
$\mathsf{Y}\in\mathbb{R}^{n}$ are correlated or not. This is formulated as a
hypothesis testing problem, where under the null hypothesis, these vectors are
statistically independent, while under the alternative, $\mathsf{X}$ and a
randomly and uniformly permuted version of $\mathsf{Y}$, are correlated with
correlation $\rho$. We analyze the thresholds at which optimal testing is
information-theoretically impossible and possible, as a function of $n$ and
$\rho$. To derive our information-theoretic lower bounds, we develop a novel
technique for evaluating the second moment of the likelihood ratio using an
orthogonal polynomials expansion, which among other things, reveals a
surprising connection to integer partition functions. We also study a
multi-dimensional generalization of the above setting, where rather than two
vectors we observe two databases/matrices, and furthermore allow for partial
correlations between these two.</div><div><a href='http://arxiv.org/abs/2401.13429v2'>2401.13429v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15791v1")'>Improving Kernel-Based Nonasymptotic Simultaneous Confidence Bands</div>
<div id='2401.15791v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-28T22:43:33Z</div><div>Authors: Balázs Csanád Csáji, Bálint Horváth</div><div style='padding-top: 10px; width: 80ex'>The paper studies the problem of constructing nonparametric simultaneous
confidence bands with nonasymptotic and distribition-free guarantees. The
target function is assumed to be band-limited and the approach is based on the
theory of Paley-Wiener reproducing kernel Hilbert spaces. The starting point of
the paper is a recently developed algorithm to which we propose three types of
improvements. First, we relax the assumptions on the noises by replacing the
symmetricity assumption with a weaker distributional invariance principle.
Then, we propose a more efficient way to estimate the norm of the target
function, and finally we enhance the construction of the confidence bands by
tightening the constraints of the underlying convex optimization problems. The
refinements are also illustrated through numerical experiments.</div><div><a href='http://arxiv.org/abs/2401.15791v1'>2401.15791v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.07735v1")'>The Minimax Rate of HSIC Estimation for Translation-Invariant Kernels</div>
<div id='2403.07735v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T15:13:21Z</div><div>Authors: Florian Kalinke, Zoltan Szabo</div><div style='padding-top: 10px; width: 80ex'>Kernel techniques are among the most influential approaches in data science
and statistics. Under mild conditions, the reproducing kernel Hilbert space
associated to a kernel is capable of encoding the independence of $M\ge 2$
random variables. Probably the most widespread independence measure relying on
kernels is the so-called Hilbert-Schmidt independence criterion (HSIC; also
referred to as distance covariance in the statistics literature). Despite
various existing HSIC estimators designed since its introduction close to two
decades ago, the fundamental question of the rate at which HSIC can be
estimated is still open. In this work, we prove that the minimax optimal rate
of HSIC estimation on $\mathbb R^d$ for Borel measures containing the Gaussians
with continuous bounded translation-invariant characteristic kernels is
$\mathcal O\!\left(n^{-1/2}\right)$. Specifically, our result implies the
optimality in the minimax sense of many of the most-frequently used estimators
(including the U-statistic, the V-statistic, and the Nystr\"om-based one) on
$\mathbb R^d$.</div><div><a href='http://arxiv.org/abs/2403.07735v1'>2403.07735v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01493v1")'>Sliced-Wasserstein Estimation with Spherical Harmonics as Control
  Variates</div>
<div id='2402.01493v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T15:22:06Z</div><div>Authors: Rémi Leluc, Aymeric Dieuleveut, François Portier, Johan Segers, Aigerim Zhuman</div><div style='padding-top: 10px; width: 80ex'>The Sliced-Wasserstein (SW) distance between probability measures is defined
as the average of the Wasserstein distances resulting for the associated
one-dimensional projections. As a consequence, the SW distance can be written
as an integral with respect to the uniform measure on the sphere and the Monte
Carlo framework can be employed for calculating the SW distance. Spherical
harmonics are polynomials on the sphere that form an orthonormal basis of the
set of square-integrable functions on the sphere. Putting these two facts
together, a new Monte Carlo method, hereby referred to as Spherical Harmonics
Control Variates (SHCV), is proposed for approximating the SW distance using
spherical harmonics as control variates. The resulting approach is shown to
have good theoretical properties, e.g., a no-error property for Gaussian
measures under a certain form of linear dependency between the variables.
Moreover, an improved rate of convergence, compared to Monte Carlo, is
established for general measures. The convergence analysis relies on the
Lipschitz property associated to the SW integrand. Several numerical
experiments demonstrate the superior performance of SHCV against
state-of-the-art methods for SW distance computation.</div><div><a href='http://arxiv.org/abs/2402.01493v1'>2402.01493v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15294v2")'>Integral Operator Approaches for Scattered Data Fitting on Spheres</div>
<div id='2401.15294v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-27T04:42:50Z</div><div>Authors: Shao-Bo Lin</div><div style='padding-top: 10px; width: 80ex'>This paper focuses on scattered data fitting problems on spheres. We study
the approximation performance of a class of weighted spectral filter
algorithms, including Tikhonov regularization, Landaweber iteration, spectral
cut-off, and iterated Tikhonov, in fitting noisy data with possibly unbounded
random noise. For the analysis, we develop an integral operator approach that
can be regarded as an extension of the widely used sampling inequality approach
and norming set method in the community of scattered data fitting. After
providing an equivalence between the operator differences and quadrature rules,
we succeed in deriving optimal Sobolev-type error estimates of weighted
spectral filter algorithms. Our derived error estimates do not suffer from the
saturation phenomenon for Tikhonov regularization in the literature,
native-space-barrier for existing error analysis and adapts to different
embedding spaces. We also propose a divide-and-conquer scheme to equip weighted
spectral filter algorithms to reduce their computational burden and present the
optimal approximation error bounds.</div><div><a href='http://arxiv.org/abs/2401.15294v2'>2401.15294v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.08364v1")'>Weighted Spectral Filters for Kernel Interpolation on Spheres: Estimates
  of Prediction Accuracy for Noisy Data</div>
<div id='2401.08364v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-16T13:46:10Z</div><div>Authors: Xiaotong Liu, Jinxin Wang, Di Wang, Shao-Bo Lin</div><div style='padding-top: 10px; width: 80ex'>Spherical radial-basis-based kernel interpolation abounds in image sciences
including geophysical image reconstruction, climate trends description and
image rendering due to its excellent spatial localization property and perfect
approximation performance. However, in dealing with noisy data, kernel
interpolation frequently behaves not so well due to the large condition number
of the kernel matrix and instability of the interpolation process. In this
paper, we introduce a weighted spectral filter approach to reduce the condition
number of the kernel matrix and then stabilize kernel interpolation. The main
building blocks of the proposed method are the well developed spherical
positive quadrature rules and high-pass spectral filters. Using a recently
developed integral operator approach for spherical data analysis, we
theoretically demonstrate that the proposed weighted spectral filter approach
succeeds in breaking through the bottleneck of kernel interpolation, especially
in fitting noisy data. We provide optimal approximation rates of the new method
to show that our approach does not compromise the predicting accuracy.
Furthermore, we conduct both toy simulations and two real-world data
experiments with synthetically added noise in geophysical image reconstruction
and climate image processing to verify our theoretical assertions and show the
feasibility of the weighted spectral filter approach.</div><div><a href='http://arxiv.org/abs/2401.08364v1'>2401.08364v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.10089v2")'>Approximation and bounding techniques for the Fisher-Rao distances</div>
<div id='2403.10089v2' style='display: none; margin-left: 20px'><div>Date: 2024-03-15T08:05:16Z</div><div>Authors: Frank Nielsen</div><div style='padding-top: 10px; width: 80ex'>The Fisher-Rao distance between two probability distributions of a
statistical model is defined as the Riemannian geodesic distance induced by the
Fisher information metric. In order to calculate the Fisher-Rao distance in
closed-form, we need (1) to elicit a formula for the Fisher-Rao geodesics, and
(2) to integrate the Fisher length element along those geodesics. We consider
several numerically robust approximation and bounding techniques for the
Fisher-Rao distances: First, we report generic upper bounds on Fisher-Rao
distances based on closed-form 1D Fisher-Rao distances of submodels. Second, we
describe several generic approximation schemes depending on whether the
Fisher-Rao geodesics or pregeodesics are available in closed-form or not. In
particular, we obtain a generic method to guarantee an arbitrarily small
additive error on the approximation provided that Fisher-Rao pregeodesics and
tight lower and upper bounds are available. Third, we consider the case of
Fisher metrics being Hessian metrics, and report generic tight upper bounds on
the Fisher-Rao distances using techniques of information geometry.
Uniparametric and biparametric statistical models always have Fisher Hessian
metrics, and in general a simple test allows to check whether the Fisher
information matrix yields a Hessian metric or not. Fourth, we consider
elliptical distribution families and show how to apply the above techniques to
these models. We also propose two new distances based either on the Fisher-Rao
lengths of curves serving as proxies of Fisher-Rao geodesics, or based on the
Birkhoff/Hilbert projective cone distance. Last, we consider an alternative
group-theoretic approach for statistical transformation models based on the
notion of maximal invariant which yields insights on the structures of the
Fisher-Rao distance formula which may be used fruitfully in applications.</div><div><a href='http://arxiv.org/abs/2403.10089v2'>2403.10089v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12302v1")'>Asymptotic Gaussian Fluctuations of Eigenvectors in Spectral Clustering</div>
<div id='2402.12302v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-19T17:25:12Z</div><div>Authors: Hugo Lebeau, Florent Chatelain, Romain Couillet</div><div style='padding-top: 10px; width: 80ex'>The performance of spectral clustering relies on the fluctuations of the
entries of the eigenvectors of a similarity matrix, which has been left
uncharacterized until now. In this letter, it is shown that the signal $+$
noise structure of a general spike random matrix model is transferred to the
eigenvectors of the corresponding Gram kernel matrix and the fluctuations of
their entries are Gaussian in the large-dimensional regime. This CLT-like
result was the last missing piece to precisely predict the classification
performance of spectral clustering. The proposed proof is very general and
relies solely on the rotational invariance of the noise. Numerical experiments
on synthetic and real data illustrate the universality of this phenomenon.</div><div><a href='http://arxiv.org/abs/2402.12302v1'>2402.12302v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.05716v1")'>Kernelized Normalizing Constant Estimation: Bridging Bayesian Quadrature
  and Bayesian Optimization</div>
<div id='2401.05716v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-11T07:45:09Z</div><div>Authors: Xu Cai, Jonathan Scarlett</div><div style='padding-top: 10px; width: 80ex'>In this paper, we study the problem of estimating the normalizing constant
$\int e^{-\lambda f(x)}dx$ through queries to the black-box function $f$, where
$f$ belongs to a reproducing kernel Hilbert space (RKHS), and $\lambda$ is a
problem parameter. We show that to estimate the normalizing constant within a
small relative error, the level of difficulty depends on the value of
$\lambda$: When $\lambda$ approaches zero, the problem is similar to Bayesian
quadrature (BQ), while when $\lambda$ approaches infinity, the problem is
similar to Bayesian optimization (BO). More generally, the problem varies
between BQ and BO. We find that this pattern holds true even when the function
evaluations are noisy, bringing new aspects to this topic. Our findings are
supported by both algorithm-independent lower bounds and algorithmic upper
bounds, as well as simulation studies conducted on a variety of benchmark
functions.</div><div><a href='http://arxiv.org/abs/2401.05716v1'>2401.05716v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.14989v1")'>Mapping-to-Parameter Nonlinear Functional Regression with Novel B-spline
  Free Knot Placement Algorithm</div>
<div id='2401.14989v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-26T16:35:48Z</div><div>Authors: Chengdong Shi, Ching-Hsun Tseng, Wei Zhao, Xiao-Jun Zeng</div><div style='padding-top: 10px; width: 80ex'>We propose a novel approach to nonlinear functional regression, called the
Mapping-to-Parameter function model, which addresses complex and nonlinear
functional regression problems in parameter space by employing any supervised
learning technique. Central to this model is the mapping of function data from
an infinite-dimensional function space to a finite-dimensional parameter space.
This is accomplished by concurrently approximating multiple functions with a
common set of B-spline basis functions by any chosen order, with their knot
distribution determined by the Iterative Local Placement Algorithm, a newly
proposed free knot placement algorithm. In contrast to the conventional
equidistant knot placement strategy that uniformly distributes knot locations
based on a predefined number of knots, our proposed algorithms determine knot
location according to the local complexity of the input or output functions.
The performance of our knot placement algorithms is shown to be robust in both
single-function approximation and multiple-function approximation contexts.
Furthermore, the effectiveness and advantage of the proposed prediction model
in handling both function-on-scalar regression and function-on-function
regression problems are demonstrated through several real data applications, in
comparison with four groups of state-of-the-art methods.</div><div><a href='http://arxiv.org/abs/2401.14989v1'>2401.14989v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.11736v1")'>Monte Carlo with kernel-based Gibbs measures: Guarantees for
  probabilistic herding</div>
<div id='2402.11736v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-18T23:39:00Z</div><div>Authors: Martin Rouault, Rémi Bardenet, Mylène Maïda</div><div style='padding-top: 10px; width: 80ex'>Kernel herding belongs to a family of deterministic quadratures that seek to
minimize the worst-case integration error over a reproducing kernel Hilbert
space (RKHS). In spite of strong experimental support, it has revealed
difficult to prove that this worst-case error decreases at a faster rate than
the standard square root of the number of quadrature nodes, at least in the
usual case where the RKHS is infinite-dimensional. In this theoretical paper,
we study a joint probability distribution over quadrature nodes, whose support
tends to minimize the same worst-case error as kernel herding. We prove that it
does outperform i.i.d. Monte Carlo, in the sense of coming with a tighter
concentration inequality on the worst-case integration error. While not
improving the rate yet, this demonstrates that the mathematical tools of the
study of Gibbs measures can help understand to what extent kernel herding and
its variants improve on computationally cheaper methods. Moreover, we provide
early experimental evidence that a faster rate of convergence, though not
worst-case, is likely.</div><div><a href='http://arxiv.org/abs/2402.11736v1'>2402.11736v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.08422v1")'>Distribution Estimation under the Infinity Norm</div>
<div id='2402.08422v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T12:49:50Z</div><div>Authors: Aryeh Kontorovich, Amichai Painsky</div><div style='padding-top: 10px; width: 80ex'>We present novel bounds for estimating discrete probability distributions
under the $\ell_\infty$ norm. These are nearly optimal in various precise
senses, including a kind of instance-optimality. Our data-dependent convergence
guarantees for the maximum likelihood estimator significantly improve upon the
currently known results. A variety of techniques are utilized and innovated
upon, including Chernoff-type inequalities and empirical Bernstein bounds. We
illustrate our results in synthetic and real-world experiments. Finally, we
apply our proposed framework to a basic selective inference problem, where we
estimate the most frequent probabilities in a sample.</div><div><a href='http://arxiv.org/abs/2402.08422v1'>2402.08422v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.10758v1")'>Stochastic Localization via Iterative Posterior Sampling</div>
<div id='2402.10758v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-16T15:28:41Z</div><div>Authors: Louis Grenioux, Maxence Noble, Marylou Gabrié, Alain Oliviero Durmus</div><div style='padding-top: 10px; width: 80ex'>Building upon score-based learning, new interest in stochastic localization
techniques has recently emerged. In these models, one seeks to noise a sample
from the data distribution through a stochastic process, called observation
process, and progressively learns a denoiser associated to this dynamics. Apart
from specific applications, the use of stochastic localization for the problem
of sampling from an unnormalized target density has not been explored
extensively. This work contributes to fill this gap. We consider a general
stochastic localization framework and introduce an explicit class of
observation processes, associated with flexible denoising schedules. We provide
a complete methodology, $\textit{Stochastic Localization via Iterative
Posterior Sampling}$ (SLIPS), to obtain approximate samples of this dynamics,
and as a by-product, samples from the target distribution. Our scheme is based
on a Markov chain Monte Carlo estimation of the denoiser and comes with
detailed practical guidelines. We illustrate the benefits and applicability of
SLIPS on several benchmarks, including Gaussian mixtures in increasing
dimensions, Bayesian logistic regression and a high-dimensional field system
from statistical-mechanics.</div><div><a href='http://arxiv.org/abs/2402.10758v1'>2402.10758v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09796v1")'>Closed-form Filtering for Non-linear Systems</div>
<div id='2402.09796v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-15T08:51:49Z</div><div>Authors: Théophile Cantelobre, Carlo Ciliberto, Benjamin Guedj, Alessandro Rudi</div><div style='padding-top: 10px; width: 80ex'>Sequential Bayesian Filtering aims to estimate the current state distribution
of a Hidden Markov Model, given the past observations. The problem is
well-known to be intractable for most application domains, except in notable
cases such as the tabular setting or for linear dynamical systems with gaussian
noise. In this work, we propose a new class of filters based on Gaussian PSD
Models, which offer several advantages in terms of density approximation and
computational efficiency. We show that filtering can be efficiently performed
in closed form when transitions and observations are Gaussian PSD Models. When
the transition and observations are approximated by Gaussian PSD Models, we
show that our proposed estimator enjoys strong theoretical guarantees, with
estimation error that depends on the quality of the approximation and is
adaptive to the regularity of the transition probabilities. In particular, we
identify regimes in which our proposed filter attains a TV $\epsilon$-error
with memory and computational complexity of $O(\epsilon^{-1})$ and
$O(\epsilon^{-3/2})$ respectively, including the offline learning step, in
contrast to the $O(\epsilon^{-2})$ complexity of sampling methods such as
particle filtering.</div><div><a href='http://arxiv.org/abs/2402.09796v1'>2402.09796v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.05899v1")'>Online Identification of Stochastic Continuous-Time Wiener Models Using
  Sampled Data</div>
<div id='2403.05899v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-09T12:33:09Z</div><div>Authors: Mohamed Abdalmoaty, Efe C. Balta, John Lygeros, Roy S. Smith</div><div style='padding-top: 10px; width: 80ex'>It is well known that ignoring the presence of stochastic disturbances in the
identification of stochastic Wiener models leads to asymptotically biased
estimators. On the other hand, optimal statistical identification, via
likelihood-based methods, is sensitive to the assumptions on the data
distribution and is usually based on relatively complex sequential Monte Carlo
algorithms. We develop a simple recursive online estimation algorithm based on
an output-error predictor, for the identification of continuous-time stochastic
parametric Wiener models through stochastic approximation. The method is
applicable to generic model parameterizations and, as demonstrated in the
numerical simulation examples, it is robust with respect to the assumptions on
the spectrum of the disturbance process.</div><div><a href='http://arxiv.org/abs/2403.05899v1'>2403.05899v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15792v1")'>Sample Complexity of the Sign-Perturbed Sums Identification Method:
  Scalar Case</div>
<div id='2401.15792v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-28T22:44:41Z</div><div>Authors: Szabolcs Szentpéteri, Balázs Csanád Csáji</div><div style='padding-top: 10px; width: 80ex'>Sign-Perturbed Sum (SPS) is a powerful finite-sample system identification
algorithm which can construct confidence regions for the true data generating
system with exact coverage probabilities, for any finite sample size. SPS was
developed in a series of papers and it has a wide range of applications, from
general linear systems, even in a closed-loop setup, to nonlinear and
nonparametric approaches. Although several theoretical properties of SPS were
proven in the literature, the sample complexity of the method was not analysed
so far. This paper aims to fill this gap and provides the first results on the
sample complexity of SPS. Here, we focus on scalar linear regression problems,
that is we study the behaviour of SPS confidence intervals. We provide high
probability upper bounds, under three different sets of assumptions, showing
that the sizes of SPS confidence intervals shrink at a geometric rate around
the true parameter, if the observation noises are subgaussian. We also show
that similar bounds hold for the previously proposed outer approximation of the
confidence region. Finally, we present simulation experiments comparing the
theoretical and the empirical convergence rates.</div><div><a href='http://arxiv.org/abs/2401.15792v1'>2401.15792v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.06940v1")'>Efficient Incremental Belief Updates Using Weighted Virtual Observations</div>
<div id='2402.06940v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-10T12:48:49Z</div><div>Authors: David Tolpin</div><div style='padding-top: 10px; width: 80ex'>We present an algorithmic solution to the problem of incremental belief
updating in the context of Monte Carlo inference in Bayesian statistical models
represented by probabilistic programs. Given a model and a sample-approximated
posterior, our solution constructs a set of weighted observations to condition
the model such that inference would result in the same posterior. This problem
arises e.g. in multi-level modelling, incremental inference, inference in
presence of privacy constraints. First, a set of virtual observations is
selected, then, observation weights are found through a computationally
efficient optimization procedure such that the reconstructed posterior
coincides with or closely approximates the original posterior. We implement and
apply the solution to a number of didactic examples and case studies, showing
efficiency and robustness of our approach. The provided reference
implementation is agnostic to the probabilistic programming language or the
inference algorithm, and can be applied to most mainstream probabilistic
programming environments.</div><div><a href='http://arxiv.org/abs/2402.06940v1'>2402.06940v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.09166v1")'>Deinterleaving of Discrete Renewal Process Mixtures with Application to
  Electronic Support Measures</div>
<div id='2402.09166v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T13:32:23Z</div><div>Authors: Jean Pinsolle, Olivier Goudet, Cyrille Enderli, Sylvain Lamprier, Jin-Kao Hao</div><div style='padding-top: 10px; width: 80ex'>In this paper, we propose a new deinterleaving method for mixtures of
discrete renewal Markov chains. This method relies on the maximization of a
penalized likelihood score. It exploits all available information about both
the sequence of the different symbols and their arrival times. A theoretical
analysis is carried out to prove that minimizing this score allows to recover
the true partition of symbols in the large sample limit, under mild conditions
on the component processes. This theoretical analysis is then validated by
experiments on synthetic data. Finally, the method is applied to deinterleave
pulse trains received from different emitters in a RESM (Radar Electronic
Support Measurements) context and we show that the proposed method competes
favorably with state-of-the-art methods on simulated warfare datasets.</div><div><a href='http://arxiv.org/abs/2402.09166v1'>2402.09166v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.14220v1")'>Estimating Unknown Population Sizes Using the Hypergeometric
  Distribution</div>
<div id='2402.14220v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T01:53:56Z</div><div>Authors: Liam Hodgson, Danilo Bzdok</div><div style='padding-top: 10px; width: 80ex'>The multivariate hypergeometric distribution describes sampling without
replacement from a discrete population of elements divided into multiple
categories. Addressing a gap in the literature, we tackle the challenge of
estimating discrete distributions when both the total population size and the
sizes of its constituent categories are unknown. Here, we propose a novel
solution using the hypergeometric likelihood to solve this estimation
challenge, even in the presence of severe under-sampling. We develop our
approach to account for a data generating process where the ground-truth is a
mixture of distributions conditional on a continuous latent variable, such as
with collaborative filtering, using the variational autoencoder framework.
Empirical data simulation demonstrates that our method outperforms other
likelihood functions used to model count data, both in terms of accuracy of
population size estimate and in its ability to learn an informative latent
space. We demonstrate our method's versatility through applications in NLP, by
inferring and estimating the complexity of latent vocabularies in text
excerpts, and in biology, by accurately recovering the true number of gene
transcripts from sparse single-cell genomics data.</div><div><a href='http://arxiv.org/abs/2402.14220v1'>2402.14220v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01050v1")'>Distributed MCMC inference for Bayesian Non-Parametric Latent Block
  Model</div>
<div id='2402.01050v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T22:43:55Z</div><div>Authors: Reda Khoufache, Anisse Belhadj, Hanene Azzag, Mustapha Lebbah</div><div style='padding-top: 10px; width: 80ex'>In this paper, we introduce a novel Distributed Markov Chain Monte Carlo
(MCMC) inference method for the Bayesian Non-Parametric Latent Block Model
(DisNPLBM), employing the Master/Worker architecture. Our non-parametric
co-clustering algorithm divides observations and features into partitions using
latent multivariate Gaussian block distributions. The workload on rows is
evenly distributed among workers, who exclusively communicate with the master
and not among themselves. DisNPLBM demonstrates its impact on cluster labeling
accuracy and execution times through experimental results. Moreover, we present
a real-use case applying our approach to co-cluster gene expression data. The
code source is publicly available at
https://github.com/redakhoufache/Distributed-NPLBM.</div><div><a href='http://arxiv.org/abs/2402.01050v1'>2402.01050v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.13537v2")'>Masked Particle Modeling on Sets: Towards Self-Supervised High Energy
  Physics Foundation Models</div>
<div id='2401.13537v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T15:46:32Z</div><div>Authors: Lukas Heinrich, Tobias Golling, Michael Kagan, Samuel Klein, Matthew Leigh, Margarita Osadchy, John Andrew Raine</div><div style='padding-top: 10px; width: 80ex'>We propose masked particle modeling (MPM) as a self-supervised method for
learning generic, transferable, and reusable representations on unordered sets
of inputs for use in high energy physics (HEP) scientific data. This work
provides a novel scheme to perform masked modeling based pre-training to learn
permutation invariant functions on sets. More generally, this work provides a
step towards building large foundation models for HEP that can be generically
pre-trained with self-supervised learning and later fine-tuned for a variety of
down-stream tasks. In MPM, particles in a set are masked and the training
objective is to recover their identity, as defined by a discretized token
representation of a pre-trained vector quantized variational autoencoder. We
study the efficacy of the method in samples of high energy jets at collider
physics experiments, including studies on the impact of discretization,
permutation invariance, and ordering. We also study the fine-tuning capability
of the model, showing that it can be adapted to tasks such as supervised and
weakly supervised jet classification, and that the model can transfer
efficiently with small fine-tuning data sets to new classes and new data
domains.</div><div><a href='http://arxiv.org/abs/2401.13537v2'>2401.13537v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14076v1")'>Improving $Λ$ Signal Extraction with Domain Adaptation via
  Normalizing Flows</div>
<div id='2403.14076v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T01:54:00Z</div><div>Authors: Rowan Kelleher, Matthew McEneaney, Anselm Vossen</div><div style='padding-top: 10px; width: 80ex'>The present study presents a novel application for normalizing flows for
domain adaptation. The study investigates the ability of flow based neural
networks to improve signal extraction of $\Lambda$ Hyperons at CLAS12.
Normalizing Flows can help model complex probability density functions that
describe physics processes, enabling uses such as event generation. $\Lambda$
signal extraction has been improved through the use of classifier networks, but
differences in simulation and data domains limit classifier performance; this
study utilizes the flows for domain adaptation between Monte Carlo simulation
and data. We were successful in training a flow network to transform between
the latent physics space and a normal distribution. We also found that applying
the flows lessened the dependence of the figure of merit on the cut on the
classifier output, meaning that there was a broader range where the cut results
in a similar figure of merit.</div><div><a href='http://arxiv.org/abs/2403.14076v1'>2403.14076v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.16688v1")'>On the connection between Noise-Contrastive Estimation and Contrastive
  Divergence</div>
<div id='2402.16688v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T16:04:47Z</div><div>Authors: Amanda Olmin, Jakob Lindqvist, Lennart Svensson, Fredrik Lindsten</div><div style='padding-top: 10px; width: 80ex'>Noise-contrastive estimation (NCE) is a popular method for estimating
unnormalised probabilistic models, such as energy-based models, which are
effective for modelling complex data distributions. Unlike classical maximum
likelihood (ML) estimation that relies on importance sampling (resulting in
ML-IS) or MCMC (resulting in contrastive divergence, CD), NCE uses a proxy
criterion to avoid the need for evaluating an often intractable normalisation
constant.
  Despite apparent conceptual differences, we show that two NCE criteria,
ranking NCE (RNCE) and conditional NCE (CNCE), can be viewed as ML estimation
methods. Specifically, RNCE is equivalent to ML estimation combined with
conditional importance sampling, and both RNCE and CNCE are special cases of
CD. These findings bridge the gap between the two method classes and allow us
to apply techniques from the ML-IS and CD literature to NCE, offering several
advantageous extensions.</div><div><a href='http://arxiv.org/abs/2402.16688v1'>2402.16688v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01543v1")'>Adaptive Optimization for Prediction with Missing Data</div>
<div id='2402.01543v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T16:35:51Z</div><div>Authors: Dimitris Bertsimas, Arthur Delarue, Jean Pauphilet</div><div style='padding-top: 10px; width: 80ex'>When training predictive models on data with missing entries, the most widely
used and versatile approach is a pipeline technique where we first impute
missing entries and then compute predictions. In this paper, we view prediction
with missing data as a two-stage adaptive optimization problem and propose a
new class of models, adaptive linear regression models, where the regression
coefficients adapt to the set of observed features. We show that some adaptive
linear regression models are equivalent to learning an imputation rule and a
downstream linear regression model simultaneously instead of sequentially. We
leverage this joint-impute-then-regress interpretation to generalize our
framework to non-linear models. In settings where data is strongly not missing
at random, our methods achieve a 2-10% improvement in out-of-sample accuracy.</div><div><a href='http://arxiv.org/abs/2402.01543v1'>2402.01543v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.17926v2")'>Certain and Approximately Certain Models for Statistical Learning</div>
<div id='2402.17926v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T22:49:33Z</div><div>Authors: Cheng Zhen, Nischal Aryal, Arash Termehchy, Alireza Aghasi, Amandeep Singh Chabada</div><div style='padding-top: 10px; width: 80ex'>Real-world data is often incomplete and contains missing values. To train
accurate models over real-world datasets, users need to spend a substantial
amount of time and resources imputing and finding proper values for missing
data items. In this paper, we demonstrate that it is possible to learn accurate
models directly from data with missing values for certain training data and
target models. We propose a unified approach for checking the necessity of data
imputation to learn accurate models across various widely-used machine learning
paradigms. We build efficient algorithms with theoretical guarantees to check
this necessity and return accurate models in cases where imputation is
unnecessary. Our extensive experiments indicate that our proposed algorithms
significantly reduce the amount of time and effort needed for data imputation
without imposing considerable computational overhead.</div><div><a href='http://arxiv.org/abs/2402.17926v2'>2402.17926v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.02372v1")'>OTClean: Data Cleaning for Conditional Independence Violations using
  Optimal Transport</div>
<div id='2403.02372v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-04T18:23:55Z</div><div>Authors: Alireza Pirhadi, Mohammad Hossein Moslemi, Alexander Cloninger, Mostafa Milani, Babak Salimi</div><div style='padding-top: 10px; width: 80ex'>Ensuring Conditional Independence (CI) constraints is pivotal for the
development of fair and trustworthy machine learning models. In this paper, we
introduce \sys, a framework that harnesses optimal transport theory for data
repair under CI constraints. Optimal transport theory provides a rigorous
framework for measuring the discrepancy between probability distributions,
thereby ensuring control over data utility. We formulate the data repair
problem concerning CIs as a Quadratically Constrained Linear Program (QCLP) and
propose an alternating method for its solution. However, this approach faces
scalability issues due to the computational cost associated with computing
optimal transport distances, such as the Wasserstein distance. To overcome
these scalability challenges, we reframe our problem as a regularized
optimization problem, enabling us to develop an iterative algorithm inspired by
Sinkhorn's matrix scaling algorithm, which efficiently addresses
high-dimensional and large-scale data. Through extensive experiments, we
demonstrate the efficacy and efficiency of our proposed methods, showcasing
their practical utility in real-world data cleaning and preprocessing tasks.
Furthermore, we provide comparisons with traditional approaches, highlighting
the superiority of our techniques in terms of preserving data utility while
ensuring adherence to the desired CI constraints.</div><div><a href='http://arxiv.org/abs/2403.02372v1'>2403.02372v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.13864v1")'>Optimal Transport for Fairness: Archival Data Repair using Small
  Research Data Sets</div>
<div id='2403.13864v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-20T09:23:20Z</div><div>Authors: Abigail Langbridge, Anthony Quinn, Robert Shorten</div><div style='padding-top: 10px; width: 80ex'>With the advent of the AI Act and other regulations, there is now an urgent
need for algorithms that repair unfairness in training data. In this paper, we
define fairness in terms of conditional independence between protected
attributes ($S$) and features ($X$), given unprotected attributes ($U$). We
address the important setting in which torrents of archival data need to be
repaired, using only a small proportion of these data, which are $S|U$-labelled
(the research data). We use the latter to design optimal transport (OT)-based
repair plans on interpolated supports. This allows {\em off-sample}, labelled,
archival data to be repaired, subject to stationarity assumptions. It also
significantly reduces the size of the supports of the OT plans, with
correspondingly large savings in the cost of their design and of their {\em
sequential\/} application to the off-sample data. We provide detailed
experimental results with simulated and benchmark real data (the Adult data
set). Our performance figures demonstrate effective repair -- in the sense of
quenching conditional dependence -- of large quantities of off-sample, labelled
(archival) data.</div><div><a href='http://arxiv.org/abs/2403.13864v1'>2403.13864v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.14578v1")'>Multivariate Online Linear Regression for Hierarchical Forecasting</div>
<div id='2402.14578v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T14:33:54Z</div><div>Authors: Massil Hihat, Guillaume Garrigos, Adeline Fermanian, Simon Bussy</div><div style='padding-top: 10px; width: 80ex'>In this paper, we consider a deterministic online linear regression model
where we allow the responses to be multivariate. To address this problem, we
introduce MultiVAW, a method that extends the well-known Vovk-Azoury-Warmuth
algorithm to the multivariate setting, and show that it also enjoys logarithmic
regret in time. We apply our results to the online hierarchical forecasting
problem and recover an algorithm from this literature as a special case,
allowing us to relax the hypotheses usually made for its analysis.</div><div><a href='http://arxiv.org/abs/2402.14578v1'>2402.14578v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.12732v1")'>Tighter Confidence Bounds for Sequential Kernel Regression</div>
<div id='2403.12732v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-19T13:47:35Z</div><div>Authors: Hamish Flynn, David Reeb</div><div style='padding-top: 10px; width: 80ex'>Confidence bounds are an essential tool for rigorously quantifying the
uncertainty of predictions. In this capacity, they can inform the
exploration-exploitation trade-off and form a core component in many sequential
learning and decision-making algorithms. Tighter confidence bounds give rise to
algorithms with better empirical performance and better performance guarantees.
In this work, we use martingale tail bounds and finite-dimensional
reformulations of infinite-dimensional convex programs to establish new
confidence bounds for sequential kernel regression. We prove that our new
confidence bounds are always tighter than existing ones in this setting. We
apply our confidence bounds to the kernel bandit problem, where future actions
depend on the previous history. When our confidence bounds replace existing
ones, the KernelUCB (GP-UCB) algorithm has better empirical performance, a
matching worst-case performance guarantee and comparable computational cost.
Our new confidence bounds can be used as a generic tool to design improved
algorithms for other kernelised learning and decision-making problems.</div><div><a href='http://arxiv.org/abs/2403.12732v1'>2403.12732v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12762v2")'>Learning under Singularity: An Information Criterion improving WBIC and
  sBIC</div>
<div id='2402.12762v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T07:09:39Z</div><div>Authors: Lirui Liu, Joe Suzuki</div><div style='padding-top: 10px; width: 80ex'>We introduce a novel Information Criterion (IC), termed Learning under
Singularity (LS), designed to enhance the functionality of the Widely
Applicable Bayes Information Criterion (WBIC) and the Singular Bayesian
Information Criterion (sBIC). LS is effective without regularity constraints
and demonstrates stability. Watanabe defined a statistical model or a learning
machine as regular if the mapping from a parameter to a probability
distribution is one-to-one and its Fisher information matrix is positive
definite. In contrast, models not meeting these conditions are termed singular.
Over the past decade, several information criteria for singular cases have been
proposed, including WBIC and sBIC. WBIC is applicable in non-regular scenarios
but faces challenges with large sample sizes and redundant estimation of known
learning coefficients. Conversely, sBIC is limited in its broader application
due to its dependence on maximum likelihood estimates. LS addresses these
limitations by enhancing the utility of both WBIC and sBIC. It incorporates the
empirical loss from the Widely Applicable Information Criterion (WAIC) to
represent the goodness of fit to the statistical model, along with a penalty
term similar to that of sBIC. This approach offers a flexible and robust method
for model selection, free from regularity constraints.</div><div><a href='http://arxiv.org/abs/2402.12762v2'>2402.12762v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04234v1")'>Fundamental limits of Non-Linear Low-Rank Matrix Estimation</div>
<div id='2403.04234v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T05:26:52Z</div><div>Authors: Pierre Mergny, Justin Ko, Florent Krzakala, Lenka Zdeborová</div><div style='padding-top: 10px; width: 80ex'>We consider the task of estimating a low-rank matrix from non-linear and
noisy observations. We prove a strong universality result showing that
Bayes-optimal performances are characterized by an equivalent Gaussian model
with an effective prior, whose parameters are entirely determined by an
expansion of the non-linear function. In particular, we show that to
reconstruct the signal accurately, one requires a signal-to-noise ratio growing
as $N^{\frac 12 (1-1/k_F)}$, where $k_F$ is the first non-zero Fisher
information coefficient of the function. We provide asymptotic characterization
for the minimal achievable mean squared error (MMSE) and an approximate
message-passing algorithm that reaches the MMSE under conditions analogous to
the linear version of the problem. We also provide asymptotic errors achieved
by methods such as principal component analysis combined with Bayesian
denoising, and compare them with Bayes-optimal MMSE.</div><div><a href='http://arxiv.org/abs/2403.04234v1'>2403.04234v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.02459v1")'>On Minimum Trace Factor Analysis -- An Old Song Sung to a New Tune</div>
<div id='2402.02459v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-04T12:15:56Z</div><div>Authors: C. Li, A. Shkolnik</div><div style='padding-top: 10px; width: 80ex'>Dimensionality reduction methods, such as principal component analysis (PCA)
and factor analysis, are central to many problems in data science. There are,
however, serious and well-understood challenges to finding robust low
dimensional approximations for data with significant heteroskedastic noise.
This paper introduces a relaxed version of Minimum Trace Factor Analysis
(MTFA), a convex optimization method with roots dating back to the work of
Ledermann in 1940. This relaxation is particularly effective at not overfitting
to heteroskedastic perturbations and addresses the commonly cited Heywood cases
in factor analysis and the recently identified "curse of ill-conditioning" for
existing spectral methods. We provide theoretical guarantees on the accuracy of
the resulting low rank subspace and the convergence rate of the proposed
algorithm to compute that matrix. We develop a number of interesting
connections to existing methods, including HeteroPCA, Lasso, and Soft-Impute,
to fill an important gap in the already large literature on low rank matrix
estimation. Numerical experiments benchmark our results against several recent
proposals for dealing with heteroskedastic noise.</div><div><a href='http://arxiv.org/abs/2402.02459v1'>2402.02459v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09754v1")'>Robust SVD Made Easy: A fast and reliable algorithm for large-scale data
  analysis</div>
<div id='2402.09754v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-15T07:08:11Z</div><div>Authors: Sangil Han, Kyoowon Kim, Sungkyu Jung</div><div style='padding-top: 10px; width: 80ex'>The singular value decomposition (SVD) is a crucial tool in machine learning
and statistical data analysis. However, it is highly susceptible to outliers in
the data matrix. Existing robust SVD algorithms often sacrifice speed for
robustness or fail in the presence of only a few outliers. This study
introduces an efficient algorithm, called Spherically Normalized SVD, for
robust SVD approximation that is highly insensitive to outliers,
computationally scalable, and provides accurate approximations of singular
vectors. The proposed algorithm achieves remarkable speed by utilizing only two
applications of a standard reduced-rank SVD algorithm to appropriately scaled
data, significantly outperforming competing algorithms in computation times. To
assess the robustness of the approximated singular vectors and their subspaces
against data contamination, we introduce new notions of breakdown points for
matrix-valued input, including row-wise, column-wise, and block-wise breakdown
points. Theoretical and empirical analyses demonstrate that our algorithm
exhibits higher breakdown points compared to standard SVD and its
modifications. We empirically validate the effectiveness of our approach in
applications such as robust low-rank approximation and robust principal
component analysis of high-dimensional microarray datasets. Overall, our study
presents a highly efficient and robust solution for SVD approximation that
overcomes the limitations of existing algorithms in the presence of outliers.</div><div><a href='http://arxiv.org/abs/2402.09754v1'>2402.09754v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.16712v2")'>l1-norm regularized l1-norm best-fit lines</div>
<div id='2402.16712v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T16:30:58Z</div><div>Authors: Xiao Ling, Paul Brooks</div><div style='padding-top: 10px; width: 80ex'>In this work, we propose an optimization framework for estimating a sparse
robust one-dimensional subspace. Our objective is to minimize both the
representation error and the penalty, in terms of the l1-norm criterion. Given
that the problem is NP-hard, we introduce a linear relaxation-based approach.
Additionally, we present a novel fitting procedure, utilizing simple ratios and
sorting techniques. The proposed algorithm demonstrates a worst-case time
complexity of $O(n^2 m \log n)$ and, in certain instances, achieves global
optimality for the sparse robust subspace, thereby exhibiting polynomial time
efficiency. Compared to extant methodologies, the proposed algorithm finds the
subspace with the lowest discordance, offering a smoother trade-off between
sparsity and fit. Its architecture affords scalability, evidenced by a 16-fold
improvement in computational speeds for matrices of 2000x2000 over CPU version.
Furthermore, this method is distinguished by several advantages, including its
independence from initialization and deterministic and replicable procedures.
Furthermore, this method is distinguished by several advantages, including its
independence from initialization and deterministic and replicable procedures.
The real-world example demonstrates the effectiveness of algorithm in achieving
meaningful sparsity, underscoring its precise and useful application across
various domains.</div><div><a href='http://arxiv.org/abs/2402.16712v2'>2402.16712v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.12206v1")'>Useful Compact Representations for Data-Fitting</div>
<div id='2403.12206v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-18T19:43:00Z</div><div>Authors: Johannes J. Brust</div><div style='padding-top: 10px; width: 80ex'>For minimization problems without 2nd derivative information, methods that
estimate Hessian matrices can be very effective. However, conventional
techniques generate dense matrices that are prohibitive for large problems.
Limited-memory compact representations express the dense arrays in terms of a
low rank representation and have become the state-of-the-art for software
implementations on large deterministic problems. We develop new compact
representations that are parameterized by a choice of vectors and that reduce
to existing well known formulas for special choices. We demonstrate
effectiveness of the compact representations for large eigenvalue computations,
tensor factorizations and nonlinear regressions.</div><div><a href='http://arxiv.org/abs/2403.12206v1'>2403.12206v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.03058v1")'>Krylov Cubic Regularized Newton: A Subspace Second-Order Method with
  Dimension-Free Convergence Rate</div>
<div id='2401.03058v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-05T20:24:18Z</div><div>Authors: Ruichen Jiang, Parameswaran Raman, Shoham Sabach, Aryan Mokhtari, Mingyi Hong, Volkan Cevher</div><div style='padding-top: 10px; width: 80ex'>Second-order optimization methods, such as cubic regularized Newton methods,
are known for their rapid convergence rates; nevertheless, they become
impractical in high-dimensional problems due to their substantial memory
requirements and computational costs. One promising approach is to execute
second-order updates within a lower-dimensional subspace, giving rise to
subspace second-order methods. However, the majority of existing subspace
second-order methods randomly select subspaces, consequently resulting in
slower convergence rates depending on the problem's dimension $d$. In this
paper, we introduce a novel subspace cubic regularized Newton method that
achieves a dimension-independent global convergence rate of
${O}\left(\frac{1}{mk}+\frac{1}{k^2}\right)$ for solving convex optimization
problems. Here, $m$ represents the subspace dimension, which can be
significantly smaller than $d$. Instead of adopting a random subspace, our
primary innovation involves performing the cubic regularized Newton update
within the Krylov subspace associated with the Hessian and the gradient of the
objective function. This result marks the first instance of a
dimension-independent convergence rate for a subspace second-order method.
Furthermore, when specific spectral conditions of the Hessian are met, our
method recovers the convergence rate of a full-dimensional cubic regularized
Newton method. Numerical experiments show our method converges faster than
existing random subspace methods, especially for high-dimensional problems.</div><div><a href='http://arxiv.org/abs/2401.03058v1'>2401.03058v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.02322v2")'>Dynamic Incremental Optimization for Best Subset Selection</div>
<div id='2402.02322v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-04T02:26:40Z</div><div>Authors: Shaogang Ren, Xiaoning Qian</div><div style='padding-top: 10px; width: 80ex'>Best subset selection is considered the `gold standard' for many sparse
learning problems. A variety of optimization techniques have been proposed to
attack this non-smooth non-convex problem. In this paper, we investigate the
dual forms of a family of $\ell_0$-regularized problems. An efficient
primal-dual algorithm is developed based on the primal and dual problem
structures. By leveraging the dual range estimation along with the incremental
strategy, our algorithm potentially reduces redundant computation and improves
the solutions of best subset selection. Theoretical analysis and experiments on
synthetic and real-world datasets validate the efficiency and statistical
properties of the proposed solutions.</div><div><a href='http://arxiv.org/abs/2402.02322v2'>2402.02322v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.02735v1")'>Shared active subspace for multivariate vector-valued functions</div>
<div id='2401.02735v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-05T10:08:38Z</div><div>Authors: Khadija Musayeva, Mickael Binois</div><div style='padding-top: 10px; width: 80ex'>This paper proposes several approaches as baselines to compute a shared
active subspace for multivariate vector-valued functions. The goal is to
minimize the deviation between the function evaluations on the original space
and those on the reconstructed one. This is done either by manipulating the
gradients or the symmetric positive (semi-)definite (SPD) matrices computed
from the gradients of each component function so as to get a single structure
common to all component functions. These approaches can be applied to any data
irrespective of the underlying distribution unlike the existing vector-valued
approach that is constrained to a normal distribution. We test the
effectiveness of these methods on five optimization problems. The experiments
show that, in general, the SPD-level methods are superior to the gradient-level
ones, and are close to the vector-valued approach in the case of a normal
distribution. Interestingly, in most cases it suffices to take the sum of the
SPD matrices to identify the best shared active subspace.</div><div><a href='http://arxiv.org/abs/2401.02735v1'>2401.02735v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.08375v1")'>Sparse PCA with False Discovery Rate Controlled Variable Selection</div>
<div id='2401.08375v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-16T14:07:36Z</div><div>Authors: Jasin Machkour, Arnaud Breloy, Michael Muma, Daniel P. Palomar, Frédéric Pascal</div><div style='padding-top: 10px; width: 80ex'>Sparse principal component analysis (PCA) aims at mapping large dimensional
data to a linear subspace of lower dimension. By imposing loading vectors to be
sparse, it performs the double duty of dimension reduction and variable
selection. Sparse PCA algorithms are usually expressed as a trade-off between
explained variance and sparsity of the loading vectors (i.e., number of
selected variables). As a high explained variance is not necessarily synonymous
with relevant information, these methods are prone to select irrelevant
variables. To overcome this issue, we propose an alternative formulation of
sparse PCA driven by the false discovery rate (FDR). We then leverage the
Terminating-Random Experiments (T-Rex) selector to automatically determine an
FDR-controlled support of the loading vectors. A major advantage of the
resulting T-Rex PCA is that no sparsity parameter tuning is required. Numerical
experiments and a stock market data example demonstrate a significant
performance improvement.</div><div><a href='http://arxiv.org/abs/2401.08375v1'>2401.08375v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.18039v1")'>Variable selection for Naïve Bayes classification</div>
<div id='2401.18039v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-31T18:01:36Z</div><div>Authors: Rafael Blanquero, Emilio Carrizosa, Pepa Ramírez-Cobo, M. Remedios Sillero-Denamiel</div><div style='padding-top: 10px; width: 80ex'>The Na\"ive Bayes has proven to be a tractable and efficient method for
classification in multivariate analysis. However, features are usually
correlated, a fact that violates the Na\"ive Bayes' assumption of conditional
independence, and may deteriorate the method's performance. Moreover, datasets
are often characterized by a large number of features, which may complicate the
interpretation of the results as well as slow down the method's execution.
  In this paper we propose a sparse version of the Na\"ive Bayes classifier
that is characterized by three properties. First, the sparsity is achieved
taking into account the correlation structure of the covariates. Second,
different performance measures can be used to guide the selection of features.
Third, performance constraints on groups of higher interest can be included.
Our proposal leads to a smart search, which yields competitive running times,
whereas the flexibility in terms of performance measure for classification is
integrated. Our findings show that, when compared against well-referenced
feature selection approaches, the proposed sparse Na\"ive Bayes obtains
competitive results regarding accuracy, sparsity and running times for balanced
datasets. In the case of datasets with unbalanced (or with different
importance) classes, a better compromise between classification rates for the
different classes is achieved.</div><div><a href='http://arxiv.org/abs/2401.18039v1'>2401.18039v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.12667v1")'>Feature Selection via Robust Weighted Score for High Dimensional Binary
  Class-Imbalanced Gene Expression Data</div>
<div id='2401.12667v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-23T11:22:03Z</div><div>Authors: Zardad Khan, Amjad Ali, Saeed Aldahmani</div><div style='padding-top: 10px; width: 80ex'>In this paper, a robust weighted score for unbalanced data (ROWSU) is
proposed for selecting the most discriminative feature for high dimensional
gene expression binary classification with class-imbalance problem. The method
addresses one of the most challenging problems of highly skewed class
distributions in gene expression datasets that adversely affect the performance
of classification algorithms. First, the training dataset is balanced by
synthetically generating data points from minority class observations. Second,
a minimum subset of genes is selected using a greedy search approach. Third, a
novel weighted robust score, where the weights are computed by support vectors,
is introduced to obtain a refined set of genes. The highest-scoring genes based
on this approach are combined with the minimum subset of genes selected by the
greedy search approach to form the final set of genes. The novel method ensures
the selection of the most discriminative genes, even in the presence of skewed
class distribution, thus improving the performance of the classifiers. The
performance of the proposed ROWSU method is evaluated on $6$ gene expression
datasets. Classification accuracy and sensitivity are used as performance
metrics to compare the proposed ROWSU algorithm with several other
state-of-the-art methods. Boxplots and stability plots are also constructed for
a better understanding of the results. The results show that the proposed
method outperforms the existing feature selection procedures based on
classification performance from k nearest neighbours (kNN) and random forest
(RF) classifiers.</div><div><a href='http://arxiv.org/abs/2401.12667v1'>2401.12667v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14980v1")'>Comparative Analysis of Data Preprocessing Methods, Feature Selection
  Techniques and Machine Learning Models for Improved Classification and
  Regression Performance on Imbalanced Genetic Data</div>
<div id='2402.14980v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T21:41:27Z</div><div>Authors: Arshmeet Kaur, Morteza Sarmadi</div><div style='padding-top: 10px; width: 80ex'>Rapid advancements in genome sequencing have led to the collection of vast
amounts of genomics data. Researchers may be interested in using machine
learning models on such data to predict the pathogenicity or clinical
significance of a genetic mutation. However, many genetic datasets contain
imbalanced target variables that pose challenges to machine learning models:
observations are skewed/imbalanced in regression tasks or class-imbalanced in
classification tasks. Genetic datasets are also often high-cardinal and contain
skewed predictor variables, which poses further challenges. We aimed to
investigate the effects of data preprocessing, feature selection techniques,
and model selection on the performance of models trained on these datasets. We
measured performance with 5-fold cross-validation and compared averaged
r-squared and accuracy metrics across different combinations of techniques. We
found that outliers/skew in predictor or target variables did not pose a
challenge to regression models. We also found that class-imbalanced target
variables and skewed predictors had little to no impact on classification
performance. Random forest was the best model to use for imbalanced regression
tasks. While our study uses a genetic dataset as an example of a real-world
application, our findings can be generalized to any similar datasets.</div><div><a href='http://arxiv.org/abs/2402.14980v1'>2402.14980v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00054v1")'>Predicting loss-of-function impact of genetic mutations: a machine
  learning approach</div>
<div id='2402.00054v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-26T19:27:38Z</div><div>Authors: Arshmeet Kaur, Morteza Sarmadi</div><div style='padding-top: 10px; width: 80ex'>The innovation of next-generation sequencing (NGS) techniques has
significantly reduced the price of genome sequencing, lowering barriers to
future medical research; it is now feasible to apply genome sequencing to
studies where it would have previously been cost-inefficient. Identifying
damaging or pathogenic mutations in vast amounts of complex, high-dimensional
genome sequencing data may be of particular interest to researchers. Thus, this
paper's aims were to train machine learning models on the attributes of a
genetic mutation to predict LoFtool scores (which measure a gene's intolerance
to loss-of-function mutations). These attributes included, but were not limited
to, the position of a mutation on a chromosome, changes in amino acids, and
changes in codons caused by the mutation. Models were built using the
univariate feature selection technique f-regression combined with K-nearest
neighbors (KNN), Support Vector Machine (SVM), Random Sample Consensus
(RANSAC), Decision Trees, Random Forest, and Extreme Gradient Boosting
(XGBoost). These models were evaluated using five-fold cross-validated averages
of r-squared, mean squared error, root mean squared error, mean absolute error,
and explained variance. The findings of this study include the training of
multiple models with testing set r-squared values of 0.97.</div><div><a href='http://arxiv.org/abs/2402.00054v1'>2402.00054v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00926v1")'>A Comparative Analysis of Gene Expression Profiling by Statistical and
  Machine Learning Approaches</div>
<div id='2402.00926v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T18:17:36Z</div><div>Authors: Myriam Bontonou, Anaïs Haget, Maria Boulougouri, Benjamin Audit, Pierre Borgnat, Jean-Michel Arbona</div><div style='padding-top: 10px; width: 80ex'>Many machine learning models have been proposed to classify phenotypes from
gene expression data. In addition to their good performance, these models can
potentially provide some understanding of phenotypes by extracting explanations
for their decisions. These explanations often take the form of a list of genes
ranked in order of importance for the predictions, the highest-ranked genes
being interpreted as linked to the phenotype. We discuss the biological and the
methodological limitations of such explanations. Experiments are performed on
several datasets gathering cancer and healthy tissue samples from the TCGA,
GTEx and TARGET databases. A collection of machine learning models including
logistic regression, multilayer perceptron, and graph neural network are
trained to classify samples according to their cancer type. Gene rankings are
obtained from explainability methods adapted to these models, and compared to
the ones from classical statistical feature selection methods such as mutual
information, DESeq2, and EdgeR. Interestingly, on simple tasks, we observe that
the information learned by black-box neural networks is related to the notion
of differential expression. In all cases, a small set containing the
best-ranked genes is sufficient to achieve a good classification. However,
these genes differ significantly between the methods and similar classification
performance can be achieved with numerous lower ranked genes. In conclusion,
although these methods enable the identification of biomarkers characteristic
of certain pathologies, our results question the completeness of the selected
gene sets and thus of explainability by the identification of the underlying
biological processes.</div><div><a href='http://arxiv.org/abs/2402.00926v1'>2402.00926v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.02976v1")'>Boosting, Voting Classifiers and Randomized Sample Compression Schemes</div>
<div id='2402.02976v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T12:58:03Z</div><div>Authors: Arthur da Cunha, Kasper Green Larsen, Martin Ritzert</div><div style='padding-top: 10px; width: 80ex'>In boosting, we aim to leverage multiple weak learners to produce a strong
learner. At the center of this paradigm lies the concept of building the strong
learner as a voting classifier, which outputs a weighted majority vote of the
weak learners. While many successful boosting algorithms, such as the iconic
AdaBoost, produce voting classifiers, their theoretical performance has long
remained sub-optimal: the best known bounds on the number of training examples
necessary for a voting classifier to obtain a given accuracy has so far always
contained at least two logarithmic factors above what is known to be achievable
by general weak-to-strong learners. In this work, we break this barrier by
proposing a randomized boosting algorithm that outputs voting classifiers whose
generalization error contains a single logarithmic dependency on the sample
size. We obtain this result by building a general framework that extends sample
compression methods to support randomized learning algorithms based on
sub-sampling.</div><div><a href='http://arxiv.org/abs/2402.02976v1'>2402.02976v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15145v1")'>The Cost of Parallelizing Boosting</div>
<div id='2402.15145v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-23T07:03:52Z</div><div>Authors: Xin Lyu, Hongxun Wu, Junzhao Yang</div><div style='padding-top: 10px; width: 80ex'>We study the cost of parallelizing weak-to-strong boosting algorithms for
learning, following the recent work of Karbasi and Larsen. Our main results are
two-fold:
  - First, we prove a tight lower bound, showing that even "slight"
parallelization of boosting requires an exponential blow-up in the complexity
of training.
  Specifically, let $\gamma$ be the weak learner's advantage over random
guessing. The famous \textsc{AdaBoost} algorithm produces an accurate
hypothesis by interacting with the weak learner for $\tilde{O}(1 / \gamma^2)$
rounds where each round runs in polynomial time.
  Karbasi and Larsen showed that "significant" parallelization must incur
exponential blow-up: Any boosting algorithm either interacts with the weak
learner for $\Omega(1 / \gamma)$ rounds or incurs an $\exp(d / \gamma)$ blow-up
in the complexity of training, where $d$ is the VC dimension of the hypothesis
class. We close the gap by showing that any boosting algorithm either has
$\Omega(1 / \gamma^2)$ rounds of interaction or incurs a smaller exponential
blow-up of $\exp(d)$.
  -Complementing our lower bound, we show that there exists a boosting
algorithm using $\tilde{O}(1/(t \gamma^2))$ rounds, and only suffer a blow-up
of $\exp(d \cdot t^2)$.
  Plugging in $t = \omega(1)$, this shows that the smaller blow-up in our lower
bound is tight. More interestingly, this provides the first trade-off between
the parallelism and the total work required for boosting.</div><div><a href='http://arxiv.org/abs/2402.15145v1'>2402.15145v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.07485v1")'>PMBO: Enhancing Black-Box Optimization through Multivariate Polynomial
  Surrogates</div>
<div id='2403.07485v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T10:21:21Z</div><div>Authors: Janina Schreiber, Pau Batlle, Damar Wicaksono, Michael Hecht</div><div style='padding-top: 10px; width: 80ex'>We introduce a surrogate-based black-box optimization method, termed
Polynomial-model-based optimization (PMBO). The algorithm alternates polynomial
approximation with Bayesian optimization steps, using Gaussian processes to
model the error between the objective and its polynomial fit. We describe the
algorithmic design of PMBO and compare the results of the performance of PMBO
with several optimization methods for a set of analytic test functions.
  The results show that PMBO outperforms the classic Bayesian optimization and
is robust with respect to the choice of its correlation function family and its
hyper-parameter setting, which, on the contrary, need to be carefully tuned in
classic Bayesian optimization. Remarkably, PMBO performs comparably with
state-of-the-art evolutionary algorithms such as the Covariance Matrix
Adaptation -- Evolution Strategy (CMA-ES). This finding suggests that PMBO
emerges as the pivotal choice among surrogate-based optimization methods when
addressing low-dimensional optimization problems. Hereby, the simple nature of
polynomials opens the opportunity for interpretation and analysis of the
inferred surrogate model, providing a macroscopic perspective on the landscape
of the objective function.</div><div><a href='http://arxiv.org/abs/2403.07485v1'>2403.07485v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14413v2")'>Model Uncertainty in Evolutionary Optimization and Bayesian
  Optimization: A Comparative Analysis</div>
<div id='2403.14413v2' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T13:59:19Z</div><div>Authors: Hao Hao, Xiaoqun Zhang, Aimin Zhou</div><div style='padding-top: 10px; width: 80ex'>Black-box optimization problems, which are common in many real-world
applications, require optimization through input-output interactions without
access to internal workings. This often leads to significant computational
resources being consumed for simulations. Bayesian Optimization (BO) and
Surrogate-Assisted Evolutionary Algorithm (SAEA) are two widely used
gradient-free optimization techniques employed to address such challenges. Both
approaches follow a similar iterative procedure that relies on surrogate models
to guide the search process. This paper aims to elucidate the similarities and
differences in the utilization of model uncertainty between these two methods,
as well as the impact of model inaccuracies on algorithmic performance. A novel
model-assisted strategy is introduced, which utilizes unevaluated solutions to
generate offspring, leveraging the population-based search capabilities of
evolutionary algorithm to enhance the effectiveness of model-assisted
optimization. Experimental results demonstrate that the proposed approach
outperforms mainstream Bayesian optimization algorithms in terms of accuracy
and efficiency.</div><div><a href='http://arxiv.org/abs/2403.14413v2'>2403.14413v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09638v1")'>Multi-Fidelity Methods for Optimization: A Survey</div>
<div id='2402.09638v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-15T00:52:34Z</div><div>Authors: Ke Li, Fan Li</div><div style='padding-top: 10px; width: 80ex'>Real-world black-box optimization often involves time-consuming or costly
experiments and simulations. Multi-fidelity optimization (MFO) stands out as a
cost-effective strategy that balances high-fidelity accuracy with computational
efficiency through a hierarchical fidelity approach. This survey presents a
systematic exploration of MFO, underpinned by a novel text mining framework
based on a pre-trained language model. We delve deep into the foundational
principles and methodologies of MFO, focusing on three core components --
multi-fidelity surrogate models, fidelity management strategies, and
optimization techniques. Additionally, this survey highlights the diverse
applications of MFO across several key domains, including machine learning,
engineering design optimization, and scientific discovery, showcasing the
adaptability and effectiveness of MFO in tackling complex computational
challenges. Furthermore, we also envision several emerging challenges and
prospects in the MFO landscape, spanning scalability, the composition of lower
fidelities, and the integration of human-in-the-loop approaches at the
algorithmic level. We also address critical issues related to benchmarking and
the advancement of open science within the MFO community. Overall, this survey
aims to catalyze further research and foster collaborations in MFO, setting the
stage for future innovations and breakthroughs in the field.</div><div><a href='http://arxiv.org/abs/2402.09638v1'>2402.09638v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.08118v1")'>Characterising harmful data sources when constructing multi-fidelity
  surrogate models</div>
<div id='2403.08118v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T22:57:53Z</div><div>Authors: Nicolau Andrés-Thió, Mario Andrés Muñoz, Kate Smith-Miles</div><div style='padding-top: 10px; width: 80ex'>Surrogate modelling techniques have seen growing attention in recent years
when applied to both modelling and optimisation of industrial design problems.
These techniques are highly relevant when assessing the performance of a
particular design carries a high cost, as the overall cost can be mitigated via
the construction of a model to be queried in lieu of the available high-cost
source. The construction of these models can sometimes employ other sources of
information which are both cheaper and less accurate. The existence of these
sources however poses the question of which sources should be used when
constructing a model. Recent studies have attempted to characterise harmful
data sources to guide practitioners in choosing when to ignore a certain
source. These studies have done so in a synthetic setting, characterising
sources using a large amount of data that is not available in practice. Some of
these studies have also been shown to potentially suffer from bias in the
benchmarks used in the analysis. In this study, we present a characterisation
of harmful low-fidelity sources using only the limited data available to train
a surrogate model. We employ recently developed benchmark filtering techniques
to conduct a bias-free assessment, providing objectively varied benchmark
suites of different sizes for future research. Analysing one of these benchmark
suites with the technique known as Instance Space Analysis, we provide an
intuitive visualisation of when a low-fidelity source should be used and use
this analysis to provide guidelines that can be used in an applied industrial
setting.</div><div><a href='http://arxiv.org/abs/2403.08118v1'>2403.08118v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.02008v1")'>Two-Stage Surrogate Modeling for Data-Driven Design Optimization with
  Application to Composite Microstructure Generation</div>
<div id='2401.02008v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-04T00:25:12Z</div><div>Authors: Farhad Pourkamali-Anaraki, Jamal F. Husseini, Evan J. Pineda, Brett A. Bednarcyk, Scott E. Stapleton</div><div style='padding-top: 10px; width: 80ex'>This paper introduces a novel two-stage machine learning-based surrogate
modeling framework to address inverse problems in scientific and engineering
fields. In the first stage of the proposed framework, a machine learning model
termed the "learner" identifies a limited set of candidates within the input
design space whose predicted outputs closely align with desired outcomes.
Subsequently, in the second stage, a separate surrogate model, functioning as
an "evaluator," is employed to assess the reduced candidate space generated in
the first stage. This evaluation process eliminates inaccurate and uncertain
solutions, guided by a user-defined coverage level. The framework's distinctive
contribution is the integration of conformal inference, providing a versatile
and efficient approach that can be widely applicable. To demonstrate the
effectiveness of the proposed framework compared to conventional single-stage
inverse problems, we conduct several benchmark tests and investigate an
engineering application focused on the micromechanical modeling of
fiber-reinforced composites. The results affirm the superiority of our proposed
framework, as it consistently produces more reliable solutions. Therefore, the
introduced framework offers a unique perspective on fostering interactions
between machine learning-based surrogate models in real-world applications.</div><div><a href='http://arxiv.org/abs/2401.02008v1'>2401.02008v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.14884v1")'>P3LS: Partial Least Squares under Privacy Preservation</div>
<div id='2401.14884v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-26T14:08:43Z</div><div>Authors: Du Nguyen Duy, Ramin Nikzad-Langerodi</div><div style='padding-top: 10px; width: 80ex'>Modern manufacturing value chains require intelligent orchestration of
processes across company borders in order to maximize profits while fostering
social and environmental sustainability. However, the implementation of
integrated, systems-level approaches for data-informed decision-making along
value chains is currently hampered by privacy concerns associated with
cross-organizational data exchange and integration. We here propose
Privacy-Preserving Partial Least Squares (P3LS) regression, a novel federated
learning technique that enables cross-organizational data integration and
process modeling with privacy guarantees. P3LS involves a singular value
decomposition (SVD) based PLS algorithm and employs removable, random masks
generated by a trusted authority in order to protect the privacy of the data
contributed by each data holder. We demonstrate the capability of P3LS to
vertically integrate process data along a hypothetical value chain consisting
of three parties and to improve the prediction performance on several
process-related key performance indicators. Furthermore, we show the numerical
equivalence of P3LS and PLS model components on simulated data and provide a
thorough privacy analysis of the former. Moreover, we propose a mechanism for
determining the relevance of the contributed data to the problem being
addressed, thus creating a basis for quantifying the contribution of
participants.</div><div><a href='http://arxiv.org/abs/2401.14884v1'>2401.14884v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.11345v1")'>Variational Entropy Search for Adjusting Expected Improvement</div>
<div id='2402.11345v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-17T17:37:53Z</div><div>Authors: Nuojin Cheng, Stephen Becker</div><div style='padding-top: 10px; width: 80ex'>Bayesian optimization is a widely used technique for optimizing black-box
functions, with Expected Improvement (EI) being the most commonly utilized
acquisition function in this domain. While EI is often viewed as distinct from
other information-theoretic acquisition functions, such as entropy search (ES)
and max-value entropy search (MES), our work reveals that EI can be considered
a special case of MES when approached through variational inference (VI). In
this context, we have developed the Variational Entropy Search (VES)
methodology and the VES-Gamma algorithm, which adapts EI by incorporating
principles from information-theoretic concepts. The efficacy of VES-Gamma is
demonstrated across a variety of test functions and read datasets, highlighting
its theoretical and practical utilities in Bayesian optimization scenarios.</div><div><a href='http://arxiv.org/abs/2402.11345v1'>2402.11345v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.13950v1")'>Evo* 2023 -- Late-Breaking Abstracts Volume</div>
<div id='2403.13950v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-20T19:42:11Z</div><div>Authors: A. M. Mora, A. I. Esparcia-Alcázar</div><div style='padding-top: 10px; width: 80ex'>Volume with the Late-Breaking Abstracts submitted to the Evo* 2023
Conference, held in Brno (Czech Republic), from 12 to 14 of April. These papers
present ongoing research and preliminary results investigating on the
application of different approaches of Bioinspired Methods (mainly Evolutionary
Computation) to different problems, most of them real world ones.</div><div><a href='http://arxiv.org/abs/2403.13950v1'>2403.13950v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.07733v1")'>Conformal Approach To Gaussian Process Surrogate Evaluation With
  Coverage Guarantees</div>
<div id='2401.07733v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T14:45:18Z</div><div>Authors: Edgar Jaber, Vincent Blot, Nicolas Brunel, Vincent Chabridon, Emmanuel Remy, Bertrand Iooss, Didier Lucor, Mathilde Mougeot, Alessandro Leite</div><div style='padding-top: 10px; width: 80ex'>Gaussian processes (GPs) are a Bayesian machine learning approach widely used
to construct surrogate models for the uncertainty quantification of computer
simulation codes in industrial applications. It provides both a mean predictor
and an estimate of the posterior prediction variance, the latter being used to
produce Bayesian credibility intervals. Interpreting these intervals relies on
the Gaussianity of the simulation model as well as the well-specification of
the priors which are not always appropriate. We propose to address this issue
with the help of conformal prediction. In the present work, a method for
building adaptive cross-conformal prediction intervals is proposed by weighting
the non-conformity score with the posterior standard deviation of the GP. The
resulting conformal prediction intervals exhibit a level of adaptivity akin to
Bayesian credibility sets and display a significant correlation with the
surrogate model local approximation error, while being free from the underlying
model assumptions and having frequentist coverage guarantees. These estimators
can thus be used for evaluating the quality of a GP surrogate model and can
assist a decision-maker in the choice of the best prior for the specific
application of the GP. The performance of the method is illustrated through a
panel of numerical examples based on various reference databases. Moreover, the
potential applicability of the method is demonstrated in the context of
surrogate modeling of an expensive-to-evaluate simulator of the clogging
phenomenon in steam generators of nuclear reactors.</div><div><a href='http://arxiv.org/abs/2401.07733v1'>2401.07733v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.11365v1")'>Data-Driven Stochastic AC-OPF using Gaussian Processes</div>
<div id='2402.11365v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-17T19:30:33Z</div><div>Authors: Mile Mitrovic</div><div style='padding-top: 10px; width: 80ex'>The thesis focuses on developing a data-driven algorithm, based on machine
learning, to solve the stochastic alternating current (AC) chance-constrained
(CC) Optimal Power Flow (OPF) problem. Although the AC CC-OPF problem has been
successful in academic circles, it is highly nonlinear and computationally
demanding, which limits its practical impact. The proposed approach aims to
address this limitation and demonstrate its empirical efficiency through
applications to multiple IEEE test cases. To solve the non-convex and
computationally challenging CC AC-OPF problem, the proposed approach relies on
a machine learning Gaussian process regression (GPR) model. The full Gaussian
process (GP) approach is capable of learning a simple yet non-convex
data-driven approximation to the AC power flow equations that can incorporate
uncertain inputs. The proposed approach uses various approximations for
GP-uncertainty propagation. The full GP CC-OPF approach exhibits highly
competitive and promising results, outperforming the state-of-the-art
sample-based chance constraint approaches. To further improve the robustness
and complexity/accuracy trade-off of the full GP CC-OPF, a fast data-driven
setup is proposed. This setup relies on the sparse and hybrid Gaussian
processes (GP) framework to model the power flow equations with input
uncertainty.</div><div><a href='http://arxiv.org/abs/2402.11365v1'>2402.11365v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.18859v1")'>Taking Second-life Batteries from Exhausted to Empowered using
  Experiments, Data Analysis, and Health Estimation</div>
<div id='2402.18859v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T05:17:36Z</div><div>Authors: Xiaofan Cui, Muhammad Aadil Khan, Gabriele Pozzato, Surinder Singh, Ratnesh Sharma, Simona Onori</div><div style='padding-top: 10px; width: 80ex'>The reuse of retired electric vehicle (EV) batteries in electric grid energy
storage emerges as a promising strategy to address environmental concerns and
boost economic value. This study concentrates on devising health monitoring
algorithms for retired batteries (BMS$_2$) deployed in grid storage
applications. Over 15 months of testing, we compile, analyze, and publicly
share a dataset of second-life (SL) batteries, implementing a cycling protocol
simulating grid energy storage load profiles within a 3 V-4 V voltage window.
Four machine learning-based health estimation models, relying on BMS$_2$
features and initial capacity, are developed and compared, with the selected
model achieving a Mean Absolute Percentage Error (MAPE) below 2.3% on test
data. Additionally, an adaptive online health estimation algorithm is proposed
by integrating a clustering-based method, limiting estimation errors during
online deployment. These results constitute an initial proof of concept,
showcasing the feasibility of repurposing retired batteries for second-life
applications. Based on obtained data and representative power demand, these SL
batteries exhibit the potential, under specific conditions, for over a decade
of grid energy storage use.</div><div><a href='http://arxiv.org/abs/2402.18859v1'>2402.18859v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.09486v1")'>UMOEA/D: A Multiobjective Evolutionary Algorithm for Uniform Pareto
  Objectives based on Decomposition</div>
<div id='2402.09486v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T08:09:46Z</div><div>Authors: Xiaoyuan Zhang, Xi Lin, Yichi Zhang, Yifan Chen, Qingfu Zhang</div><div style='padding-top: 10px; width: 80ex'>Multiobjective optimization (MOO) is prevalent in numerous applications, in
which a Pareto front (PF) is constructed to display optima under various
preferences. Previous methods commonly utilize the set of Pareto objectives
(particles on the PF) to represent the entire PF. However, the empirical
distribution of the Pareto objectives on the PF is rarely studied, which
implicitly impedes the generation of diverse and representative Pareto
objectives in previous methods. To bridge the gap, we suggest in this paper
constructing \emph{uniformly distributed} Pareto objectives on the PF, so as to
alleviate the limited diversity found in previous MOO approaches. We are the
first to formally define the concept of ``uniformity" for an MOO problem. We
optimize the maximal minimal distances on the Pareto front using a neural
network, resulting in both asymptotically and non-asymptotically uniform Pareto
objectives. Our proposed method is validated through experiments on real-world
and synthetic problems, which demonstrates the efficacy in generating
high-quality uniform Pareto objectives and the encouraging performance
exceeding existing state-of-the-art methods.
  The detailed model implementation and the code are scheduled to be
open-sourced upon publication.</div><div><a href='http://arxiv.org/abs/2402.09486v1'>2402.09486v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.01192v1")'>Deep-ELA: Deep Exploratory Landscape Analysis with Self-Supervised
  Pretrained Transformers for Single- and Multi-Objective Continuous
  Optimization Problems</div>
<div id='2401.01192v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-02T12:41:17Z</div><div>Authors: Moritz Vinzent Seiler, Pascal Kerschke, Heike Trautmann</div><div style='padding-top: 10px; width: 80ex'>In many recent works, the potential of Exploratory Landscape Analysis (ELA)
features to numerically characterize, in particular, single-objective
continuous optimization problems has been demonstrated. These numerical
features provide the input for all kinds of machine learning tasks on
continuous optimization problems, ranging, i.a., from High-level Property
Prediction to Automated Algorithm Selection and Automated Algorithm
Configuration. Without ELA features, analyzing and understanding the
characteristics of single-objective continuous optimization problems would be
impossible.
  Yet, despite their undisputed usefulness, ELA features suffer from several
drawbacks. These include, in particular, (1.) a strong correlation between
multiple features, as well as (2.) its very limited applicability to
multi-objective continuous optimization problems. As a remedy, recent works
proposed deep learning-based approaches as alternatives to ELA. In these works,
e.g., point-cloud transformers were used to characterize an optimization
problem's fitness landscape. However, these approaches require a large amount
of labeled training data.
  Within this work, we propose a hybrid approach, Deep-ELA, which combines (the
benefits of) deep learning and ELA features. Specifically, we pre-trained four
transformers on millions of randomly generated optimization problems to learn
deep representations of the landscapes of continuous single- and
multi-objective optimization problems. Our proposed framework can either be
used out-of-the-box for analyzing single- and multi-objective continuous
optimization problems, or subsequently fine-tuned to various tasks focussing on
algorithm behavior and problem understanding.</div><div><a href='http://arxiv.org/abs/2401.01192v1'>2401.01192v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.15941v1")'>Implementing Recycling Methods for Linear Systems in Python with an
  Application to Multiple Objective Optimization</div>
<div id='2402.15941v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-25T00:15:30Z</div><div>Authors: Ainara Garcia, Sihong Xie, Arielle Carr</div><div style='padding-top: 10px; width: 80ex'>Sequences of linear systems arise in the predictor-corrector method when
computing the Pareto front for multi-objective optimization. Rather than
discarding information generated when solving one system, it may be
advantageous to recycle information for subsequent systems. To accomplish this,
we seek to reduce the overall cost of computation when solving linear systems
using common recycling methods. In this work, we assessed the performance of
recycling minimum residual (RMINRES) method along with a map between
coefficient matrices. For these methods to be fully integrated into the
software used in Enouen et al. (2022), there must be working version of each in
both Python and PyTorch. Herein, we discuss the challenges we encountered and
solutions undertaken (and some ongoing) when computing efficient Python
implementations of these recycling strategies. The goal of this project was to
implement RMINRES in Python and PyTorch and add it to the established Pareto
front code to reduce computational cost. Additionally, we wanted to implement
the sparse approximate maps code in Python and PyTorch, so that it can be
parallelized in future work.</div><div><a href='http://arxiv.org/abs/2402.15941v1'>2402.15941v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.01192v2")'>A Composite Decomposition Method for Large-Scale Global Optimization</div>
<div id='2403.01192v2' style='display: none; margin-left: 20px'><div>Date: 2024-03-02T12:12:04Z</div><div>Authors: Maojiang Tian, Minyang Chen, Wei Du, Yang Tang, Yaochu Jin, Gary G. Yen</div><div style='padding-top: 10px; width: 80ex'>Cooperative co-evolution (CC) algorithms, based on the divide-and-conquer
strategy, have emerged as the predominant approach to solving large-scale
global optimization (LSGO) problems. The efficiency and accuracy of the
grouping stage significantly impact the performance of the optimization
process. While the general separability grouping (GSG) method has overcome the
limitation of previous differential grouping (DG) methods by enabling the
decomposition of non-additively separable functions, it suffers from high
computational complexity. To address this challenge, this article proposes a
composite separability grouping (CSG) method, seamlessly integrating DG and GSG
into a problem decomposition framework to utilize the strengths of both
approaches. CSG introduces a step-by-step decomposition framework that
accurately decomposes various problem types using fewer computational
resources. By sequentially identifying additively, multiplicatively and
generally separable variables, CSG progressively groups non-separable variables
by recursively considering the interactions between each non-separable variable
and the formed non-separable groups. Furthermore, to enhance the efficiency and
accuracy of CSG, we introduce two innovative methods: a multiplicatively
separable variable detection method and a non-separable variable grouping
method. These two methods are designed to effectively detect multiplicatively
separable variables and efficiently group non-separable variables,
respectively. Extensive experimental results demonstrate that CSG achieves more
accurate variable grouping with lower computational complexity compared to GSG
and state-of-the-art DG series designs.</div><div><a href='http://arxiv.org/abs/2403.01192v2'>2403.01192v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16683v1")'>Polynomial Chaos Expansions on Principal Geodesic Grassmannian
  Submanifolds for Surrogate Modeling and Uncertainty Quantification</div>
<div id='2401.16683v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T02:13:02Z</div><div>Authors: Dimitris G. Giovanis, Dimitrios Loukrezis, Ioannis G. Kevrekidis, Michael D. Shields</div><div style='padding-top: 10px; width: 80ex'>In this work we introduce a manifold learning-based surrogate modeling
framework for uncertainty quantification in high-dimensional stochastic
systems. Our first goal is to perform data mining on the available simulation
data to identify a set of low-dimensional (latent) descriptors that efficiently
parameterize the response of the high-dimensional computational model. To this
end, we employ Principal Geodesic Analysis on the Grassmann manifold of the
response to identify a set of disjoint principal geodesic submanifolds, of
possibly different dimension, that captures the variation in the data. Since
operations on the Grassmann require the data to be concentrated, we propose an
adaptive algorithm based on Riemanniann K-means and the minimization of the
sample Frechet variance on the Grassmann manifold to identify "local" principal
geodesic submanifolds that represent different system behavior across the
parameter space. Polynomial chaos expansion is then used to construct a mapping
between the random input parameters and the projection of the response on these
local principal geodesic submanifolds. The method is demonstrated on four test
cases, a toy-example that involves points on a hypersphere, a Lotka-Volterra
dynamical system, a continuous-flow stirred-tank chemical reactor system, and a
two-dimensional Rayleigh-Benard convection problem</div><div><a href='http://arxiv.org/abs/2401.16683v1'>2401.16683v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.05882v1")'>DiffRed: Dimensionality Reduction guided by stable rank</div>
<div id='2403.05882v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-09T11:24:34Z</div><div>Authors: Prarabdh Shukla, Gagan Raj Gupta, Kunal Dutta</div><div style='padding-top: 10px; width: 80ex'>In this work, we propose a novel dimensionality reduction technique, DiffRed,
which first projects the data matrix, A, along first $k_1$ principal components
and the residual matrix $A^{*}$ (left after subtracting its $k_1$-rank
approximation) along $k_2$ Gaussian random vectors. We evaluate M1, the
distortion of mean-squared pair-wise distance, and Stress, the normalized value
of RMS of distortion of the pairwise distances. We rigorously prove that
DiffRed achieves a general upper bound of
$O\left(\sqrt{\frac{1-p}{k_2}}\right)$ on Stress and
$O\left(\frac{(1-p)}{\sqrt{k_2*\rho(A^{*})}}\right)$ on M1 where $p$ is the
fraction of variance explained by the first $k_1$ principal components and
$\rho(A^{*})$ is the stable rank of $A^{*}$. These bounds are tighter than the
currently known results for Random maps. Our extensive experiments on a variety
of real-world datasets demonstrate that DiffRed achieves near zero M1 and much
lower values of Stress as compared to the well-known dimensionality reduction
techniques. In particular, DiffRed can map a 6 million dimensional dataset to
10 dimensions with 54% lower Stress than PCA.</div><div><a href='http://arxiv.org/abs/2403.05882v1'>2403.05882v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.01100v2")'>Scalable manifold learning by uniform landmark sampling and constrained
  locally linear embedding</div>
<div id='2401.01100v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-02T08:43:06Z</div><div>Authors: Dehua Peng, Zhipeng Gui, Wenzhang Wei, Huayi Wu</div><div style='padding-top: 10px; width: 80ex'>As a pivotal approach in machine learning and data science, manifold learning
aims to uncover the intrinsic low-dimensional structure within complex
nonlinear manifolds in high-dimensional space. By exploiting the manifold
hypothesis, various techniques for nonlinear dimension reduction have been
developed to facilitate visualization, classification, clustering, and gaining
key insights. Although existing manifold learning methods have achieved
remarkable successes, they still suffer from extensive distortions incurred in
the global structure, which hinders the understanding of underlying patterns.
Scalability issues also limit their applicability for handling large-scale
data. Here, we propose a scalable manifold learning (scML) method that can
manipulate large-scale and high-dimensional data in an efficient manner. It
starts by seeking a set of landmarks to construct the low-dimensional skeleton
of the entire data, and then incorporates the non-landmarks into the learned
space based on the constrained locally linear embedding (CLLE). We empirically
validated the effectiveness of scML on synthetic datasets and real-world
benchmarks of different types, and applied it to analyze the single-cell
transcriptomics and detect anomalies in electrocardiogram (ECG) signals. scML
scales well with increasing data sizes and embedding dimensions, and exhibits
promising performance in preserving the global structure. The experiments
demonstrate notable robustness in embedding quality as the sample rate
decreases.</div><div><a href='http://arxiv.org/abs/2401.01100v2'>2401.01100v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.02203v1")'>Robust bilinear factor analysis based on the matrix-variate $t$
  distribution</div>
<div id='2401.02203v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-04T11:15:44Z</div><div>Authors: Xuan Ma, Jianhua Zhao, Changchun Shang, Fen Jiang, Philip L. H. Yu</div><div style='padding-top: 10px; width: 80ex'>Factor Analysis based on multivariate $t$ distribution ($t$fa) is a useful
robust tool for extracting common factors on heavy-tailed or contaminated data.
However, $t$fa is only applicable to vector data. When $t$fa is applied to
matrix data, it is common to first vectorize the matrix observations. This
introduces two challenges for $t$fa: (i) the inherent matrix structure of the
data is broken, and (ii) robustness may be lost, as vectorized matrix data
typically results in a high data dimension, which could easily lead to the
breakdown of $t$fa. To address these issues, starting from the intrinsic matrix
structure of matrix data, a novel robust factor analysis model, namely bilinear
factor analysis built on the matrix-variate $t$ distribution ($t$bfa), is
proposed in this paper. The novelty is that it is capable to simultaneously
extract common factors for both row and column variables of interest on
heavy-tailed or contaminated matrix data. Two efficient algorithms for maximum
likelihood estimation of $t$bfa are developed. Closed-form expression for the
Fisher information matrix to calculate the accuracy of parameter estimates are
derived. Empirical studies are conducted to understand the proposed $t$bfa
model and compare with related competitors. The results demonstrate the
superiority and practicality of $t$bfa. Importantly, $t$bfa exhibits a
significantly higher breakdown point than $t$fa, making it more suitable for
matrix data.</div><div><a href='http://arxiv.org/abs/2401.02203v1'>2401.02203v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03905v2")'>Black-Box $k$-to-$1$-PCA Reductions: Theory and Applications</div>
<div id='2403.03905v2' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T18:07:20Z</div><div>Authors: Arun Jambulapati, Syamantak Kumar, Jerry Li, Shourya Pandey, Ankit Pensia, Kevin Tian</div><div style='padding-top: 10px; width: 80ex'>The $k$-principal component analysis ($k$-PCA) problem is a fundamental
algorithmic primitive that is widely-used in data analysis and dimensionality
reduction applications. In statistical settings, the goal of $k$-PCA is to
identify a top eigenspace of the covariance matrix of a distribution, which we
only have implicit access to via samples. Motivated by these implicit settings,
we analyze black-box deflation methods as a framework for designing $k$-PCA
algorithms, where we model access to the unknown target matrix via a black-box
$1$-PCA oracle which returns an approximate top eigenvector, under two popular
notions of approximation. Despite being arguably the most natural
reduction-based approach to $k$-PCA algorithm design, such black-box methods,
which recursively call a $1$-PCA oracle $k$ times, were previously
poorly-understood.
  Our main contribution is significantly sharper bounds on the approximation
parameter degradation of deflation methods for $k$-PCA. For a quadratic form
notion of approximation we term ePCA (energy PCA), we show deflation methods
suffer no parameter loss. For an alternative well-studied approximation notion
we term cPCA (correlation PCA), we tightly characterize the parameter regimes
where deflation methods are feasible. Moreover, we show that in all feasible
regimes, $k$-cPCA deflation algorithms suffer no asymptotic parameter loss for
any constant $k$. We apply our framework to obtain state-of-the-art $k$-PCA
algorithms robust to dataset contamination, improving prior work both in sample
complexity and approximation quality.</div><div><a href='http://arxiv.org/abs/2403.03905v2'>2403.03905v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07240v2")'>Thresholded Oja does Sparse PCA?</div>
<div id='2402.07240v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-11T16:36:48Z</div><div>Authors: Syamantak Kumar, Purnamrita Sarkar</div><div style='padding-top: 10px; width: 80ex'>We consider the problem of Sparse Principal Component Analysis (PCA) when the
ratio $d/n \rightarrow c &gt; 0$. There has been a lot of work on optimal rates on
sparse PCA in the offline setting, where all the data is available for multiple
passes. In contrast, when the population eigenvector is $s$-sparse, streaming
algorithms that have $O(d)$ storage and $O(nd)$ time complexity either
typically require strong initialization conditions or have a suboptimal error.
We show that a simple algorithm that thresholds and renormalizes the output of
Oja's algorithm (the Oja vector) obtains a near-optimal error rate. This is
very surprising because, without thresholding, the Oja vector has a large
error. Our analysis centers around bounding the entries of the unnormalized Oja
vector, which involves the projection of a product of independent random
matrices on a random initial vector. This is nontrivial and novel since
previous analyses of Oja's algorithm and matrix products have been done when
the trace of the population covariance matrix is bounded while in our setting,
this quantity can be as large as $n$.</div><div><a href='http://arxiv.org/abs/2402.07240v2'>2402.07240v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.08134v1")'>Randomized Algorithms for Symmetric Nonnegative Matrix Factorization</div>
<div id='2402.08134v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T00:02:05Z</div><div>Authors: Koby Hayashi, Sinan G. Aksoy, Grey Ballard, Haesun Park</div><div style='padding-top: 10px; width: 80ex'>Symmetric Nonnegative Matrix Factorization (SymNMF) is a technique in data
analysis and machine learning that approximates a symmetric matrix with a
product of a nonnegative, low-rank matrix and its transpose. To design faster
and more scalable algorithms for SymNMF we develop two randomized algorithms
for its computation. The first algorithm uses randomized matrix sketching to
compute an initial low-rank input matrix and proceeds to use this input to
rapidly compute a SymNMF. The second algorithm uses randomized leverage score
sampling to approximately solve constrained least squares problems. Many
successful methods for SymNMF rely on (approximately) solving sequences of
constrained least squares problems. We prove theoretically that leverage score
sampling can approximately solve nonnegative least squares problems to a chosen
accuracy with high probability. Finally we demonstrate that both methods work
well in practice by applying them to graph clustering tasks on large real world
data sets. These experiments show that our methods approximately maintain
solution quality and achieve significant speed ups for both large dense and
large sparse problems.</div><div><a href='http://arxiv.org/abs/2402.08134v1'>2402.08134v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.00184v1")'>Entry-Specific Bounds for Low-Rank Matrix Completion under Highly
  Non-Uniform Sampling</div>
<div id='2403.00184v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T23:24:43Z</div><div>Authors: Xumei Xi, Christina Lee Yu, Yudong Chen</div><div style='padding-top: 10px; width: 80ex'>Low-rank matrix completion concerns the problem of estimating unobserved
entries in a matrix using a sparse set of observed entries. We consider the
non-uniform setting where the observed entries are sampled with highly varying
probabilities, potentially with different asymptotic scalings. We show that
under structured sampling probabilities, it is often better and sometimes
optimal to run estimation algorithms on a smaller submatrix rather than the
entire matrix. In particular, we prove error upper bounds customized to each
entry, which match the minimax lower bounds under certain conditions. Our
bounds characterize the hardness of estimating each entry as a function of the
localized sampling probabilities. We provide numerical experiments that confirm
our theoretical findings.</div><div><a href='http://arxiv.org/abs/2403.00184v1'>2403.00184v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.10547v1")'>Robust Second-Order Nonconvex Optimization and Its Application to Low
  Rank Matrix Sensing</div>
<div id='2403.10547v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T01:27:44Z</div><div>Authors: Shuyao Li, Yu Cheng, Ilias Diakonikolas, Jelena Diakonikolas, Rong Ge, Stephen J. Wright</div><div style='padding-top: 10px; width: 80ex'>Finding an approximate second-order stationary point (SOSP) is a well-studied
and fundamental problem in stochastic nonconvex optimization with many
applications in machine learning. However, this problem is poorly understood in
the presence of outliers, limiting the use of existing nonconvex algorithms in
adversarial settings.
  In this paper, we study the problem of finding SOSPs in the strong
contamination model, where a constant fraction of datapoints are arbitrarily
corrupted. We introduce a general framework for efficiently finding an
approximate SOSP with \emph{dimension-independent} accuracy guarantees, using
$\widetilde{O}({D^2}/{\epsilon})$ samples where $D$ is the ambient dimension
and $\epsilon$ is the fraction of corrupted datapoints.
  As a concrete application of our framework, we apply it to the problem of low
rank matrix sensing, developing efficient and provably robust algorithms that
can tolerate corruptions in both the sensing matrices and the measurements. In
addition, we establish a Statistical Query lower bound providing evidence that
the quadratic dependence on $D$ in the sample complexity is necessary for
computationally efficient algorithms.</div><div><a href='http://arxiv.org/abs/2403.10547v1'>2403.10547v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04726v1")'>A Sub-Quadratic Time Algorithm for Robust Sparse Mean Estimation</div>
<div id='2403.04726v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T18:23:51Z</div><div>Authors: Ankit Pensia</div><div style='padding-top: 10px; width: 80ex'>We study the algorithmic problem of sparse mean estimation in the presence of
adversarial outliers. Specifically, the algorithm observes a \emph{corrupted}
set of samples from $\mathcal{N}(\mu,\mathbf{I}_d)$, where the unknown mean
$\mu \in \mathbb{R}^d$ is constrained to be $k$-sparse. A series of prior works
has developed efficient algorithms for robust sparse mean estimation with
sample complexity $\mathrm{poly}(k,\log d, 1/\epsilon)$ and runtime $d^2
\mathrm{poly}(k,\log d,1/\epsilon)$, where $\epsilon$ is the fraction of
contamination. In particular, the fastest runtime of existing algorithms is
quadratic ($\Omega(d^2)$), which can be prohibitive in high dimensions. This
quadratic barrier in the runtime stems from the reliance of these algorithms on
the sample covariance matrix, which is of size $d^2$. Our main contribution is
an algorithm for robust sparse mean estimation which runs in
\emph{subquadratic} time using $\mathrm{poly}(k,\log d,1/\epsilon)$ samples. We
also provide analogous results for robust sparse PCA. Our results build on
algorithmic advances in detecting weak correlations, a generalized version of
the light-bulb problem by Valiant.</div><div><a href='http://arxiv.org/abs/2403.04726v1'>2403.04726v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14925v1")'>Efficient Unbiased Sparsification</div>
<div id='2402.14925v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T19:15:50Z</div><div>Authors: Leighton Barnes, Timothy Chow, Emma Cohen, Keith Frankston, Benjamin Howard, Fred Kochman, Daniel Scheinerman, Jeffrey VanderKam</div><div style='padding-top: 10px; width: 80ex'>An unbiased $m$-sparsification of a vector $p\in \mathbb{R}^n$ is a random
vector $Q\in \mathbb{R}^n$ with mean $p$ that has at most $m&lt;n$ nonzero
coordinates. Unbiased sparsification compresses the original vector without
introducing bias; it arises in various contexts, such as in federated learning
and sampling sparse probability distributions. Ideally, unbiased sparsification
should also minimize the expected value of a divergence function
$\mathsf{Div}(Q,p)$ that measures how far away $Q$ is from the original $p$. If
$Q$ is optimal in this sense, then we call it efficient. Our main results
describe efficient unbiased sparsifications for divergences that are either
permutation-invariant or additively separable. Surprisingly, the
characterization for permutation-invariant divergences is robust to the choice
of divergence function, in the sense that our class of optimal $Q$ for squared
Euclidean distance coincides with our class of optimal $Q$ for Kullback-Leibler
divergence, or indeed any of a wide variety of divergences.</div><div><a href='http://arxiv.org/abs/2402.14925v1'>2402.14925v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.08425v1")'>Transfer Operators from Batches of Unpaired Points via Entropic
  Transport Kernels</div>
<div id='2402.08425v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T12:52:41Z</div><div>Authors: Florian Beier, Hancheng Bi, Clément Sarrazin, Bernhard Schmitzer, Gabriele Steidl</div><div style='padding-top: 10px; width: 80ex'>In this paper, we are concerned with estimating the joint probability of
random variables $X$ and $Y$, given $N$ independent observation blocks
$(\boldsymbol{x}^i,\boldsymbol{y}^i)$, $i=1,\ldots,N$, each of $M$ samples
$(\boldsymbol{x}^i,\boldsymbol{y}^i) = \bigl((x^i_j, y^i_{\sigma^i(j)})
\bigr)_{j=1}^M$, where $\sigma^i$ denotes an unknown permutation of i.i.d.
sampled pairs $(x^i_j,y_j^i)$, $j=1,\ldots,M$. This means that the internal
ordering of the $M$ samples within an observation block is not known. We derive
a maximum-likelihood inference functional, propose a computationally tractable
approximation and analyze their properties. In particular, we prove a
$\Gamma$-convergence result showing that we can recover the true density from
empirical approximations as the number $N$ of blocks goes to infinity. Using
entropic optimal transport kernels, we model a class of hypothesis spaces of
density functions over which the inference functional can be minimized. This
hypothesis class is particularly suited for approximate inference of transfer
operators from data. We solve the resulting discrete minimization problem by a
modification of the EMML algorithm to take addional transition probability
constraints into account and prove the convergence of this algorithm.
Proof-of-concept examples demonstrate the potential of our method.</div><div><a href='http://arxiv.org/abs/2402.08425v1'>2402.08425v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.07445v1")'>Top-$K$ ranking with a monotone adversary</div>
<div id='2402.07445v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-12T06:57:34Z</div><div>Authors: Yuepeng Yang, Antares Chen, Lorenzo Orecchia, Cong Ma</div><div style='padding-top: 10px; width: 80ex'>In this paper, we address the top-$K$ ranking problem with a monotone
adversary. We consider the scenario where a comparison graph is randomly
generated and the adversary is allowed to add arbitrary edges. The
statistician's goal is then to accurately identify the top-$K$ preferred items
based on pairwise comparisons derived from this semi-random comparison graph.
The main contribution of this paper is to develop a weighted maximum likelihood
estimator (MLE) that achieves near-optimal sample complexity, up to a
$\log^2(n)$ factor, where n denotes the number of items under comparison. This
is made possible through a combination of analytical and algorithmic
innovations. On the analytical front, we provide a refined $\ell_\infty$ error
analysis of the weighted MLE that is more explicit and tighter than existing
analyses. It relates the $\ell_\infty$ error with the spectral properties of
the weighted comparison graph. Motivated by this, our algorithmic innovation
involves the development of an SDP-based approach to reweight the semi-random
graph and meet specified spectral properties. Additionally, we propose a
first-order method based on the Matrix Multiplicative Weight Update (MMWU)
framework. This method efficiently solves the resulting SDP in nearly-linear
time relative to the size of the semi-random comparison graph.</div><div><a href='http://arxiv.org/abs/2402.07445v1'>2402.07445v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14305v1")'>Towards Efficient Pareto-optimal Utility-Fairness between Groups in
  Repeated Rankings</div>
<div id='2402.14305v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T05:48:54Z</div><div>Authors: Phuong Dinh Mai, Duc-Trong Le, Tuan-Anh Hoang, Dung D. Le</div><div style='padding-top: 10px; width: 80ex'>In this paper, we tackle the problem of computing a sequence of rankings with
the guarantee of the Pareto-optimal balance between (1) maximizing the utility
of the consumers and (2) minimizing unfairness between producers of the items.
Such a multi-objective optimization problem is typically solved using a
combination of a scalarization method and linear programming on bi-stochastic
matrices, representing the distribution of possible rankings of items. However,
the above-mentioned approach relies on Birkhoff-von Neumann (BvN)
decomposition, of which the computational complexity is $\mathcal{O}(n^5)$ with
$n$ being the number of items, making it impractical for large-scale systems.
To address this drawback, we introduce a novel approach to the above problem by
using the Expohedron - a permutahedron whose points represent all achievable
exposures of items. On the Expohedron, we profile the Pareto curve which
captures the trade-off between group fairness and user utility by identifying a
finite number of Pareto optimal solutions. We further propose an efficient
method by relaxing our optimization problem on the Expohedron's circumscribed
$n$-sphere, which significantly improve the running time. Moreover, the
approximate Pareto curve is asymptotically close to the real Pareto optimal
curve as the number of substantial solutions increases. Our methods are
applicable with different ranking merits that are non-decreasing functions of
item relevance. The effectiveness of our methods are validated through
experiments on both synthetic and real-world datasets.</div><div><a href='http://arxiv.org/abs/2402.14305v1'>2402.14305v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03252v1")'>Fair Active Ranking from Pairwise Preferences</div>
<div id='2402.03252v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T18:09:48Z</div><div>Authors: Sruthi Gorantla, Sara Ahmadian</div><div style='padding-top: 10px; width: 80ex'>We investigate the problem of probably approximately correct and fair (PACF)
ranking of items by adaptively evoking pairwise comparisons. Given a set of $n$
items that belong to disjoint groups, our goal is to find an $(\epsilon,
\delta)$-PACF-Ranking according to a fair objective function that we propose.
We assume access to an oracle, wherein, for each query, the learner can choose
a pair of items and receive stochastic winner feedback from the oracle. Our
proposed objective function asks to minimize the $\ell_q$ norm of the error of
the groups, where the error of a group is the $\ell_p$ norm of the error of all
the items within that group, for $p, q \geq 1$. This generalizes the objective
function of $\epsilon$-Best-Ranking, proposed by Saha &amp; Gopalan (2019).
  By adopting our objective function, we gain the flexibility to explore
fundamental fairness concepts like equal or proportionate errors within a
unified framework. Adjusting parameters $p$ and $q$ allows tailoring to
specific fairness preferences. We present both group-blind and group-aware
algorithms and analyze their sample complexity. We provide matching lower
bounds up to certain logarithmic factors for group-blind algorithms. For a
restricted class of group-aware algorithms, we show that we can get reasonable
lower bounds. We conduct comprehensive experiments on both real-world and
synthetic datasets to complement our theoretical findings.</div><div><a href='http://arxiv.org/abs/2402.03252v1'>2402.03252v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09326v1")'>Stability and Multigroup Fairness in Ranking with Uncertain Predictions</div>
<div id='2402.09326v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T17:17:05Z</div><div>Authors: Siddartha Devic, Aleksandra Korolova, David Kempe, Vatsal Sharan</div><div style='padding-top: 10px; width: 80ex'>Rankings are ubiquitous across many applications, from search engines to
hiring committees. In practice, many rankings are derived from the output of
predictors. However, when predictors trained for classification tasks have
intrinsic uncertainty, it is not obvious how this uncertainty should be
represented in the derived rankings. Our work considers ranking functions: maps
from individual predictions for a classification task to distributions over
rankings. We focus on two aspects of ranking functions: stability to
perturbations in predictions and fairness towards both individuals and
subgroups. Not only is stability an important requirement for its own sake, but
-- as we show -- it composes harmoniously with individual fairness in the sense
of Dwork et al. (2012). While deterministic ranking functions cannot be stable
aside from trivial scenarios, we show that the recently proposed uncertainty
aware (UA) ranking functions of Singh et al. (2021) are stable. Our main result
is that UA rankings also achieve multigroup fairness through successful
composition with multiaccurate or multicalibrated predictors. Our work
demonstrates that UA rankings naturally interpolate between group and
individual level fairness guarantees, while simultaneously satisfying stability
guarantees important whenever machine-learned predictions are used.</div><div><a href='http://arxiv.org/abs/2402.09326v1'>2402.09326v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13391v1")'>Beyond Accuracy-Fairness: Stop evaluating bias mitigation methods solely
  on between-group metrics</div>
<div id='2401.13391v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T11:41:30Z</div><div>Authors: Sofie Goethals, Toon Calders, David Martens</div><div style='padding-top: 10px; width: 80ex'>Artificial Intelligence (AI) finds widespread applications across various
domains, sparking concerns about fairness in its deployment. While fairness in
AI remains a central concern, the prevailing discourse often emphasizes
outcome-based metrics without a nuanced consideration of the differential
impacts within subgroups. Bias mitigation techniques do not only affect the
ranking of pairs of instances across sensitive groups, but often also
significantly affect the ranking of instances within these groups. Such changes
are hard to explain and raise concerns regarding the validity of the
intervention. Unfortunately, these effects largely remain under the radar in
the accuracy-fairness evaluation framework that is usually applied. This paper
challenges the prevailing metrics for assessing bias mitigation techniques,
arguing that they do not take into account the changes within-groups and that
the resulting prediction labels fall short of reflecting real-world scenarios.
We propose a paradigm shift: initially, we should focus on generating the most
precise ranking for each subgroup. Following this, individuals should be chosen
from these rankings to meet both fairness standards and practical
considerations.</div><div><a href='http://arxiv.org/abs/2401.13391v1'>2401.13391v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.14893v1")'>A structured regression approach for evaluating model performance across
  intersectional subgroups</div>
<div id='2401.14893v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-26T14:21:45Z</div><div>Authors: Christine Herlihy, Kimberly Truong, Alexandra Chouldechova, Miroslav Dudik</div><div style='padding-top: 10px; width: 80ex'>Disaggregated evaluation is a central task in AI fairness assessment, with
the goal to measure an AI system's performance across different subgroups
defined by combinations of demographic or other sensitive attributes. The
standard approach is to stratify the evaluation data across subgroups and
compute performance metrics separately for each group. However, even for
moderately-sized evaluation datasets, sample sizes quickly get small once
considering intersectional subgroups, which greatly limits the extent to which
intersectional groups are considered in many disaggregated evaluations. In this
work, we introduce a structured regression approach to disaggregated evaluation
that we demonstrate can yield reliable system performance estimates even for
very small subgroups. We also provide corresponding inference strategies for
constructing confidence intervals and explore how goodness-of-fit testing can
yield insight into the structure of fairness-related harms experienced by
intersectional groups. We evaluate our approach on two publicly available
datasets, and several variants of semi-synthetic data. The results show that
our method is considerably more accurate than the standard approach, especially
for small subgroups, and goodness-of-fit testing helps identify the key factors
that drive differences in performance.</div><div><a href='http://arxiv.org/abs/2401.14893v1'>2401.14893v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16088v1")'>Fairness in Algorithmic Recourse Through the Lens of Substantive
  Equality of Opportunity</div>
<div id='2401.16088v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T11:55:45Z</div><div>Authors: Andrew Bell, Joao Fonseca, Carlo Abrate, Francesco Bonchi, Julia Stoyanovich</div><div style='padding-top: 10px; width: 80ex'>Algorithmic recourse -- providing recommendations to those affected
negatively by the outcome of an algorithmic system on how they can take action
and change that outcome -- has gained attention as a means of giving persons
agency in their interactions with artificial intelligence (AI) systems. Recent
work has shown that even if an AI decision-making classifier is ``fair''
(according to some reasonable criteria), recourse itself may be unfair due to
differences in the initial circumstances of individuals, compounding
disparities for marginalized populations and requiring them to exert more
effort than others. There is a need to define more methods and metrics for
evaluating fairness in recourse that span a range of normative views of the
world, and specifically those that take into account time. Time is a critical
element in recourse because the longer it takes an individual to act, the more
the setting may change due to model or data drift.
  This paper seeks to close this research gap by proposing two notions of
fairness in recourse that are in normative alignment with substantive equality
of opportunity, and that consider time. The first considers the (often
repeated) effort individuals exert per successful recourse event, and the
second considers time per successful recourse event. Building upon an
agent-based framework for simulating recourse, this paper demonstrates how much
effort is needed to overcome disparities in initial circumstances. We then
proposes an intervention to improve the fairness of recourse by rewarding
effort, and compare it to existing strategies.</div><div><a href='http://arxiv.org/abs/2401.16088v1'>2401.16088v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.05540v1")'>Extinction Risks from AI: Invisible to Science?</div>
<div id='2403.05540v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T23:04:13Z</div><div>Authors: Vojtech Kovarik, Christian van Merwijk, Ida Mattsson</div><div style='padding-top: 10px; width: 80ex'>In an effort to inform the discussion surrounding existential risks from AI,
we formulate Extinction-level Goodhart's Law as "Virtually any goal
specification, pursued to the extreme, will result in the extinction of
humanity", and we aim to understand which formal models are suitable for
investigating this hypothesis. Note that we remain agnostic as to whether
Extinction-level Goodhart's Law holds or not. As our key contribution, we
identify a set of conditions that are necessary for a model that aims to be
informative for evaluating specific arguments for Extinction-level Goodhart's
Law. Since each of the conditions seems to significantly contribute to the
complexity of the resulting model, formally evaluating the hypothesis might be
exceedingly difficult. This raises the possibility that whether the risk of
extinction from artificial intelligence is real or not, the underlying dynamics
might be invisible to current scientific methods.</div><div><a href='http://arxiv.org/abs/2403.05540v1'>2403.05540v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.07836v2")'>Two Types of AI Existential Risk: Decisive and Accumulative</div>
<div id='2401.07836v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T17:06:02Z</div><div>Authors: Atoosa Kasirzadeh</div><div style='padding-top: 10px; width: 80ex'>The conventional discourse on existential risks (x-risks) from AI typically
focuses on abrupt, dire events caused by advanced AI systems, particularly
those that might achieve or surpass human-level intelligence. These events have
severe consequences that either lead to human extinction or irreversibly
cripple human civilization to a point beyond recovery. This discourse, however,
often neglects the serious possibility of AI x-risks manifesting incrementally
through a series of smaller yet interconnected disruptions, gradually crossing
critical thresholds over time. This paper contrasts the conventional "decisive
AI x-risk hypothesis" with an "accumulative AI x-risk hypothesis." While the
former envisions an overt AI takeover pathway, characterized by scenarios like
uncontrollable superintelligence, the latter suggests a different causal
pathway to existential catastrophes. This involves a gradual accumulation of
critical AI-induced threats such as severe vulnerabilities and systemic erosion
of econopolitical structures. The accumulative hypothesis suggests a boiling
frog scenario where incremental AI risks slowly converge, undermining
resilience until a triggering event results in irreversible collapse. Through
systems analysis, this paper examines the distinct assumptions differentiating
these two hypotheses. It is then argued that the accumulative view reconciles
seemingly incompatible perspectives on AI risks. The implications of
differentiating between these causal pathways -- the decisive and the
accumulative -- for the governance of AI risks as well as long-term AI safety
are discussed.</div><div><a href='http://arxiv.org/abs/2401.07836v2'>2401.07836v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.16565v1")'>Partial Rankings of Optimizers</div>
<div id='2402.16565v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T13:43:25Z</div><div>Authors: Julian Rodemann, Hannah Blocher</div><div style='padding-top: 10px; width: 80ex'>We introduce a framework for benchmarking optimizers according to multiple
criteria over various test functions. Based on a recently introduced union-free
generic depth function for partial orders/rankings, it fully exploits the
ordinal information and allows for incomparability. Our method describes the
distribution of all partial orders/rankings, avoiding the notorious
shortcomings of aggregation. This permits to identify test functions that
produce central or outlying rankings of optimizers and to assess the quality of
benchmarking suites.</div><div><a href='http://arxiv.org/abs/2402.16565v1'>2402.16565v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15800v1")'>Provably Stable Feature Rankings with SHAP and LIME</div>
<div id='2401.15800v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-28T23:14:51Z</div><div>Authors: Jeremy Goldwasser, Giles Hooker</div><div style='padding-top: 10px; width: 80ex'>Feature attributions are ubiquitous tools for understanding the predictions
of machine learning models. However, popular methods for scoring input
variables such as SHAP and LIME suffer from high instability due to random
sampling. Leveraging ideas from multiple hypothesis testing, we devise
attribution methods that correctly rank the most important features with high
probability. Our algorithm RankSHAP guarantees that the $K$ highest Shapley
values have the proper ordering with probability exceeding $1-\alpha$.
Empirical results demonstrate its validity and impressive computational
efficiency. We also build on previous work to yield similar results for LIME,
ensuring the most important features are selected in the right order.</div><div><a href='http://arxiv.org/abs/2401.15800v1'>2401.15800v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.11840v1")'>Multi-Criteria Comparison as a Method of Advancing Knowledge-Guided
  Machine Learning</div>
<div id='2403.11840v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-18T14:50:48Z</div><div>Authors: Jason L. Harman, Jaelle Scheuerman</div><div style='padding-top: 10px; width: 80ex'>This paper describes a generalizable model evaluation method that can be
adapted to evaluate AI/ML models across multiple criteria including core
scientific principles and more practical outcomes. Emerging from prediction
competitions in Psychology and Decision Science, the method evaluates a group
of candidate models of varying type and structure across multiple scientific,
theoretic, and practical criteria. Ordinal ranking of criteria scores are
evaluated using voting rules from the field of computational social choice and
allow the comparison of divergent measures and types of models in a holistic
evaluation. Additional advantages and applications are discussed.</div><div><a href='http://arxiv.org/abs/2403.11840v1'>2403.11840v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.02211v1")'>Query-decision Regression between Shortest Path and Minimum Steiner Tree</div>
<div id='2402.02211v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-03T17:05:01Z</div><div>Authors: Guangmo Tong, Peng Zhao, Mina Samizadeh</div><div style='padding-top: 10px; width: 80ex'>Considering a graph with unknown weights, can we find the shortest path for a
pair of nodes if we know the minimal Steiner trees associated with some subset
of nodes? That is, with respect to a fixed latent decision-making system (e.g.,
a weighted graph), we seek to solve one optimization problem (e.g., the
shortest path problem) by leveraging information associated with another
optimization problem (e.g., the minimal Steiner tree problem). In this paper,
we study such a prototype problem called \textit{query-decision regression with
task shifts}, focusing on the shortest path problem and the minimum Steiner
tree problem. We provide theoretical insights regarding the design of
realizable hypothesis spaces for building scoring models, and present two
principled learning frameworks. Our experimental studies show that such
problems can be solved to a decent extent with statistical significance.</div><div><a href='http://arxiv.org/abs/2402.02211v1'>2402.02211v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.12213v1")'>Private graphon estimation via sum-of-squares</div>
<div id='2403.12213v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-18T19:54:59Z</div><div>Authors: Hongjie Chen, Jingqiu Ding, Tommaso d'Orsi, Yiding Hua, Chih-Hung Liu, David Steurer</div><div style='padding-top: 10px; width: 80ex'>We develop the first pure node-differentially-private algorithms for learning
stochastic block models and for graphon estimation with polynomial running time
for any constant number of blocks. The statistical utility guarantees match
those of the previous best information-theoretic (exponential-time)
node-private mechanisms for these problems. The algorithm is based on an
exponential mechanism for a score function defined in terms of a sum-of-squares
relaxation whose level depends on the number of blocks. The key ingredients of
our results are (1) a characterization of the distance between the block
graphons in terms of a quadratic optimization over the polytope of doubly
stochastic matrices, (2) a general sum-of-squares convergence result for
polynomial optimization over arbitrary polytopes, and (3) a general approach to
perform Lipschitz extensions of score functions as part of the sum-of-squares
algorithmic paradigm.</div><div><a href='http://arxiv.org/abs/2403.12213v1'>2403.12213v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.08197v2")'>Matrix Completion with Hypergraphs:Sharp Thresholds and Efficient
  Algorithms</div>
<div id='2401.08197v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-16T08:25:29Z</div><div>Authors: Zhongtian Ma, Qiaosheng Zhang, Zhen Wang</div><div style='padding-top: 10px; width: 80ex'>This paper considers the problem of completing a rating matrix based on
sub-sampled matrix entries as well as observed social graphs and hypergraphs.
We show that there exists a \emph{sharp threshold} on the sample probability
for the task of exactly completing the rating matrix -- the task is achievable
when the sample probability is above the threshold, and is impossible otherwise
-- demonstrating a phase transition phenomenon. The threshold can be expressed
as a function of the ``quality'' of hypergraphs, enabling us to \emph{quantify}
the amount of reduction in sample probability due to the exploitation of
hypergraphs. This also highlights the usefulness of hypergraphs in the matrix
completion problem. En route to discovering the sharp threshold, we develop a
computationally efficient matrix completion algorithm that effectively exploits
the observed graphs and hypergraphs. Theoretical analyses show that our
algorithm succeeds with high probability as long as the sample probability
exceeds the aforementioned threshold, and this theoretical result is further
validated by synthetic experiments. Moreover, our experiments on a real social
network dataset (with both graphs and hypergraphs) show that our algorithm
outperforms other state-of-the-art matrix completion algorithms.</div><div><a href='http://arxiv.org/abs/2401.08197v2'>2401.08197v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.10989v1")'>Provably Scalable Black-Box Variational Inference with Structured
  Variational Families</div>
<div id='2401.10989v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-19T19:04:23Z</div><div>Authors: Joohwan Ko, Kyurae Kim, Woo Chang Kim, Jacob R. Gardner</div><div style='padding-top: 10px; width: 80ex'>Variational families with full-rank covariance approximations are known not
to work well in black-box variational inference (BBVI), both empirically and
theoretically. In fact, recent computational complexity results for BBVI have
established that full-rank variational families scale poorly with the
dimensionality of the problem compared to e.g. mean field families. This is
particularly critical to hierarchical Bayesian models with local variables;
their dimensionality increases with the size of the datasets. Consequently, one
gets an iteration complexity with an explicit $\mathcal{O}(N^2)$ dependence on
the dataset size $N$. In this paper, we explore a theoretical middle ground
between mean-field variational families and full-rank families: structured
variational families. We rigorously prove that certain scale matrix structures
can achieve a better iteration complexity of $\mathcal{O}(N)$, implying better
scaling with respect to $N$. We empirically verify our theoretical results on
large-scale hierarchical models.</div><div><a href='http://arxiv.org/abs/2401.10989v1'>2401.10989v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.04847v2")'>On the Correctness of the Generalized Isotonic Recursive Partitioning
  Algorithm</div>
<div id='2401.04847v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-09T23:17:05Z</div><div>Authors: Joong-Ho Won, Jihan Jung</div><div style='padding-top: 10px; width: 80ex'>This paper presents an in-depth analysis of the generalized isotonic
recursive partitioning (GIRP) algorithm for fitting isotonic models under
separable convex losses, proposed by Luss and Rosset [J. Comput. Graph.
Statist., 23 (2014), pp. 192--201] for differentiable losses and extended by
Painsky and Rosset [IEEE Trans. Pattern Anal. Mach. Intell., 38 (2016), pp.
308-321] for nondifferentiable losses. The GIRP algorithm poseses an attractive
feature that in each step of the algorithm, the intermediate solution satisfies
the isotonicity constraint. The paper begins with an example showing that the
GIRP algorithm as described in the literature may fail to produce an isotonic
model, suggesting that the existence and uniqueness of the solution to the
isotonic regression problem must be carefully addressed. It proceeds with
showing that, among possibly many solutions, there indeed exists a solution
that can be found by recursive binary partitioning of the set of observed data.
A small modification of the GIRP algorithm suffices to obtain a correct
solution and preserve the desired property that all the intermediate solutions
are isotonic. This proposed modification includes a proper choice of
intermediate solutions and a simplification of the partitioning step from
ternary to binary.</div><div><a href='http://arxiv.org/abs/2401.04847v2'>2401.04847v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.07463v1")'>Consistency of semi-supervised learning, stochastic tug-of-war games,
  and the p-Laplacian</div>
<div id='2401.07463v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T04:20:39Z</div><div>Authors: Jeff Calder, Nadejda Drenska</div><div style='padding-top: 10px; width: 80ex'>In this paper we give a broad overview of the intersection of partial
differential equations (PDEs) and graph-based semi-supervised learning. The
overview is focused on a large body of recent work on PDE continuum limits of
graph-based learning, which have been used to prove well-posedness of
semi-supervised learning algorithms in the large data limit. We highlight some
interesting research directions revolving around consistency of graph-based
semi-supervised learning, and present some new results on the consistency of
p-Laplacian semi-supervised learning using the stochastic tug-of-war game
interpretation of the p-Laplacian. We also present the results of some
numerical experiments that illustrate our results and suggest directions for
future work.</div><div><a href='http://arxiv.org/abs/2401.07463v1'>2401.07463v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.10232v3")'>Simple, unified analysis of Johnson-Lindenstrauss with applications</div>
<div id='2402.10232v3' style='display: none; margin-left: 20px'><div>Date: 2024-02-10T15:37:46Z</div><div>Authors: Yingru Li</div><div style='padding-top: 10px; width: 80ex'>We present a simple and unified analysis of the Johnson-Lindenstrauss (JL)
lemma, a cornerstone in the field of dimensionality reduction critical for
managing high-dimensional data. Our approach not only simplifies the
understanding but also unifies various constructions under the JL framework,
including spherical, binary-coin, sparse JL, Gaussian and sub-Gaussian models.
This simplification and unification make significant strides in preserving the
intrinsic geometry of data, essential across diverse applications from
streaming algorithms to reinforcement learning. Notably, we deliver the first
rigorous proof of the spherical construction's effectiveness and provide a
general class of sub-Gaussian constructions within this simplified framework.
At the heart of our contribution is an innovative extension of the
Hanson-Wright inequality to high dimensions, complete with explicit constants.
By employing simple yet powerful probabilistic tools and analytical techniques,
such as an enhanced diagonalization process, our analysis not only solidifies
the JL lemma's theoretical foundation by removing an independence assumption
but also extends its practical reach, showcasing its adaptability and
importance in contemporary computational algorithms.</div><div><a href='http://arxiv.org/abs/2402.10232v3'>2402.10232v3</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.11652v1")'>Doubly Robust Inference in Causal Latent Factor Models</div>
<div id='2402.11652v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-18T17:13:46Z</div><div>Authors: Alberto Abadie, Anish Agarwal, Raaz Dwivedi, Abhin Shah</div><div style='padding-top: 10px; width: 80ex'>This article introduces a new framework for estimating average treatment
effects under unobserved confounding in modern data-rich environments featuring
large numbers of units and outcomes. The proposed estimator is doubly robust,
combining outcome imputation, inverse probability weighting, and a novel
cross-fitting procedure for matrix completion. We derive finite-sample and
asymptotic guarantees, and show that the error of the new estimator converges
to a mean-zero Gaussian distribution at a parametric rate. Simulation results
demonstrate the practical relevance of the formal properties of the estimators
analyzed in this article.</div><div><a href='http://arxiv.org/abs/2402.11652v1'>2402.11652v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01972v1")'>Combining T-learning and DR-learning: a framework for oracle-efficient
  estimation of causal contrasts</div>
<div id='2402.01972v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-03T00:47:50Z</div><div>Authors: Lars van der Laan, Marco Carone, Alex Luedtke</div><div style='padding-top: 10px; width: 80ex'>We introduce efficient plug-in (EP) learning, a novel framework for the
estimation of heterogeneous causal contrasts, such as the conditional average
treatment effect and conditional relative risk. The EP-learning framework
enjoys the same oracle-efficiency as Neyman-orthogonal learning strategies,
such as DR-learning and R-learning, while addressing some of their primary
drawbacks, including that (i) their practical applicability can be hindered by
loss function non-convexity; and (ii) they may suffer from poor performance and
instability due to inverse probability weighting and pseudo-outcomes that
violate bounds. To avoid these drawbacks, EP-learner constructs an efficient
plug-in estimator of the population risk function for the causal contrast,
thereby inheriting the stability and robustness properties of plug-in
estimation strategies like T-learning. Under reasonable conditions, EP-learners
based on empirical risk minimization are oracle-efficient, exhibiting
asymptotic equivalence to the minimizer of an oracle-efficient one-step
debiased estimator of the population risk function. In simulation experiments,
we illustrate that EP-learners of the conditional average treatment effect and
conditional relative risk outperform state-of-the-art competitors, including
T-learner, R-learner, and DR-learner. Open-source implementations of the
proposed methods are available in our R package hte3.</div><div><a href='http://arxiv.org/abs/2402.01972v1'>2402.01972v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.18392v1")'>Unveiling the Potential of Robustness in Evaluating Causal Inference
  Models</div>
<div id='2402.18392v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-28T15:12:24Z</div><div>Authors: Yiyan Huang, Cheuk Hang Leung, Siyi Wang, Yijun Li, Qi Wu</div><div style='padding-top: 10px; width: 80ex'>The growing demand for personalized decision-making has led to a surge of
interest in estimating the Conditional Average Treatment Effect (CATE). The
intersection of machine learning and causal inference has yielded various
effective CATE estimators. However, deploying these estimators in practice is
often hindered by the absence of counterfactual labels, making it challenging
to select the desirable CATE estimator using conventional model selection
procedures like cross-validation. Existing approaches for CATE estimator
selection, such as plug-in and pseudo-outcome metrics, face two inherent
challenges. Firstly, they are required to determine the metric form and the
underlying machine learning models for fitting nuisance parameters or plug-in
learners. Secondly, they lack a specific focus on selecting a robust estimator.
To address these challenges, this paper introduces a novel approach, the
Distributionally Robust Metric (DRM), for CATE estimator selection. The
proposed DRM not only eliminates the need to fit additional models but also
excels at selecting a robust CATE estimator. Experimental studies demonstrate
the efficacy of the DRM method, showcasing its consistent effectiveness in
identifying superior estimators while mitigating the risk of selecting inferior
ones.</div><div><a href='http://arxiv.org/abs/2402.18392v1'>2402.18392v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03240v1")'>Triple/Debiased Lasso for Statistical Inference of Conditional Average
  Treatment Effects</div>
<div id='2403.03240v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-05T18:29:36Z</div><div>Authors: Masahiro Kato</div><div style='padding-top: 10px; width: 80ex'>This study investigates the estimation and the statistical inference about
Conditional Average Treatment Effects (CATEs), which have garnered attention as
a metric representing individualized causal effects. In our data-generating
process, we assume linear models for the outcomes associated with binary
treatments and define the CATE as a difference between the expected outcomes of
these linear models. This study allows the linear models to be
high-dimensional, and our interest lies in consistent estimation and
statistical inference for the CATE. In high-dimensional linear regression, one
typical approach is to assume sparsity. However, in our study, we do not assume
sparsity directly. Instead, we consider sparsity only in the difference of the
linear models. We first use a doubly robust estimator to approximate this
difference and then regress the difference on covariates with Lasso
regularization. Although this regression estimator is consistent for the CATE,
we further reduce the bias using the techniques in double/debiased machine
learning (DML) and debiased Lasso, leading to $\sqrt{n}$-consistency and
confidence intervals. We refer to the debiased estimator as the triple/debiased
Lasso (TDL), applying both DML and debiased Lasso techniques. We confirm the
soundness of our proposed method through simulation studies.</div><div><a href='http://arxiv.org/abs/2403.03240v1'>2403.03240v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15447v1")'>Continuous Treatment Effect Estimation Using Gradient Interpolation and
  Kernel Smoothing</div>
<div id='2401.15447v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-27T15:52:58Z</div><div>Authors: Lokesh Nagalapatti, Akshay Iyer, Abir De, Sunita Sarawagi</div><div style='padding-top: 10px; width: 80ex'>We address the Individualized continuous treatment effect (ICTE) estimation
problem where we predict the effect of any continuous-valued treatment on an
individual using observational data. The main challenge in this estimation task
is the potential confounding of treatment assignment with an individual's
covariates in the training data, whereas during inference ICTE requires
prediction on independently sampled treatments. In contrast to prior work that
relied on regularizers or unstable GAN training, we advocate the direct
approach of augmenting training individuals with independently sampled
treatments and inferred counterfactual outcomes. We infer counterfactual
outcomes using a two-pronged strategy: a Gradient Interpolation for
close-to-observed treatments, and a Gaussian Process based Kernel Smoothing
which allows us to downweigh high variance inferences. We evaluate our method
on five benchmarks and show that our method outperforms six state-of-the-art
methods on the counterfactual estimation error. We analyze the superior
performance of our method by showing that (1) our inferred counterfactual
responses are more accurate, and (2) adding them to the training data reduces
the distributional distance between the confounded training distribution and
test distribution where treatment is independent of covariates. Our proposed
method is model-agnostic and we show that it improves ICTE accuracy of several
existing models.</div><div><a href='http://arxiv.org/abs/2401.15447v1'>2401.15447v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.17739v1")'>reBandit: Random Effects based Online RL algorithm for Reducing Cannabis
  Use</div>
<div id='2402.17739v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T18:18:23Z</div><div>Authors: Susobhan Ghosh, Yongyi Guo, Pei-Yao Hung, Lara Coughlin, Erin Bonar, Inbal Nahum-Shani, Maureen Walton, Susan Murphy</div><div style='padding-top: 10px; width: 80ex'>The escalating prevalence of cannabis use, and associated cannabis-use
disorder (CUD), poses a significant public health challenge globally. With a
notably wide treatment gap, especially among emerging adults (EAs; ages 18-25),
addressing cannabis use and CUD remains a pivotal objective within the 2030
United Nations Agenda for Sustainable Development Goals (SDG). In this work, we
develop an online reinforcement learning (RL) algorithm called reBandit which
will be utilized in a mobile health study to deliver personalized mobile health
interventions aimed at reducing cannabis use among EAs. reBandit utilizes
random effects and informative Bayesian priors to learn quickly and efficiently
in noisy mobile health environments. Moreover, reBandit employs Empirical Bayes
and optimization techniques to autonomously update its hyper-parameters online.
To evaluate the performance of our algorithm, we construct a simulation testbed
using data from a prior study, and compare against commonly used algorithms in
mobile health studies. We show that reBandit performs equally well or better
than all the baseline algorithms, and the performance gap widens as population
heterogeneity increases in the simulation environment, proving its adeptness to
adapt to diverse population of study participants.</div><div><a href='http://arxiv.org/abs/2402.17739v1'>2402.17739v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.17003v1")'>Monitoring Fidelity of Online Reinforcement Learning Algorithms in
  Clinical Trials</div>
<div id='2402.17003v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T20:19:14Z</div><div>Authors: Anna L. Trella, Kelly W. Zhang, Inbal Nahum-Shani, Vivek Shetty, Iris Yan, Finale Doshi-Velez, Susan A. Murphy</div><div style='padding-top: 10px; width: 80ex'>Online reinforcement learning (RL) algorithms offer great potential for
personalizing treatment for participants in clinical trials. However, deploying
an online, autonomous algorithm in the high-stakes healthcare setting makes
quality control and data quality especially difficult to achieve. This paper
proposes algorithm fidelity as a critical requirement for deploying online RL
algorithms in clinical trials. It emphasizes the responsibility of the
algorithm to (1) safeguard participants and (2) preserve the scientific utility
of the data for post-trial analyses. We also present a framework for
pre-deployment planning and real-time monitoring to help algorithm developers
and clinical researchers ensure algorithm fidelity. To illustrate our
framework's practical application, we present real-world examples from the
Oralytics clinical trial. Since Spring 2023, this trial successfully deployed
an autonomous, online RL algorithm to personalize behavioral interventions for
participants at risk for dental disease.</div><div><a href='http://arxiv.org/abs/2402.17003v1'>2402.17003v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.11123v1")'>Optimizing Warfarin Dosing Using Contextual Bandit: An Offline Policy
  Learning and Evaluation Method</div>
<div id='2402.11123v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-16T23:13:05Z</div><div>Authors: Yong Huang, Charles A. Downs, Amir M. Rahmani</div><div style='padding-top: 10px; width: 80ex'>Warfarin, an anticoagulant medication, is formulated to prevent and address
conditions associated with abnormal blood clotting, making it one of the most
prescribed drugs globally. However, determining the suitable dosage remains
challenging due to individual response variations, and prescribing an incorrect
dosage may lead to severe consequences. Contextual bandit and reinforcement
learning have shown promise in addressing this issue. Given the wide
availability of observational data and safety concerns of decision-making in
healthcare, we focused on using exclusively observational data from historical
policies as demonstrations to derive new policies; we utilized offline policy
learning and evaluation in a contextual bandit setting to establish the optimal
personalized dosage strategy. Our learned policies surpassed these baseline
approaches without genotype inputs, even when given a suboptimal demonstration,
showcasing promising application potential.</div><div><a href='http://arxiv.org/abs/2402.11123v1'>2402.11123v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07344v1")'>Measurement Scheduling for ICU Patients with Offline Reinforcement
  Learning</div>
<div id='2402.07344v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-12T00:22:47Z</div><div>Authors: Zongliang Ji, Anna Goldenberg, Rahul G. Krishnan</div><div style='padding-top: 10px; width: 80ex'>Scheduling laboratory tests for ICU patients presents a significant
challenge. Studies show that 20-40% of lab tests ordered in the ICU are
redundant and could be eliminated without compromising patient safety. Prior
work has leveraged offline reinforcement learning (Offline-RL) to find optimal
policies for ordering lab tests based on patient information. However, new ICU
patient datasets have since been released, and various advancements have been
made in Offline-RL methods. In this study, we first introduce a preprocessing
pipeline for the newly-released MIMIC-IV dataset geared toward time-series
tasks. We then explore the efficacy of state-of-the-art Offline-RL methods in
identifying better policies for ICU patient lab test scheduling. Besides
assessing methodological performance, we also discuss the overall suitability
and practicality of using Offline-RL frameworks for scheduling laboratory tests
in ICU settings.</div><div><a href='http://arxiv.org/abs/2402.07344v1'>2402.07344v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.10618v1")'>Limits of Approximating the Median Treatment Effect</div>
<div id='2403.10618v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-15T18:30:06Z</div><div>Authors: Raghavendra Addanki, Siddharth Bhandari</div><div style='padding-top: 10px; width: 80ex'>Average Treatment Effect (ATE) estimation is a well-studied problem in causal
inference. However, it does not necessarily capture the heterogeneity in the
data, and several approaches have been proposed to tackle the issue, including
estimating the Quantile Treatment Effects. In the finite population setting
containing $n$ individuals, with treatment and control values denoted by the
potential outcome vectors $\mathbf{a}, \mathbf{b}$, much of the prior work
focused on estimating median$(\mathbf{a}) -$ median$(\mathbf{b})$, where
median($\mathbf x$) denotes the median value in the sorted ordering of all the
values in vector $\mathbf x$. It is known that estimating the difference of
medians is easier than the desired estimand of median$(\mathbf{a-b})$, called
the Median Treatment Effect (MTE). The fundamental problem of causal inference
-- for every individual $i$, we can only observe one of the potential outcome
values, i.e., either the value $a_i$ or $b_i$, but not both, makes estimating
MTE particularly challenging. In this work, we argue that MTE is not estimable
and detail a novel notion of approximation that relies on the sorted order of
the values in $\mathbf{a-b}$. Next, we identify a quantity called variability
that exactly captures the complexity of MTE estimation. By drawing connections
to instance-optimality studied in theoretical computer science, we show that
every algorithm for estimating the MTE obtains an approximation error that is
no better than the error of an algorithm that computes variability. Finally, we
provide a simple linear time algorithm for computing the variability exactly.
Unlike much prior work, a particular highlight of our work is that we make no
assumptions about how the potential outcome vectors are generated or how they
are correlated, except that the potential outcome values are $k$-ary, i.e.,
take one of $k$ discrete values.</div><div><a href='http://arxiv.org/abs/2403.10618v1'>2403.10618v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.14512v3")'>Who Are We Missing? A Principled Approach to Characterizing the
  Underrepresented Population</div>
<div id='2401.14512v3' style='display: none; margin-left: 20px'><div>Date: 2024-01-25T21:11:35Z</div><div>Authors: Harsh Parikh, Rachael Ross, Elizabeth Stuart, Kara Rudolph</div><div style='padding-top: 10px; width: 80ex'>Randomized controlled trials (RCTs) serve as the cornerstone for
understanding causal effects, yet extending inferences to target populations
presents challenges due to effect heterogeneity and underrepresentation. Our
paper addresses the critical issue of identifying and characterizing
underrepresented subgroups in RCTs, proposing a novel framework for refining
target populations to improve generalizability. We introduce an
optimization-based approach, Rashomon Set of Optimal Trees (ROOT), to
characterize underrepresented groups. ROOT optimizes the target subpopulation
distribution by minimizing the variance of the target average treatment effect
estimate, ensuring more precise treatment effect estimations. Notably, ROOT
generates interpretable characteristics of the underrepresented population,
aiding researchers in effective communication. Our approach demonstrates
improved precision and interpretability compared to alternatives, as
illustrated with synthetic data experiments. We apply our methodology to extend
inferences from the Starting Treatment with Agonist Replacement Therapies
(START) trial -- investigating the effectiveness of medication for opioid use
disorder -- to the real-world population represented by the Treatment Episode
Dataset: Admissions (TEDS-A). By refining target populations using ROOT, our
framework offers a systematic approach to enhance decision-making accuracy and
inform future trials in diverse populations.</div><div><a href='http://arxiv.org/abs/2401.14512v3'>2401.14512v3</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00168v1")'>Continuous Treatment Effects with Surrogate Outcomes</div>
<div id='2402.00168v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-31T20:50:18Z</div><div>Authors: Zhenghao Zeng, David Arbour, Avi Feller, Raghavendra Addanki, Ryan Rossi, Ritwik Sinha, Edward H. Kennedy</div><div style='padding-top: 10px; width: 80ex'>In many real-world causal inference applications, the primary outcomes
(labels) are often partially missing, especially if they are expensive or
difficult to collect. If the missingness depends on covariates (i.e.,
missingness is not completely at random), analyses based on fully-observed
samples alone may be biased. Incorporating surrogates, which are fully observed
post-treatment variables related to the primary outcome, can improve estimation
in this case. In this paper, we study the role of surrogates in estimating
continuous treatment effects and propose a doubly robust method to efficiently
incorporate surrogates in the analysis, which uses both labeled and unlabeled
data and does not suffer from the above selection bias problem. Importantly, we
establish asymptotic normality of the proposed estimator and show possible
improvements on the variance compared with methods that solely use labeled
data. Extensive simulations show our methods enjoy appealing empirical
performance.</div><div><a href='http://arxiv.org/abs/2402.00168v1'>2402.00168v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.10766v1")'>ODE Discovery for Longitudinal Heterogeneous Treatment Effects Inference</div>
<div id='2403.10766v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-16T02:07:45Z</div><div>Authors: Krzysztof Kacprzyk, Samuel Holt, Jeroen Berrevoets, Zhaozhi Qian, Mihaela van der Schaar</div><div style='padding-top: 10px; width: 80ex'>Inferring unbiased treatment effects has received widespread attention in the
machine learning community. In recent years, our community has proposed
numerous solutions in standard settings, high-dimensional treatment settings,
and even longitudinal settings. While very diverse, the solution has mostly
relied on neural networks for inference and simultaneous correction of
assignment bias. New approaches typically build on top of previous approaches
by proposing new (or refined) architectures and learning algorithms. However,
the end result -- a neural-network-based inference machine -- remains
unchallenged. In this paper, we introduce a different type of solution in the
longitudinal setting: a closed-form ordinary differential equation (ODE). While
we still rely on continuous optimization to learn an ODE, the resulting
inference machine is no longer a neural network. Doing so yields several
advantages such as interpretability, irregular sampling, and a different set of
identification assumptions. Above all, we consider the introduction of a
completely new type of solution to be our most important contribution as it may
spark entirely new innovations in treatment effects in general. We facilitate
this by formulating our contribution as a framework that can transform any ODE
discovery method into a treatment effects method.</div><div><a href='http://arxiv.org/abs/2403.10766v1'>2403.10766v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03274v1")'>From Noise to Signal: Unveiling Treatment Effects from Digital Health
  Data through Pharmacology-Informed Neural-SDE</div>
<div id='2403.03274v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-05T19:13:57Z</div><div>Authors: Samira Pakravan, Nikolaos Evangelou, Maxime Usdin, Logan Brooks, James Lu</div><div style='padding-top: 10px; width: 80ex'>Digital health technologies (DHT), such as wearable devices, provide
personalized, continuous, and real-time monitoring of patient. These
technologies are contributing to the development of novel therapies and
personalized medicine. Gaining insight from these technologies requires
appropriate modeling techniques to capture clinically-relevant changes in
disease state. The data generated from these devices is characterized by being
stochastic in nature, may have missing elements, and exhibits considerable
inter-individual variability - thereby making it difficult to analyze using
traditional longitudinal modeling techniques. We present a novel
pharmacology-informed neural stochastic differential equation (SDE) model
capable of addressing these challenges. Using synthetic data, we demonstrate
that our approach is effective in identifying treatment effects and learning
causal relationships from stochastic data, thereby enabling counterfactual
simulation.</div><div><a href='http://arxiv.org/abs/2403.03274v1'>2403.03274v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.13851v1")'>Control of Medical Digital Twins with Artificial Neural Networks</div>
<div id='2403.13851v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-18T19:30:46Z</div><div>Authors: Lucas Böttcher, Luis L. Fonseca, Reinhard C. Laubenbacher</div><div style='padding-top: 10px; width: 80ex'>The objective of personalized medicine is to tailor interventions to an
individual patient's unique characteristics. A key technology for this purpose
involves medical digital twins, computational models of human biology that can
be personalized and dynamically updated to incorporate patient-specific data
collected over time. Certain aspects of human biology, such as the immune
system, are not easily captured with physics-based models, such as differential
equations. Instead, they are often multi-scale, stochastic, and hybrid. This
poses a challenge to existing model-based control and optimization approaches
that cannot be readily applied to such models. Recent advances in automatic
differentiation and neural-network control methods hold promise in addressing
complex control problems. However, the application of these approaches to
biomedical systems is still in its early stages. This work introduces
dynamics-informed neural-network controllers as an alternative approach to
control of medical digital twins. As a first use case for this method, the
focus is on agent-based models, a versatile and increasingly common modeling
platform in biomedicine. The effectiveness of the proposed neural-network
control method is illustrated and benchmarked against other methods with two
widely-used agent-based model types. The relevance of the method introduced
here extends beyond medical digital twins to other complex dynamical systems.</div><div><a href='http://arxiv.org/abs/2403.13851v1'>2403.13851v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.02661v1")'>Nurse-in-the-Loop Artificial Intelligence for Precision Management of
  Type 2 Diabetes in a Clinical Trial Utilizing Transfer-Learned Predictive
  Digital Twin</div>
<div id='2401.02661v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-05T06:38:50Z</div><div>Authors: Syed Hasib Akhter Faruqui, Adel Alaeddini, Yan Du, Shiyu Li, Kumar Sharma, Jing Wang</div><div style='padding-top: 10px; width: 80ex'>Background: Type 2 diabetes (T2D) is a prevalent chronic disease with a
significant risk of serious health complications and negative impacts on the
quality of life. Given the impact of individual characteristics and lifestyle
on the treatment plan and patient outcomes, it is crucial to develop precise
and personalized management strategies. Artificial intelligence (AI) provides
great promise in combining patterns from various data sources with nurses'
expertise to achieve optimal care. Methods: This is a 6-month ancillary study
among T2D patients (n = 20, age = 57 +- 10). Participants were randomly
assigned to an intervention (AI, n=10) group to receive daily AI-generated
individualized feedback or a control group without receiving the daily feedback
(non-AI, n=10) in the last three months. The study developed an online
nurse-in-the-loop predictive control (ONLC) model that utilizes a predictive
digital twin (PDT). The PDT was developed using a transfer-learning-based
Artificial Neural Network. The PDT was trained on participants self-monitoring
data (weight, food logs, physical activity, glucose) from the first three
months, and the online control algorithm applied particle swarm optimization to
identify impactful behavioral changes for maintaining the patient's glucose and
weight levels for the next three months. The ONLC provided the intervention
group with individualized feedback and recommendations via text messages. The
PDT was re-trained weekly to improve its performance. Findings: The trained
ONLC model achieved &gt;=80% prediction accuracy across all patients while the
model was tuned online. Participants in the intervention group exhibited a
trend of improved daily steps and stable or improved total caloric and total
carb intake as recommended.</div><div><a href='http://arxiv.org/abs/2401.02661v1'>2401.02661v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.13852v2")'>Neural Control System for Continuous Glucose Monitoring and Maintenance</div>
<div id='2402.13852v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-21T14:56:36Z</div><div>Authors: Azmine Toushik Wasi</div><div style='padding-top: 10px; width: 80ex'>Precise glucose level monitoring is critical for people with diabetes to
avoid serious complications. While there are several methods for continuous
glucose level monitoring, research on maintenance devices is limited. To
mitigate the gap, we provide a novel neural control system for continuous
glucose monitoring and management that uses differential predictive control.
Our approach, led by a sophisticated neural policy and differentiable modeling,
constantly adjusts insulin supply in real-time, thereby improving glucose level
optimization in the body. This end-to-end method maximizes efficiency,
providing personalized care and improved health outcomes, as confirmed by
empirical evidence.</div><div><a href='http://arxiv.org/abs/2402.13852v2'>2402.13852v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.18851v1")'>Applications of 0-1 Neural Networks in Prescription and Prediction</div>
<div id='2402.18851v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T05:00:01Z</div><div>Authors: Vrishabh Patil, Kara Hoppe, Yonatan Mintz</div><div style='padding-top: 10px; width: 80ex'>A key challenge in medical decision making is learning treatment policies for
patients with limited observational data. This challenge is particularly
evident in personalized healthcare decision-making, where models need to take
into account the intricate relationships between patient characteristics,
treatment options, and health outcomes. To address this, we introduce
prescriptive networks (PNNs), shallow 0-1 neural networks trained with mixed
integer programming that can be used with counterfactual estimation to optimize
policies in medium data settings. These models offer greater interpretability
than deep neural networks and can encode more complex policies than common
models such as decision trees. We show that PNNs can outperform existing
methods in both synthetic data experiments and in a case study of assigning
treatments for postpartum hypertension. In particular, PNNs are shown to
produce policies that could reduce peak blood pressure by 5.47 mm Hg (p=0.02)
over existing clinical practice, and by 2 mm Hg (p=0.01) over the next best
prescriptive modeling technique. Moreover PNNs were more likely than all other
models to correctly identify clinically significant features while existing
models relied on potentially dangerous features such as patient insurance
information and race that could lead to bias in treatment.</div><div><a href='http://arxiv.org/abs/2402.18851v1'>2402.18851v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.08224v4")'>Privacy Preserving Adaptive Experiment Design</div>
<div id='2401.08224v4' style='display: none; margin-left: 20px'><div>Date: 2024-01-16T09:22:12Z</div><div>Authors: Jiachun Li, Kaining Shi, David Simchi-Levi</div><div style='padding-top: 10px; width: 80ex'>Adaptive experiment is widely adopted to estimate conditional average
treatment effect (CATE) in clinical trials and many other scenarios. While the
primary goal in experiment is to maximize estimation accuracy, due to the
imperative of social welfare, it's also crucial to provide treatment with
superior outcomes to patients, which is measured by regret in contextual bandit
framework. These two objectives often lead to contrast optimal allocation
mechanism. Furthermore, privacy concerns arise in clinical scenarios containing
sensitive data like patients health records. Therefore, it's essential for the
treatment allocation mechanism to incorporate robust privacy protection
measures. In this paper, we investigate the tradeoff between loss of social
welfare and statistical power in contextual bandit experiment. We propose a
matched upper and lower bound for the multi-objective optimization problem, and
then adopt the concept of Pareto optimality to mathematically characterize the
optimality condition. Furthermore, we propose differentially private algorithms
which still matches the lower bound, showing that privacy is "almost free".
Additionally, we derive the asymptotic normality of the estimator, which is
essential in statistical inference and hypothesis testing.</div><div><a href='http://arxiv.org/abs/2401.08224v4'>2401.08224v4</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.17737v1")'>Hierarchical Bias-Driven Stratification for Interpretable Causal Effect
  Estimation</div>
<div id='2401.17737v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-31T10:58:13Z</div><div>Authors: Lucile Ter-Minassian, Liran Szlak, Ehud Karavani, Chris Holmes, Yishai Shimoni</div><div style='padding-top: 10px; width: 80ex'>Interpretability and transparency are essential for incorporating causal
effect models from observational data into policy decision-making. They can
provide trust for the model in the absence of ground truth labels to evaluate
the accuracy of such models. To date, attempts at transparent causal effect
estimation consist of applying post hoc explanation methods to black-box
models, which are not interpretable. Here, we present BICauseTree: an
interpretable balancing method that identifies clusters where natural
experiments occur locally. Our approach builds on decision trees with a
customized objective function to improve balancing and reduce treatment
allocation bias. Consequently, it can additionally detect subgroups presenting
positivity violations, exclude them, and provide a covariate-based definition
of the target population we can infer from and generalize to. We evaluate the
method's performance using synthetic and realistic datasets, explore its
bias-interpretability tradeoff, and show that it is comparable with existing
approaches.</div><div><a href='http://arxiv.org/abs/2401.17737v1'>2401.17737v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.17042v1")'>Towards Generalizing Inferences from Trials to Target Populations</div>
<div id='2402.17042v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T21:49:44Z</div><div>Authors: Melody Y Huang, Sarah E Robertson, Harsh Parikh</div><div style='padding-top: 10px; width: 80ex'>Randomized Controlled Trials (RCTs) are pivotal in generating internally
valid estimates with minimal assumptions, serving as a cornerstone for
researchers dedicated to advancing causal inference methods. However, extending
these findings beyond the experimental cohort to achieve externally valid
estimates is crucial for broader scientific inquiry. This paper delves into the
forefront of addressing these external validity challenges, encapsulating the
essence of a multidisciplinary workshop held at the Institute for Computational
and Experimental Research in Mathematics (ICERM), Brown University, in Fall
2023. The workshop congregated experts from diverse fields including social
science, medicine, public health, statistics, computer science, and education,
to tackle the unique obstacles each discipline faces in extrapolating
experimental findings. Our study presents three key contributions: we integrate
ongoing efforts, highlighting methodological synergies across fields; provide
an exhaustive review of generalizability and transportability based on the
workshop's discourse; and identify persistent hurdles while suggesting avenues
for future research. By doing so, this paper aims to enhance the collective
understanding of the generalizability and transportability of causal effects,
fostering cross-disciplinary collaboration and offering valuable insights for
researchers working on refining and applying causal inference methods.</div><div><a href='http://arxiv.org/abs/2402.17042v1'>2402.17042v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.00105v1")'>Longitudinal Counterfactuals: Constraints and Opportunities</div>
<div id='2403.00105v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T20:17:08Z</div><div>Authors: Alexander Asemota, Giles Hooker</div><div style='padding-top: 10px; width: 80ex'>Counterfactual explanations are a common approach to providing recourse to
data subjects. However, current methodology can produce counterfactuals that
cannot be achieved by the subject, making the use of counterfactuals for
recourse difficult to justify in practice. Though there is agreement that
plausibility is an important quality when using counterfactuals for algorithmic
recourse, ground truth plausibility continues to be difficult to quantify. In
this paper, we propose using longitudinal data to assess and improve
plausibility in counterfactuals. In particular, we develop a metric that
compares longitudinal differences to counterfactual differences, allowing us to
evaluate how similar a counterfactual is to prior observed changes.
Furthermore, we use this metric to generate plausible counterfactuals. Finally,
we discuss some of the inherent difficulties of using counterfactuals for
recourse.</div><div><a href='http://arxiv.org/abs/2403.00105v1'>2403.00105v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.11771v1")'>Evaluating the Effectiveness of Index-Based Treatment Allocation</div>
<div id='2402.11771v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-19T01:55:55Z</div><div>Authors: Niclas Boehmer, Yash Nair, Sanket Shah, Lucas Janson, Aparna Taneja, Milind Tambe</div><div style='padding-top: 10px; width: 80ex'>When resources are scarce, an allocation policy is needed to decide who
receives a resource. This problem occurs, for instance, when allocating scarce
medical resources and is often solved using modern ML methods. This paper
introduces methods to evaluate index-based allocation policies -- that allocate
a fixed number of resources to those who need them the most -- by using data
from a randomized control trial. Such policies create dependencies between
agents, which render the assumptions behind standard statistical tests invalid
and limit the effectiveness of estimators. Addressing these challenges, we
translate and extend recent ideas from the statistics literature to present an
efficient estimator and methods for computing asymptotically correct confidence
intervals. This enables us to effectively draw valid statistical conclusions, a
critical gap in previous work. Our extensive experiments validate our
methodology in practical settings, while also showcasing its statistical power.
We conclude by proposing and empirically verifying extensions of our
methodology that enable us to reevaluate a past randomized control trial to
evaluate different ML allocation policies in the context of a mHealth program,
drawing previously invisible conclusions.</div><div><a href='http://arxiv.org/abs/2402.11771v1'>2402.11771v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04039v1")'>Sample size planning for conditional counterfactual mean estimation with
  a K-armed randomized experiment</div>
<div id='2403.04039v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T20:37:29Z</div><div>Authors: Gabriel Ruiz</div><div style='padding-top: 10px; width: 80ex'>We cover how to determine a sufficiently large sample size for a $K$-armed
randomized experiment in order to estimate conditional counterfactual
expectations in data-driven subgroups. The sub-groups can be output by any
feature space partitioning algorithm, including as defined by binning users
having similar predictive scores or as defined by a learned policy tree. After
carefully specifying the inference target, a minimum confidence level, and a
maximum margin of error, the key is to turn the original goal into a
simultaneous inference problem where the recommended sample size to offset an
increased possibility of estimation error is directly related to the number of
inferences to be conducted. Given a fixed sample size budget, our result allows
us to invert the question to one about the feasible number of treatment arms or
partition complexity (e.g. number of decision tree leaves). Using policy trees
to learn sub-groups, we evaluate our nominal guarantees on a large
publicly-available randomized experiment test data set.</div><div><a href='http://arxiv.org/abs/2403.04039v1'>2403.04039v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.04795v2")'>First 100 days of pandemic; an interplay of pharmaceutical, behavioral
  and digital interventions -- A study using agent based modeling</div>
<div id='2401.04795v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-09T19:38:59Z</div><div>Authors: Gauri Gupta, Ritvik Kapila, Ayush Chopra, Ramesh Raskar</div><div style='padding-top: 10px; width: 80ex'>Pandemics, notably the recent COVID-19 outbreak, have impacted both public
health and the global economy. A profound understanding of disease progression
and efficient response strategies is thus needed to prepare for potential
future outbreaks. In this paper, we emphasize the potential of Agent-Based
Models (ABM) in capturing complex infection dynamics and understanding the
impact of interventions. We simulate realistic pharmaceutical, behavioral, and
digital interventions that mirror challenges in real-world policy adoption and
suggest a holistic combination of these interventions for pandemic response.
Using these simulations, we study the trends of emergent behavior on a
large-scale population based on real-world socio-demographic and geo-census
data from Kings County in Washington. Our analysis reveals the pivotal role of
the initial 100 days in dictating a pandemic's course, emphasizing the
importance of quick decision-making and efficient policy development. Further,
we highlight that investing in behavioral and digital interventions can reduce
the burden on pharmaceutical interventions by reducing the total number of
infections and hospitalizations, and by delaying the pandemic's peak. We also
infer that allocating the same amount of dollars towards extensive testing with
contact tracing and self-quarantine offers greater cost efficiency compared to
spending the entire budget on vaccinations.</div><div><a href='http://arxiv.org/abs/2401.04795v2'>2401.04795v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.09674v1")'>Navigating the Peril of Generated Alternative Facts: A ChatGPT-4
  Fabricated Omega Variant Case as a Cautionary Tale in Medical Misinformation</div>
<div id='2403.09674v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-04T13:21:19Z</div><div>Authors: Malik Sallam, Jan Egger, Rainer Roehrig, Behrus Puladi</div><div style='padding-top: 10px; width: 80ex'>In an era where artificial intelligence (AI) intertwines with medical
research, the delineation of truth becomes increasingly complex. This study
ostensibly examines a purported novel SARS-CoV-2 variant, dubbed the Omega
variant, showcasing 31 unique mutations in the S gene region. However, the real
undercurrent of this narrative is a demonstration of the ease with which AI,
specifically ChatGPT-4, can fabricate convincing yet entirely fictional
scientific data. The so-called Omega variant was identified in a fully
vaccinated, previously infected 35-year-old male presenting with severe
COVID-19 symptoms. Through a detailed, albeit artificial, genomic analysis and
contact tracing, this study mirrors the rigorous methodology of genuine case
reports, thereby setting the stage for a compelling but entirely constructed
narrative. The entire case study was generated by ChatGPT-4, a large language
model by OpenAI. The fabricated Omega variant features an ensemble of
mutations, including N501Y and E484K, known for enhancing ACE2 receptor
affinity, alongside L452R and P681H, ostensibly indicative of immune evasion.
This variant's contrived interaction dynamics - severe symptoms in a vaccinated
individual versus mild ones in unvaccinated contacts - were designed to mimic
real-world complexities, including suggestions of antibody-dependent
enhancement (ADE). While the Omega variant is a product of AI-generated
fiction, the implications of this exercise are real and profound. The ease with
which AI can generate believable but false scientific information, as
illustrated in this case, raises significant concerns about the potential for
misinformation in medicine. This study, therefore, serves as a cautionary tale,
emphasizing the necessity for critical evaluation of sources, especially in an
age where AI tools like ChatGPT are becoming increasingly sophisticated and
widespread in their use.</div><div><a href='http://arxiv.org/abs/2403.09674v1'>2403.09674v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.00694v1")'>Defining Expertise: Applications to Treatment Effect Estimation</div>
<div id='2403.00694v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-01T17:30:49Z</div><div>Authors: Alihan Hüyük, Qiyao Wei, Alicia Curth, Mihaela van der Schaar</div><div style='padding-top: 10px; width: 80ex'>Decision-makers are often experts of their domain and take actions based on
their domain knowledge. Doctors, for instance, may prescribe treatments by
predicting the likely outcome of each available treatment. Actions of an expert
thus naturally encode part of their domain knowledge, and can help make
inferences within the same domain: Knowing doctors try to prescribe the best
treatment for their patients, we can tell treatments prescribed more frequently
are likely to be more effective. Yet in machine learning, the fact that most
decision-makers are experts is often overlooked, and "expertise" is seldom
leveraged as an inductive bias. This is especially true for the literature on
treatment effect estimation, where often the only assumption made about actions
is that of overlap. In this paper, we argue that expertise - particularly the
type of expertise the decision-makers of a domain are likely to have - can be
informative in designing and selecting methods for treatment effect estimation.
We formally define two types of expertise, predictive and prognostic, and
demonstrate empirically that: (i) the prominent type of expertise in a domain
significantly influences the performance of different methods in treatment
effect estimation, and (ii) it is possible to predict the type of expertise
present in a dataset, which can provide a quantitative basis for model
selection.</div><div><a href='http://arxiv.org/abs/2403.00694v1'>2403.00694v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00793v1")'>Distinguishing the Indistinguishable: Human Expertise in Algorithmic
  Prediction</div>
<div id='2402.00793v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T17:23:54Z</div><div>Authors: Rohan Alur, Manish Raghavan, Devavrat Shah</div><div style='padding-top: 10px; width: 80ex'>We introduce a novel framework for incorporating human expertise into
algorithmic predictions. Our approach focuses on the use of human judgment to
distinguish inputs which `look the same' to any feasible predictive algorithm.
We argue that this framing clarifies the problem of human/AI collaboration in
prediction tasks, as experts often have access to information -- particularly
subjective information -- which is not encoded in the algorithm's training
data. We use this insight to develop a set of principled algorithms for
selectively incorporating human feedback only when it improves the performance
of any feasible predictor. We find empirically that although algorithms often
outperform their human counterparts on average, human judgment can
significantly improve algorithmic predictions on specific instances (which can
be identified ex-ante). In an X-ray classification task, we find that this
subset constitutes nearly 30% of the patient population. Our approach provides
a natural way of uncovering this heterogeneity and thus enabling effective
human-AI collaboration.</div><div><a href='http://arxiv.org/abs/2402.00793v1'>2402.00793v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15268v2")'>Towards Stable Preferences for Stakeholder-aligned Machine Learning</div>
<div id='2401.15268v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-27T02:21:31Z</div><div>Authors: Haleema Sheraz, Stefan C. Kremer, Joshua August Skorburg, Graham Taylor, Walter Sinnott-Armstrong, Kyle Boerstler</div><div style='padding-top: 10px; width: 80ex'>In response to the pressing challenge of kidney allocation, characterized by
growing demands for organs, this research sets out to develop a data-driven
solution to this problem, which also incorporates stakeholder values. The
primary objective of this study is to create a method for learning both
individual and group-level preferences pertaining to kidney allocations.
Drawing upon data from the 'Pairwise Kidney Patient Online Survey.' Leveraging
two distinct datasets and evaluating across three levels - Individual, Group
and Stability - we employ machine learning classifiers assessed through several
metrics. The Individual level model predicts individual participant
preferences, the Group level model aggregates preferences across participants,
and the Stability level model, an extension of the Group level, evaluates the
stability of these preferences over time. By incorporating stakeholder
preferences into the kidney allocation process, we aspire to advance the
ethical dimensions of organ transplantation, contributing to more transparent
and equitable practices while promoting the integration of moral values into
algorithmic decision-making.</div><div><a href='http://arxiv.org/abs/2401.15268v2'>2401.15268v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.19226v1")'>Investigating Gender Fairness in Machine Learning-driven Personalized
  Care for Chronic Pain</div>
<div id='2402.19226v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T14:58:15Z</div><div>Authors: Pratik Gajane, Sean Newman, John D. Piette</div><div style='padding-top: 10px; width: 80ex'>This study investigates gender fairness in personalized pain care
recommendations using machine learning algorithms. Leveraging a contextual
bandits framework, personalized recommendations are formulated and evaluated
using LinUCB algorithm on a dataset comprising interactions with $164$ patients
across $10$ sessions each. Results indicate that while adjustments to algorithm
parameters influence the quality of pain care recommendations, this impact
remains consistent across genders. However, when certain patient information,
such as self-reported pain measurements, is absent, the quality of pain care
recommendations for women is notably inferior to that for men.</div><div><a href='http://arxiv.org/abs/2402.19226v1'>2402.19226v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.07031v1")'>The Cram Method for Efficient Simultaneous Learning and Evaluation</div>
<div id='2403.07031v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-11T04:19:05Z</div><div>Authors: Zeyang Jia, Kosuke Imai, Michael Lingzhi Li</div><div style='padding-top: 10px; width: 80ex'>We introduce the "cram" method, a general and efficient approach to
simultaneous learning and evaluation using a generic machine learning (ML)
algorithm. In a single pass of batched data, the proposed method repeatedly
trains an ML algorithm and tests its empirical performance. Because it utilizes
the entire sample for both learning and evaluation, cramming is significantly
more data-efficient than sample-splitting. The cram method also naturally
accommodates online learning algorithms, making its implementation
computationally efficient. To demonstrate the power of the cram method, we
consider the standard policy learning setting where cramming is applied to the
same data to both develop an individualized treatment rule (ITR) and estimate
the average outcome that would result if the learned ITR were to be deployed.
We show that under a minimal set of assumptions, the resulting crammed
evaluation estimator is consistent and asymptotically normal. While our
asymptotic results require a relatively weak stabilization condition of ML
algorithm, we develop a simple, generic method that can be used with any policy
learning algorithm to satisfy this condition. Our extensive simulation studies
show that, when compared to sample-splitting, cramming reduces the evaluation
standard error by more than 40% while improving the performance of learned
policy. We also apply the cram method to a randomized clinical trial to
demonstrate its applicability to real-world problems. Finally, we briefly
discuss future extensions of the cram method to other learning and evaluation
settings.</div><div><a href='http://arxiv.org/abs/2403.07031v1'>2403.07031v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.17205v2")'>Adaptive Experiment Design with Synthetic Controls</div>
<div id='2401.17205v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T17:45:47Z</div><div>Authors: Alihan Hüyük, Zhaozhi Qian, Mihaela van der Schaar</div><div style='padding-top: 10px; width: 80ex'>Clinical trials are typically run in order to understand the effects of a new
treatment on a given population of patients. However, patients in large
populations rarely respond the same way to the same treatment. This
heterogeneity in patient responses necessitates trials that investigate effects
on multiple subpopulations - especially when a treatment has marginal or no
benefit for the overall population but might have significant benefit for a
particular subpopulation. Motivated by this need, we propose Syntax, an
exploratory trial design that identifies subpopulations with positive treatment
effect among many subpopulations. Syntax is sample efficient as it (i) recruits
and allocates patients adaptively and (ii) estimates treatment effects by
forming synthetic controls for each subpopulation that combines control samples
from other subpopulations. We validate the performance of Syntax and provide
insights into when it might have an advantage over conventional trial designs
through experiments.</div><div><a href='http://arxiv.org/abs/2401.17205v2'>2401.17205v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.17705v1")'>Federated Learning for Estimating Heterogeneous Treatment Effects</div>
<div id='2402.17705v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T17:33:23Z</div><div>Authors: Disha Makhija, Joydeep Ghosh, Yejin Kim</div><div style='padding-top: 10px; width: 80ex'>Machine learning methods for estimating heterogeneous treatment effects (HTE)
facilitate large-scale personalized decision-making across various domains such
as healthcare, policy making, education, and more. Current machine learning
approaches for HTE require access to substantial amounts of data per treatment,
and the high costs associated with interventions makes centrally collecting so
much data for each intervention a formidable challenge. To overcome this
obstacle, in this work, we propose a novel framework for collaborative learning
of HTE estimators across institutions via Federated Learning. We show that even
under a diversity of interventions and subject populations across clients, one
can jointly learn a common feature representation, while concurrently and
privately learning the specific predictive functions for outcomes under
distinct interventions across institutions. Our framework and the associated
algorithm are based on this insight, and leverage tabular transformers to map
multiple input data to feature representations which are then used for outcome
prediction via multi-task learning. We also propose a novel way of federated
training of personalised transformers that can work with heterogeneous input
feature spaces. Experimental results on real-world clinical trial data
demonstrate the effectiveness of our method.</div><div><a href='http://arxiv.org/abs/2402.17705v1'>2402.17705v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00955v1")'>FairEHR-CLP: Towards Fairness-Aware Clinical Predictions with
  Contrastive Learning in Multimodal Electronic Health Records</div>
<div id='2402.00955v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T19:24:45Z</div><div>Authors: Yuqing Wang, Malvika Pillai, Yun Zhao, Catherine Curtin, Tina Hernandez-Boussard</div><div style='padding-top: 10px; width: 80ex'>In the high-stakes realm of healthcare, ensuring fairness in predictive
models is crucial. Electronic Health Records (EHRs) have become integral to
medical decision-making, yet existing methods for enhancing model fairness
restrict themselves to unimodal data and fail to address the multifaceted
social biases intertwined with demographic factors in EHRs. To mitigate these
biases, we present FairEHR-CLP: a general framework for Fairness-aware Clinical
Predictions with Contrastive Learning in EHRs. FairEHR-CLP operates through a
two-stage process, utilizing patient demographics, longitudinal data, and
clinical notes. First, synthetic counterparts are generated for each patient,
allowing for diverse demographic identities while preserving essential health
information. Second, fairness-aware predictions employ contrastive learning to
align patient representations across sensitive attributes, jointly optimized
with an MLP classifier with a softmax layer for clinical classification tasks.
Acknowledging the unique challenges in EHRs, such as varying group sizes and
class imbalance, we introduce a novel fairness metric to effectively measure
error rate disparities across subgroups. Extensive experiments on three diverse
EHR datasets on three tasks demonstrate the effectiveness of FairEHR-CLP in
terms of fairness and utility compared with competitive baselines. FairEHR-CLP
represents an advancement towards ensuring both accuracy and equity in
predictive healthcare models.</div><div><a href='http://arxiv.org/abs/2402.00955v1'>2402.00955v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.05235v1")'>Fairness-Aware Interpretable Modeling (FAIM) for Trustworthy Machine
  Learning in Healthcare</div>
<div id='2403.05235v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-08T11:51:00Z</div><div>Authors: Mingxuan Liu, Yilin Ning, Yuhe Ke, Yuqing Shang, Bibhas Chakraborty, Marcus Eng Hock Ong, Roger Vaughan, Nan Liu</div><div style='padding-top: 10px; width: 80ex'>The escalating integration of machine learning in high-stakes fields such as
healthcare raises substantial concerns about model fairness. We propose an
interpretable framework - Fairness-Aware Interpretable Modeling (FAIM), to
improve model fairness without compromising performance, featuring an
interactive interface to identify a "fairer" model from a set of
high-performing models and promoting the integration of data-driven evidence
and clinical expertise to enhance contextualized fairness. We demonstrated
FAIM's value in reducing sex and race biases by predicting hospital admission
with two real-world databases, MIMIC-IV-ED and SGH-ED. We show that for both
datasets, FAIM models not only exhibited satisfactory discriminatory
performance but also significantly mitigated biases as measured by
well-established fairness metrics, outperforming commonly used bias-mitigation
methods. Our approach demonstrates the feasibility of improving fairness
without sacrificing performance and provides an a modeling mode that invites
domain experts to engage, fostering a multidisciplinary effort toward tailored
AI fairness.</div><div><a href='http://arxiv.org/abs/2403.05235v1'>2403.05235v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.13635v1")'>The METRIC-framework for assessing data quality for trustworthy AI in
  medicine: a systematic review</div>
<div id='2402.13635v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-21T09:15:46Z</div><div>Authors: Daniel Schwabe, Katinka Becker, Martin Seyferth, Andreas Klaß, Tobias Schäffter</div><div style='padding-top: 10px; width: 80ex'>The adoption of machine learning (ML) and, more specifically, deep learning
(DL) applications into all major areas of our lives is underway. The
development of trustworthy AI is especially important in medicine due to the
large implications for patients' lives. While trustworthiness concerns various
aspects including ethical, technical and privacy requirements, we focus on the
importance of data quality (training/test) in DL. Since data quality dictates
the behaviour of ML products, evaluating data quality will play a key part in
the regulatory approval of medical AI products. We perform a systematic review
following PRISMA guidelines using the databases PubMed and ACM Digital Library.
We identify 2362 studies, out of which 62 records fulfil our eligibility
criteria. From this literature, we synthesise the existing knowledge on data
quality frameworks and combine it with the perspective of ML applications in
medicine. As a result, we propose the METRIC-framework, a specialised data
quality framework for medical training data comprising 15 awareness dimensions,
along which developers of medical ML applications should investigate a dataset.
This knowledge helps to reduce biases as a major source of unfairness, increase
robustness, facilitate interpretability and thus lays the foundation for
trustworthy AI in medicine. Incorporating such systematic assessment of medical
datasets into regulatory approval processes has the potential to accelerate the
approval of ML products and builds the basis for new standards.</div><div><a href='http://arxiv.org/abs/2402.13635v1'>2402.13635v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.13111v1")'>Deep learning with noisy labels in medical prediction problems: a
  scoping review</div>
<div id='2403.13111v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-19T19:24:00Z</div><div>Authors: Yishu Wei, Yu Deng, Cong Sun, Mingquan Lin, Hongmei Jiang, Yifan Peng</div><div style='padding-top: 10px; width: 80ex'>Objectives: Medical research faces substantial challenges from noisy labels
attributed to factors like inter-expert variability and machine-extracted
labels. Despite this, the adoption of label noise management remains limited,
and label noise is largely ignored. To this end, there is a critical need to
conduct a scoping review focusing on the problem space. This scoping review
aims to comprehensively review label noise management in deep learning-based
medical prediction problems, which includes label noise detection, label noise
handling, and evaluation. Research involving label uncertainty is also
included.
  Methods: Our scoping review follows the Preferred Reporting Items for
Systematic Reviews and Meta-Analyses (PRISMA) guidelines. We searched 4
databases, including PubMed, IEEE Xplore, Google Scholar, and Semantic Scholar.
Our search terms include "noisy label AND medical / healthcare / clinical",
"un-certainty AND medical / healthcare / clinical", and "noise AND medical /
healthcare / clinical".
  Results: A total of 60 papers met inclusion criteria between 2016 and 2023. A
series of practical questions in medical research are investigated. These
include the sources of label noise, the impact of label noise, the detection of
label noise, label noise handling techniques, and their evaluation.
Categorization of both label noise detection methods and handling techniques
are provided.
  Discussion: From a methodological perspective, we observe that the medical
community has been up to date with the broader deep-learning community, given
that most techniques have been evaluated on medical data. We recommend
considering label noise as a standard element in medical research, even if it
is not dedicated to handling noisy labels. Initial experiments can start with
easy-to-implement methods, such as noise-robust loss functions, weighting, and
curriculum learning.</div><div><a href='http://arxiv.org/abs/2403.13111v1'>2403.13111v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16796v1")'>Learnable Prompt as Pseudo-Imputation: Reassessing the Necessity of
  Traditional EHR Data Imputation in Downstream Clinical Prediction</div>
<div id='2401.16796v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T07:19:36Z</div><div>Authors: Weibin Liao, Yinghao Zhu, Zixiang Wang, Xu Chu, Yasha Wang, Liantao Ma</div><div style='padding-top: 10px; width: 80ex'>Analyzing the health status of patients based on Electronic Health Records
(EHR) is a fundamental research problem in medical informatics. The presence of
extensive missing values in EHR makes it challenging for deep neural networks
to directly model the patient's health status based on EHR. Existing deep
learning training protocols require the use of statistical information or
imputation models to reconstruct missing values; however, the protocols inject
non-realistic data into downstream EHR analysis models, significantly limiting
model performance. This paper introduces Learnable Prompt as Pseudo Imputation
(PAI) as a new training protocol. PAI no longer introduces any imputed data but
constructs a learnable prompt to model the implicit preferences of the
downstream model for missing values, resulting in a significant performance
improvement for all EHR analysis models. Additionally, our experiments show
that PAI exhibits higher robustness in situations of data insufficiency and
high missing rates. More importantly, in a real-world application involving
cross-institutional data with zero-shot evaluation, PAI demonstrates stronger
model generalization capabilities for non-overlapping features.</div><div><a href='http://arxiv.org/abs/2401.16796v1'>2401.16796v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.03478v1")'>Hyper-Diffusion: Estimating Epistemic and Aleatoric Uncertainty with a
  Single Model</div>
<div id='2402.03478v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T19:39:52Z</div><div>Authors: Matthew A. Chan, Maria J. Molina, Christopher A. Metzler</div><div style='padding-top: 10px; width: 80ex'>Estimating and disentangling epistemic uncertainty (uncertainty that can be
reduced with more training data) and aleatoric uncertainty (uncertainty that is
inherent to the task at hand) is critically important when applying machine
learning (ML) to high-stakes applications such as medical imaging and weather
forecasting. Conditional diffusion models' breakthrough ability to accurately
and efficiently sample from the posterior distribution of a dataset now makes
uncertainty estimation conceptually straightforward: One need only train and
sample from a large ensemble of diffusion models. Unfortunately, training such
an ensemble becomes computationally intractable as the complexity of the model
architecture grows.
  In this work we introduce a new approach to ensembling, hyper-diffusion,
which allows one to accurately estimate epistemic and aleatoric uncertainty
with a single model. Unlike existing Monte Carlo dropout based single-model
ensembling methods, hyper-diffusion offers the same prediction accuracy as
multi-model ensembles. We validate our approach on two distinct tasks: x-ray
computed tomography (CT) reconstruction and weather temperature forecasting.</div><div><a href='http://arxiv.org/abs/2402.03478v1'>2402.03478v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.14039v1")'>Specialty detection in the context of telemedicine in a highly
  imbalanced multi-class distribution</div>
<div id='2402.14039v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-21T06:39:04Z</div><div>Authors: Alaa Alomari, Hossam Faris, Pedro A. Castillo</div><div style='padding-top: 10px; width: 80ex'>The Covid-19 pandemic has led to an increase in the awareness of and demand
for telemedicine services, resulting in a need for automating the process and
relying on machine learning (ML) to reduce the operational load. This research
proposes a specialty detection classifier based on a machine learning model to
automate the process of detecting the correct specialty for each question and
routing it to the correct doctor. The study focuses on handling multiclass and
highly imbalanced datasets for Arabic medical questions, comparing some
oversampling techniques, developing a Deep Neural Network (DNN) model for
specialty detection, and exploring the hidden business areas that rely on
specialty detection such as customizing and personalizing the consultation flow
for different specialties. The proposed module is deployed in both synchronous
and asynchronous medical consultations to provide more real-time
classification, minimize the doctor effort in addressing the correct specialty,
and give the system more flexibility in customizing the medical consultation
flow. The evaluation and assessment are based on accuracy, precision, recall,
and F1-score. The experimental results suggest that combining multiple
techniques, such as SMOTE and reweighing with keyword identification, is
necessary to achieve improved performance in detecting rare classes in
imbalanced multiclass datasets. By using these techniques, specialty detection
models can more accurately detect rare classes in real-world scenarios where
imbalanced data is common.</div><div><a href='http://arxiv.org/abs/2402.14039v1'>2402.14039v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.02458v1")'>Data-Centric Foundation Models in Computational Healthcare: A Survey</div>
<div id='2401.02458v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-04T08:00:32Z</div><div>Authors: Yunkun Zhang, Jin Gao, Zheling Tan, Lingfeng Zhou, Kexin Ding, Mu Zhou, Shaoting Zhang, Dequan Wang</div><div style='padding-top: 10px; width: 80ex'>The advent of foundation models (FMs) as an emerging suite of AI techniques
has struck a wave of opportunities in computational healthcare. The interactive
nature of these models, guided by pre-training data and human instructions, has
ignited a data-centric AI paradigm that emphasizes better data
characterization, quality, and scale. In healthcare AI, obtaining and
processing high-quality clinical data records has been a longstanding
challenge, ranging from data quantity, annotation, patient privacy, and ethics.
In this survey, we investigate a wide range of data-centric approaches in the
FM era (from model pre-training to inference) towards improving the healthcare
workflow. We discuss key perspectives in AI security, assessment, and alignment
with human values. Finally, we offer a promising outlook of FM-based analytics
to enhance the performance of patient outcome and clinical workflow in the
evolving landscape of healthcare and medicine. We provide an up-to-date list of
healthcare-related foundation models and datasets at
https://github.com/Yunkun-Zhang/Data-Centric-FM-Healthcare .</div><div><a href='http://arxiv.org/abs/2401.02458v1'>2401.02458v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13716v1")'>Can I trust my fake data -- A comprehensive quality assessment framework
  for synthetic tabular data in healthcare</div>
<div id='2401.13716v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T08:14:20Z</div><div>Authors: Vibeke Binz Vallevik, Aleksandar Babic, Serena Elizabeth Marshall, Severin Elvatun, Helga Brøgger, Sharmini Alagaratnam, Bjørn Edwin, Narasimha Raghavan Veeraragavan, Anne Kjersti Befring, Jan Franz Nygård</div><div style='padding-top: 10px; width: 80ex'>Ensuring safe adoption of AI tools in healthcare hinges on access to
sufficient data for training, testing and validation. In response to privacy
concerns and regulatory requirements, using synthetic data has been suggested.
Synthetic data is created by training a generator on real data to produce a
dataset with similar statistical properties. Competing metrics with differing
taxonomies for quality evaluation have been suggested, resulting in a complex
landscape. Optimising quality entails balancing considerations that make the
data fit for use, yet relevant dimensions are left out of existing frameworks.
We performed a comprehensive literature review on the use of quality evaluation
metrics on SD within the scope of tabular healthcare data and SD made using
deep generative methods. Based on this and the collective team experiences, we
developed a conceptual framework for quality assurance. The applicability was
benchmarked against a practical case from the Dutch National Cancer Registry.
We present a conceptual framework for quality assurance of SD for AI
applications in healthcare that aligns diverging taxonomies, expands on common
quality dimensions to include the dimensions of Fairness and Carbon footprint,
and proposes stages necessary to support real-life applications. Building trust
in synthetic data by increasing transparency and reducing the safety risk will
accelerate the development and uptake of trustworthy AI tools for the benefit
of patients. Despite the growing emphasis on algorithmic fairness and carbon
footprint, these metrics were scarce in the literature review. The overwhelming
focus was on statistical similarity using distance metrics while sequential
logic detection was scarce. A consensus-backed framework that includes all
relevant quality dimensions can provide assurance for safe and responsible
real-life applications of SD.</div><div><a href='http://arxiv.org/abs/2401.13716v1'>2401.13716v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.17653v1")'>A primer on synthetic health data</div>
<div id='2401.17653v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-31T08:13:35Z</div><div>Authors: Jennifer Anne Bartell, Sander Boisen Valentin, Anders Krogh, Henning Langberg, Martin Bøgsted</div><div style='padding-top: 10px; width: 80ex'>Recent advances in deep generative models have greatly expanded the potential
to create realistic synthetic health datasets. These synthetic datasets aim to
preserve the characteristics, patterns, and overall scientific conclusions
derived from sensitive health datasets without disclosing patient identity or
sensitive information. Thus, synthetic data can facilitate safe data sharing
that supports a range of initiatives including the development of new
predictive models, advanced health IT platforms, and general project ideation
and hypothesis development. However, many questions and challenges remain,
including how to consistently evaluate a synthetic dataset's similarity and
predictive utility in comparison to the original real dataset and risk to
privacy when shared. Additional regulatory and governance issues have not been
widely addressed. In this primer, we map the state of synthetic health data,
including generation and evaluation methods and tools, existing examples of
deployment, the regulatory and ethical landscape, access and governance
options, and opportunities for further development.</div><div><a href='http://arxiv.org/abs/2401.17653v1'>2401.17653v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.13612v1")'>Does Differentially Private Synthetic Data Lead to Synthetic
  Discoveries?</div>
<div id='2403.13612v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-20T14:03:57Z</div><div>Authors: Ileana Montoya Perez, Parisa Movahedi, Valtteri Nieminen, Antti Airola, Tapio Pahikkala</div><div style='padding-top: 10px; width: 80ex'>Background: Synthetic data has been proposed as a solution for sharing
anonymized versions of sensitive biomedical datasets. Ideally, synthetic data
should preserve the structure and statistical properties of the original data,
while protecting the privacy of the individual subjects. Differential privacy
(DP) is currently considered the gold standard approach for balancing this
trade-off.
  Objectives: The aim of this study is to evaluate the Mann-Whitney U test on
DP-synthetic biomedical data in terms of Type I and Type II errors, in order to
establish whether statistical hypothesis testing performed on privacy
preserving synthetic data is likely to lead to loss of test's validity or
decreased power.
  Methods: We evaluate the Mann-Whitney U test on DP-synthetic data generated
from real-world data, including a prostate cancer dataset (n=500) and a
cardiovascular dataset (n=70 000), as well as on data drawn from two Gaussian
distributions. Five different DP-synthetic data generation methods are
evaluated, including two basic DP histogram release methods and MWEM,
Private-PGM, and DP GAN algorithms.
  Conclusion: Most of the tested DP-synthetic data generation methods showed
inflated Type I error, especially at privacy budget levels of $\epsilon\leq 1$.
This result calls for caution when releasing and analyzing DP-synthetic data:
low p-values may be obtained in statistical tests simply as a byproduct of the
noise added to protect privacy. A DP smoothed histogram-based synthetic data
generation method was shown to produce valid Type I error for all privacy
levels tested but required a large original dataset size and a modest privacy
budget ($\epsilon\geq 5$) in order to have reasonable Type II error levels.</div><div><a href='http://arxiv.org/abs/2403.13612v1'>2403.13612v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14042v2")'>Protect and Extend -- Using GANs for Synthetic Data Generation of
  Time-Series Medical Records</div>
<div id='2402.14042v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-21T10:24:34Z</div><div>Authors: Navid Ashrafi, Vera Schmitt, Robert P. Spang, Sebastian Möller, Jan-Niklas Voigt-Antons</div><div style='padding-top: 10px; width: 80ex'>Preservation of private user data is of paramount importance for high Quality
of Experience (QoE) and acceptability, particularly with services treating
sensitive data, such as IT-based health services. Whereas anonymization
techniques were shown to be prone to data re-identification, synthetic data
generation has gradually replaced anonymization since it is relatively less
time and resource-consuming and more robust to data leakage. Generative
Adversarial Networks (GANs) have been used for generating synthetic datasets,
especially GAN frameworks adhering to the differential privacy phenomena. This
research compares state-of-the-art GAN-based models for synthetic data
generation to generate time-series synthetic medical records of dementia
patients which can be distributed without privacy concerns. Predictive
modeling, autocorrelation, and distribution analysis are used to assess the
Quality of Generating (QoG) of the generated data. The privacy preservation of
the respective models is assessed by applying membership inference attacks to
determine potential data leakage risks. Our experiments indicate the
superiority of the privacy-preserving GAN (PPGAN) model over other models
regarding privacy preservation while maintaining an acceptable level of QoG.
The presented results can support better data protection for medical use cases
in the future.</div><div><a href='http://arxiv.org/abs/2402.14042v2'>2402.14042v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13327v1")'>Generating Synthetic Health Sensor Data for Privacy-Preserving Wearable
  Stress Detection</div>
<div id='2401.13327v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T09:44:57Z</div><div>Authors: Lucas Lange, Nils Wenzlitschke, Erhard Rahm</div><div style='padding-top: 10px; width: 80ex'>Smartwatch health sensor data is increasingly utilized in smart health
applications and patient monitoring, including stress detection. However, such
medical data often comprises sensitive personal information and is
resource-intensive to acquire for research purposes. In response to this
challenge, we introduce the privacy-aware synthetization of multi-sensor
smartwatch health readings related to moments of stress. Our method involves
the generation of synthetic sequence data through Generative Adversarial
Networks (GANs), coupled with the implementation of Differential Privacy (DP)
safeguards for protecting patient information during model training. To ensure
the integrity of our synthetic data, we employ a range of quality assessments
and monitor the plausibility between synthetic and original data. To test the
usefulness, we create private machine learning models on a commonly used,
albeit small, stress detection dataset, exploring strategies for enhancing the
existing data foundation with our synthetic data. Through our GAN-based
augmentation methods, we observe improvements in model performance, both in
non-private (0.45% F1) and private (11.90-15.48% F1) training scenarios. We
underline the potential of differentially private synthetic data in optimizing
utility-privacy trade-offs, especially with limited availability of real
training samples.</div><div><a href='http://arxiv.org/abs/2401.13327v1'>2401.13327v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.10862v1")'>Differential Private Federated Transfer Learning for Mental Health
  Monitoring in Everyday Settings: A Case Study on Stress Detection</div>
<div id='2402.10862v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-16T18:00:04Z</div><div>Authors: Ziyu Wang, Zhongqi Yang, Iman Azimi, Amir M. Rahmani</div><div style='padding-top: 10px; width: 80ex'>Mental health conditions, prevalent across various demographics, necessitate
efficient monitoring to mitigate their adverse impacts on life quality. The
surge in data-driven methodologies for mental health monitoring has underscored
the importance of privacy-preserving techniques in handling sensitive health
data. Despite strides in federated learning for mental health monitoring,
existing approaches struggle with vulnerabilities to certain cyber-attacks and
data insufficiency in real-world applications. In this paper, we introduce a
differential private federated transfer learning framework for mental health
monitoring to enhance data privacy and enrich data sufficiency. To accomplish
this, we integrate federated learning with two pivotal elements: (1)
differential privacy, achieved by introducing noise into the updates, and (2)
transfer learning, employing a pre-trained universal model to adeptly address
issues of data imbalance and insufficiency. We evaluate the framework by a case
study on stress detection, employing a dataset of physiological and contextual
data from a longitudinal study. Our finding show that the proposed approach can
attain a 10% boost in accuracy and a 21% enhancement in recall, while ensuring
privacy protection.</div><div><a href='http://arxiv.org/abs/2402.10862v1'>2402.10862v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.14724v1")'>Six Levels of Privacy: A Framework for Financial Synthetic Data</div>
<div id='2403.14724v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-20T20:41:26Z</div><div>Authors: Tucker Balch, Vamsi K. Potluru, Deepak Paramanand, Manuela Veloso</div><div style='padding-top: 10px; width: 80ex'>Synthetic Data is increasingly important in financial applications. In
addition to the benefits it provides, such as improved financial modeling and
better testing procedures, it poses privacy risks as well. Such data may arise
from client information, business information, or other proprietary sources
that must be protected. Even though the process by which Synthetic Data is
generated serves to obscure the original data to some degree, the extent to
which privacy is preserved is hard to assess. Accordingly, we introduce a
hierarchy of ``levels'' of privacy that are useful for categorizing Synthetic
Data generation methods and the progressively improved protections they offer.
While the six levels were devised in the context of financial applications,
they may also be appropriate for other industries as well. Our paper includes:
A brief overview of Financial Synthetic Data, how it can be used, how its value
can be assessed, privacy risks, and privacy attacks. We close with details of
the ``Six Levels'' that include defenses against those attacks.</div><div><a href='http://arxiv.org/abs/2403.14724v1'>2403.14724v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.10657v1")'>FIMBA: Evaluating the Robustness of AI in Genomics via Feature
  Importance Adversarial Attacks</div>
<div id='2401.10657v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-19T12:04:31Z</div><div>Authors: Heorhii Skovorodnikov, Hoda Alkhzaimi</div><div style='padding-top: 10px; width: 80ex'>With the steady rise of the use of AI in bio-technical applications and the
widespread adoption of genomics sequencing, an increasing amount of AI-based
algorithms and tools is entering the research and production stage affecting
critical decision-making streams like drug discovery and clinical outcomes.
This paper demonstrates the vulnerability of AI models often utilized
downstream tasks on recognized public genomics datasets. We undermine model
robustness by deploying an attack that focuses on input transformation while
mimicking the real data and confusing the model decision-making, ultimately
yielding a pronounced deterioration in model performance. Further, we enhance
our approach by generating poisoned data using a variational autoencoder-based
model. Our empirical findings unequivocally demonstrate a decline in model
performance, underscored by diminished accuracy and an upswing in false
positives and false negatives. Furthermore, we analyze the resulting
adversarial samples via spectral analysis yielding conclusions for
countermeasures against such attacks.</div><div><a href='http://arxiv.org/abs/2401.10657v1'>2401.10657v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.06263v1")'>FedTabDiff: Federated Learning of Diffusion Probabilistic Models for
  Synthetic Mixed-Type Tabular Data Generation</div>
<div id='2401.06263v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-11T21:17:50Z</div><div>Authors: Timur Sattarov, Marco Schreyer, Damian Borth</div><div style='padding-top: 10px; width: 80ex'>Realistic synthetic tabular data generation encounters significant challenges
in preserving privacy, especially when dealing with sensitive information in
domains like finance and healthcare. In this paper, we introduce
\textit{Federated Tabular Diffusion} (FedTabDiff) for generating high-fidelity
mixed-type tabular data without centralized access to the original tabular
datasets. Leveraging the strengths of \textit{Denoising Diffusion Probabilistic
Models} (DDPMs), our approach addresses the inherent complexities in tabular
data, such as mixed attribute types and implicit relationships. More
critically, FedTabDiff realizes a decentralized learning scheme that permits
multiple entities to collaboratively train a generative model while respecting
data privacy and locality. We extend DDPMs into the federated setting for
tabular data generation, which includes a synchronous update scheme and
weighted averaging for effective model aggregation. Experimental evaluations on
real-world financial and medical datasets attest to the framework's capability
to produce synthetic data that maintains high fidelity, utility, privacy, and
coverage.</div><div><a href='http://arxiv.org/abs/2401.06263v1'>2401.06263v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.01652v1")'>User-Centric AI Analytics for Chronic Health Conditions Management</div>
<div id='2402.01652v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-09T17:22:04Z</div><div>Authors: Aladdin Ayesh</div><div style='padding-top: 10px; width: 80ex'>The use of AI analytics in health informatics has seen a rapid growth in
recent years. In this talk, we look at AI analytics use in managing chronic
health conditions such as diabetes, obesity, etc. We focus on the challenges in
managing these conditions especially with drug-free approaches due to the
variations in individual circumstances. These variations directed the research
into user-centric approach leading to variety of research questions. In this
short paper, we give examples from recent and current research work and
conclude with what, in our opinion, to be the next steps and some remaining
open research questions.</div><div><a href='http://arxiv.org/abs/2402.01652v1'>2402.01652v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.10816v2")'>Co-Pilot for Health: Personalized Algorithmic AI Nudging to Improve
  Health Outcomes</div>
<div id='2401.10816v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-19T17:03:37Z</div><div>Authors: Jodi Chiam, Aloysius Lim, Cheryl Nott, Nicholas Mark, Ankur Teredesai, Sunil Shinde</div><div style='padding-top: 10px; width: 80ex'>The ability to shape health behaviors of large populations automatically,
across wearable types and disease conditions at scale has tremendous potential
to improve global health outcomes. We designed and implemented an AI driven
platform for digital algorithmic nudging, enabled by a Graph-Neural Network
(GNN) based Recommendation System, and granular health behavior data from
wearable fitness devices. Here we describe the efficacy results of this
platform with its capabilities of personalized and contextual nudging to
$n=84,764$ individuals over a 12-week period in Singapore. We statistically
validated that participants in the target group who received such AI optimized
daily nudges increased daily physical activity like step count by 6.17% ($p =
3.09\times10^{-4}$) and weekly minutes of Moderate to Vigorous Physical
Activity (MVPA) by 7.61% ($p = 1.16\times10^{-2}$), compared to matched
participants in control group who did not receive any nudges. Further, such
nudges were very well received, with a 13.1% of nudges sent being opened (open
rate), and 11.7% of the opened nudges rated useful compared to 1.9% rated as
not useful thereby demonstrating significant improvement in population level
engagement metrics.</div><div><a href='http://arxiv.org/abs/2401.10816v2'>2401.10816v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.16909v1")'>Impact of Physical Activity on Quality of Life During Pregnancy: A
  Causal ML Approach</div>
<div id='2402.16909v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-25T12:07:32Z</div><div>Authors: Kianoosh Kazemi, Iina Ryhtä, Iman Azimi, Hannakaisa Niela-Vilen, Anna Axelin, Amir M. Rahmani, Pasi Liljeberg</div><div style='padding-top: 10px; width: 80ex'>The concept of Quality of Life (QoL) refers to a holistic measurement of an
individual's well-being, incorporating psychological and social aspects.
Pregnant women, especially those with obesity and stress, often experience
lower QoL. Physical activity (PA) has shown the potential to enhance the QoL.
However, pregnant women who are overweight and obese rarely meet the
recommended level of PA. Studies have investigated the relationship between PA
and QoL during pregnancy using correlation-based approaches. These methods aim
to discover spurious correlations between variables rather than causal
relationships. Besides, the existing methods mainly rely on physical activity
parameters and neglect the use of different factors such as maternal (medical)
history and context data, leading to biased estimates. Furthermore, the
estimations lack an understanding of mediators and counterfactual scenarios
that might affect them. In this paper, we investigate the causal relationship
between being physically active (treatment variable) and the QoL (outcome)
during pregnancy and postpartum. To estimate the causal effect, we develop a
Causal Machine Learning method, integrating causal discovery and causal
inference components. The data for our investigation is derived from a
long-term wearable-based health monitoring study focusing on overweight and
obese pregnant women. The machine learning (meta-learner) estimation technique
is used to estimate the causal effect. Our result shows that performing
adequate physical activity during pregnancy and postpartum improves the QoL by
units of 7.3 and 3.4 on average in physical health and psychological domains,
respectively. In the final step, four refutation analysis techniques are
employed to validate our estimation.</div><div><a href='http://arxiv.org/abs/2402.16909v1'>2402.16909v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.12007v2")'>Defining Effective Engagement For Enhancing Cancer Patients' Well-being
  with Mobile Digital Behavior Change Interventions</div>
<div id='2403.12007v2' style='display: none; margin-left: 20px'><div>Date: 2024-03-18T17:43:40Z</div><div>Authors: Aneta Lisowska, Szymon Wilk, Laura Locati, Mimma Rizzo, Lucia Sacchi, Silvana Quaglini, Matteo Terzaghi, Valentina Tibollo, Mor Peleg</div><div style='padding-top: 10px; width: 80ex'>Digital Behavior Change Interventions (DBCIs) are supporting development of
new health behaviors. Evaluating their effectiveness is crucial for their
improvement and understanding of success factors. However, comprehensive
guidance for developers, particularly in small-scale studies with ethical
constraints, is limited. Building on the CAPABLE project, this study aims to
define effective engagement with DBCIs for supporting cancer patients in
enhancing their quality of life. We identify metrics for measuring engagement,
explore the interest of both patients and clinicians in DBCIs, and propose
hypotheses for assessing the impact of DBCIs in such contexts. Our findings
suggest that clinician prescriptions significantly increase sustained
engagement with mobile DBCIs. In addition, while one weekly engagement with a
DBCI is sufficient to maintain well-being, transitioning from extrinsic to
intrinsic motivation may require a higher level of engagement.</div><div><a href='http://arxiv.org/abs/2403.12007v2'>2403.12007v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.07915v1")'>Research on Older Adults' Interaction with E-Health Interface Based on
  Explainable Artificial Intelligence</div>
<div id='2402.07915v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T16:39:02Z</div><div>Authors: Xueting Huang, Zhibo Zhang, Fusen Guo, Xianghao Wang, Kun Chi, Kexin Wu</div><div style='padding-top: 10px; width: 80ex'>This paper proposed a comprehensive mixed-methods framework with varied
samples of older adults, including user experience, usability assessments, and
in-depth interviews with the integration of Explainable Artificial Intelligence
(XAI) methods. The experience of older adults' interaction with the Ehealth
interface is collected through interviews and transformed into operatable
databases whereas XAI methods are utilized to explain the collected interview
results in this research work. The results show that XAI-infused e-health
interfaces could play an important role in bridging the age-related digital
divide by investigating elders' preferences when interacting with E-health
interfaces. Furthermore, the study identifies important design factors, such as
intuitive visualization and straightforward explanations, that are critical for
creating efficient Human Computer Interaction (HCI) tools among older users.
Furthermore, this study emphasizes the revolutionary potential of XAI in
e-health interfaces for older users, emphasizing the importance of transparency
and understandability in HCI-driven healthcare solutions. This study's findings
have far-reaching implications for the design and development of user-centric
e-health technologies, intending to increase the overall well-being of older
adults.</div><div><a href='http://arxiv.org/abs/2402.07915v1'>2402.07915v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.17554v1")'>Evaluation of Predictive Reliability to Foster Trust in Artificial
  Intelligence. A case study in Multiple Sclerosis</div>
<div id='2402.17554v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T14:48:07Z</div><div>Authors: Lorenzo Peracchio, Giovanna Nicora, Enea Parimbelli, Tommaso Mario Buonocore, Roberto Bergamaschi, Eleonora Tavazzi, Arianna Dagliati, Riccardo Bellazzi</div><div style='padding-top: 10px; width: 80ex'>Applying Artificial Intelligence (AI) and Machine Learning (ML) in critical
contexts, such as medicine, requires the implementation of safety measures to
reduce risks of harm in case of prediction errors. Spotting ML failures is of
paramount importance when ML predictions are used to drive clinical decisions.
ML predictive reliability measures the degree of trust of a ML prediction on a
new instance, thus allowing decision-makers to accept or reject it based on its
reliability. To assess reliability, we propose a method that implements two
principles. First, our approach evaluates whether an instance to be classified
is coming from the same distribution of the training set. To do this, we
leverage Autoencoders (AEs) ability to reconstruct the training set with low
error. An instance is considered Out-of-Distribution (OOD) if the AE
reconstructs it with a high error. Second, it is evaluated whether the ML
classifier has good performances on samples similar to the newly classified
instance by using a proxy model. We show that this approach is able to assess
reliability both in a simulated scenario and on a model trained to predict
disease progression of Multiple Sclerosis patients. We also developed a Python
package, named relAI, to embed reliability measures into ML pipelines. We
propose a simple approach that can be used in the deployment phase of any ML
model to suggest whether to trust predictions or not. Our method holds the
promise to provide effective support to clinicians by spotting potential ML
failures during deployment.</div><div><a href='http://arxiv.org/abs/2402.17554v1'>2402.17554v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.04139v2")'>CCNETS: A Novel Brain-Inspired Approach for Enhanced Pattern Recognition
  in Imbalanced Datasets</div>
<div id='2401.04139v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-07T14:41:31Z</div><div>Authors: Hanbeot Park, Yunjeong Cho, Hoon-Hee Kim</div><div style='padding-top: 10px; width: 80ex'>This study introduces CCNETS (Causal Learning with Causal Cooperative Nets),
a novel generative model-based classifier designed to tackle the challenge of
generating data for imbalanced datasets in pattern recognition. CCNETS is
uniquely crafted to emulate brain-like information processing and comprises
three main components: Explainer, Producer, and Reasoner. Each component is
designed to mimic specific brain functions, which aids in generating
high-quality datasets and enhancing classification performance.
  The model is particularly focused on addressing the common and significant
challenge of handling imbalanced datasets in machine learning. CCNETS's
effectiveness is demonstrated through its application to a "fraud dataset,"
where normal transactions significantly outnumber fraudulent ones (99.83% vs.
0.17%). Traditional methods often struggle with such imbalances, leading to
skewed performance metrics. However, CCNETS exhibits superior classification
ability, as evidenced by its performance metrics. Specifically, it achieved an
F1-score of 0.7992, outperforming traditional models like Autoencoders and
Multi-layer Perceptrons (MLP) in the same context. This performance indicates
CCNETS's proficiency in more accurately distinguishing between normal and
fraudulent patterns.
  The innovative structure of CCNETS enhances the coherence between generative
and classification models, helping to overcome the limitations of pattern
recognition that rely solely on generative models. This study emphasizes
CCNETS's potential in diverse applications, especially where quality data
generation and pattern recognition are key. It proves effective in machine
learning, particularly for imbalanced datasets. CCNETS overcomes current
challenges in these datasets and advances machine learning with brain-inspired
approaches.</div><div><a href='http://arxiv.org/abs/2401.04139v2'>2401.04139v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.11079v1")'>Bridging Expert Knowledge with Deep Learning Techniques for Just-In-Time
  Defect Prediction</div>
<div id='2403.11079v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-17T04:20:38Z</div><div>Authors: Xin Zhou, DongGyun Han, David Lo</div><div style='padding-top: 10px; width: 80ex'>Just-In-Time (JIT) defect prediction aims to automatically predict whether a
commit is defective or not, and has been widely studied in recent years. In
general, most studies can be classified into two categories: 1) simple models
using traditional machine learning classifiers with hand-crafted features, and
2) complex models using deep learning techniques to automatically extract
features from commit contents. Hand-crafted features used by simple models are
based on expert knowledge but may not fully represent the semantic meaning of
the commits. On the other hand, deep learning-based features used by complex
models represent the semantic meaning of commits but may not reflect useful
expert knowledge. Simple models and complex models seem complementary to each
other to some extent. To utilize the advantages of both simple and complex
models, we propose a model fusion framework that adopts both early fusions on
the feature level and late fusions on the decision level. We propose SimCom++
by adopting the best early and late fusion strategies. The experimental results
show that SimCom++ can significantly outperform the baselines by 5.7--26.9\%.
In addition, our experimental results confirm that the simple model and complex
model are complementary to each other.</div><div><a href='http://arxiv.org/abs/2403.11079v1'>2403.11079v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.05683v1")'>Efficient Public Health Intervention Planning Using Decomposition-Based
  Decision-Focused Learning</div>
<div id='2403.05683v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-08T21:31:00Z</div><div>Authors: Sanket Shah, Arun Suggala, Milind Tambe, Aparna Taneja</div><div style='padding-top: 10px; width: 80ex'>The declining participation of beneficiaries over time is a key concern in
public health programs. A popular strategy for improving retention is to have
health workers `intervene' on beneficiaries at risk of dropping out. However,
the availability and time of these health workers are limited resources. As a
result, there has been a line of research on optimizing these limited
intervention resources using Restless Multi-Armed Bandits (RMABs). The key
technical barrier to using this framework in practice lies in the need to
estimate the beneficiaries' RMAB parameters from historical data. Recent
research has shown that Decision-Focused Learning (DFL), which focuses on
maximizing the beneficiaries' adherence rather than predictive accuracy,
improves the performance of intervention targeting using RMABs. Unfortunately,
these gains come at a high computational cost because of the need to solve and
evaluate the RMAB in each DFL training step. In this paper, we provide a
principled way to exploit the structure of RMABs to speed up intervention
planning by cleverly decoupling the planning for different beneficiaries. We
use real-world data from an Indian NGO, ARMMAN, to show that our approach is up
to two orders of magnitude faster than the state-of-the-art approach while also
yielding superior model performance. This would enable the NGO to scale up
deployments using DFL to potentially millions of mothers, ultimately advancing
progress toward UNSDG 3.1.</div><div><a href='http://arxiv.org/abs/2403.05683v1'>2403.05683v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.03482v1")'>Uncertainty Quantification on Clinical Trial Outcome Prediction</div>
<div id='2401.03482v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-07T13:48:05Z</div><div>Authors: Tianyi Chen, Nan Hao, Yingzhou Lu, Capucine Van Rechem</div><div style='padding-top: 10px; width: 80ex'>The importance of uncertainty quantification is increasingly recognized in
the diverse field of machine learning. Accurately assessing model prediction
uncertainty can help provide deeper understanding and confidence for
researchers and practitioners. This is especially critical in medical diagnosis
and drug discovery areas, where reliable predictions directly impact research
quality and patient health.
  In this paper, we proposed incorporating uncertainty quantification into
clinical trial outcome predictions. Our main goal is to enhance the model's
ability to discern nuanced differences, thereby significantly improving its
overall performance.
  We have adopted a selective classification approach to fulfill our objective,
integrating it seamlessly with the Hierarchical Interaction Network (HINT),
which is at the forefront of clinical trial prediction modeling. Selective
classification, encompassing a spectrum of methods for uncertainty
quantification, empowers the model to withhold decision-making in the face of
samples marked by ambiguity or low confidence, thereby amplifying the accuracy
of predictions for the instances it chooses to classify. A series of
comprehensive experiments demonstrate that incorporating selective
classification into clinical trial predictions markedly enhances the model's
performance, as evidenced by significant upticks in pivotal metrics such as
PR-AUC, F1, ROC-AUC, and overall accuracy.
  Specifically, the proposed method achieved 32.37\%, 21.43\%, and 13.27\%
relative improvement on PR-AUC over the base model (HINT) in phase I, II, and
III trial outcome prediction, respectively. When predicting phase III, our
method reaches 0.9022 PR-AUC scores.
  These findings illustrate the robustness and prospective utility of this
strategy within the area of clinical trial predictions, potentially setting a
new benchmark in the field.</div><div><a href='http://arxiv.org/abs/2401.03482v1'>2401.03482v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12190v2")'>Towards AI-Based Precision Oncology: A Machine Learning Framework for
  Personalized Counterfactual Treatment Suggestions based on Multi-Omics Data</div>
<div id='2402.12190v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-19T14:54:20Z</div><div>Authors: Manuel Schürch, Laura Boos, Viola Heinzelmann-Schwarz, Gabriele Gut, Michael Krauthammer, Andreas Wicki, Tumor Profiler Consortium</div><div style='padding-top: 10px; width: 80ex'>AI-driven precision oncology has the transformative potential to reshape
cancer treatment by leveraging the power of AI models to analyze the
interaction between complex patient characteristics and their corresponding
treatment outcomes. New technological platforms have facilitated the timely
acquisition of multimodal data on tumor biology at an unprecedented resolution,
such as single-cell multi-omics data, making this quality and quantity of data
available for data-driven improved clinical decision-making. In this work, we
propose a modular machine learning framework designed for personalized
counterfactual cancer treatment suggestions based on an ensemble of machine
learning experts trained on diverse multi-omics technologies. These specialized
counterfactual experts per technology are consistently aggregated into a more
powerful expert with superior performance and can provide both confidence and
an explanation of its decision. The framework is tailored to address critical
challenges inherent in data-driven cancer research, including the
high-dimensional nature of the data, and the presence of treatment assignment
bias in the retrospective observational data. The framework is showcased
through comprehensive demonstrations using data from in-vitro and in-vivo
treatment responses from a cohort of patients with ovarian cancer. Our method
aims to empower clinicians with a reality-centric decision-support tool
including probabilistic treatment suggestions with calibrated confidence and
personalized explanations for tailoring treatment strategies to multi-omics
characteristics of individual cancer patients.</div><div><a href='http://arxiv.org/abs/2402.12190v2'>2402.12190v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14232v1")'>Contrastive Balancing Representation Learning for Heterogeneous
  Dose-Response Curves Estimation</div>
<div id='2403.14232v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T08:41:53Z</div><div>Authors: Minqin Zhu, Anpeng Wu, Haoxuan Li, Ruoxuan Xiong, Bo Li, Xiaoqing Yang, Xuan Qin, Peng Zhen, Jiecheng Guo, Fei Wu, Kun Kuang</div><div style='padding-top: 10px; width: 80ex'>Estimating the individuals' potential response to varying treatment doses is
crucial for decision-making in areas such as precision medicine and management
science. Most recent studies predict counterfactual outcomes by learning a
covariate representation that is independent of the treatment variable.
However, such independence constraints neglect much of the covariate
information that is useful for counterfactual prediction, especially when the
treatment variables are continuous. To tackle the above issue, in this paper,
we first theoretically demonstrate the importance of the balancing and
prognostic representations for unbiased estimation of the heterogeneous
dose-response curves, that is, the learned representations are constrained to
satisfy the conditional independence between the covariates and both of the
treatment variables and the potential responses. Based on this, we propose a
novel Contrastive balancing Representation learning Network using a partial
distance measure, called CRNet, for estimating the heterogeneous dose-response
curves without losing the continuity of treatments. Extensive experiments are
conducted on synthetic and real-world datasets demonstrating that our proposal
significantly outperforms previous methods.</div><div><a href='http://arxiv.org/abs/2403.14232v1'>2403.14232v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.10690v1")'>Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and
  unfairness in dyadic regression models</div>
<div id='2401.10690v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-19T13:41:08Z</div><div>Authors: Jorge Paz-Ruza, Amparo Alonso-Betanzos, Bertha Guijarro-Berdiñas, Brais Cancela, Carlos Eiras-Franco</div><div style='padding-top: 10px; width: 80ex'>Dyadic regression models, which predict real-valued outcomes for pairs of
entities, are fundamental in many domains (e.g. predicting the rating of a user
to a product in Recommender Systems) and promising and under exploration in
many others (e.g. approximating the adequate dosage of a drug for a patient in
personalized pharmacology). In this work, we demonstrate that non-uniformity in
the observed value distributions of individual entities leads to severely
biased predictions in state-of-the-art models, skewing predictions towards the
average of observed past values for the entity and providing worse-than-random
predictive power in eccentric yet equally important cases. We show that the
usage of global error metrics like Root Mean Squared Error (RMSE) and Mean
Absolute Error (MAE) is insufficient to capture this phenomenon, which we name
eccentricity bias, and we introduce Eccentricity-Area Under the Curve (EAUC) as
a new complementary metric that can quantify it in all studied models and
datasets. We also prove the adequateness of EAUC by using naive de-biasing
corrections to demonstrate that a lower model bias correlates with a lower EAUC
and vice-versa. This work contributes a bias-aware evaluation of dyadic
regression models to avoid potential unfairness and risks in critical
real-world applications of such systems.</div><div><a href='http://arxiv.org/abs/2401.10690v1'>2401.10690v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.14264v2")'>Structure-agnostic Optimality of Doubly Robust Learning for Treatment
  Effect Estimation</div>
<div id='2402.14264v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T04:03:32Z</div><div>Authors: Jikai Jin, Vasilis Syrgkanis</div><div style='padding-top: 10px; width: 80ex'>Average treatment effect estimation is the most central problem in causal
inference with application to numerous disciplines. While many estimation
strategies have been proposed in the literature, the statistical optimality of
these methods has still remained an open area of investigation, especially in
regimes where these methods do not achieve parametric rates. In this paper, we
adopt the recently introduced structure-agnostic framework of statistical lower
bounds, which poses no structural properties on the nuisance functions other
than access to black-box estimators that achieve some statistical estimation
rate. This framework is particularly appealing when one is only willing to
consider estimation strategies that use non-parametric regression and
classification oracles as black-box sub-processes. Within this framework, we
prove the statistical optimality of the celebrated and widely used doubly
robust estimators for both the Average Treatment Effect (ATE) and the Average
Treatment Effect on the Treated (ATT), as well as weighted variants of the
former, which arise in policy evaluation.</div><div><a href='http://arxiv.org/abs/2402.14264v2'>2402.14264v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01635v1")'>kNN Algorithm for Conditional Mean and Variance Estimation with
  Automated Uncertainty Quantification and Variable Selection</div>
<div id='2402.01635v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T18:54:18Z</div><div>Authors: Marcos Matabuena, Juan C. Vidal, Oscar Hernan Madrid Padilla, Jukka-Pekka Onnela</div><div style='padding-top: 10px; width: 80ex'>In this paper, we introduce a kNN-based regression method that synergizes the
scalability and adaptability of traditional non-parametric kNN models with a
novel variable selection technique. This method focuses on accurately
estimating the conditional mean and variance of random response variables,
thereby effectively characterizing conditional distributions across diverse
scenarios.Our approach incorporates a robust uncertainty quantification
mechanism, leveraging our prior estimation work on conditional mean and
variance. The employment of kNN ensures scalable computational efficiency in
predicting intervals and statistical accuracy in line with optimal
non-parametric rates. Additionally, we introduce a new kNN semi-parametric
algorithm for estimating ROC curves, accounting for covariates. For selecting
the smoothing parameter k, we propose an algorithm with theoretical
guarantees.Incorporation of variable selection enhances the performance of the
method significantly over conventional kNN techniques in various modeling
tasks. We validate the approach through simulations in low, moderate, and
high-dimensional covariate spaces. The algorithm's effectiveness is
particularly notable in biomedical applications as demonstrated in two case
studies. Concluding with a theoretical analysis, we highlight the consistency
and convergence rate of our method over traditional kNN models, particularly
when the underlying regression model takes values in a low-dimensional space.</div><div><a href='http://arxiv.org/abs/2402.01635v1'>2402.01635v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.03359v1")'>In-Database Data Imputation</div>
<div id='2401.03359v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-07T01:57:41Z</div><div>Authors: Massimo Perini, Milos Nikolic</div><div style='padding-top: 10px; width: 80ex'>Missing data is a widespread problem in many domains, creating challenges in
data analysis and decision making. Traditional techniques for dealing with
missing data, such as excluding incomplete records or imputing simple estimates
(e.g., mean), are computationally efficient but may introduce bias and disrupt
variable relationships, leading to inaccurate analyses. Model-based imputation
techniques offer a more robust solution that preserves the variability and
relationships in the data, but they demand significantly more computation time,
limiting their applicability to small datasets.
  This work enables efficient, high-quality, and scalable data imputation
within a database system using the widely used MICE method. We adapt this
method to exploit computation sharing and a ring abstraction for faster model
training. To impute both continuous and categorical values, we develop
techniques for in-database learning of stochastic linear regression and
Gaussian discriminant analysis models. Our MICE implementations in PostgreSQL
and DuckDB outperform alternative MICE implementations and model-based
imputation techniques by up to two orders of magnitude in terms of computation
time, while maintaining high imputation quality.</div><div><a href='http://arxiv.org/abs/2401.03359v1'>2401.03359v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.06899v1")'>Analyses and Concerns in Precision Medicine: A Statistical Perspective</div>
<div id='2401.06899v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-12T21:33:17Z</div><div>Authors: Xiaofei Chen</div><div style='padding-top: 10px; width: 80ex'>This article explores the critical role of statistical analysis in precision
medicine. It discusses how personalized healthcare is enhanced by statistical
methods that interpret complex, multidimensional datasets, focusing on
predictive modeling, machine learning algorithms, and data visualization
techniques. The paper addresses challenges in data integration and
interpretation, particularly with diverse data sources like electronic health
records (EHRs) and genomic data. It also delves into ethical considerations
such as patient privacy and data security. In addition, the paper highlights
the evolution of statistical analysis in medicine, core statistical
methodologies in precision medicine, and future directions in the field,
emphasizing the integration of artificial intelligence (AI) and machine
learning (ML).</div><div><a href='http://arxiv.org/abs/2401.06899v1'>2401.06899v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01955v1")'>OPSurv: Orthogonal Polynomials Quadrature Algorithm for Survival
  Analysis</div>
<div id='2402.01955v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T23:26:09Z</div><div>Authors: Lilian W. Bialokozowicz, Hoang M. Le, Tristan Sylvain, Peter A. I. Forsyth, Vineel Nagisetty, Greg Mori</div><div style='padding-top: 10px; width: 80ex'>This paper introduces the Orthogonal Polynomials Quadrature Algorithm for
Survival Analysis (OPSurv), a new method providing time-continuous functional
outputs for both single and competing risks scenarios in survival analysis.
OPSurv utilizes the initial zero condition of the Cumulative Incidence function
and a unique decomposition of probability densities using orthogonal
polynomials, allowing it to learn functional approximation coefficients for
each risk event and construct Cumulative Incidence Function estimates via
Gauss--Legendre quadrature. This approach effectively counters overfitting,
particularly in competing risks scenarios, enhancing model expressiveness and
control. The paper further details empirical validations and theoretical
justifications of OPSurv, highlighting its robust performance as an advancement
in survival analysis with competing risks.</div><div><a href='http://arxiv.org/abs/2402.01955v1'>2402.01955v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.04489v1")'>Optimal Survival Trees: A Dynamic Programming Approach</div>
<div id='2401.04489v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-09T11:01:11Z</div><div>Authors: Tim Huisman, Jacobus G. M. van der Linden, Emir Demirović</div><div style='padding-top: 10px; width: 80ex'>Survival analysis studies and predicts the time of death, or other singular
unrepeated events, based on historical data, while the true time of death for
some instances is unknown. Survival trees enable the discovery of complex
nonlinear relations in a compact human comprehensible model, by recursively
splitting the population and predicting a distinct survival distribution in
each leaf node. We use dynamic programming to provide the first survival tree
method with optimality guarantees, enabling the assessment of the optimality
gap of heuristics. We improve the scalability of our method through a special
algorithm for computing trees up to depth two. The experiments show that our
method's run time even outperforms some heuristics for realistic cases while
obtaining similar out-of-sample performance with the state-of-the-art.</div><div><a href='http://arxiv.org/abs/2401.04489v1'>2401.04489v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15330v2")'>Optimal Sparse Survival Trees</div>
<div id='2401.15330v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-27T07:26:10Z</div><div>Authors: Rui Zhang, Rui Xin, Margo Seltzer, Cynthia Rudin</div><div style='padding-top: 10px; width: 80ex'>Interpretability is crucial for doctors, hospitals, pharmaceutical companies
and biotechnology corporations to analyze and make decisions for high stakes
problems that involve human health. Tree-based methods have been widely adopted
for survival analysis due to their appealing interpretablility and their
ability to capture complex relationships. However, most existing methods to
produce survival trees rely on heuristic (or greedy) algorithms, which risk
producing sub-optimal models. We present a dynamic-programming-with-bounds
approach that finds provably-optimal sparse survival tree models, frequently in
only a few seconds.</div><div><a href='http://arxiv.org/abs/2401.15330v2'>2401.15330v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.13150v1")'>Training Survival Models using Scoring Rules</div>
<div id='2403.13150v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-19T20:58:38Z</div><div>Authors: Philipp Kopper, David Rügamer, Raphael Sonabend, Bernd Bischl, Andreas Bender</div><div style='padding-top: 10px; width: 80ex'>Survival Analysis provides critical insights for partially incomplete
time-to-event data in various domains. It is also an important example of
probabilistic machine learning. The probabilistic nature of the predictions can
be exploited by using (proper) scoring rules in the model fitting process
instead of likelihood-based optimization. Our proposal does so in a generic
manner and can be used for a variety of model classes. We establish different
parametric and non-parametric sub-frameworks that allow different degrees of
flexibility. Incorporated into neural networks, it leads to a computationally
efficient and scalable optimization routine, yielding state-of-the-art
predictive performance. Finally, we show that using our framework, we can
recover various parametric models and demonstrate that optimization works
equally well when compared to likelihood-based methods.</div><div><a href='http://arxiv.org/abs/2403.13150v1'>2403.13150v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.02708v1")'>TripleSurv: Triplet Time-adaptive Coordinate Loss for Survival Analysis</div>
<div id='2401.02708v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-05T08:37:57Z</div><div>Authors: Liwen Zhang, Lianzhen Zhong, Fan Yang, Di Dong, Hui Hui, Jie Tian</div><div style='padding-top: 10px; width: 80ex'>A core challenge in survival analysis is to model the distribution of
censored time-to-event data, where the event of interest may be a death,
failure, or occurrence of a specific event. Previous studies have showed that
ranking and maximum likelihood estimation (MLE)loss functions are widely-used
for survival analysis. However, ranking loss only focus on the ranking of
survival time and does not consider potential effect of samples for exact
survival time values. Furthermore, the MLE is unbounded and easily subject to
outliers (e.g., censored data), which may cause poor performance of modeling.
To handle the complexities of learning process and exploit valuable survival
time values, we propose a time-adaptive coordinate loss function, TripleSurv,
to achieve adaptive adjustments by introducing the differences in the survival
time between sample pairs into the ranking, which can encourage the model to
quantitatively rank relative risk of pairs, ultimately enhancing the accuracy
of predictions. Most importantly, the TripleSurv is proficient in quantifying
the relative risk between samples by ranking ordering of pairs, and consider
the time interval as a trade-off to calibrate the robustness of model over
sample distribution. Our TripleSurv is evaluated on three real-world survival
datasets and a public synthetic dataset. The results show that our method
outperforms the state-of-the-art methods and exhibits good model performance
and robustness on modeling various sophisticated data distributions with
different censor rates. Our code will be available upon acceptance.</div><div><a href='http://arxiv.org/abs/2401.02708v1'>2401.02708v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.02277v2")'>Causal Bayesian Optimization via Exogenous Distribution Learning</div>
<div id='2402.02277v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-03T22:14:54Z</div><div>Authors: Shaogang Ren, Xiaoning Qian</div><div style='padding-top: 10px; width: 80ex'>Maximizing a target variable as an operational objective in a structured
causal model is an important problem. Existing Causal Bayesian Optimization
(CBO) methods either rely on hard interventions that alter the causal structure
to maximize the reward; or introduce action nodes to endogenous variables so
that the data generation mechanisms are adjusted to achieve the objective. In
this paper, a novel method is introduced to learn the distribution of exogenous
variables, which is typically ignored or marginalized through expectation by
existing methods. Exogenous distribution learning improves the approximation
accuracy of structured causal models in a surrogate model that is usually
trained with limited observational data. Moreover, the learned exogenous
distribution extends existing CBO to general causal schemes beyond Additive
Noise Models (ANM). The recovery of exogenous variables allows us to use a more
flexible prior for noise or unobserved hidden variables. A new CBO method is
developed by leveraging the learned exogenous distribution. Experiments on
different datasets and applications show the benefits of our proposed method.</div><div><a href='http://arxiv.org/abs/2402.02277v2'>2402.02277v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.02624v2")'>Pareto-Optimal Estimation and Policy Learning on Short-term and
  Long-term Treatment Effects</div>
<div id='2403.02624v2' style='display: none; margin-left: 20px'><div>Date: 2024-03-05T03:32:02Z</div><div>Authors: Yingrong Wang, Anpeng Wu, Haoxuan Li, Weiming Liu, Qiaowei Miao, Ruoxuan Xiong, Fei Wu, Kun Kuang</div><div style='padding-top: 10px; width: 80ex'>This paper focuses on developing Pareto-optimal estimation and policy
learning to identify the most effective treatment that maximizes the total
reward from both short-term and long-term effects, which might conflict with
each other. For example, a higher dosage of medication might increase the speed
of a patient's recovery (short-term) but could also result in severe long-term
side effects. Although recent works have investigated the problems about
short-term or long-term effects or the both, how to trade-off between them to
achieve optimal treatment remains an open challenge. Moreover, when multiple
objectives are directly estimated using conventional causal representation
learning, the optimization directions among various tasks can conflict as well.
In this paper, we systematically investigate these issues and introduce a
Pareto-Efficient algorithm, comprising Pareto-Optimal Estimation (POE) and
Pareto-Optimal Policy Learning (POPL), to tackle them. POE incorporates a
continuous Pareto module with representation balancing, enhancing estimation
efficiency across multiple tasks. As for POPL, it involves deriving short-term
and long-term outcomes linked with various treatment levels, facilitating an
exploration of the Pareto frontier emanating from these outcomes. Results on
both the synthetic and real-world datasets demonstrate the superiority of our
method.</div><div><a href='http://arxiv.org/abs/2403.02624v2'>2403.02624v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.12369v1")'>SubgroupTE: Advancing Treatment Effect Estimation with Subgroup
  Identification</div>
<div id='2401.12369v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-22T21:41:26Z</div><div>Authors: Seungyeon Lee, Ruoqi Liu, Wenyu Song, Lang Li, Ping Zhang</div><div style='padding-top: 10px; width: 80ex'>Precise estimation of treatment effects is crucial for evaluating
intervention effectiveness. While deep learning models have exhibited promising
performance in learning counterfactual representations for treatment effect
estimation (TEE), a major limitation in most of these models is that they treat
the entire population as a homogeneous group, overlooking the diversity of
treatment effects across potential subgroups that have varying treatment
effects. This limitation restricts the ability to precisely estimate treatment
effects and provide subgroup-specific treatment recommendations. In this paper,
we propose a novel treatment effect estimation model, named SubgroupTE, which
incorporates subgroup identification in TEE. SubgroupTE identifies
heterogeneous subgroups with different treatment responses and more precisely
estimates treatment effects by considering subgroup-specific causal effects. In
addition, SubgroupTE iteratively optimizes subgrouping and treatment effect
estimation networks to enhance both estimation and subgroup identification.
Comprehensive experiments on the synthetic and semi-synthetic datasets exhibit
the outstanding performance of SubgroupTE compared with the state-of-the-art
models on treatment effect estimation. Additionally, a real-world study
demonstrates the capabilities of SubgroupTE in enhancing personalized treatment
recommendations for patients with opioid use disorder (OUD) by advancing
treatment effect estimation with subgroup identification.</div><div><a href='http://arxiv.org/abs/2401.12369v1'>2401.12369v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.17027v1")'>Heterogeneous treatment effect estimation with subpopulation
  identification for personalized medicine in opioid use disorder</div>
<div id='2401.17027v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T14:02:49Z</div><div>Authors: Seungyeon Lee, Ruoqi Liu, Wenyu Song, Ping Zhang</div><div style='padding-top: 10px; width: 80ex'>Deep learning models have demonstrated promising results in estimating
treatment effects (TEE). However, most of them overlook the variations in
treatment outcomes among subgroups with distinct characteristics. This
limitation hinders their ability to provide accurate estimations and treatment
recommendations for specific subgroups. In this study, we introduce a novel
neural network-based framework, named SubgroupTE, which incorporates subgroup
identification and treatment effect estimation. SubgroupTE identifies diverse
subgroups and simultaneously estimates treatment effects for each subgroup,
improving the treatment effect estimation by considering the heterogeneity of
treatment responses. Comparative experiments on synthetic data show that
SubgroupTE outperforms existing models in treatment effect estimation.
Furthermore, experiments on a real-world dataset related to opioid use disorder
(OUD) demonstrate the potential of our approach to enhance personalized
treatment recommendations for OUD patients.</div><div><a href='http://arxiv.org/abs/2401.17027v1'>2401.17027v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.11130v1")'>Identification and Estimation of Conditional Average Partial Causal
  Effects via Instrumental Variable</div>
<div id='2401.11130v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-20T05:48:46Z</div><div>Authors: Yuta Kawakami, Manabu Kuroki, Jin Tian</div><div style='padding-top: 10px; width: 80ex'>There has been considerable recent interest in estimating heterogeneous
causal effects. In this paper, we introduce conditional average partial causal
effects (CAPCE) to reveal the heterogeneity of causal effects with continuous
treatment. We provide conditions for identifying CAPCE in an instrumental
variable setting. We develop three families of CAPCE estimators: sieve,
parametric, and reproducing kernel Hilbert space (RKHS)-based, and analyze
their statistical properties. We illustrate the proposed CAPCE estimators on
synthetic and real-world data.</div><div><a href='http://arxiv.org/abs/2401.11130v1'>2401.11130v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.06925v1")'>Modeling Latent Selection with Structural Causal Models</div>
<div id='2401.06925v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-12T23:14:34Z</div><div>Authors: Leihao Chen, Onno Zoeter, Joris M. Mooij</div><div style='padding-top: 10px; width: 80ex'>Selection bias is ubiquitous in real-world data, and can lead to misleading
results if not dealt with properly. We introduce a conditioning operation on
Structural Causal Models (SCMs) to model latent selection from a causal
perspective. We show that the conditioning operation transforms an SCM with the
presence of an explicit latent selection mechanism into an SCM without such
selection mechanism, which partially encodes the causal semantics of the
selected subpopulation according to the original SCM. Furthermore, we show that
this conditioning operation preserves the simplicity, acyclicity, and linearity
of SCMs, and commutes with marginalization. Thanks to these properties,
combined with marginalization and intervention, the conditioning operation
offers a valuable tool for conducting causal reasoning tasks within causal
models where latent details have been abstracted away. We demonstrate by
example how classical results of causal inference can be generalized to include
selection bias and how the conditioning operation helps with modeling of
real-world problems.</div><div><a href='http://arxiv.org/abs/2401.06925v1'>2401.06925v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.06499v1")'>Detection of Unobserved Common Causes based on NML Code in Discrete,
  Mixed, and Continuous Variables</div>
<div id='2403.06499v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-11T08:11:52Z</div><div>Authors: Masatoshi Kobayashi, Kohei Miyagichi, Shin Matsushima</div><div style='padding-top: 10px; width: 80ex'>Causal discovery in the presence of unobserved common causes from
observational data only is a crucial but challenging problem. We categorize all
possible causal relationships between two random variables into the following
four categories and aim to identify one from observed data: two cases in which
either of the direct causality exists, a case that variables are independent,
and a case that variables are confounded by latent confounders. Although
existing methods have been proposed to tackle this problem, they require
unobserved variables to satisfy assumptions on the form of their equation
models. In our previous study (Kobayashi et al., 2022), the first causal
discovery method without such assumptions is proposed for discrete data and
named CLOUD. Using Normalized Maximum Likelihood (NML) Code, CLOUD selects a
model that yields the minimum codelength of the observed data from a set of
model candidates. This paper extends CLOUD to apply for various data types
across discrete, mixed, and continuous. We not only performed theoretical
analysis to show the consistency of CLOUD in terms of the model selection, but
also demonstrated that CLOUD is more effective than existing methods in
inferring causal relationships by extensive experiments on both synthetic and
real-world data.</div><div><a href='http://arxiv.org/abs/2403.06499v1'>2403.06499v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.05218v1")'>Invariant Causal Prediction with Locally Linear Models</div>
<div id='2401.05218v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-10T15:34:42Z</div><div>Authors: Alexander Mey, Rui Manuel Castro</div><div style='padding-top: 10px; width: 80ex'>We consider the task of identifying the causal parents of a target variable
among a set of candidate variables from observational data. Our main assumption
is that the candidate variables are observed in different environments which
may, for example, correspond to different settings of a machine or different
time intervals in a dynamical process. Under certain assumptions different
environments can be regarded as interventions on the observed system. We assume
a linear relationship between target and covariates, which can be different in
each environment with the only restriction that the causal structure is
invariant across environments. This is an extension of the ICP
($\textbf{I}$nvariant $\textbf{C}$ausal $\textbf{P}$rediction) principle by
Peters et al. [2016], who assumed a fixed linear relationship across all
environments. Within our proposed setting we provide sufficient conditions for
identifiability of the causal parents and introduce a practical method called
LoLICaP ($\textbf{Lo}$cally $\textbf{L}$inear $\textbf{I}$nvariant
$\textbf{Ca}$usal $\textbf{P}$rediction), which is based on a hypothesis test
for parent identification using a ratio of minimum and maximum statistics. We
then show in a simplified setting that the statistical power of LoLICaP
converges exponentially fast in the sample size, and finally we analyze the
behavior of LoLICaP experimentally in more general settings.</div><div><a href='http://arxiv.org/abs/2401.05218v1'>2401.05218v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04919v1")'>Identifying Causal Effects Under Functional Dependencies</div>
<div id='2403.04919v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T22:04:35Z</div><div>Authors: Yizuo Chen, Adnan Darwiche</div><div style='padding-top: 10px; width: 80ex'>We study the identification of causal effects, motivated by two improvements
to identifiability which can be attained if one knows that some variables in a
causal graph are functionally determined by their parents (without needing to
know the specific functions). First, an unidentifiable causal effect may become
identifiable when certain variables are functional. Second, certain functional
variables can be excluded from being observed without affecting the
identifiability of a causal effect, which may significantly reduce the number
of needed variables in observational data. Our results are largely based on an
elimination procedure which removes functional variables from a causal graph
while preserving key properties in the resulting causal graph, including the
identifiability of causal effects.</div><div><a href='http://arxiv.org/abs/2403.04919v1'>2403.04919v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.09300v1")'>Recursive Causal Discovery</div>
<div id='2403.09300v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T11:46:25Z</div><div>Authors: Ehsan Mokhtarian, Sepehr Elahi, Sina Akbari, Negar Kiyavash</div><div style='padding-top: 10px; width: 80ex'>Causal discovery, i.e., learning the causal graph from data, is often the
first step toward the identification and estimation of causal effects, a key
requirement in numerous scientific domains. Causal discovery is hampered by two
main challenges: limited data results in errors in statistical testing and the
computational complexity of the learning task is daunting. This paper builds
upon and extends four of our prior publications (Mokhtarian et al., 2021;
Akbari et al., 2021; Mokhtarian et al., 2022, 2023a). These works introduced
the concept of removable variables, which are the only variables that can be
removed recursively for the purpose of causal discovery. Presence and
identification of removable variables allow recursive approaches for causal
discovery, a promising solution that helps to address the aforementioned
challenges by reducing the problem size successively. This reduction not only
minimizes conditioning sets in each conditional independence (CI) test, leading
to fewer errors but also significantly decreases the number of required CI
tests. The worst-case performances of these methods nearly match the lower
bound. In this paper, we present a unified framework for the proposed
algorithms, refined with additional details and enhancements for a coherent
presentation. A comprehensive literature review is also included, comparing the
computational complexity of our methods with existing approaches, showcasing
their state-of-the-art efficiency. Another contribution of this paper is the
release of RCD, a Python package that efficiently implements these algorithms.
This package is designed for practitioners and researchers interested in
applying these methods in practical scenarios. The package is available at
github.com/ban-epfl/rcd, with comprehensive documentation provided at
rcdpackage.com.</div><div><a href='http://arxiv.org/abs/2403.09300v1'>2403.09300v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01929v1")'>Sample, estimate, aggregate: A recipe for causal discovery foundation
  models</div>
<div id='2402.01929v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T21:57:58Z</div><div>Authors: Menghua Wu, Yujia Bao, Regina Barzilay, Tommi Jaakkola</div><div style='padding-top: 10px; width: 80ex'>Causal discovery, the task of inferring causal structure from data, promises
to accelerate scientific research, inform policy making, and more. However, the
per-dataset nature of existing causal discovery algorithms renders them slow,
data hungry, and brittle. Inspired by foundation models, we propose a causal
discovery framework where a deep learning model is pretrained to resolve
predictions from classical discovery algorithms run over smaller subsets of
variables. This method is enabled by the observations that the outputs from
classical algorithms are fast to compute for small problems, informative of
(marginal) data structure, and their structure outputs as objects remain
comparable across datasets. Our method achieves state-of-the-art performance on
synthetic and realistic datasets, generalizes to data generating mechanisms not
seen during training, and offers inference speeds that are orders of magnitude
faster than existing models.</div><div><a href='http://arxiv.org/abs/2402.01929v1'>2402.01929v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.01426v1")'>Modular Learning of Deep Causal Generative Models for High-dimensional
  Causal Inference</div>
<div id='2401.01426v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-02T20:31:15Z</div><div>Authors: Md Musfiqur Rahman, Murat Kocaoglu</div><div style='padding-top: 10px; width: 80ex'>Pearl's causal hierarchy establishes a clear separation between
observational, interventional, and counterfactual questions. Researchers
proposed sound and complete algorithms to compute identifiable causal queries
at a given level of the hierarchy using the causal structure and data from the
lower levels of the hierarchy. However, most of these algorithms assume that we
can accurately estimate the probability distribution of the data, which is an
impractical assumption for high-dimensional variables such as images. On the
other hand, modern generative deep learning architectures can be trained to
learn how to accurately sample from such high-dimensional distributions.
Especially with the recent rise of foundation models for images, it is
desirable to leverage pre-trained models to answer causal queries with such
high-dimensional data. To address this, we propose a sequential training
algorithm that, given the causal structure and a pre-trained conditional
generative model, can train a deep causal generative model, which utilizes the
pre-trained model and can provably sample from identifiable interventional and
counterfactual distributions. Our algorithm, called Modular-DCM, uses
adversarial training to learn the network weights, and to the best of our
knowledge, is the first algorithm that can make use of pre-trained models and
provably sample from any identifiable causal query in the presence of latent
confounders with high-dimensional data. We demonstrate the utility of our
algorithm using semi-synthetic and real-world datasets containing images as
variables in the causal structure.</div><div><a href='http://arxiv.org/abs/2401.01426v1'>2401.01426v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07419v1")'>Conditional Generative Models are Sufficient to Sample from Any Causal
  Effect Estimand</div>
<div id='2402.07419v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-12T05:48:31Z</div><div>Authors: Md Musfiqur Rahman, Matt Jordan, Murat Kocaoglu</div><div style='padding-top: 10px; width: 80ex'>Causal inference from observational data has recently found many applications
in machine learning. While sound and complete algorithms exist to compute
causal effects, many of these algorithms require explicit access to conditional
likelihoods over the observational distribution, which is difficult to estimate
in the high-dimensional regime, such as with images. To alleviate this issue,
researchers have approached the problem by simulating causal relations with
neural models and obtained impressive results. However, none of these existing
approaches can be applied to generic scenarios such as causal graphs on image
data with latent confounders, or obtain conditional interventional samples. In
this paper, we show that any identifiable causal effect given an arbitrary
causal graph can be computed through push-forward computations of conditional
generative models. Based on this result, we devise a diffusion-based approach
to sample from any (conditional) interventional distribution on image data. To
showcase our algorithm's performance, we conduct experiments on a Colored MNIST
dataset having both the treatment ($X$) and the target variables ($Y$) as
images and obtain interventional samples from $P(y|do(x))$. As an application
of our algorithm, we evaluate two large conditional generative models that are
pre-trained on the CelebA dataset by analyzing the strength of spurious
correlations and the level of disentanglement they achieve.</div><div><a href='http://arxiv.org/abs/2402.07419v1'>2402.07419v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14781v1")'>Rao-Blackwellising Bayesian Causal Inference</div>
<div id='2402.14781v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T18:39:24Z</div><div>Authors: Christian Toth, Christian Knoll, Franz Pernkopf, Robert Peharz</div><div style='padding-top: 10px; width: 80ex'>Bayesian causal inference, i.e., inferring a posterior over causal models for
the use in downstream causal reasoning tasks, poses a hard computational
inference problem that is little explored in literature. In this work, we
combine techniques from order-based MCMC structure learning with recent
advances in gradient-based graph learning into an effective Bayesian causal
inference framework. Specifically, we decompose the problem of inferring the
causal structure into (i) inferring a topological order over variables and (ii)
inferring the parent sets for each variable. When limiting the number of
parents per variable, we can exactly marginalise over the parent sets in
polynomial time. We further use Gaussian processes to model the unknown causal
mechanisms, which also allows their exact marginalisation. This introduces a
Rao-Blackwellization scheme, where all components are eliminated from the
model, except for the causal order, for which we learn a distribution via
gradient-based optimisation. The combination of Rao-Blackwellization with our
sequential inference procedure for causal orders yields state-of-the-art on
linear and non-linear additive noise benchmarks with scale-free and Erdos-Renyi
graph structures.</div><div><a href='http://arxiv.org/abs/2402.14781v1'>2402.14781v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03772v1")'>AcceleratedLiNGAM: Learning Causal DAGs at the speed of GPUs</div>
<div id='2403.03772v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T15:06:11Z</div><div>Authors: Victor Akinwande, J. Zico Kolter</div><div style='padding-top: 10px; width: 80ex'>Existing causal discovery methods based on combinatorial optimization or
search are slow, prohibiting their application on large-scale datasets. In
response, more recent methods attempt to address this limitation by formulating
causal discovery as structure learning with continuous optimization but such
approaches thus far provide no statistical guarantees. In this paper, we show
that by efficiently parallelizing existing causal discovery methods, we can in
fact scale them to thousands of dimensions, making them practical for
substantially larger-scale problems. In particular, we parallelize the LiNGAM
method, which is quadratic in the number of variables, obtaining up to a
32-fold speed-up on benchmark datasets when compared with existing sequential
implementations. Specifically, we focus on the causal ordering subprocedure in
DirectLiNGAM and implement GPU kernels to accelerate it. This allows us to
apply DirectLiNGAM to causal inference on large-scale gene expression data with
genetic interventions yielding competitive results compared with specialized
continuous optimization methods, and Var-LiNGAM for causal discovery on U.S.
stock data.</div><div><a href='http://arxiv.org/abs/2403.03772v1'>2403.03772v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01341v2")'>Fundamental Properties of Causal Entropy and Information Gain</div>
<div id='2402.01341v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T11:55:57Z</div><div>Authors: Francisco N. F. Q. Simoes, Mehdi Dastani, Thijs van Ommen</div><div style='padding-top: 10px; width: 80ex'>Recent developments enable the quantification of causal control given a
structural causal model (SCM). This has been accomplished by introducing
quantities which encode changes in the entropy of one variable when intervening
on another. These measures, named causal entropy and causal information gain,
aim to address limitations in existing information theoretical approaches for
machine learning tasks where causality plays a crucial role. They have not yet
been properly mathematically studied. Our research contributes to the formal
understanding of the notions of causal entropy and causal information gain by
establishing and analyzing fundamental properties of these concepts, including
bounds and chain rules. Furthermore, we elucidate the relationship between
causal entropy and stochastic interventions. We also propose definitions for
causal conditional entropy and causal conditional information gain. Overall,
this exploration paves the way for enhancing causal machine learning tasks
through the study of recently-proposed information theoretic quantities
grounded in considerations about causality.</div><div><a href='http://arxiv.org/abs/2402.01341v2'>2402.01341v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.02467v1")'>Applied Causal Inference Powered by ML and AI</div>
<div id='2403.02467v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-04T20:28:28Z</div><div>Authors: Victor Chernozhukov, Christian Hansen, Nathan Kallus, Martin Spindler, Vasilis Syrgkanis</div><div style='padding-top: 10px; width: 80ex'>An introduction to the emerging fusion of machine learning and causal
inference. The book presents ideas from classical structural equation models
(SEMs) and their modern AI equivalent, directed acyclical graphs (DAGs) and
structural causal models (SCMs), and covers Double/Debiased Machine Learning
methods to do inference in such models using modern predictive tools.</div><div><a href='http://arxiv.org/abs/2403.02467v1'>2403.02467v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14385v1")'>Estimating Causal Effects with Double Machine Learning -- A Method
  Evaluation</div>
<div id='2403.14385v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T13:21:33Z</div><div>Authors: Jonathan Fuhr, Philipp Berens, Dominik Papies</div><div style='padding-top: 10px; width: 80ex'>The estimation of causal effects with observational data continues to be a
very active research area. In recent years, researchers have developed new
frameworks which use machine learning to relax classical assumptions necessary
for the estimation of causal effects. In this paper, we review one of the most
prominent methods - "double/debiased machine learning" (DML) - and empirically
evaluate it by comparing its performance on simulated data relative to more
traditional statistical methods, before applying it to real-world data. Our
findings indicate that the application of a suitably flexible machine learning
algorithm within DML improves the adjustment for various nonlinear confounding
relationships. This advantage enables a departure from traditional functional
form assumptions typically necessary in causal effect estimation. However, we
demonstrate that the method continues to critically depend on standard
assumptions about causal structure and identification. When estimating the
effects of air pollution on housing prices in our application, we find that DML
estimates are consistently larger than estimates of less flexible methods. From
our overall results, we provide actionable recommendations for specific choices
researchers must make when applying DML in practice.</div><div><a href='http://arxiv.org/abs/2403.14385v1'>2403.14385v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09891v1")'>Predictors from causal features do not generalize better to new domains</div>
<div id='2402.09891v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-15T11:34:38Z</div><div>Authors: Vivian Y. Nastl, Moritz Hardt</div><div style='padding-top: 10px; width: 80ex'>We study how well machine learning models trained on causal features
generalize across domains. We consider 16 prediction tasks on tabular datasets
covering applications in health, employment, education, social benefits, and
politics. Each dataset comes with multiple domains, allowing us to test how
well a model trained in one domain performs in another. For each prediction
task, we select features that have a causal influence on the target of
prediction. Our goal is to test the hypothesis that models trained on causal
features generalize better across domains. Without exception, we find that
predictors using all available features, regardless of causality, have better
in-domain and out-of-domain accuracy than predictors using causal features.
Moreover, even the absolute drop in accuracy from one domain to the other is no
better for causal predictors than for models that use all features. If the goal
is to generalize to new domains, practitioners might as well train the best
possible model on all available features.</div><div><a href='http://arxiv.org/abs/2402.09891v1'>2402.09891v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.00886v1")'>Evaluating and Correcting Performative Effects of Decision Support
  Systems via Causal Domain Shift</div>
<div id='2403.00886v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-01T10:19:17Z</div><div>Authors: Philip Boeken, Onno Zoeter, Joris M. Mooij</div><div style='padding-top: 10px; width: 80ex'>When predicting a target variable $Y$ from features $X$, the prediction
$\hat{Y}$ can be performative: an agent might act on this prediction, affecting
the value of $Y$ that we eventually observe. Performative predictions are
deliberately prevalent in algorithmic decision support, where a Decision
Support System (DSS) provides a prediction for an agent to affect the value of
the target variable. When deploying a DSS in high-stakes settings (e.g.
healthcare, law, predictive policing, or child welfare screening) it is
imperative to carefully assess the performative effects of the DSS. In the case
that the DSS serves as an alarm for a predicted negative outcome, naive
retraining of the prediction model is bound to result in a model that
underestimates the risk, due to effective workings of the previous model. In
this work, we propose to model the deployment of a DSS as causal domain shift
and provide novel cross-domain identification results for the conditional
expectation $E[Y | X]$, allowing for pre- and post-hoc assessment of the
deployment of the DSS, and for retraining of a model that assesses the risk
under a baseline policy where the DSS is not deployed. Using a running example,
we empirically show that a repeated regression procedure provides a practical
framework for estimating these quantities, even when the data is affected by
sample selection bias and selective labelling, offering for a practical,
unified solution for multiple forms of target variable bias.</div><div><a href='http://arxiv.org/abs/2403.00886v1'>2403.00886v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.08788v1")'>The Impact of Differential Feature Under-reporting on Algorithmic
  Fairness</div>
<div id='2401.08788v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-16T19:16:22Z</div><div>Authors: Nil-Jana Akpinar, Zachary C. Lipton, Alexandra Chouldechova</div><div style='padding-top: 10px; width: 80ex'>Predictive risk models in the public sector are commonly developed using
administrative data that is more complete for subpopulations that more greatly
rely on public services. In the United States, for instance, information on
health care utilization is routinely available to government agencies for
individuals supported by Medicaid and Medicare, but not for the privately
insured. Critiques of public sector algorithms have identified such
differential feature under-reporting as a driver of disparities in algorithmic
decision-making. Yet this form of data bias remains understudied from a
technical viewpoint. While prior work has examined the fairness impacts of
additive feature noise and features that are clearly marked as missing, the
setting of data missingness absent indicators (i.e. differential feature
under-reporting) has been lacking in research attention. In this work, we
present an analytically tractable model of differential feature under-reporting
which we then use to characterize the impact of this kind of data bias on
algorithmic fairness. We demonstrate how standard missing data methods
typically fail to mitigate bias in this setting, and propose a new set of
methods specifically tailored to differential feature under-reporting. Our
results show that, in real world data settings, under-reporting typically leads
to increasing disparities. The proposed solution methods show success in
mitigating increases in unfairness.</div><div><a href='http://arxiv.org/abs/2401.08788v1'>2401.08788v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14713v1")'>Auditing Fairness under Unobserved Confounding</div>
<div id='2403.14713v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-18T21:09:06Z</div><div>Authors: Yewon Byun, Dylan Sam, Michael Oberst, Zachary C. Lipton, Bryan Wilder</div><div style='padding-top: 10px; width: 80ex'>A fundamental problem in decision-making systems is the presence of inequity
across demographic lines. However, inequity can be difficult to quantify,
particularly if our notion of equity relies on hard-to-measure notions like
risk (e.g., equal access to treatment for those who would die without it).
Auditing such inequity requires accurate measurements of individual risk, which
is difficult to estimate in the realistic setting of unobserved confounding. In
the case that these unobservables "explain" an apparent disparity, we may
understate or overstate inequity. In this paper, we show that one can still
give informative bounds on allocation rates among high-risk individuals, even
while relaxing or (surprisingly) even when eliminating the assumption that all
relevant risk factors are observed. We utilize the fact that in many real-world
settings (e.g., the introduction of a novel treatment) we have data from a
period prior to any allocation, to derive unbiased estimates of risk. We
demonstrate the effectiveness of our framework on a real-world study of
Paxlovid allocation to COVID-19 patients, finding that observed racial inequity
cannot be explained by unobserved confounders of the same strength as important
observed covariates.</div><div><a href='http://arxiv.org/abs/2403.14713v1'>2403.14713v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.09286v1")'>Nutrition Facts, Drug Facts, and Model Facts: Putting AI Ethics into
  Practice in Gun Violence Research</div>
<div id='2402.09286v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T16:19:09Z</div><div>Authors: Jessica Zhu, Dr. Michel Cukier, Dr. Joseph Richardson Jr</div><div style='padding-top: 10px; width: 80ex'>Objective: Firearm injury research necessitates using data from
often-exploited vulnerable populations of Black and Brown Americans. In order
to minimize distrust, this study provides a framework for establishing AI trust
and transparency with the general population. Methods: We propose a Model Facts
template that is easily extendable and decomposes accuracy and demographics
into standardized and minimally complex values. This framework allows general
users to assess the validity and biases of a model without diving into
technical model documentation. Examples: We apply the Model Facts template on
two previously published models, a violence risk identification model and a
suicide risk prediction model. We demonstrate the ease of accessing the
appropriate information when the data is structured appropriately. Discussion:
The Model Facts template is limited in its current form to human based data and
biases. Like nutrition facts, it also will require some educational resources
for users to grasp its full utility. Human computer interaction experiments
should be conducted to ensure that the interaction between user interface and
model interface is as desired. Conclusion: The Model Facts label is the first
framework dedicated to establishing trust with end users and general population
consumers. Implementation of Model Facts into firearm injury research will
provide public health practitioners and those impacted by firearm injury
greater faith in the tools the research provides.</div><div><a href='http://arxiv.org/abs/2402.09286v1'>2402.09286v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.05573v1")'>Beyond Predictive Algorithms in Child Welfare</div>
<div id='2403.05573v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T08:59:46Z</div><div>Authors: Erina Seh-Young Moon, Devansh Saxena, Tegan Maharaj, Shion Guha</div><div style='padding-top: 10px; width: 80ex'>Caseworkers in the child welfare (CW) sector use predictive decision-making
algorithms built on risk assessment (RA) data to guide and support CW
decisions. Researchers have highlighted that RAs can contain biased signals
which flatten CW case complexities and that the algorithms may benefit from
incorporating contextually rich case narratives, i.e. - casenotes written by
caseworkers. To investigate this hypothesized improvement, we quantitatively
deconstructed two commonly used RAs from a United States CW agency. We trained
classifier models to compare the predictive validity of RAs with and without
casenote narratives and applied computational text analysis on casenotes to
highlight topics uncovered in the casenotes. Our study finds that common risk
metrics used to assess families and build CWS predictive risk models (PRMs) are
unable to predict discharge outcomes for children who are not reunified with
their birth parent(s). We also find that although casenotes cannot predict
discharge outcomes, they contain contextual case signals. Given the lack of
predictive validity of RA scores and casenotes, we propose moving beyond
quantitative risk assessments for public sector algorithms and towards using
contextual sources of information such as narratives to study public
sociotechnical systems.</div><div><a href='http://arxiv.org/abs/2403.05573v1'>2403.05573v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.06523v1")'>Boosting Causal Additive Models</div>
<div id='2401.06523v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-12T11:43:11Z</div><div>Authors: Maximilian Kertel, Nadja Klein</div><div style='padding-top: 10px; width: 80ex'>We present a boosting-based method to learn additive Structural Equation
Models (SEMs) from observational data, with a focus on the theoretical aspects
of determining the causal order among variables. We introduce a family of score
functions based on arbitrary regression techniques, for which we establish
necessary conditions to consistently favor the true causal ordering. Our
analysis reveals that boosting with early stopping meets these criteria and
thus offers a consistent score function for causal orderings. To address the
challenges posed by high-dimensional data sets, we adapt our approach through a
component-wise gradient descent in the space of additive SEMs. Our simulation
study underlines our theoretical results for lower dimensions and demonstrates
that our high-dimensional adaptation is competitive with state-of-the-art
methods. In addition, it exhibits robustness with respect to the choice of the
hyperparameters making the procedure easy to tune.</div><div><a href='http://arxiv.org/abs/2401.06523v1'>2401.06523v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.09580v1")'>Algorithmic syntactic causal identification</div>
<div id='2403.09580v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T17:14:53Z</div><div>Authors: Dhurim Cakiqi, Max A. Little</div><div style='padding-top: 10px; width: 80ex'>Causal identification in causal Bayes nets (CBNs) is an important tool in
causal inference allowing the derivation of interventional distributions from
observational distributions where this is possible in principle. However, most
existing formulations of causal identification using techniques such as
d-separation and do-calculus are expressed within the mathematical language of
classical probability theory on CBNs. However, there are many causal settings
where probability theory and hence current causal identification techniques are
inapplicable such as relational databases, dataflow programs such as hardware
description languages, distributed systems and most modern machine learning
algorithms. We show that this restriction can be lifted by replacing the use of
classical probability theory with the alternative axiomatic foundation of
symmetric monoidal categories. In this alternative axiomatization, we show how
an unambiguous and clean distinction can be drawn between the general syntax of
causal models and any specific semantic implementation of that causal model.
This allows a purely syntactic algorithmic description of general causal
identification by a translation of recent formulations of the general ID
algorithm through fixing. Our description is given entirely in terms of the
non-parametric ADMG structure specifying a causal model and the algebraic
signature of the corresponding monoidal category, to which a sequence of
manipulations is then applied so as to arrive at a modified monoidal category
in which the desired, purely syntactic interventional causal model, is
obtained. We use this idea to derive purely syntactic analogues of classical
back-door and front-door causal adjustment, and illustrate an application to a
more complex causal model.</div><div><a href='http://arxiv.org/abs/2403.09580v1'>2403.09580v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.18017v1")'>Causal Discovery by Kernel Deviance Measures with Heterogeneous
  Transforms</div>
<div id='2401.18017v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-31T17:28:05Z</div><div>Authors: Tim Tse, Zhitang Chen, Shengyu Zhu, Yue Liu</div><div style='padding-top: 10px; width: 80ex'>The discovery of causal relationships in a set of random variables is a
fundamental objective of science and has also recently been argued as being an
essential component towards real machine intelligence. One class of causal
discovery techniques are founded based on the argument that there are inherent
structural asymmetries between the causal and anti-causal direction which could
be leveraged in determining the direction of causation. To go about capturing
these discrepancies between cause and effect remains to be a challenge and many
current state-of-the-art algorithms propose to compare the norms of the kernel
mean embeddings of the conditional distributions. In this work, we argue that
such approaches based on RKHS embeddings are insufficient in capturing
principal markers of cause-effect asymmetry involving higher-order structural
variabilities of the conditional distributions. We propose Kernel Intrinsic
Invariance Measure with Heterogeneous Transform (KIIM-HT) which introduces a
novel score measure based on heterogeneous transformation of RKHS embeddings to
extract relevant higher-order moments of the conditional densities for causal
discovery. Inference is made via comparing the score of each hypothetical
cause-effect direction. Tests and comparisons on a synthetic dataset, a
two-dimensional synthetic dataset and the real-world benchmark dataset
T\"ubingen Cause-Effect Pairs verify our approach. In addition, we conduct a
sensitivity analysis to the regularization parameter to faithfully compare
previous work to our method and an experiment with trials on varied
hyperparameter values to showcase the robustness of our algorithm.</div><div><a href='http://arxiv.org/abs/2401.18017v1'>2401.18017v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15625v1")'>Learning Cyclic Causal Models from Incomplete Data</div>
<div id='2402.15625v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-23T22:03:12Z</div><div>Authors: Muralikrishnna G. Sethuraman, Faramarz Fekri</div><div style='padding-top: 10px; width: 80ex'>Causal learning is a fundamental problem in statistics and science, offering
insights into predicting the effects of unseen treatments on a system. Despite
recent advances in this topic, most existing causal discovery algorithms
operate under two key assumptions: (i) the underlying graph is acyclic, and
(ii) the available data is complete. These assumptions can be problematic as
many real-world systems contain feedback loops (e.g., biological systems), and
practical scenarios frequently involve missing data. In this work, we propose a
novel framework, named MissNODAGS, for learning cyclic causal graphs from
partially missing data. Under the additive noise model, MissNODAGS learns the
causal graph by alternating between imputing the missing data and maximizing
the expected log-likelihood of the visible part of the data in each training
step, following the principles of the expectation-maximization (EM) framework.
Through synthetic experiments and real-world single-cell perturbation data, we
demonstrate improved performance when compared to using state-of-the-art
imputation techniques followed by causal learning on partially missing
interventional data.</div><div><a href='http://arxiv.org/abs/2402.15625v1'>2402.15625v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13009v1")'>Comparative Study of Causal Discovery Methods for Cyclic Models with
  Hidden Confounders</div>
<div id='2401.13009v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-23T08:51:39Z</div><div>Authors: Boris Lorbeer, Mustafa Mohsen</div><div style='padding-top: 10px; width: 80ex'>Nowadays, the need for causal discovery is ubiquitous. A better understanding
of not just the stochastic dependencies between parts of a system, but also the
actual cause-effect relations, is essential for all parts of science. Thus, the
need for reliable methods to detect causal directions is growing constantly. In
the last 50 years, many causal discovery algorithms have emerged, but most of
them are applicable only under the assumption that the systems have no feedback
loops and that they are causally sufficient, i.e. that there are no unmeasured
subsystems that can affect multiple measured variables. This is unfortunate
since those restrictions can often not be presumed in practice. Feedback is an
integral feature of many processes, and real-world systems are rarely
completely isolated and fully measured. Fortunately, in recent years, several
techniques, that can cope with cyclic, causally insufficient systems, have been
developed. And with multiple methods available, a practical application of
those algorithms now requires knowledge of the respective strengths and
weaknesses. Here, we focus on the problem of causal discovery for sparse linear
models which are allowed to have cycles and hidden confounders. We have
prepared a comprehensive and thorough comparative study of four causal
discovery techniques: two versions of the LLC method [10] and two variants of
the ASP-based algorithm [11]. The evaluation investigates the performance of
those techniques for various experiments with multiple interventional setups
and different dataset sizes.</div><div><a href='http://arxiv.org/abs/2401.13009v1'>2401.13009v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15255v1")'>Optimal Transport for Structure Learning Under Missing Data</div>
<div id='2402.15255v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-23T10:49:04Z</div><div>Authors: Vy Vo, He Zhao, Trung Le, Edwin V. Bonilla, Dinh Phung</div><div style='padding-top: 10px; width: 80ex'>Causal discovery in the presence of missing data introduces a chicken-and-egg
dilemma. While the goal is to recover the true causal structure, robust
imputation requires considering the dependencies or preferably causal relations
among variables. Merely filling in missing values with existing imputation
methods and subsequently applying structure learning on the complete data is
empirical shown to be sub-optimal. To this end, we propose in this paper a
score-based algorithm, based on optimal transport, for learning causal
structure from missing data. This optimal transport viewpoint diverges from
existing score-based approaches that are dominantly based on EM. We project
structure learning as a density fitting problem, where the goal is to find the
causal model that induces a distribution of minimum Wasserstein distance with
the distribution over the observed data. Through extensive simulations and
real-data experiments, our framework is shown to recover the true causal graphs
more effectively than the baselines in various simulations and real-data
experiments. Empirical evidences also demonstrate the superior scalability of
our approach, along with the flexibility to incorporate any off-the-shelf
causal discovery methods for complete data.</div><div><a href='http://arxiv.org/abs/2402.15255v1'>2402.15255v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.13241v2")'>Federated Causal Discovery from Heterogeneous Data</div>
<div id='2402.13241v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T18:53:53Z</div><div>Authors: Loka Li, Ignavier Ng, Gongxu Luo, Biwei Huang, Guangyi Chen, Tongliang Liu, Bin Gu, Kun Zhang</div><div style='padding-top: 10px; width: 80ex'>Conventional causal discovery methods rely on centralized data, which is
inconsistent with the decentralized nature of data in many real-world
situations. This discrepancy has motivated the development of federated causal
discovery (FCD) approaches. However, existing FCD methods may be limited by
their potentially restrictive assumptions of identifiable functional causal
models or homogeneous data distributions, narrowing their applicability in
diverse scenarios. In this paper, we propose a novel FCD method attempting to
accommodate arbitrary causal models and heterogeneous data. We first utilize a
surrogate variable corresponding to the client index to account for the data
heterogeneity across different clients. We then develop a federated conditional
independence test (FCIT) for causal skeleton discovery and establish a
federated independent change principle (FICP) to determine causal directions.
These approaches involve constructing summary statistics as a proxy of the raw
data to protect data privacy. Owing to the nonparametric properties, FCIT and
FICP make no assumption about particular functional forms, thereby facilitating
the handling of arbitrary causal models. We conduct extensive experiments on
synthetic and real datasets to show the efficacy of our method. The code is
available at https://github.com/lokali/FedCDH.git.</div><div><a href='http://arxiv.org/abs/2402.13241v2'>2402.13241v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.18800v1")'>BlockEcho: Retaining Long-Range Dependencies for Imputing Block-Wise
  Missing Data</div>
<div id='2402.18800v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T02:13:10Z</div><div>Authors: Qiao Han, Mingqian Li, Yao Yang, Yiteng Zhai</div><div style='padding-top: 10px; width: 80ex'>Block-wise missing data poses significant challenges in real-world data
imputation tasks. Compared to scattered missing data, block-wise gaps
exacerbate adverse effects on subsequent analytic and machine learning tasks,
as the lack of local neighboring elements significantly reduces the
interpolation capability and predictive power. However, this issue has not
received adequate attention. Most SOTA matrix completion methods appeared less
effective, primarily due to overreliance on neighboring elements for
predictions. We systematically analyze the issue and propose a novel matrix
completion method ``BlockEcho" for a more comprehensive solution. This method
creatively integrates Matrix Factorization (MF) within Generative Adversarial
Networks (GAN) to explicitly retain long-distance inter-element relationships
in the original matrix. Besides, we incorporate an additional discriminator for
GAN, comparing the generator's intermediate progress with pre-trained MF
results to constrain high-order feature distributions. Subsequently, we
evaluate BlockEcho on public datasets across three domains. Results demonstrate
superior performance over both traditional and SOTA methods when imputing
block-wise missing data, especially at higher missing rates. The advantage also
holds for scattered missing data at high missing rates. We also contribute on
the analyses in providing theoretical justification on the optimality and
convergence of fusing MF and GAN for missing block data.</div><div><a href='http://arxiv.org/abs/2402.18800v1'>2402.18800v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.13863v1")'>DiffImpute: Tabular Data Imputation With Denoising Diffusion
  Probabilistic Model</div>
<div id='2403.13863v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-20T08:45:31Z</div><div>Authors: Yizhu Wen, Kai Yi, Jing Ke, Yiqing Shen</div><div style='padding-top: 10px; width: 80ex'>Tabular data plays a crucial role in various domains but often suffers from
missing values, thereby curtailing its potential utility. Traditional
imputation techniques frequently yield suboptimal results and impose
substantial computational burdens, leading to inaccuracies in subsequent
modeling tasks. To address these challenges, we propose DiffImpute, a novel
Denoising Diffusion Probabilistic Model (DDPM). Specifically, DiffImpute is
trained on complete tabular datasets, ensuring that it can produce credible
imputations for missing entries without undermining the authenticity of the
existing data. Innovatively, it can be applied to various settings of Missing
Completely At Random (MCAR) and Missing At Random (MAR). To effectively handle
the tabular features in DDPM, we tailor four tabular denoising networks,
spanning MLP, ResNet, Transformer, and U-Net. We also propose Harmonization to
enhance coherence between observed and imputed data by infusing the data back
and denoising them multiple times during the sampling stage. To enable
efficient inference while maintaining imputation performance, we propose a
refined non-Markovian sampling process that works along with Harmonization.
Empirical evaluations on seven diverse datasets underscore the prowess of
DiffImpute. Specifically, when paired with the Transformer as the denoising
network, it consistently outperforms its competitors, boasting an average
ranking of 1.7 and the most minimal standard deviation. In contrast, the next
best method lags with a ranking of 2.8 and a standard deviation of 0.9. The
code is available at https://github.com/Dendiiiii/DiffImpute.</div><div><a href='http://arxiv.org/abs/2403.13863v1'>2403.13863v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.16664v2")'>Fast Dual-Regularized Autoencoder for Sparse Biological Data</div>
<div id='2401.16664v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T01:28:48Z</div><div>Authors: Aleksandar Poleksic</div><div style='padding-top: 10px; width: 80ex'>Relationship inference from sparse data is an important task with
applications ranging from product recommendation to drug discovery. A recently
proposed linear model for sparse matrix completion has demonstrated surprising
advantage in speed and accuracy over more sophisticated recommender systems
algorithms. Here we extend the linear model to develop a shallow autoencoder
for the dual neighborhood-regularized matrix completion problem. We demonstrate
the speed and accuracy advantage of our approach over the existing
state-of-the-art in predicting drug-target interactions and drug-disease
associations.</div><div><a href='http://arxiv.org/abs/2401.16664v2'>2401.16664v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.08616v1")'>Adjustment Identification Distance: A gadjid for Causal Structure
  Learning</div>
<div id='2402.08616v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T17:32:59Z</div><div>Authors: Leonard Henckel, Theo Würtzen, Sebastian Weichwald</div><div style='padding-top: 10px; width: 80ex'>Evaluating graphs learned by causal discovery algorithms is difficult: The
number of edges that differ between two graphs does not reflect how the graphs
differ with respect to the identifying formulas they suggest for causal
effects. We introduce a framework for developing causal distances between
graphs which includes the structural intervention distance for directed acyclic
graphs as a special case. We use this framework to develop improved
adjustment-based distances as well as extensions to completed partially
directed acyclic graphs and causal orders. We develop polynomial-time
reachability algorithms to compute the distances efficiently. In our package
gadjid (open source at https://github.com/CausalDisco/gadjid), we provide
implementations of our distances; they are orders of magnitude faster than the
structural intervention distance and thereby provide a success metric for
causal discovery that scales to graph sizes that were previously prohibitive.</div><div><a href='http://arxiv.org/abs/2402.08616v1'>2402.08616v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.10495v1")'>Causal Layering via Conditional Entropy</div>
<div id='2401.10495v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-19T05:18:28Z</div><div>Authors: Itai Feigenbaum, Devansh Arpit, Huan Wang, Shelby Heinecke, Juan Carlos Niebles, Weiran Yao, Caiming Xiong, Silvio Savarese</div><div style='padding-top: 10px; width: 80ex'>Causal discovery aims to recover information about an unobserved causal graph
from the observable data it generates. Layerings are orderings of the variables
which place causes before effects. In this paper, we provide ways to recover
layerings of a graph by accessing the data via a conditional entropy oracle,
when distributions are discrete. Our algorithms work by repeatedly removing
sources or sinks from the graph. Under appropriate assumptions and
conditioning, we can separate the sources or sinks from the remainder of the
nodes by comparing their conditional entropy to the unconditional entropy of
their noise. Our algorithms are provably correct and run in worst-case
quadratic time. The main assumptions are faithfulness and injective noise, and
either known noise entropies or weakly monotonically increasing noise entropies
along directed paths. In addition, we require one of either a very mild
extension of faithfulness, or strictly monotonically increasing noise
entropies, or expanding noise injectivity to include an additional single
argument in the structural functions.</div><div><a href='http://arxiv.org/abs/2401.10495v1'>2401.10495v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.08229v1")'>Causal Discovery under Off-Target Interventions</div>
<div id='2402.08229v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T05:43:49Z</div><div>Authors: Davin Choo, Kirankumar Shiragur, Caroline Uhler</div><div style='padding-top: 10px; width: 80ex'>Causal graph discovery is a significant problem with applications across
various disciplines. However, with observational data alone, the underlying
causal graph can only be recovered up to its Markov equivalence class, and
further assumptions or interventions are necessary to narrow down the true
graph. This work addresses the causal discovery problem under the setting of
stochastic interventions with the natural goal of minimizing the number of
interventions performed. We propose the following stochastic intervention model
which subsumes existing adaptive noiseless interventions in the literature
while capturing scenarios such as fat-hand interventions and CRISPR gene
knockouts: any intervention attempt results in an actual intervention on a
random subset of vertices, drawn from a distribution dependent on attempted
action. Under this model, we study the two fundamental problems in causal
discovery of verification and search and provide approximation algorithms with
polylogarithmic competitive ratios and provide some preliminary experimental
results.</div><div><a href='http://arxiv.org/abs/2402.08229v1'>2402.08229v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.02930v1")'>Dagma-DCE: Interpretable, Non-Parametric Differentiable Causal Discovery</div>
<div id='2401.02930v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-05T18:15:19Z</div><div>Authors: Daniel Waxman, Kurt Butler, Petar M. Djuric</div><div style='padding-top: 10px; width: 80ex'>We introduce Dagma-DCE, an interpretable and model-agnostic scheme for
differentiable causal discovery. Current non- or over-parametric methods in
differentiable causal discovery use opaque proxies of ``independence'' to
justify the inclusion or exclusion of a causal relationship. We show
theoretically and empirically that these proxies may be arbitrarily different
than the actual causal strength. Juxtaposed to existing differentiable causal
discovery algorithms, \textsc{Dagma-DCE} uses an interpretable measure of
causal strength to define weighted adjacency matrices. In a number of simulated
datasets, we show our method achieves state-of-the-art level performance. We
additionally show that \textsc{Dagma-DCE} allows for principled thresholding
and sparsity penalties by domain-experts. The code for our method is available
open-source at https://github.com/DanWaxman/DAGMA-DCE, and can easily be
adapted to arbitrary differentiable models.</div><div><a href='http://arxiv.org/abs/2401.02930v1'>2401.02930v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01207v3")'>Efficient Causal Graph Discovery Using Large Language Models</div>
<div id='2402.01207v3' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T08:25:32Z</div><div>Authors: Thomas Jiralerspong, Xiaoyin Chen, Yash More, Vedant Shah, Yoshua Bengio</div><div style='padding-top: 10px; width: 80ex'>We propose a novel framework that leverages LLMs for full causal graph
discovery. While previous LLM-based methods have used a pairwise query
approach, this requires a quadratic number of queries which quickly becomes
impractical for larger causal graphs. In contrast, the proposed framework uses
a breadth-first search (BFS) approach which allows it to use only a linear
number of queries. We also show that the proposed method can easily incorporate
observational data when available, to improve performance. In addition to being
more time and data-efficient, the proposed framework achieves state-of-the-art
results on real-world causal graphs of varying sizes. The results demonstrate
the effectiveness and efficiency of the proposed method in discovering causal
relationships, showcasing its potential for broad applicability in causal graph
discovery tasks across different domains.</div><div><a href='http://arxiv.org/abs/2402.01207v3'>2402.01207v3</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15301v1")'>Causal Graph Discovery with Retrieval-Augmented Generation based Large
  Language Models</div>
<div id='2402.15301v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-23T13:02:10Z</div><div>Authors: Yuzhe Zhang, Yipeng Zhang, Yidong Gan, Lina Yao, Chen Wang</div><div style='padding-top: 10px; width: 80ex'>Causal graph recovery is essential in the field of causal inference.
Traditional methods are typically knowledge-based or statistical
estimation-based, which are limited by data collection biases and individuals'
knowledge about factors affecting the relations between variables of interests.
The advance of large language models (LLMs) provides opportunities to address
these problems. We propose a novel method that utilizes the extensive knowledge
contained within a large corpus of scientific literature to deduce causal
relationships in general causal graph recovery tasks. This method leverages
Retrieval Augmented-Generation (RAG) based LLMs to systematically analyze and
extract pertinent information from a comprehensive collection of research
papers. Our method first retrieves relevant text chunks from the aggregated
literature. Then, the LLM is tasked with identifying and labelling potential
associations between factors. Finally, we give a method to aggregate the
associational relationships to build a causal graph. We demonstrate our method
is able to construct high quality causal graphs on the well-known SACHS dataset
solely from literature.</div><div><a href='http://arxiv.org/abs/2402.15301v1'>2402.15301v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01454v1")'>Integrating Large Language Models in Causal Discovery: A Statistical
  Causal Approach</div>
<div id='2402.01454v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T14:43:19Z</div><div>Authors: Masayuki Takayama, Tadahisa Okuda, Thong Pham, Tatsuyoshi Ikenoue, Shingo Fukuma, Shohei Shimizu, Akiyoshi Sannai</div><div style='padding-top: 10px; width: 80ex'>In practical statistical causal discovery (SCD), embedding domain expert
knowledge as constraints into the algorithm is widely accepted as significant
for creating consistent meaningful causal models, despite the recognized
challenges in systematic acquisition of the background knowledge. To overcome
these challenges, this paper proposes a novel methodology for causal inference,
in which SCD methods and knowledge based causal inference (KBCI) with a large
language model (LLM) are synthesized through "statistical causal prompting
(SCP)" for LLMs and prior knowledge augmentation for SCD. Experiments have
revealed that GPT-4 can cause the output of the LLM-KBCI and the SCD result
with prior knowledge from LLM-KBCI to approach the ground truth, and that the
SCD result can be further improved, if GPT-4 undergoes SCP. Furthermore, it has
been clarified that an LLM can improve SCD with its background knowledge, even
if the LLM does not contain information on the dataset. The proposed approach
can thus address challenges such as dataset biases and limitations,
illustrating the potential of LLMs to improve data-driven causal inference
across diverse scientific domains.</div><div><a href='http://arxiv.org/abs/2402.01454v1'>2402.01454v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.16429v1")'>Combining topic modelling and citation network analysis to study case
  law from the European Court on Human Rights on the right to respect for
  private and family life</div>
<div id='2401.16429v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-19T14:30:35Z</div><div>Authors: M. Mohammadi, L. M. Bruijn, M. Wieling, M. Vols</div><div style='padding-top: 10px; width: 80ex'>As legal case law databases such as HUDOC continue to grow rapidly, it has
become essential for legal researchers to find efficient methods to handle such
large-scale data sets. Such case law databases usually consist of the textual
content of cases together with the citations between them. This paper focuses
on case law from the European Court of Human Rights on Article 8 of the
European Convention of Human Rights, the right to respect private and family
life, home and correspondence. In this study, we demonstrate and compare the
potential of topic modelling and citation network to find and organize case law
on Article 8 based on their general themes and citation patterns, respectively.
Additionally, we explore whether combining these two techniques leads to better
results compared to the application of only one of the methods. We evaluate the
effectiveness of the combined method on a unique manually collected and
annotated dataset of Aricle 8 case law on evictions. The results of our
experiments show that our combined (text and citation-based) approach provides
the best results in finding and grouping case law, providing scholars with an
effective way to extract and analyse relevant cases on a specific issue.</div><div><a href='http://arxiv.org/abs/2401.16429v1'>2401.16429v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.14125v1")'>Learning causal graphs using variable grouping according to ancestral
  relationship</div>
<div id='2403.14125v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T04:42:04Z</div><div>Authors: Ming Cai, Hisayuki Hara</div><div style='padding-top: 10px; width: 80ex'>Several causal discovery algorithms have been proposed. However, when the
sample size is small relative to the number of variables, the accuracy of
estimating causal graphs using existing methods decreases. And some methods are
not feasible when the sample size is smaller than the number of variables. To
circumvent these problems, some researchers proposed causal structure learning
algorithms using divide-and-conquer approaches. For learning the entire causal
graph, the approaches first split variables into several subsets according to
the conditional independence relationships among the variables, then apply a
conventional causal discovery algorithm to each subset and merge the estimated
results. Since the divide-and-conquer approach reduces the number of variables
to which a causal structure learning algorithm is applied, it is expected to
improve the estimation accuracy of causal graphs, especially when the sample
size is small relative to the number of variables and the model is sparse.
However, existing methods are either computationally expensive or do not
provide sufficient accuracy when the sample size is small. This paper proposes
a new algorithm for grouping variables based the ancestral relationships among
the variables, under the LiNGAM assumption, where the causal relationships are
linear, and the mutually independent noise are distributed as continuous
non-Gaussian distributions. We call the proposed algorithm CAG. The time
complexity of the ancestor finding in CAG is shown to be cubic to the number of
variables. Extensive computer experiments confirm that the proposed method
outperforms the original DirectLiNGAM without grouping variables and other
divide-and-conquer approaches not only in estimation accuracy but also in
computation time when the sample size is small relative to the number of
variables and the model is sparse.</div><div><a href='http://arxiv.org/abs/2403.14125v1'>2403.14125v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07762v1")'>Scalable Structure Learning for Sparse Context-Specific Causal Systems</div>
<div id='2402.07762v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-12T16:28:52Z</div><div>Authors: Felix Leopoldo Rios, Alex Markham, Liam Solus</div><div style='padding-top: 10px; width: 80ex'>Several approaches to graphically representing context-specific relations
among jointly distributed categorical variables have been proposed, along with
structure learning algorithms. While existing optimization-based methods have
limited scalability due to the large number of context-specific models, the
constraint-based methods are more prone to error than even constraint-based DAG
learning algorithms since more relations must be tested. We present a hybrid
algorithm for learning context-specific models that scales to hundreds of
variables while testing no more constraints than standard DAG learning
algorithms. Scalable learning is achieved through a combination of an
order-based MCMC algorithm and sparsity assumptions analogous to those
typically invoked for DAG models. To implement the method, we solve a special
case of an open problem recently posed by Alon and Balogh. The method is shown
to perform well on synthetic data and real world examples, in terms of both
accuracy and scalability.</div><div><a href='http://arxiv.org/abs/2402.07762v1'>2402.07762v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12175v1")'>Learning Discretized Bayesian Networks with GOMEA</div>
<div id='2402.12175v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-19T14:29:35Z</div><div>Authors: Damy M. F. Ha, Tanja Alderliesten, Peter A. N. Bosman</div><div style='padding-top: 10px; width: 80ex'>Bayesian networks model relationships between random variables under
uncertainty and can be used to predict the likelihood of events and outcomes
while incorporating observed evidence. From an eXplainable AI (XAI)
perspective, such models are interesting as they tend to be compact. Moreover,
captured relations can be directly inspected by domain experts. In practice,
data is often real-valued. Unless assumptions of normality can be made,
discretization is often required. The optimal discretization, however, depends
on the relations modelled between the variables. This complicates learning
Bayesian networks from data. For this reason, most literature focuses on
learning conditional dependencies between sets of variables, called structure
learning. In this work, we extend an existing state-of-the-art structure
learning approach based on the Gene-pool Optimal Mixing Evolutionary Algorithm
(GOMEA) to jointly learn variable discretizations. The proposed Discretized
Bayesian Network GOMEA (DBN-GOMEA) obtains similar or better results than the
current state-of-the-art when tasked to retrieve randomly generated
ground-truth networks. Moreover, leveraging a key strength of evolutionary
algorithms, we can straightforwardly perform DBN learning multi-objectively. We
show how this enables incorporating expert knowledge in a uniquely insightful
fashion, finding multiple DBNs that trade-off complexity, accuracy, and the
difference with a pre-determined expert network.</div><div><a href='http://arxiv.org/abs/2402.12175v1'>2402.12175v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16419v1")'>Semi-parametric Expert Bayesian Network Learning with Gaussian Processes
  and Horseshoe Priors</div>
<div id='2401.16419v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T18:57:45Z</div><div>Authors: Yidou Weng, Finale Doshi-Velez</div><div style='padding-top: 10px; width: 80ex'>This paper proposes a model learning Semi-parametric relationships in an
Expert Bayesian Network (SEBN) with linear parameter and structure constraints.
We use Gaussian Processes and a Horseshoe prior to introduce minimal nonlinear
components. To prioritize modifying the expert graph over adding new edges, we
optimize differential Horseshoe scales. In real-world datasets with unknown
truth, we generate diverse graphs to accommodate user input, addressing
identifiability issues and enhancing interpretability. Evaluation on synthetic
and UCI Liver Disorders datasets, using metrics like structural Hamming
Distance and test likelihood, demonstrates our models outperform
state-of-the-art semi-parametric Bayesian Network model.</div><div><a href='http://arxiv.org/abs/2401.16419v1'>2401.16419v1</a></div>
</div></div>
    <div><a href="arxiv_8.html">Prev (8)</a></div>
    <div><a href="arxiv_10.html">Next (10)</a></div>
    