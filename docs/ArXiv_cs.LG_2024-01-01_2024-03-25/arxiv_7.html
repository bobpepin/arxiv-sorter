
<!doctype html>
<meta charset="utf-8">
<style>
body { margin: 20px; }
</style>
<script>
function toggle(arxiv) {
  let elt = document.getElementById(arxiv);
  console.log(elt, elt.style.display);
  if(elt.style.display == "block") {
    elt.style.display = "none";
  } else {
    elt.style.display = "block";
  }
}
</script>
<div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.17319v1")'>Decentralized Federated Learning: A Survey on Security and Privacy</div>
<div id='2401.17319v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-25T23:35:47Z</div><div>Authors: Ehsan Hallaji, Roozbeh Razavi-Far, Mehrdad Saif, Boyu Wang, Qiang Yang</div><div style='padding-top: 10px; width: 80ex'>Federated learning has been rapidly evolving and gaining popularity in recent
years due to its privacy-preserving features, among other advantages.
Nevertheless, the exchange of model updates and gradients in this architecture
provides new attack surfaces for malicious users of the network which may
jeopardize the model performance and user and data privacy. For this reason,
one of the main motivations for decentralized federated learning is to
eliminate server-related threats by removing the server from the network and
compensating for it through technologies such as blockchain. However, this
advantage comes at the cost of challenging the system with new privacy threats.
Thus, performing a thorough security analysis in this new paradigm is
necessary. This survey studies possible variations of threats and adversaries
in decentralized federated learning and overviews the potential defense
mechanisms. Trustability and verifiability of decentralized federated learning
are also considered in this study.</div><div><a href='http://arxiv.org/abs/2401.17319v1'>2401.17319v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00342v1")'>Survey of Privacy Threats and Countermeasures in Federated Learning</div>
<div id='2402.00342v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T05:13:14Z</div><div>Authors: Masahiro Hayashitani, Junki Mori, Isamu Teranishi</div><div style='padding-top: 10px; width: 80ex'>Federated learning is widely considered to be as a privacy-aware learning
method because no training data is exchanged directly between clients.
Nevertheless, there are threats to privacy in federated learning, and privacy
countermeasures have been studied. However, we note that common and unique
privacy threats among typical types of federated learning have not been
categorized and described in a comprehensive and specific way. In this paper,
we describe privacy threats and countermeasures for the typical types of
federated learning; horizontal federated learning, vertical federated learning,
and transfer federated learning.</div><div><a href='http://arxiv.org/abs/2402.00342v1'>2402.00342v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.02268v1")'>Federated Learning with New Knowledge: Fundamentals, Advances, and
  Futures</div>
<div id='2402.02268v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-03T21:29:31Z</div><div>Authors: Lixu Wang, Yang Zhao, Jiahua Dong, Ating Yin, Qinbin Li, Xiao Wang, Dusit Niyato, Qi Zhu</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) is a privacy-preserving distributed learning approach
that is rapidly developing in an era where privacy protection is increasingly
valued. It is this rapid development trend, along with the continuous emergence
of new demands for FL in the real world, that prompts us to focus on a very
important problem: Federated Learning with New Knowledge. The primary challenge
here is to effectively incorporate various new knowledge into existing FL
systems and evolve these systems to reduce costs, extend their lifespan, and
facilitate sustainable development. In this paper, we systematically define the
main sources of new knowledge in FL, including new features, tasks, models, and
algorithms. For each source, we thoroughly analyze and discuss how to
incorporate new knowledge into existing FL systems and examine the impact of
the form and timing of new knowledge arrival on the incorporation process.
Furthermore, we comprehensively discuss the potential future directions for FL
with new knowledge, considering a variety of factors such as scenario setups,
efficiency, and security. There is also a continuously updating repository for
this topic: https://github.com/conditionWang/FLNK.</div><div><a href='http://arxiv.org/abs/2402.02268v1'>2402.02268v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.05968v1")'>Federated Learning Priorities Under the European Union Artificial
  Intelligence Act</div>
<div id='2402.05968v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T19:52:19Z</div><div>Authors: Herbert Woisetschläger, Alexander Erben, Bill Marino, Shiqiang Wang, Nicholas D. Lane, Ruben Mayer, Hans-Arno Jacobsen</div><div style='padding-top: 10px; width: 80ex'>The age of AI regulation is upon us, with the European Union Artificial
Intelligence Act (AI Act) leading the way. Our key inquiry is how this will
affect Federated Learning (FL), whose starting point of prioritizing data
privacy while performing ML fundamentally differs from that of centralized
learning. We believe the AI Act and future regulations could be the missing
catalyst that pushes FL toward mainstream adoption. However, this can only
occur if the FL community reprioritizes its research focus. In our position
paper, we perform a first-of-its-kind interdisciplinary analysis (legal and ML)
of the impact the AI Act may have on FL and make a series of observations
supporting our primary position through quantitative and qualitative analysis.
We explore data governance issues and the concern for privacy. We establish new
challenges regarding performance and energy efficiency within lifecycle
monitoring. Taken together, our analysis suggests there is a sizable
opportunity for FL to become a crucial component of AI Act-compliant ML systems
and for the new regulation to drive the adoption of FL techniques in general.
Most noteworthy are the opportunities to defend against data bias and enhance
private and secure computation</div><div><a href='http://arxiv.org/abs/2402.05968v1'>2402.05968v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.17671v1")'>Securing Reliability: A Brief Overview on Enhancing In-Context Learning
  for Foundation Models</div>
<div id='2402.17671v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T16:44:09Z</div><div>Authors: Yunpeng Huang, Yaonan Gu, Jingwei Xu, Zhihong Zhu, Zhaorun Chen, Xiaoxing Ma</div><div style='padding-top: 10px; width: 80ex'>As foundation models (FMs) continue to shape the landscape of AI, the
in-context learning (ICL) paradigm thrives but also encounters issues such as
toxicity, hallucination, disparity, adversarial vulnerability, and
inconsistency. Ensuring the reliability and responsibility of FMs is crucial
for the sustainable development of the AI ecosystem. In this concise overview,
we investigate recent advancements in enhancing the reliability and
trustworthiness of FMs within ICL frameworks, focusing on four key
methodologies, each with its corresponding subgoals. We sincerely hope this
paper can provide valuable insights for researchers and practitioners
endeavoring to build safe and dependable FMs and foster a stable and consistent
ICL environment, thereby unlocking their vast potential.</div><div><a href='http://arxiv.org/abs/2402.17671v1'>2402.17671v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.00023v1")'>Auditable Homomorphic-based Decentralized Collaborative AI with
  Attribute-based Differential Privacy</div>
<div id='2403.00023v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-28T14:51:18Z</div><div>Authors: Lo-Yao Yeh, Sheng-Po Tseng, Chia-Hsun Lu, Chih-Ya Shen</div><div style='padding-top: 10px; width: 80ex'>In recent years, the notion of federated learning (FL) has led to the new
paradigm of distributed artificial intelligence (AI) with privacy preservation.
However, most current FL systems suffer from data privacy issues due to the
requirement of a trusted third party. Although some previous works introduce
differential privacy to protect the data, however, it may also significantly
deteriorate the model performance. To address these issues, we propose a novel
decentralized collaborative AI framework, named Auditable Homomorphic-based
Decentralised Collaborative AI (AerisAI), to improve security with homomorphic
encryption and fine-grained differential privacy. Our proposed AerisAI directly
aggregates the encrypted parameters with a blockchain-based smart contract to
get rid of the need of a trusted third party. We also propose a brand-new
concept for eliminating the negative impacts of differential privacy for model
performance. Moreover, the proposed AerisAI also provides the broadcast-aware
group key management based on ciphertext-policy attribute-based encryption
(CPABE) to achieve fine-grained access control based on different service-level
agreements. We provide a formal theoretical analysis of the proposed AerisAI as
well as the functionality comparison with the other baselines. We also conduct
extensive experiments on real datasets to evaluate the proposed approach. The
experimental results indicate that our proposed AerisAI significantly
outperforms the other state-of-the-art baselines.</div><div><a href='http://arxiv.org/abs/2403.00023v1'>2403.00023v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15111v1")'>Chu-ko-nu: A Reliable, Efficient, and Anonymously Authentication-Enabled
  Realization for Multi-Round Secure Aggregation in Federated Learning</div>
<div id='2402.15111v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-23T05:50:43Z</div><div>Authors: Kaiping Cui, Xia Feng, Liangmin Wang, Haiqin Wu, Xiaoyu Zhang, Boris Düdder</div><div style='padding-top: 10px; width: 80ex'>Secure aggregation enables federated learning (FL) to perform collaborative
training of clients from local gradient updates without exposing raw data.
However, existing secure aggregation schemes inevitably perform an expensive
fresh setup per round because each client needs to establish fresh
input-independent secrets over different rounds. The latest research, Flamingo
(S&amp;P 2023), designed a share-transfer-based reusable secret key to support the
server continuously performing multiple rounds of aggregation. Nevertheless,
the share transfer mechanism it proposed can only be achieved with P
probability, which has limited reliability. To tackle the aforementioned
problems, we propose a more reliable and anonymously authenticated scheme
called Chu-ko-nu for multi-round secure aggregation. Specifically, in terms of
share transfer, Chu-ko-nu breaks the probability P barrier by supplementing a
redistribution process of secret key components (the sum of all components is
the secret key), thus ensuring the reusability of the secret key. Based on this
reusable secret key, Chu-ko-nu can efficiently perform consecutive aggregation
in the following rounds. Furthermore, considering the client identity
authentication and privacy protection issue most approaches ignore, Chu-ko-nu
introduces a zero-knowledge proof-based authentication mechanism. It can
support clients anonymously participating in FL training and enables the server
to authenticate clients effectively in the presence of various attacks.
Rigorous security proofs and extensive experiments demonstrated that Chu-ko-nu
can provide reliable and anonymously authenticated aggregation for FL with low
aggregation costs, at least a 21.02% reduction compared to the state-of-the-art
schemes.</div><div><a href='http://arxiv.org/abs/2402.15111v1'>2402.15111v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04146v1")'>FL-GUARD: A Holistic Framework for Run-Time Detection and Recovery of
  Negative Federated Learning</div>
<div id='2403.04146v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T01:52:05Z</div><div>Authors: Hong Lin, Lidan Shou, Ke Chen, Gang Chen, Sai Wu</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) is a promising approach for learning a model from
data distributed on massive clients without exposing data privacy. It works
effectively in the ideal federation where clients share homogeneous data
distribution and learning behavior. However, FL may fail to function
appropriately when the federation is not ideal, amid an unhealthy state called
Negative Federated Learning (NFL), in which most clients gain no benefit from
participating in FL. Many studies have tried to address NFL. However, their
solutions either (1) predetermine to prevent NFL in the entire learning
life-cycle or (2) tackle NFL in the aftermath of numerous learning rounds.
Thus, they either (1) indiscriminately incur extra costs even if FL can perform
well without such costs or (2) waste numerous learning rounds. Additionally,
none of the previous work takes into account the clients who may be
unwilling/unable to follow the proposed NFL solutions when using those
solutions to upgrade an FL system in use. This paper introduces FL-GUARD, a
holistic framework that can be employed on any FL system for tackling NFL in a
run-time paradigm. That is, to dynamically detect NFL at the early stage (tens
of rounds) of learning and then to activate recovery measures when necessary.
Specifically, we devise a cost-effective NFL detection mechanism, which relies
on an estimation of performance gain on clients. Only when NFL is detected, we
activate the NFL recovery process, in which each client learns in parallel an
adapted model when training the global model. Extensive experiment results
confirm the effectiveness of FL-GUARD in detecting NFL and recovering from NFL
to a healthy learning state. We also show that FL-GUARD is compatible with
previous NFL solutions and robust against clients unwilling/unable to take any
recovery measures.</div><div><a href='http://arxiv.org/abs/2403.04146v1'>2403.04146v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03688v1")'>A Survey of Privacy Threats and Defense in Vertical Federated Learning:
  From Model Life Cycle Perspective</div>
<div id='2402.03688v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-06T04:22:44Z</div><div>Authors: Lei Yu, Meng Han, Yiming Li, Changting Lin, Yao Zhang, Mingyang Zhang, Yan Liu, Haiqin Weng, Yuseok Jeon, Ka-Ho Chow, Stacy Patterson</div><div style='padding-top: 10px; width: 80ex'>Vertical Federated Learning (VFL) is a federated learning paradigm where
multiple participants, who share the same set of samples but hold different
features, jointly train machine learning models. Although VFL enables
collaborative machine learning without sharing raw data, it is still
susceptible to various privacy threats. In this paper, we conduct the first
comprehensive survey of the state-of-the-art in privacy attacks and defenses in
VFL. We provide taxonomies for both attacks and defenses, based on their
characterizations, and discuss open challenges and future research directions.
Specifically, our discussion is structured around the model's life cycle, by
delving into the privacy threats encountered during different stages of machine
learning and their corresponding countermeasures. This survey not only serves
as a resource for the research community but also offers clear guidance and
actionable insights for practitioners to safeguard data privacy throughout the
model's life cycle.</div><div><a href='http://arxiv.org/abs/2402.03688v1'>2402.03688v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.10765v2")'>Starlit: Privacy-Preserving Federated Learning to Enhance Financial
  Fraud Detection</div>
<div id='2401.10765v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-19T15:37:11Z</div><div>Authors: Aydin Abadi, Bradley Doyle, Francesco Gini, Kieron Guinamard, Sasi Kumar Murakonda, Jack Liddell, Paul Mellor, Steven J. Murdoch, Mohammad Naseri, Hector Page, George Theodorakopoulos, Suzanne Weller</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) is a data-minimization approach enabling
collaborative model training across diverse clients with local data, avoiding
direct data exchange. However, state-of-the-art FL solutions to identify
fraudulent financial transactions exhibit a subset of the following
limitations. They (1) lack a formal security definition and proof, (2) assume
prior freezing of suspicious customers' accounts by financial institutions
(limiting the solutions' adoption), (3) scale poorly, involving either $O(n^2)$
computationally expensive modular exponentiation (where $n$ is the total number
of financial institutions) or highly inefficient fully homomorphic encryption,
(4) assume the parties have already completed the identity alignment phase,
hence excluding it from the implementation, performance evaluation, and
security analysis, and (5) struggle to resist clients' dropouts. This work
introduces Starlit, a novel scalable privacy-preserving FL mechanism that
overcomes these limitations. It has various applications, such as enhancing
financial fraud detection, mitigating terrorism, and enhancing digital health.
We implemented Starlit and conducted a thorough performance analysis using
synthetic data from a key player in global financial transactions. The
evaluation indicates Starlit's scalability, efficiency, and accuracy.</div><div><a href='http://arxiv.org/abs/2401.10765v2'>2401.10765v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.02450v1")'>Locally Differentially Private Embedding Models in Distributed Fraud
  Prevention Systems</div>
<div id='2401.02450v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-03T14:04:18Z</div><div>Authors: Iker Perez, Jason Wong, Piotr Skalski, Stuart Burrell, Richard Mortier, Derek McAuley, David Sutton</div><div style='padding-top: 10px; width: 80ex'>Global financial crime activity is driving demand for machine learning
solutions in fraud prevention. However, prevention systems are commonly
serviced to financial institutions in isolation, and few provisions exist for
data sharing due to fears of unintentional leaks and adversarial attacks.
Collaborative learning advances in finance are rare, and it is hard to find
real-world insights derived from privacy-preserving data processing systems. In
this paper, we present a collaborative deep learning framework for fraud
prevention, designed from a privacy standpoint, and awarded at the recent PETs
Prize Challenges. We leverage latent embedded representations of varied-length
transaction sequences, along with local differential privacy, in order to
construct a data release mechanism which can securely inform externally hosted
fraud and anomaly detection models. We assess our contribution on two
distributed data sets donated by large payment networks, and demonstrate
robustness to popular inference-time attacks, along with utility-privacy
trade-offs analogous to published work in alternative application domains.</div><div><a href='http://arxiv.org/abs/2401.02450v1'>2401.02450v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09830v1")'>Utilizing GANs for Fraud Detection: Model Training with Synthetic
  Transaction Data</div>
<div id='2402.09830v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-15T09:48:20Z</div><div>Authors: Mengran Zhu, Yulu Gong, Yafei Xiang, Hanyi Yu, Shuning Huo</div><div style='padding-top: 10px; width: 80ex'>Anomaly detection is a critical challenge across various research domains,
aiming to identify instances that deviate from normal data distributions. This
paper explores the application of Generative Adversarial Networks (GANs) in
fraud detection, comparing their advantages with traditional methods. GANs, a
type of Artificial Neural Network (ANN), have shown promise in modeling complex
data distributions, making them effective tools for anomaly detection. The
paper systematically describes the principles of GANs and their derivative
models, emphasizing their application in fraud detection across different
datasets. And by building a collection of adversarial verification graphs, we
will effectively prevent fraud caused by bots or automated systems and ensure
that the users in the transaction are real. The objective of the experiment is
to design and implement a fake face verification code and fraud detection
system based on Generative Adversarial network (GANs) algorithm to enhance the
security of the transaction process.The study demonstrates the potential of
GANs in enhancing transaction security through deep learning techniques.</div><div><a href='http://arxiv.org/abs/2402.09830v1'>2402.09830v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.14983v1")'>Privacy-Enhancing Collaborative Information Sharing through Federated
  Learning -- A Case of the Insurance Industry</div>
<div id='2402.14983v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T21:46:24Z</div><div>Authors: Panyi Dong, Zhiyu Quan, Brandon Edwards, Shih-han Wang, Runhuan Feng, Tianyang Wang, Patrick Foley, Prashant Shah</div><div style='padding-top: 10px; width: 80ex'>The report demonstrates the benefits (in terms of improved claims loss
modeling) of harnessing the value of Federated Learning (FL) to learn a single
model across multiple insurance industry datasets without requiring the
datasets themselves to be shared from one company to another. The application
of FL addresses two of the most pressing concerns: limited data volume and data
variety, which are caused by privacy concerns, the rarity of claim events, the
lack of informative rating factors, etc.. During each round of FL,
collaborators compute improvements on the model using their local private data,
and these insights are combined to update a global model. Such aggregation of
insights allows for an increase to the effectiveness in forecasting claims
losses compared to models individually trained at each collaborator.
Critically, this approach enables machine learning collaboration without the
need for raw data to leave the compute infrastructure of each respective data
owner. Additionally, the open-source framework, OpenFL, that is used in our
experiments is designed so that it can be run using confidential computing as
well as with additional algorithmic protections against leakage of information
via the shared model updates. In such a way, FL is implemented as a
privacy-enhancing collaborative learning technique that addresses the
challenges posed by the sensitivity and privacy of data in traditional machine
learning solutions. This paper's application of FL can also be expanded to
other areas including fraud detection, catastrophe modeling, etc., that have a
similar need to incorporate data privacy into machine learning collaborations.
Our framework and empirical results provide a foundation for future
collaborations among insurers, regulators, academic researchers, and InsurTech
experts.</div><div><a href='http://arxiv.org/abs/2402.14983v1'>2402.14983v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03368v1")'>Leveraging Federated Learning for Automatic Detection of Clopidogrel
  Treatment Failures</div>
<div id='2403.03368v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-05T23:31:07Z</div><div>Authors: Samuel Kim, Min Sang Kim</div><div style='padding-top: 10px; width: 80ex'>The effectiveness of clopidogrel, a widely used antiplatelet medication,
varies significantly among individuals, necessitating the development of
precise predictive models to optimize patient care. In this study, we leverage
federated learning strategies to address clopidogrel treatment failure
detection. Our research harnesses the collaborative power of multiple
healthcare institutions, allowing them to jointly train machine learning models
while safeguarding sensitive patient data. Utilizing the UK Biobank dataset,
which encompasses a vast and diverse population, we partitioned the data based
on geographic centers and evaluated the performance of federated learning. Our
results show that while centralized training achieves higher Area Under the
Curve (AUC) values and faster convergence, federated learning approaches can
substantially narrow this performance gap. Our findings underscore the
potential of federated learning in addressing clopidogrel treatment failure
detection, offering a promising avenue for enhancing patient care through
personalized treatment strategies while respecting data privacy. This study
contributes to the growing body of research on federated learning in healthcare
and lays the groundwork for secure and privacy-preserving predictive models for
various medical conditions.</div><div><a href='http://arxiv.org/abs/2403.03368v1'>2403.03368v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00205v1")'>Decentralised, Collaborative, and Privacy-preserving Machine Learning
  for Multi-Hospital Data</div>
<div id='2402.00205v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-31T22:06:10Z</div><div>Authors: Congyu Fang, Adam Dziedzic, Lin Zhang, Laura Oliva, Amol Verma, Fahad Razak, Nicolas Papernot, Bo Wang</div><div style='padding-top: 10px; width: 80ex'>Machine Learning (ML) has demonstrated its great potential on medical data
analysis. Large datasets collected from diverse sources and settings are
essential for ML models in healthcare to achieve better accuracy and
generalizability. Sharing data across different healthcare institutions is
challenging because of complex and varying privacy and regulatory requirements.
Hence, it is hard but crucial to allow multiple parties to collaboratively
train an ML model leveraging the private datasets available at each party
without the need for direct sharing of those datasets or compromising the
privacy of the datasets through collaboration. In this paper, we address this
challenge by proposing Decentralized, Collaborative, and Privacy-preserving ML
for Multi-Hospital Data (DeCaPH). It offers the following key benefits: (1) it
allows different parties to collaboratively train an ML model without
transferring their private datasets; (2) it safeguards patient privacy by
limiting the potential privacy leakage arising from any contents shared across
the parties during the training process; and (3) it facilitates the ML model
training without relying on a centralized server. We demonstrate the
generalizability and power of DeCaPH on three distinct tasks using real-world
distributed medical datasets: patient mortality prediction using electronic
health records, cell-type classification using single-cell human genomes, and
pathology identification using chest radiology images. We demonstrate that the
ML models trained with DeCaPH framework have an improved utility-privacy
trade-off, showing it enables the models to have good performance while
preserving the privacy of the training data points. In addition, the ML models
trained with DeCaPH framework in general outperform those trained solely with
the private datasets from individual parties, showing that DeCaPH enhances the
model generalizability.</div><div><a href='http://arxiv.org/abs/2402.00205v1'>2402.00205v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14527v1")'>Federated Learning on Transcriptomic Data: Model Quality and Performance
  Trade-Offs</div>
<div id='2402.14527v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T13:21:26Z</div><div>Authors: Anika Hannemann, Jan Ewald, Leo Seeger, Erik Buchmann</div><div style='padding-top: 10px; width: 80ex'>Machine learning on large-scale genomic or transcriptomic data is important
for many novel health applications. For example, precision medicine tailors
medical treatments to patients on the basis of individual biomarkers, cellular
and molecular states, etc. However, the data required is sensitive, voluminous,
heterogeneous, and typically distributed across locations where dedicated
machine learning hardware is not available. Due to privacy and regulatory
reasons, it is also problematic to aggregate all data at a trusted third
party.Federated learning is a promising solution to this dilemma, because it
enables decentralized, collaborative machine learning without exchanging raw
data. In this paper, we perform comparative experiments with the federated
learning frameworks TensorFlow Federated and Flower. Our test case is the
training of disease prognosis and cell type classification models. We train the
models with distributed transcriptomic data, considering both data
heterogeneity and architectural heterogeneity. We measure model quality,
robustness against privacy-enhancing noise, computational performance and
resource overhead. Each of the federated learning frameworks has different
strengths. However, our experiments confirm that both frameworks can readily
build models on transcriptomic data, without transferring personal raw data to
a third party with abundant computational resources.</div><div><a href='http://arxiv.org/abs/2402.14527v1'>2402.14527v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.10861v1")'>FedQNN: Federated Learning using Quantum Neural Networks</div>
<div id='2403.10861v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-16T08:58:03Z</div><div>Authors: Nouhaila Innan, Muhammad Al-Zafar Khan, Alberto Marchisio, Muhammad Shafique, Mohamed Bennai</div><div style='padding-top: 10px; width: 80ex'>In this study, we explore the innovative domain of Quantum Federated Learning
(QFL) as a framework for training Quantum Machine Learning (QML) models via
distributed networks. Conventional machine learning models frequently grapple
with issues about data privacy and the exposure of sensitive information. Our
proposed Federated Quantum Neural Network (FedQNN) framework emerges as a
cutting-edge solution, integrating the singular characteristics of QML with the
principles of classical federated learning. This work thoroughly investigates
QFL, underscoring its capability to secure data handling in a distributed
environment and facilitate cooperative learning without direct data sharing.
Our research corroborates the concept through experiments across varied
datasets, including genomics and healthcare, thereby validating the versatility
and efficacy of our FedQNN framework. The results consistently exceed 86%
accuracy across three distinct datasets, proving its suitability for conducting
various QML tasks. Our research not only identifies the limitations of
classical paradigms but also presents a novel framework to propel the field of
QML into a new era of secure and collaborative innovation.</div><div><a href='http://arxiv.org/abs/2403.10861v1'>2403.10861v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.07464v1")'>Quantum Privacy Aggregation of Teacher Ensembles (QPATE) for
  Privacy-preserving Quantum Machine Learning</div>
<div id='2401.07464v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T04:38:06Z</div><div>Authors: William Watkins, Heehwan Wang, Sangyoon Bae, Huan-Hsin Tseng, Jiook Cha, Samuel Yen-Chi Chen, Shinjae Yoo</div><div style='padding-top: 10px; width: 80ex'>The utility of machine learning has rapidly expanded in the last two decades
and presents an ethical challenge. Papernot et. al. developed a technique,
known as Private Aggregation of Teacher Ensembles (PATE) to enable federated
learning in which multiple teacher models are trained on disjoint datasets.
This study is the first to apply PATE to an ensemble of quantum neural networks
(QNN) to pave a new way of ensuring privacy in quantum machine learning (QML)
models.</div><div><a href='http://arxiv.org/abs/2401.07464v1'>2401.07464v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.17621v1")'>Supervised machine learning for microbiomics: bridging the gap between
  current and best practices</div>
<div id='2402.17621v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T15:49:26Z</div><div>Authors: Natasha K. Dudek, Mariam Chakhvadze, Saba Kobakhidze, Omar Kantidze, Yuriy Gankin</div><div style='padding-top: 10px; width: 80ex'>Machine learning (ML) is set to accelerate innovations in clinical
microbiomics, such as in disease diagnostics and prognostics. This will require
high-quality, reproducible, interpretable workflows whose predictive
capabilities meet or exceed the high thresholds set for clinical tools by
regulatory agencies. Here, we capture a snapshot of current practices in the
application of supervised ML to microbiomics data, through an in-depth analysis
of 100 peer-reviewed journal articles published in 2021-2022. We apply a
data-driven approach to steer discussion of the merits of varied approaches to
experimental design, including key considerations such as how to mitigate the
effects of small dataset size while avoiding data leakage. We further provide
guidance on how to avoid common experimental design pitfalls that can hurt
model performance, trustworthiness, and reproducibility. Discussion is
accompanied by an interactive online tutorial that demonstrates foundational
principles of ML experimental design, tailored to the microbiomics community.
Formalizing community best practices for supervised ML in microbiomics is an
important step towards improving the success and efficiency of clinical
research, to the benefit of patients and other stakeholders.</div><div><a href='http://arxiv.org/abs/2402.17621v1'>2402.17621v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.06967v1")'>NHANES-GCP: Leveraging the Google Cloud Platform and BigQuery ML for
  reproducible machine learning with data from the National Health and
  Nutrition Examination Survey</div>
<div id='2401.06967v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-13T03:41:54Z</div><div>Authors: B. Ross Katz, Abdul Khan, James York-Winegar, Alexander J. Titus</div><div style='padding-top: 10px; width: 80ex'>Summary: NHANES, the National Health and Nutrition Examination Survey, is a
program of studies led by the Centers for Disease Control and Prevention (CDC)
designed to assess the health and nutritional status of adults and children in
the United States (U.S.). NHANES data is frequently used by biostatisticians
and clinical scientists to study health trends across the U.S., but every
analysis requires extensive data management and cleaning before use and this
repetitive data engineering collectively costs valuable research time and
decreases the reproducibility of analyses. Here, we introduce NHANES-GCP, a
Cloud Development Kit for Terraform (CDKTF) Infrastructure-as-Code (IaC) and
Data Build Tool (dbt) resources built on the Google Cloud Platform (GCP) that
automates the data engineering and management aspects of working with NHANES
data. With current GCP pricing, NHANES-GCP costs less than $2 to run and less
than $15/yr of ongoing costs for hosting the NHANES data, all while providing
researchers with clean data tables that can readily be integrated for
large-scale analyses. We provide examples of leveraging BigQuery ML to carry
out the process of selecting data, integrating data, training machine learning
and statistical models, and generating results all from a single SQL-like
query. NHANES-GCP is designed to enhance the reproducibility of analyses and
create a well-engineered NHANES data resource for statistics, machine learning,
and fine-tuning Large Language Models (LLMs).
  Availability and implementation" NHANES-GCP is available at
https://github.com/In-Vivo-Group/NHANES-GCP</div><div><a href='http://arxiv.org/abs/2401.06967v1'>2401.06967v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00077v1")'>Unlocking the Power of Multi-institutional Data: Integrating and
  Harmonizing Genomic Data Across Institutions</div>
<div id='2402.00077v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T23:25:05Z</div><div>Authors: Yuan Chen, Ronglai Shen, Xiwen Feng, Katherine Panageas</div><div style='padding-top: 10px; width: 80ex'>Cancer is a complex disease driven by genomic alterations, and tumor
sequencing is becoming a mainstay of clinical care for cancer patients. The
emergence of multi-institution sequencing data presents a powerful resource for
learning real-world evidence to enhance precision oncology. GENIE BPC, led by
the American Association for Cancer Research, establishes a unique database
linking genomic data with clinical information for patients treated at multiple
cancer centers. However, leveraging such multi-institutional sequencing data
presents significant challenges. Variations in gene panels result in loss of
information when the analysis is conducted on common gene sets. Additionally,
differences in sequencing techniques and patient heterogeneity across
institutions add complexity. High data dimensionality, sparse gene mutation
patterns, and weak signals at the individual gene level further complicate
matters. Motivated by these real-world challenges, we introduce the Bridge
model. It uses a quantile-matched latent variable approach to derive integrated
features to preserve information beyond common genes and maximize the
utilization of all available data while leveraging information sharing to
enhance both learning efficiency and the model's capacity to generalize. By
extracting harmonized and noise-reduced lower-dimensional latent variables, the
true mutation pattern unique to each individual is captured. We assess the
model's performance and parameter estimation through extensive simulation
studies. The extracted latent features from the Bridge model consistently excel
in predicting patient survival across six cancer types in GENIE BPC data.</div><div><a href='http://arxiv.org/abs/2402.00077v1'>2402.00077v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03018v1")'>CRISPR: Ensemble Model</div>
<div id='2403.03018v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-05T14:55:14Z</div><div>Authors: Mohammad Rostami, Amin Ghariyazi, Hamed Dashti, Mohammad Hossein Rohban, Hamid R. Rabiee</div><div style='padding-top: 10px; width: 80ex'>Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR) is a gene
editing technology that has revolutionized the fields of biology and medicine.
However, one of the challenges of using CRISPR is predicting the on-target
efficacy and off-target sensitivity of single-guide RNAs (sgRNAs). This is
because most existing methods are trained on separate datasets with different
genes and cells, which limits their generalizability. In this paper, we propose
a novel ensemble learning method for sgRNA design that is accurate and
generalizable. Our method combines the predictions of multiple machine learning
models to produce a single, more robust prediction. This approach allows us to
learn from a wider range of data, which improves the generalizability of our
model. We evaluated our method on a benchmark dataset of sgRNA designs and
found that it outperformed existing methods in terms of both accuracy and
generalizability. Our results suggest that our method can be used to design
sgRNAs with high sensitivity and specificity, even for new genes or cells. This
could have important implications for the clinical use of CRISPR, as it would
allow researchers to design more effective and safer treatments for a variety
of diseases.</div><div><a href='http://arxiv.org/abs/2403.03018v1'>2403.03018v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.01987v1")'>Online Transfer Learning for RSV Case Detection</div>
<div id='2402.01987v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-03T02:13:08Z</div><div>Authors: Yiming Sun, Yuhe Gao, Runxue Bao, Gregory F. Cooper, Jessi Espino, Harry Hochheiser, Marian G. Michaels, John M. Aronis, Ye Ye</div><div style='padding-top: 10px; width: 80ex'>Transfer learning has become a pivotal technique in machine learning,
renowned for its effectiveness in various real-world applications. However, a
significant challenge arises when applying this approach to sequential
epidemiological data, often characterized by a scarcity of labeled information.
To address this challenge, we introduce Predictive Volume-Adaptive Weighting
(PVAW), a novel online multi-source transfer learning method. PVAW innovatively
implements a dynamic weighting mechanism within an ensemble model, allowing for
the automatic adjustment of weights based on the relevance and contribution of
each source and target model. We demonstrate the effectiveness of PVAW through
its application in analyzing Respiratory Syncytial Virus (RSV) data, collected
over multiple seasons at the University of Pittsburgh Medical Center. Our
method showcases significant improvements in model performance over existing
baselines, highlighting the potential of online transfer learning in handling
complex, sequential data. This study not only underscores the adaptability and
sophistication of transfer learning in healthcare but also sets a new direction
for future research in creating advanced predictive models.</div><div><a href='http://arxiv.org/abs/2402.01987v1'>2402.01987v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.12438v1")'>Secure Federated Learning Approaches to Diagnosing COVID-19</div>
<div id='2401.12438v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-23T02:14:05Z</div><div>Authors: Rittika Adhikari, Christopher Settles</div><div style='padding-top: 10px; width: 80ex'>The recent pandemic has underscored the importance of accurately diagnosing
COVID-19 in hospital settings. A major challenge in this regard is
differentiating COVID-19 from other respiratory illnesses based on chest
X-rays, compounded by the restrictions of HIPAA compliance which limit the
comparison of patient X-rays. This paper introduces a HIPAA-compliant model to
aid in the diagnosis of COVID-19, utilizing federated learning. Federated
learning is a distributed machine learning approach that allows for algorithm
training across multiple decentralized devices using local data samples,
without the need for data sharing. Our model advances previous efforts in chest
X-ray diagnostic models. We examined leading models from established
competitions in this domain and developed our own models tailored to be
effective with specific hospital data. Considering the model's operation in a
federated learning context, we explored the potential impact of biased data
updates on the model's performance. To enhance hospital understanding of the
model's decision-making process and to verify that the model is not focusing on
irrelevant features, we employed a visualization technique that highlights key
features in chest X-rays indicative of a positive COVID-19 diagnosis.</div><div><a href='http://arxiv.org/abs/2401.12438v1'>2401.12438v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.08999v1")'>Exploring Federated Deep Learning for Standardising Naming Conventions
  in Radiotherapy Data</div>
<div id='2402.08999v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T07:52:28Z</div><div>Authors: Ali Haidar, Daniel Al Mouiee, Farhannah Aly, David Thwaites, Lois Holloway</div><div style='padding-top: 10px; width: 80ex'>Standardising structure volume names in radiotherapy (RT) data is necessary
to enable data mining and analyses, especially across multi-institutional
centres. This process is time and resource intensive, which highlights the need
for new automated and efficient approaches to handle the task. Several machine
learning-based methods have been proposed and evaluated to standardise
nomenclature. However, no studies have considered that RT patient records are
distributed across multiple data centres. This paper introduces a method that
emulates real-world environments to establish standardised nomenclature. This
is achieved by integrating decentralised real-time data and federated learning
(FL). A multimodal deep artificial neural network was proposed to standardise
RT data in federated settings. Three types of possible attributes were
extracted from the structures to train the deep learning models: tabular,
visual, and volumetric. Simulated experiments were carried out to train the
models across several scenarios including multiple data centres, input
modalities, and aggregation strategies. The models were compared against models
developed with single modalities in federated settings, in addition to models
trained in centralised settings. Categorical classification accuracy was
calculated on hold-out samples to inform the models performance. Our results
highlight the need for fusing multiple modalities when training such models,
with better performance reported with tabular-volumetric models. In addition,
we report comparable accuracy compared to models built in centralised settings.
This demonstrates the suitability of FL for handling the standardization task.
Additional ablation analyses showed that the total number of samples in the
data centres and the number of data centres highly affects the training process
and should be carefully considered when building standardisation models.</div><div><a href='http://arxiv.org/abs/2402.08999v1'>2402.08999v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.00896v1")'>Privacy and Security Implications of Cloud-Based AI Services : A Survey</div>
<div id='2402.00896v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-31T13:30:20Z</div><div>Authors: Alka Luqman, Riya Mahesh, Anupam Chattopadhyay</div><div style='padding-top: 10px; width: 80ex'>This paper details the privacy and security landscape in today's cloud
ecosystem and identifies that there is a gap in addressing the risks introduced
by machine learning models. As machine learning algorithms continue to evolve
and find applications across diverse domains, the need to categorize and
quantify privacy and security risks becomes increasingly critical. With the
emerging trend of AI-as-a-Service (AIaaS), machine learned AI models (or ML
models) are deployed on the cloud by model providers and used by model
consumers. We first survey the AIaaS landscape to document the various kinds of
liabilities that ML models, especially Deep Neural Networks pose and then
introduce a taxonomy to bridge this gap by holistically examining the risks
that creators and consumers of ML models are exposed to and their known
defences till date. Such a structured approach will be beneficial for ML model
providers to create robust solutions. Likewise, ML model consumers will find it
valuable to evaluate such solutions and understand the implications of their
engagement with such services. The proposed taxonomies provide a foundational
basis for solutions in private, secure and robust ML, paving the way for more
transparent and resilient AI systems.</div><div><a href='http://arxiv.org/abs/2402.00896v1'>2402.00896v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.14332v1")'>SunBlock: Cloudless Protection for IoT Systems</div>
<div id='2401.14332v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-25T17:30:08Z</div><div>Authors: Vadim Safronov, Anna Maria Mandalari, Daniel J. Dubois, David Choffnes, Hamed Haddadi</div><div style='padding-top: 10px; width: 80ex'>With an increasing number of Internet of Things (IoT) devices present in
homes, there is a rise in the number of potential information leakage channels
and their associated security threats and privacy risks. Despite a long history
of attacks on IoT devices in unprotected home networks, the problem of
accurate, rapid detection and prevention of such attacks remains open. Many
existing IoT protection solutions are cloud-based, sometimes ineffective, and
might share consumer data with unknown third parties. This paper investigates
the potential for effective IoT threat detection locally, on a home router,
using AI tools combined with classic rule-based traffic-filtering algorithms.
Our results show that with a slight rise of router hardware resources caused by
machine learning and traffic filtering logic, a typical home router
instrumented with our solution is able to effectively detect risks and protect
a typical home IoT network, equaling or outperforming existing popular
solutions, without any effects on benign IoT functionality, and without relying
on cloud services and third parties.</div><div><a href='http://arxiv.org/abs/2401.14332v1'>2401.14332v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.17191v1")'>AI-Driven Anonymization: Protecting Personal Data Privacy While
  Leveraging Machine Learning</div>
<div id='2402.17191v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T04:12:25Z</div><div>Authors: Le Yang, Miao Tian, Duan Xin, Qishuo Cheng, Jiajian Zheng</div><div style='padding-top: 10px; width: 80ex'>The development of artificial intelligence has significantly transformed
people's lives. However, it has also posed a significant threat to privacy and
security, with numerous instances of personal information being exposed online
and reports of criminal attacks and theft. Consequently, the need to achieve
intelligent protection of personal information through machine learning
algorithms has become a paramount concern. Artificial intelligence leverages
advanced algorithms and technologies to effectively encrypt and anonymize
personal data, enabling valuable data analysis and utilization while
safeguarding privacy. This paper focuses on personal data privacy protection
and the promotion of anonymity as its core research objectives. It achieves
personal data privacy protection and detection through the use of machine
learning's differential privacy protection algorithm. The paper also addresses
existing challenges in machine learning related to privacy and personal data
protection, offers improvement suggestions, and analyzes factors impacting
datasets to enable timely personal data privacy detection and protection.</div><div><a href='http://arxiv.org/abs/2402.17191v1'>2402.17191v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.06672v1")'>Provable Mutual Benefits from Federated Learning in Privacy-Sensitive
  Domains</div>
<div id='2403.06672v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-11T12:43:44Z</div><div>Authors: Nikita Tsoy, Anna Mihalkova, Teodora Todorova, Nikola Konstantinov</div><div style='padding-top: 10px; width: 80ex'>Cross-silo federated learning (FL) allows data owners to train accurate
machine learning models by benefiting from each others private datasets.
Unfortunately, the model accuracy benefits of collaboration are often
undermined by privacy defenses. Therefore, to incentivize client participation
in privacy-sensitive domains, a FL protocol should strike a delicate balance
between privacy guarantees and end-model accuracy. In this paper, we study the
question of when and how a server could design a FL protocol provably
beneficial for all participants. First, we provide necessary and sufficient
conditions for the existence of mutually beneficial protocols in the context of
mean estimation and convex stochastic optimization. We also derive protocols
that maximize the total clients' utility, given symmetric privacy preferences.
Finally, we design protocols maximizing end-model accuracy and demonstrate
their benefits in synthetic experiments.</div><div><a href='http://arxiv.org/abs/2403.06672v1'>2403.06672v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09715v1")'>DPBalance: Efficient and Fair Privacy Budget Scheduling for Federated
  Learning as a Service</div>
<div id='2402.09715v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-15T05:19:53Z</div><div>Authors: Yu Liu, Zibo Wang, Yifei Zhu, Chen Chen</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) has emerged as a prevalent distributed machine
learning scheme that enables collaborative model training without aggregating
raw data. Cloud service providers further embrace Federated Learning as a
Service (FLaaS), allowing data analysts to execute their FL training pipelines
over differentially-protected data. Due to the intrinsic properties of
differential privacy, the enforced privacy level on data blocks can be viewed
as a privacy budget that requires careful scheduling to cater to diverse
training pipelines. Existing privacy budget scheduling studies prioritize
either efficiency or fairness individually. In this paper, we propose
DPBalance, a novel privacy budget scheduling mechanism that jointly optimizes
both efficiency and fairness. We first develop a comprehensive utility function
incorporating data analyst-level dominant shares and FL-specific performance
metrics. A sequential allocation mechanism is then designed using the Lagrange
multiplier method and effective greedy heuristics. We theoretically prove that
DPBalance satisfies Pareto Efficiency, Sharing Incentive, Envy-Freeness, and
Weak Strategy Proofness. We also theoretically prove the existence of a
fairness-efficiency tradeoff in privacy budgeting. Extensive experiments
demonstrate that DPBalance outperforms state-of-the-art solutions, achieving an
average efficiency improvement of $1.44\times \sim 3.49 \times$, and an average
fairness improvement of $1.37\times \sim 24.32 \times$.</div><div><a href='http://arxiv.org/abs/2402.09715v1'>2402.09715v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.02740v3")'>Fairness-Aware Job Scheduling for Multi-Job Federated Learning</div>
<div id='2401.02740v3' style='display: none; margin-left: 20px'><div>Date: 2024-01-05T10:29:08Z</div><div>Authors: Yuxin Shi, Han Yu</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) enables multiple data owners (a.k.a. FL clients) to
collaboratively train machine learning models without disclosing sensitive
private data. Existing FL research mostly focuses on the monopoly scenario in
which a single FL server selects a subset of FL clients to update their local
models in each round of training. In practice, there can be multiple FL servers
simultaneously trying to select clients from the same pool. In this paper, we
propose a first-of-its-kind Fairness-aware Federated Job Scheduling (FairFedJS)
approach to bridge this gap. Based on Lyapunov optimization, it ensures fair
allocation of high-demand FL client datasets to FL jobs in need of them, by
jointly considering the current demand and the job payment bids, in order to
prevent prolonged waiting. Extensive experiments comparing FairFedJS against
four state-of-the-art approaches on two datasets demonstrate its significant
advantages. It outperforms the best baseline by 31.9% and 1.0% on average in
terms of scheduling fairness and convergence time, respectively, while
achieving comparable test accuracy.</div><div><a href='http://arxiv.org/abs/2401.02740v3'>2401.02740v3</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15247v1")'>A Bargaining-based Approach for Feature Trading in Vertical Federated
  Learning</div>
<div id='2402.15247v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-23T10:21:07Z</div><div>Authors: Yue Cui, Liuyi Yao, Zitao Li, Yaliang Li, Bolin Ding, Xiaofang Zhou</div><div style='padding-top: 10px; width: 80ex'>Vertical Federated Learning (VFL) has emerged as a popular machine learning
paradigm, enabling model training across the data and the task parties with
different features about the same user set while preserving data privacy. In
production environment, VFL usually involves one task party and one data party.
Fair and economically efficient feature trading is crucial to the
commercialization of VFL, where the task party is considered as the data
consumer who buys the data party's features. However, current VFL feature
trading practices often price the data party's data as a whole and assume
transactions occur prior to the performing VFL. Neglecting the performance
gains resulting from traded features may lead to underpayment and overpayment
issues. In this study, we propose a bargaining-based feature trading approach
in VFL to encourage economically efficient transactions. Our model incorporates
performance gain-based pricing, taking into account the revenue-based
optimization objectives of both parties. We analyze the proposed bargaining
model under perfect and imperfect performance information settings, proving the
existence of an equilibrium that optimizes the parties' objectives. Moreover,
we develop performance gain estimation-based bargaining strategies for
imperfect performance information scenarios and discuss potential security
issues and solutions. Experiments on three real-world datasets demonstrate the
effectiveness of the proposed bargaining model.</div><div><a href='http://arxiv.org/abs/2402.15247v1'>2402.15247v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01802v1")'>An Auction-based Marketplace for Model Trading in Federated Learning</div>
<div id='2402.01802v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T07:25:53Z</div><div>Authors: Yue Cui, Liuyi Yao, Yaliang Li, Ziqian Chen, Bolin Ding, Xiaofang Zhou</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) is increasingly recognized for its efficacy in
training models using locally distributed data. However, the proper valuation
of shared data in this collaborative process remains insufficiently addressed.
In this work, we frame FL as a marketplace of models, where clients act as both
buyers and sellers, engaging in model trading. This FL market allows clients to
gain monetary reward by selling their own models and improve local model
performance through the purchase of others' models. We propose an auction-based
solution to ensure proper pricing based on performance gain. Incentive
mechanisms are designed to encourage clients to truthfully reveal their model
valuations. Furthermore, we introduce a reinforcement learning (RL) framework
for marketing operations, aiming to achieve maximum trading volumes under the
dynamic and evolving market status. Experimental results on four datasets
demonstrate that the proposed FL market can achieve high trading revenue and
fair downstream task accuracy.</div><div><a href='http://arxiv.org/abs/2402.01802v1'>2402.01802v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.02230v1")'>Federated Learning with Differential Privacy</div>
<div id='2402.02230v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-03T18:21:38Z</div><div>Authors: Adrien Banse, Jan Kreischer, Xavier Oliva i Jürgens</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL), as a type of distributed machine learning, is
capable of significantly preserving client's private data from being shared
among different parties. Nevertheless, private information can still be
divulged by analyzing uploaded parameter weights from clients. In this report,
we showcase our empirical benchmark of the effect of the number of clients and
the addition of differential privacy (DP) mechanisms on the performance of the
model on different types of data. Our results show that non-i.i.d and small
datasets have the highest decrease in performance in a distributed and
differentially private setting.</div><div><a href='http://arxiv.org/abs/2402.02230v1'>2402.02230v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.00973v1")'>Facebook Report on Privacy of fNIRS data</div>
<div id='2401.00973v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-01T23:30:31Z</div><div>Authors: Md Imran Hossen, Sai Venkatesh Chilukoti, Liqun Shan, Vijay Srinivas Tida, Xiali Hei</div><div style='padding-top: 10px; width: 80ex'>The primary goal of this project is to develop privacy-preserving machine
learning model training techniques for fNIRS data. This project will build a
local model in a centralized setting with both differential privacy (DP) and
certified robustness. It will also explore collaborative federated learning to
train a shared model between multiple clients without sharing local fNIRS
datasets. To prevent unintentional private information leakage of such clients'
private datasets, we will also implement DP in the federated learning setting.</div><div><a href='http://arxiv.org/abs/2401.00973v1'>2401.00973v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.02453v1")'>Adaptive Differential Privacy in Federated Learning: A Priority-Based
  Approach</div>
<div id='2401.02453v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-04T03:01:15Z</div><div>Authors: Mahtab Talaei, Iman Izadi</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) as one of the novel branches of distributed machine
learning (ML), develops global models through a private procedure without
direct access to local datasets. However, access to model updates (e.g.
gradient updates in deep neural networks) transferred between clients and
servers can reveal sensitive information to adversaries. Differential privacy
(DP) offers a framework that gives a privacy guarantee by adding certain
amounts of noise to parameters. This approach, although being effective in
terms of privacy, adversely affects model performance due to noise involvement.
Hence, it is always needed to find a balance between noise injection and the
sacrificed accuracy. To address this challenge, we propose adaptive noise
addition in FL which decides the value of injected noise based on features'
relative importance. Here, we first propose two effective methods for
prioritizing features in deep neural network models and then perturb models'
weights based on this information. Specifically, we try to figure out whether
the idea of adding more noise to less important parameters and less noise to
more important parameters can effectively save the model accuracy while
preserving privacy. Our experiments confirm this statement under some
conditions. The amount of noise injected, the proportion of parameters
involved, and the number of global iterations can significantly change the
output. While a careful choice of parameters by considering the properties of
datasets can improve privacy without intense loss of accuracy, a bad choice can
make the model performance worse.</div><div><a href='http://arxiv.org/abs/2401.02453v1'>2401.02453v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14905v1")'>Adaptive Coded Federated Learning: Privacy Preservation and Straggler
  Mitigation</div>
<div id='2403.14905v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-22T01:51:48Z</div><div>Authors: Chengxi Li, Ming Xiao, Mikael Skoglund</div><div style='padding-top: 10px; width: 80ex'>In this article, we address the problem of federated learning in the presence
of stragglers. For this problem, a coded federated learning framework has been
proposed, where the central server aggregates gradients received from the
non-stragglers and gradient computed from a privacy-preservation global coded
dataset to mitigate the negative impact of the stragglers. However, when
aggregating these gradients, fixed weights are consistently applied across
iterations, neglecting the generation process of the global coded dataset and
the dynamic nature of the trained model over iterations. This oversight may
result in diminished learning performance. To overcome this drawback, we
propose a new method named adaptive coded federated learning (ACFL). In ACFL,
before the training, each device uploads a coded local dataset with additive
noise to the central server to generate a global coded dataset under privacy
preservation requirements. During each iteration of the training, the central
server aggregates the gradients received from the non-stragglers and the
gradient computed from the global coded dataset, where an adaptive policy for
varying the aggregation weights is designed. Under this policy, we optimize the
performance in terms of privacy and learning, where the learning performance is
analyzed through convergence analysis and the privacy performance is
characterized via mutual information differential privacy. Finally, we perform
simulations to demonstrate the superiority of ACFL compared with the
non-adaptive methods.</div><div><a href='http://arxiv.org/abs/2403.14905v1'>2403.14905v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.08100v1")'>Efficient Language Model Architectures for Differentially Private
  Federated Learning</div>
<div id='2403.08100v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T22:21:48Z</div><div>Authors: Jae Hun Ro, Srinadh Bhojanapalli, Zheng Xu, Yanxiang Zhang, Ananda Theertha Suresh</div><div style='padding-top: 10px; width: 80ex'>Cross-device federated learning (FL) is a technique that trains a model on
data distributed across typically millions of edge devices without data leaving
the devices. SGD is the standard client optimizer for on device training in
cross-device FL, favored for its memory and computational efficiency. However,
in centralized training of neural language models, adaptive optimizers are
preferred as they offer improved stability and performance. In light of this,
we ask if language models can be modified such that they can be efficiently
trained with SGD client optimizers and answer this affirmatively.
  We propose a scale-invariant Coupled Input Forget Gate (SI CIFG) recurrent
network by modifying the sigmoid and tanh activations in the recurrent cell and
show that this new model converges faster and achieves better utility than the
standard CIFG recurrent model in cross-device FL in large scale experiments. We
further show that the proposed scale invariant modification also helps in
federated learning of larger transformer models. Finally, we demonstrate the
scale invariant modification is also compatible with other non-adaptive
algorithms. Particularly, our results suggest an improved privacy utility
trade-off in federated learning with differential privacy.</div><div><a href='http://arxiv.org/abs/2403.08100v1'>2403.08100v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04207v1")'>HeteroSwitch: Characterizing and Taming System-Induced Data
  Heterogeneity in Federated Learning</div>
<div id='2403.04207v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T04:23:07Z</div><div>Authors: Gyudong Kim, Mehdi Ghasemi, Soroush Heidari, Seungryong Kim, Young Geun Kim, Sarma Vrudhula, Carole-Jean Wu</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) is a practical approach to train deep learning models
collaboratively across user-end devices, protecting user privacy by retaining
raw data on-device. In FL, participating user-end devices are highly fragmented
in terms of hardware and software configurations. Such fragmentation introduces
a new type of data heterogeneity in FL, namely \textit{system-induced data
heterogeneity}, as each device generates distinct data depending on its
hardware and software configurations. In this paper, we first characterize the
impact of system-induced data heterogeneity on FL model performance. We collect
a dataset using heterogeneous devices with variations across vendors and
performance tiers. By using this dataset, we demonstrate that
\textit{system-induced data heterogeneity} negatively impacts accuracy, and
deteriorates fairness and domain generalization problems in FL. To address
these challenges, we propose HeteroSwitch, which adaptively adopts
generalization techniques (i.e., ISP transformation and SWAD) depending on the
level of bias caused by varying HW and SW configurations. In our evaluation
with a realistic FL dataset (FLAIR), HeteroSwitch reduces the variance of
averaged precision by 6.3\% across device types.</div><div><a href='http://arxiv.org/abs/2403.04207v1'>2403.04207v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14737v1")'>FedMef: Towards Memory-efficient Federated Dynamic Pruning</div>
<div id='2403.14737v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T13:54:36Z</div><div>Authors: Hong Huang, Weiming Zhuang, Chen Chen, Lingjuan Lyu</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) promotes decentralized training while prioritizing
data confidentiality. However, its application on resource-constrained devices
is challenging due to the high demand for computation and memory resources to
train deep learning models. Neural network pruning techniques, such as dynamic
pruning, could enhance model efficiency, but directly adopting them in FL still
poses substantial challenges, including post-pruning performance degradation,
high activation memory usage, etc. To address these challenges, we propose
FedMef, a novel and memory-efficient federated dynamic pruning framework.
FedMef comprises two key components. First, we introduce the budget-aware
extrusion that maintains pruning efficiency while preserving post-pruning
performance by salvaging crucial information from parameters marked for pruning
within a given budget. Second, we propose scaled activation pruning to
effectively reduce activation memory footprints, which is particularly
beneficial for deploying FL to memory-limited devices. Extensive experiments
demonstrate the effectiveness of our proposed FedMef. In particular, it
achieves a significant reduction of 28.5% in memory footprint compared to
state-of-the-art methods while obtaining superior accuracy.</div><div><a href='http://arxiv.org/abs/2403.14737v1'>2403.14737v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00906v1")'>BrainLeaks: On the Privacy-Preserving Properties of Neuromorphic
  Architectures against Model Inversion Attacks</div>
<div id='2402.00906v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T03:16:40Z</div><div>Authors: Hamed Poursiami, Ihsen Alouani, Maryam Parsa</div><div style='padding-top: 10px; width: 80ex'>With the mainstream integration of machine learning into security-sensitive
domains such as healthcare and finance, concerns about data privacy have
intensified. Conventional artificial neural networks (ANNs) have been found
vulnerable to several attacks that can leak sensitive data. Particularly, model
inversion (MI) attacks enable the reconstruction of data samples that have been
used to train the model. Neuromorphic architectures have emerged as a paradigm
shift in neural computing, enabling asynchronous and energy-efficient
computation. However, little to no existing work has investigated the privacy
of neuromorphic architectures against model inversion. Our study is motivated
by the intuition that the non-differentiable aspect of spiking neural networks
(SNNs) might result in inherent privacy-preserving properties, especially
against gradient-based attacks. To investigate this hypothesis, we propose a
thorough exploration of SNNs' privacy-preserving capabilities. Specifically, we
develop novel inversion attack strategies that are comprehensively designed to
target SNNs, offering a comparative analysis with their conventional ANN
counterparts. Our experiments, conducted on diverse event-based and static
datasets, demonstrate the effectiveness of the proposed attack strategies and
therefore questions the assumption of inherent privacy-preserving in
neuromorphic architectures.</div><div><a href='http://arxiv.org/abs/2402.00906v1'>2402.00906v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.00942v1")'>Resilience of Entropy Model in Distributed Neural Networks</div>
<div id='2403.00942v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-01T19:39:19Z</div><div>Authors: Milin Zhang, Mohammad Abdi, Shahriar Rifat, Francesco Restuccia</div><div style='padding-top: 10px; width: 80ex'>Distributed deep neural networks (DNNs) have emerged as a key technique to
reduce communication overhead without sacrificing performance in edge computing
systems. Recently, entropy coding has been introduced to further reduce the
communication overhead. The key idea is to train the distributed DNN jointly
with an entropy model, which is used as side information during inference time
to adaptively encode latent representations into bit streams with variable
length. To the best of our knowledge, the resilience of entropy models is yet
to be investigated. As such, in this paper we formulate and investigate the
resilience of entropy models to intentional interference (e.g., adversarial
attacks) and unintentional interference (e.g., weather changes and motion
blur). Through an extensive experimental campaign with 3 different DNN
architectures, 2 entropy models and 4 rate-distortion trade-off factors, we
demonstrate that the entropy attacks can increase the communication overhead by
up to 95%. By separating compression features in frequency and spatial domain,
we propose a new defense mechanism that can reduce the transmission overhead of
the attacked input by about 9% compared to unperturbed data, with only about 2%
accuracy loss. Importantly, the proposed defense mechanism is a standalone
approach which can be applied in conjunction with approaches such as
adversarial training to further improve robustness. Code will be shared for
reproducibility.</div><div><a href='http://arxiv.org/abs/2403.00942v1'>2403.00942v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.14184v1")'>Friendly Attacks to Improve Channel Coding Reliability</div>
<div id='2401.14184v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-25T13:46:21Z</div><div>Authors: Anastasiia Kurmukova, Deniz Gunduz</div><div style='padding-top: 10px; width: 80ex'>This paper introduces a novel approach called "friendly attack" aimed at
enhancing the performance of error correction channel codes. Inspired by the
concept of adversarial attacks, our method leverages the idea of introducing
slight perturbations to the neural network input, resulting in a substantial
impact on the network's performance. By introducing small perturbations to
fixed-point modulated codewords before transmission, we effectively improve the
decoder's performance without violating the input power constraint. The
perturbation design is accomplished by a modified iterative fast gradient
method. This study investigates various decoder architectures suitable for
computing gradients to obtain the desired perturbations. Specifically, we
consider belief propagation (BP) for LDPC codes; the error correcting code
transformer, BP and neural BP (NBP) for polar codes, and neural BCJR for
convolutional codes. We demonstrate that the proposed friendly attack method
can improve the reliability across different channels, modulations, codes, and
decoders. This method allows us to increase the reliability of communication
with a legacy receiver by simply modifying the transmitted codeword
appropriately.</div><div><a href='http://arxiv.org/abs/2401.14184v1'>2401.14184v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.02299v1")'>A Review and Comparison of AI Enhanced Side Channel Analysis</div>
<div id='2402.02299v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-03T23:33:24Z</div><div>Authors: Max Panoff, Honggang Yu, Haoqi Shan, Yier Jin</div><div style='padding-top: 10px; width: 80ex'>Side Channel Analysis (SCA) presents a clear threat to privacy and security
in modern computing systems. The vast majority of communications are secured
through cryptographic algorithms. These algorithms are often provably-secure
from a cryptographical perspective, but their implementation on real hardware
introduces vulnerabilities. Adversaries can exploit these vulnerabilities to
conduct SCA and recover confidential information, such as secret keys or
internal states. The threat of SCA has greatly increased as machine learning,
and in particular deep learning, enhanced attacks become more common. In this
work, we will examine the latest state-of-the-art deep learning techniques for
side channel analysis, the theory behind them, and how they are conducted. Our
focus will be on profiling attacks using deep learning techniques, but we will
also examine some new and emerging methodologies enhanced by deep learning
techniques, such as non-profiled attacks, artificial trace generation, and
others. Finally, different deep learning enhanced SCA schemes attempted against
the ANSSI SCA Database (ASCAD) and their relative performance will be evaluated
and compared. This will lead to new research directions to secure cryptographic
implementations against the latest SCA attacks.</div><div><a href='http://arxiv.org/abs/2402.02299v1'>2402.02299v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.19037v1")'>A Deep-Learning Technique to Locate Cryptographic Operations in
  Side-Channel Traces</div>
<div id='2402.19037v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T11:02:47Z</div><div>Authors: Giuseppe Chiari, Davide Galli, Francesco Lattari, Matteo Matteucci, Davide Zoni</div><div style='padding-top: 10px; width: 80ex'>Side-channel attacks allow extracting secret information from the execution
of cryptographic primitives by correlating the partially known computed data
and the measured side-channel signal. However, to set up a successful
side-channel attack, the attacker has to perform i) the challenging task of
locating the time instant in which the target cryptographic primitive is
executed inside a side-channel trace and then ii)the time-alignment of the
measured data on that time instant. This paper presents a novel deep-learning
technique to locate the time instant in which the target computed cryptographic
operations are executed in the side-channel trace. In contrast to
state-of-the-art solutions, the proposed methodology works even in the presence
of trace deformations obtained through random delay insertion techniques. We
validated our proposal through a successful attack against a variety of
unprotected and protected cryptographic primitives that have been executed on
an FPGA-implemented system-on-chip featuring a RISC-V CPU.</div><div><a href='http://arxiv.org/abs/2402.19037v1'>2402.19037v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.12436v1")'>Wasserstein Differential Privacy</div>
<div id='2401.12436v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-23T02:08:20Z</div><div>Authors: Chengyi Yang, Jiayin Qi, Aimin Zhou</div><div style='padding-top: 10px; width: 80ex'>Differential privacy (DP) has achieved remarkable results in the field of
privacy-preserving machine learning. However, existing DP frameworks do not
satisfy all the conditions for becoming metrics, which prevents them from
deriving better basic private properties and leads to exaggerated values on
privacy budgets. We propose Wasserstein differential privacy (WDP), an
alternative DP framework to measure the risk of privacy leakage, which
satisfies the properties of symmetry and triangle inequality. We show and prove
that WDP has 13 excellent properties, which can be theoretical supports for the
better performance of WDP than other DP frameworks. In addition, we derive a
general privacy accounting method called Wasserstein accountant, which enables
WDP to be applied in stochastic gradient descent (SGD) scenarios containing
sub-sampling. Experiments on basic mechanisms, compositions and deep learning
show that the privacy budgets obtained by Wasserstein accountant are relatively
stable and less influenced by order. Moreover, the overestimation on privacy
budgets can be effectively alleviated. The code is available at
https://github.com/Hifipsysta/WDP.</div><div><a href='http://arxiv.org/abs/2401.12436v1'>2401.12436v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.09247v1")'>Momentum Approximation in Asynchronous Private Federated Learning</div>
<div id='2402.09247v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T15:35:53Z</div><div>Authors: Tao Yu, Congzheng Song, Jianyu Wang, Mona Chitnis</div><div style='padding-top: 10px; width: 80ex'>Asynchronous protocols have been shown to improve the scalability of
federated learning (FL) with a massive number of clients. Meanwhile,
momentum-based methods can achieve the best model quality in synchronous FL.
However, naively applying momentum in asynchronous FL algorithms leads to
slower convergence and degraded model performance. It is still unclear how to
effective combinie these two techniques together to achieve a win-win. In this
paper, we find that asynchrony introduces implicit bias to momentum updates. In
order to address this problem, we propose momentum approximation that minimizes
the bias by finding an optimal weighted average of all historical model
updates. Momentum approximation is compatible with secure aggregation as well
as differential privacy, and can be easily integrated in production FL systems
with a minor communication and storage cost. We empirically demonstrate that on
benchmark FL datasets, momentum approximation can achieve $1.15
\textrm{--}4\times$ speed up in convergence compared to existing asynchronous
FL optimizers with momentum.</div><div><a href='http://arxiv.org/abs/2402.09247v1'>2402.09247v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.01168v1")'>FedQV: Leveraging Quadratic Voting in Federated Learning</div>
<div id='2401.01168v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-02T11:53:06Z</div><div>Authors: Tianyue Chu, Nikolaos Laoutaris</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) permits different parties to collaboratively train a
global model without disclosing their respective local labels. A crucial step
of FL, that of aggregating local models to produce the global one, shares many
similarities with public decision-making, and elections in particular. In that
context, a major weakness of FL, namely its vulnerability to poisoning attacks,
can be interpreted as a consequence of the one person one vote (henceforth
1p1v) principle underpinning most contemporary aggregation rules. In this
paper, we propose FedQV, a novel aggregation algorithm built upon the quadratic
voting scheme, recently proposed as a better alternative to 1p1v-based
elections. Our theoretical analysis establishes that FedQV is a truthful
mechanism in which bidding according to one's true valuation is a dominant
strategy that achieves a convergence rate that matches those of
state-of-the-art methods. Furthermore, our empirical analysis using multiple
real-world datasets validates the superior performance of FedQV against
poisoning attacks. It also shows that combining FedQV with unequal voting
``budgets'' according to a reputation score increases its performance benefits
even further. Finally, we show that FedQV can be easily combined with
Byzantine-robust privacy-preserving mechanisms to enhance its robustness
against both poisoning and privacy attacks.</div><div><a href='http://arxiv.org/abs/2401.01168v1'>2401.01168v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.11343v1")'>Federated Transfer Learning with Differential Privacy</div>
<div id='2403.11343v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-17T21:04:48Z</div><div>Authors: Mengchu Li, Ye Tian, Yang Feng, Yi Yu</div><div style='padding-top: 10px; width: 80ex'>Federated learning is gaining increasing popularity, with data heterogeneity
and privacy being two prominent challenges. In this paper, we address both
issues within a federated transfer learning framework, aiming to enhance
learning on a target data set by leveraging information from multiple
heterogeneous source data sets while adhering to privacy constraints. We
rigorously formulate the notion of \textit{federated differential privacy},
which offers privacy guarantees for each data set without assuming a trusted
central server. Under this privacy constraint, we study three classical
statistical problems, namely univariate mean estimation, low-dimensional linear
regression, and high-dimensional linear regression. By investigating the
minimax rates and identifying the costs of privacy for these problems, we show
that federated differential privacy is an intermediate privacy model between
the well-established local and central models of differential privacy. Our
analyses incorporate data heterogeneity and privacy, highlighting the
fundamental costs of both in federated learning and underscoring the benefit of
knowledge transfer across data sets.</div><div><a href='http://arxiv.org/abs/2403.11343v1'>2403.11343v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16251v2")'>Cross-silo Federated Learning with Record-level Personalized
  Differential Privacy</div>
<div id='2401.16251v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T16:01:46Z</div><div>Authors: Junxu Liu, Jian Lou, Li Xiong, Jinfei Liu, Xiaofeng Meng</div><div style='padding-top: 10px; width: 80ex'>Federated learning enhanced by differential privacy has emerged as a popular
approach to better safeguard the privacy of client-side data by protecting
clients' contributions during the training process. Existing solutions
typically assume a uniform privacy budget for all records and provide
one-size-fits-all solutions that may not be adequate to meet each record's
privacy requirement. In this paper, we explore the uncharted territory of
cross-silo FL with record-level personalized differential privacy. We devise a
novel framework named rPDP-FL, employing a two-stage hybrid sampling scheme
with both client-level sampling and non-uniform record-level sampling to
accommodate varying privacy requirements. A critical and non-trivial problem is
to select the ideal per-record sampling probability q given the personalized
privacy budget {\epsilon}. We introduce a versatile solution named
Simulation-CurveFitting, allowing us to uncover a significant insight into the
nonlinear correlation between q and {\epsilon} and derive an elegant
mathematical model to tackle the problem. Our evaluation demonstrates that our
solution can provide significant performance gains over the baselines that do
not consider personalized privacy preservation.</div><div><a href='http://arxiv.org/abs/2401.16251v2'>2401.16251v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.08351v1")'>Personalized Federated Learning of Probabilistic Models: A PAC-Bayesian
  Approach</div>
<div id='2401.08351v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-16T13:30:37Z</div><div>Authors: Mahrokh Ghoddousi Boroujeni, Andreas Krause, Giancarlo Ferrari Trecate</div><div style='padding-top: 10px; width: 80ex'>Federated learning aims to infer a shared model from private and
decentralized data stored locally by multiple clients. Personalized federated
learning (PFL) goes one step further by adapting the global model to each
client, enhancing the model's fit for different clients. A significant level of
personalization is required for highly heterogeneous clients, but can be
challenging to achieve especially when they have small datasets. To address
this problem, we propose a PFL algorithm named PAC-PFL for learning
probabilistic models within a PAC-Bayesian framework that utilizes differential
privacy to handle data-dependent priors. Our algorithm collaboratively learns a
shared hyper-posterior and regards each client's posterior inference as the
personalization step. By establishing and minimizing a generalization bound on
the average true risk of clients, PAC-PFL effectively combats over-fitting.
PACPFL achieves accurate and well-calibrated predictions, supported by
experiments on a dataset of photovoltaic panel power generation, FEMNIST
dataset (Caldas et al., 2019), and Dirichlet-partitioned EMNIST dataset (Cohen
et al., 2017).</div><div><a href='http://arxiv.org/abs/2401.08351v1'>2401.08351v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12537v2")'>Hierarchical Bayes Approach to Personalized Federated Unsupervised
  Learning</div>
<div id='2402.12537v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-19T20:53:27Z</div><div>Authors: Kaan Ozkara, Bruce Huang, Ruida Zhou, Suhas Diggavi</div><div style='padding-top: 10px; width: 80ex'>Statistical heterogeneity of clients' local data is an important
characteristic in federated learning, motivating personalized algorithms
tailored to the local data statistics. Though there has been a plethora of
algorithms proposed for personalized supervised learning, discovering the
structure of local data through personalized unsupervised learning is less
explored. We initiate a systematic study of such personalized unsupervised
learning by developing algorithms based on optimization criteria inspired by a
hierarchical Bayesian statistical framework. We develop adaptive algorithms
that discover the balance between using limited local data and collaborative
information. We do this in the context of two unsupervised learning tasks:
personalized dimensionality reduction and personalized diffusion models. We
develop convergence analyses for our adaptive algorithms which illustrate the
dependence on problem parameters (e.g., heterogeneity, local sample size). We
also develop a theoretical framework for personalized diffusion models, which
shows the benefits of collaboration even under heterogeneity. We finally
evaluate our proposed algorithms using synthetic and real data, demonstrating
the effective sample amplification for personalized tasks, induced through
collaboration, despite data heterogeneity.</div><div><a href='http://arxiv.org/abs/2402.12537v2'>2402.12537v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12812v1")'>Scalable Decentralized Algorithms for Online Personalized Mean
  Estimation</div>
<div id='2402.12812v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T08:30:46Z</div><div>Authors: Franco Galante, Giovanni Neglia, Emilio Leonardi</div><div style='padding-top: 10px; width: 80ex'>In numerous settings, agents lack sufficient data to directly learn a model.
Collaborating with other agents may help, but it introduces a bias-variance
trade-off, when local data distributions differ. A key challenge is for each
agent to identify clients with similar distributions while learning the model,
a problem that remains largely unresolved. This study focuses on a simplified
version of the overarching problem, where each agent collects samples from a
real-valued distribution over time to estimate its mean. Existing algorithms
face impractical space and time complexities (quadratic in the number of agents
A). To address scalability challenges, we propose a framework where agents
self-organize into a graph, allowing each agent to communicate with only a
selected number of peers r. We introduce two collaborative mean estimation
algorithms: one draws inspiration from belief propagation, while the other
employs a consensus-based approach, with complexity of O( r |A| log |A|) and
O(r |A|), respectively. We establish conditions under which both algorithms
yield asymptotically optimal estimates and offer a theoretical characterization
of their performance.</div><div><a href='http://arxiv.org/abs/2402.12812v1'>2402.12812v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.13182v1")'>Order-Optimal Regret in Distributed Kernel Bandits using Uniform
  Sampling with Shared Randomness</div>
<div id='2402.13182v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T17:49:10Z</div><div>Authors: Nikola Pavlovic, Sudeep Salgia, Qing Zhao</div><div style='padding-top: 10px; width: 80ex'>We consider distributed kernel bandits where $N$ agents aim to
collaboratively maximize an unknown reward function that lies in a reproducing
kernel Hilbert space. Each agent sequentially queries the function to obtain
noisy observations at the query points. Agents can share information through a
central server, with the objective of minimizing regret that is accumulating
over time $T$ and aggregating over agents. We develop the first algorithm that
achieves the optimal regret order (as defined by centralized learning) with a
communication cost that is sublinear in both $N$ and $T$. The key features of
the proposed algorithm are the uniform exploration at the local agents and
shared randomness with the central server. Working together with the sparse
approximation of the GP model, these two key components make it possible to
preserve the learning rate of the centralized setting at a diminishing rate of
communication.</div><div><a href='http://arxiv.org/abs/2402.13182v1'>2402.13182v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.01857v1")'>Position Paper: Assessing Robustness, Privacy, and Fairness in Federated
  Learning Integrated with Foundation Models</div>
<div id='2402.01857v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T19:26:00Z</div><div>Authors: Xi Li, Jiaqi Wang</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL), while a breakthrough in decentralized machine
learning, contends with significant challenges such as limited data
availability and the variability of computational resources, which can stifle
the performance and scalability of the models. The integration of Foundation
Models (FMs) into FL presents a compelling solution to these issues, with the
potential to enhance data richness and reduce computational demands through
pre-training and data augmentation. However, this incorporation introduces
novel issues in terms of robustness, privacy, and fairness, which have not been
sufficiently addressed in the existing research. We make a preliminary
investigation into this field by systematically evaluating the implications of
FM-FL integration across these dimensions. We analyze the trade-offs involved,
uncover the threats and issues introduced by this integration, and propose a
set of criteria and strategies for navigating these challenges. Furthermore, we
identify potential research directions for advancing this field, laying a
foundation for future development in creating reliable, secure, and equitable
FL systems.</div><div><a href='http://arxiv.org/abs/2402.01857v1'>2402.01857v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12271v1")'>Secure Federated Learning Across Heterogeneous Cloud and
  High-Performance Computing Resources -- A Case Study on Federated Fine-tuning
  of LLaMA 2</div>
<div id='2402.12271v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-19T16:34:59Z</div><div>Authors: Zilinghan Li, Shilan He, Pranshu Chaturvedi, Volodymyr Kindratenko, Eliu A Huerta, Kibaek Kim, Ravi Madduri</div><div style='padding-top: 10px; width: 80ex'>Federated learning enables multiple data owners to collaboratively train
robust machine learning models without transferring large or sensitive local
datasets by only sharing the parameters of the locally trained models. In this
paper, we elaborate on the design of our Advanced Privacy-Preserving Federated
Learning (APPFL) framework, which streamlines end-to-end secure and reliable
federated learning experiments across cloud computing facilities and
high-performance computing resources by leveraging Globus Compute, a
distributed function as a service platform, and Amazon Web Services. We further
demonstrate the use case of APPFL in fine-tuning a LLaMA 2 7B model using
several cloud resources and supercomputers.</div><div><a href='http://arxiv.org/abs/2402.12271v1'>2402.12271v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04546v1")'>Architectural Blueprint For Heterogeneity-Resilient Federated Learning</div>
<div id='2403.04546v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T14:42:33Z</div><div>Authors: Satwat Bashir, Tasos Dagiuklas, Kasra Kassai, Muddesar Iqbal</div><div style='padding-top: 10px; width: 80ex'>This paper proposes a novel three tier architecture for federated learning to
optimize edge computing environments. The proposed architecture addresses the
challenges associated with client data heterogeneity and computational
constraints. It introduces a scalable, privacy preserving framework that
enhances the efficiency of distributed machine learning. Through
experimentation, the paper demonstrates the architecture capability to manage
non IID data sets more effectively than traditional federated learning models.
Additionally, the paper highlights the potential of this innovative approach to
significantly improve model accuracy, reduce communication overhead, and
facilitate broader adoption of federated learning technologies.</div><div><a href='http://arxiv.org/abs/2403.04546v1'>2403.04546v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.08723v1")'>HierSFL: Local Differential Privacy-aided Split Federated Learning in
  Mobile Edge Computing</div>
<div id='2401.08723v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-16T09:34:10Z</div><div>Authors: Minh K. Quan, Dinh C. Nguyen, Van-Dinh Nguyen, Mayuri Wijayasundara, Sujeeva Setunge, Pubudu N. Pathirana</div><div style='padding-top: 10px; width: 80ex'>Federated Learning is a promising approach for learning from user data while
preserving data privacy. However, the high requirements of the model training
process make it difficult for clients with limited memory or bandwidth to
participate. To tackle this problem, Split Federated Learning is utilized,
where clients upload their intermediate model training outcomes to a cloud
server for collaborative server-client model training. This methodology
facilitates resource-constrained clients' participation in model training but
also increases the training time and communication overhead. To overcome these
limitations, we propose a novel algorithm, called Hierarchical Split Federated
Learning (HierSFL), that amalgamates models at the edge and cloud phases,
presenting qualitative directives for determining the best aggregation
timeframes to reduce computation and communication expenses. By implementing
local differential privacy at the client and edge server levels, we enhance
privacy during local model parameter updates. Our experiments using CIFAR-10
and MNIST datasets show that HierSFL outperforms standard FL approaches with
better training accuracy, training time, and communication-computing
trade-offs. HierSFL offers a promising solution to mobile edge computing's
challenges, ultimately leading to faster content delivery and improved mobile
service quality.</div><div><a href='http://arxiv.org/abs/2401.08723v1'>2401.08723v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15903v1")'>ESFL: Efficient Split Federated Learning over Resource-Constrained
  Heterogeneous Wireless Devices</div>
<div id='2402.15903v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-24T20:50:29Z</div><div>Authors: Guangyu Zhu, Yiqin Deng, Xianhao Chen, Haixia Zhang, Yuguang Fang, Tan F. Wong</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) allows multiple parties (distributed devices) to
train a machine learning model without sharing raw data. How to effectively and
efficiently utilize the resources on devices and the central server is a highly
interesting yet challenging problem. In this paper, we propose an efficient
split federated learning algorithm (ESFL) to take full advantage of the
powerful computing capabilities at a central server under a split federated
learning framework with heterogeneous end devices (EDs). By splitting the model
into different submodels between the server and EDs, our approach jointly
optimizes user-side workload and server-side computing resource allocation by
considering users' heterogeneity. We formulate the whole optimization problem
as a mixed-integer non-linear program, which is an NP-hard problem, and develop
an iterative approach to obtain an approximate solution efficiently. Extensive
simulations have been conducted to validate the significantly increased
efficiency of our ESFL approach compared with standard federated learning,
split learning, and splitfed learning.</div><div><a href='http://arxiv.org/abs/2402.15903v1'>2402.15903v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00208v1")'>MP-SL: Multihop Parallel Split Learning</div>
<div id='2402.00208v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-31T22:09:40Z</div><div>Authors: Joana Tirana, Spyros Lalis, Dimitris Chatzopoulos</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) stands out as a widely adopted protocol facilitating
the training of Machine Learning (ML) models while maintaining decentralized
data. However, challenges arise when dealing with a heterogeneous set of
participating devices, causing delays in the training process, particularly
among devices with limited resources. Moreover, the task of training ML models
with a vast number of parameters demands computing and memory resources beyond
the capabilities of small devices, such as mobile and Internet of Things (IoT)
devices. To address these issues, techniques like Parallel Split Learning (SL)
have been introduced, allowing multiple resource-constrained devices to
actively participate in collaborative training processes with assistance from
resourceful compute nodes. Nonetheless, a drawback of Parallel SL is the
substantial memory allocation required at the compute nodes, for instance
training VGG-19 with 100 participants needs 80 GB. In this paper, we introduce
Multihop Parallel SL (MP-SL), a modular and extensible ML as a Service (MLaaS)
framework designed to facilitate the involvement of resource-constrained
devices in collaborative and distributed ML model training. Notably, to
alleviate memory demands per compute node, MP-SL supports multihop Parallel
SL-based training. This involves splitting the model into multiple parts and
utilizing multiple compute nodes in a pipelined manner. Extensive
experimentation validates MP-SL's capability to handle system heterogeneity,
demonstrating that the multihop configuration proves more efficient than
horizontally scaled one-hop Parallel SL setups, especially in scenarios
involving more cost-effective compute nodes.</div><div><a href='http://arxiv.org/abs/2402.00208v1'>2402.00208v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14346v1")'>Dependable Distributed Training of Compressed Machine Learning Models</div>
<div id='2402.14346v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T07:24:26Z</div><div>Authors: Francesco Malandrino, Giuseppe Di Giacomo, Marco Levorato, Carla Fabiana Chiasserini</div><div style='padding-top: 10px; width: 80ex'>The existing work on the distributed training of machine learning (ML) models
has consistently overlooked the distribution of the achieved learning quality,
focusing instead on its average value. This leads to a poor dependability}of
the resulting ML models, whose performance may be much worse than expected. We
fill this gap by proposing DepL, a framework for dependable learning
orchestration, able to make high-quality, efficient decisions on (i) the data
to leverage for learning, (ii) the models to use and when to switch among them,
and (iii) the clusters of nodes, and the resources thereof, to exploit. For
concreteness, we consider as possible available models a full DNN and its
compressed versions. Unlike previous studies, DepL guarantees that a target
learning quality is reached with a target probability, while keeping the
training cost at a minimum. We prove that DepL has constant competitive ratio
and polynomial complexity, and show that it outperforms the state-of-the-art by
over 27% and closely matches the optimum.</div><div><a href='http://arxiv.org/abs/2402.14346v1'>2402.14346v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04144v1")'>FedClust: Optimizing Federated Learning on Non-IID Data through
  Weight-Driven Client Clustering</div>
<div id='2403.04144v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T01:50:36Z</div><div>Authors: Md Sirajul Islam, Simin Javaherian, Fei Xu, Xu Yuan, Li Chen, Nian-Feng Tzeng</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) is an emerging distributed machine learning paradigm
enabling collaborative model training on decentralized devices without exposing
their local data. A key challenge in FL is the uneven data distribution across
client devices, violating the well-known assumption of
independent-and-identically-distributed (IID) training samples in conventional
machine learning. Clustered federated learning (CFL) addresses this challenge
by grouping clients based on the similarity of their data distributions.
However, existing CFL approaches require a large number of communication rounds
for stable cluster formation and rely on a predefined number of clusters, thus
limiting their flexibility and adaptability. This paper proposes FedClust, a
novel CFL approach leveraging correlations between local model weights and
client data distributions. FedClust groups clients into clusters in a one-shot
manner using strategically selected partial model weights and dynamically
accommodates newcomers in real-time. Experimental results demonstrate FedClust
outperforms baseline approaches in terms of accuracy and communication costs.</div><div><a href='http://arxiv.org/abs/2403.04144v1'>2403.04144v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.08769v1")'>FLASH: Federated Learning Across Simultaneous Heterogeneities</div>
<div id='2402.08769v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T20:04:39Z</div><div>Authors: Xiangyu Chang, Sk Miraj Ahmed, Srikanth V. Krishnamurthy, Basak Guler, Ananthram Swami, Samet Oymak, Amit K. Roy-Chowdhury</div><div style='padding-top: 10px; width: 80ex'>The key premise of federated learning (FL) is to train ML models across a
diverse set of data-owners (clients), without exchanging local data. An
overarching challenge to this date is client heterogeneity, which may arise not
only from variations in data distribution, but also in data quality, as well as
compute/communication latency. An integrated view of these diverse and
concurrent sources of heterogeneity is critical; for instance, low-latency
clients may have poor data quality, and vice versa. In this work, we propose
FLASH(Federated Learning Across Simultaneous Heterogeneities), a lightweight
and flexible client selection algorithm that outperforms state-of-the-art FL
frameworks under extensive sources of heterogeneity, by trading-off the
statistical information associated with the client's data quality, data
distribution, and latency. FLASH is the first method, to our knowledge, for
handling all these heterogeneities in a unified manner. To do so, FLASH models
the learning dynamics through contextual multi-armed bandits (CMAB) and
dynamically selects the most promising clients. Through extensive experiments,
we demonstrate that FLASH achieves substantial and consistent improvements over
state-of-the-art baselines -- as much as 10% in absolute accuracy -- thanks to
its unified approach. Importantly, FLASH also outperforms federated aggregation
methods that are designed to handle highly heterogeneous settings and even
enjoys a performance boost when integrated with them.</div><div><a href='http://arxiv.org/abs/2402.08769v1'>2402.08769v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.09086v1")'>Learning from straggler clients in federated learning</div>
<div id='2403.09086v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T04:06:45Z</div><div>Authors: Andrew Hard, Antonious M. Girgis, Ehsan Amid, Sean Augenstein, Lara McConnaughey, Rajiv Mathews, Rohan Anil</div><div style='padding-top: 10px; width: 80ex'>How well do existing federated learning algorithms learn from client devices
that return model updates with a significant time delay? Is it even possible to
learn effectively from clients that report back minutes, hours, or days after
being scheduled? We answer these questions by developing Monte Carlo
simulations of client latency that are guided by real-world applications. We
study synchronous optimization algorithms like FedAvg and FedAdam as well as
the asynchronous FedBuff algorithm, and observe that all these existing
approaches struggle to learn from severely delayed clients. To improve upon
this situation, we experiment with modifications, including distillation
regularization and exponential moving averages of model weights. Finally, we
introduce two new algorithms, FARe-DUST and FeAST-on-MSG, based on distillation
and averaging, respectively. Experiments with the EMNIST, CIFAR-100, and
StackOverflow benchmark federated learning tasks demonstrate that our new
algorithms outperform existing ones in terms of accuracy for straggler clients,
while also providing better trade-offs between training time and total
accuracy.</div><div><a href='http://arxiv.org/abs/2403.09086v1'>2403.09086v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01863v1")'>DFML: Decentralized Federated Mutual Learning</div>
<div id='2402.01863v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T19:35:05Z</div><div>Authors: Yasser H. Khalil, Amir H. Estiri, Mahdi Beitollahi, Nader Asadi, Sobhan Hemati, Xu Li, Guojun Zhang, Xi Chen</div><div style='padding-top: 10px; width: 80ex'>In the realm of real-world devices, centralized servers in Federated Learning
(FL) present challenges including communication bottlenecks and susceptibility
to a single point of failure. Additionally, contemporary devices inherently
exhibit model and data heterogeneity. Existing work lacks a Decentralized FL
(DFL) framework capable of accommodating such heterogeneity without imposing
architectural restrictions or assuming the availability of public data. To
address these issues, we propose a Decentralized Federated Mutual Learning
(DFML) framework that is serverless, supports nonrestrictive heterogeneous
models, and avoids reliance on public data. DFML effectively handles model and
data heterogeneity through mutual learning, which distills knowledge between
clients, and cyclically varying the amount of supervision and distillation
signals. Extensive experimental results demonstrate consistent effectiveness of
DFML in both convergence speed and global accuracy, outperforming prevalent
baselines under various conditions. For example, with the CIFAR-100 dataset and
50 clients, DFML achieves a substantial increase of +17.20% and +19.95% in
global accuracy under Independent and Identically Distributed (IID) and non-IID
data shifts, respectively.</div><div><a href='http://arxiv.org/abs/2402.01863v1'>2402.01863v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.01387v1")'>A Comprehensive Survey of Federated Transfer Learning: Challenges,
  Methods and Applications</div>
<div id='2403.01387v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-03T03:52:27Z</div><div>Authors: Wei Guo, Fuzhen Zhuang, Xiao Zhang, Yiqi Tong, Jin Dong</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) is a novel distributed machine learning paradigm that
enables participants to collaboratively train a centralized model with privacy
preservation by eliminating the requirement of data sharing. In practice, FL
often involves multiple participants and requires the third party to aggregate
global information to guide the update of the target participant. Therefore,
many FL methods do not work well due to the training and test data of each
participant may not be sampled from the same feature space and the same
underlying distribution. Meanwhile, the differences in their local devices
(system heterogeneity), the continuous influx of online data (incremental
data), and labeled data scarcity may further influence the performance of these
methods. To solve this problem, federated transfer learning (FTL), which
integrates transfer learning (TL) into FL, has attracted the attention of
numerous researchers. However, since FL enables a continuous share of knowledge
among participants with each communication round while not allowing local data
to be accessed by other participants, FTL faces many unique challenges that are
not present in TL. In this survey, we focus on categorizing and reviewing the
current progress on federated transfer learning, and outlining corresponding
solutions and applications. Furthermore, the common setting of FTL scenarios,
available datasets, and significant related research are summarized in this
survey.</div><div><a href='http://arxiv.org/abs/2403.01387v1'>2403.01387v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15968v2")'>CoDream: Exchanging dreams instead of models for federated aggregation
  with heterogeneous models</div>
<div id='2402.15968v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-25T03:07:32Z</div><div>Authors: Abhishek Singh, Gauri Gupta, Ritvik Kapila, Yichuan Shi, Alex Dang, Sheshank Shankar, Mohammed Ehab, Ramesh Raskar</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) enables collaborative optimization of machine
learning models across decentralized data by aggregating model parameters. Our
approach extends this concept by aggregating "knowledge" derived from models,
instead of model parameters. We present a novel framework called CoDream, where
clients collaboratively optimize randomly initialized data using federated
optimization in the input data space, similar to how randomly initialized model
parameters are optimized in FL. Our key insight is that jointly optimizing this
data can effectively capture the properties of the global data distribution.
Sharing knowledge in data space offers numerous benefits: (1) model-agnostic
collaborative learning, i.e., different clients can have different model
architectures; (2) communication that is independent of the model size,
eliminating scalability concerns with model parameters; (3) compatibility with
secure aggregation, thus preserving the privacy benefits of federated learning;
(4) allowing of adaptive optimization of knowledge shared for personalized
learning. We empirically validate CoDream on standard FL tasks, demonstrating
competitive performance despite not sharing model parameters. Our code:
https://mitmedialab.github.io/codream.github.io/</div><div><a href='http://arxiv.org/abs/2402.15968v2'>2402.15968v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14371v1")'>Loop Improvement: An Efficient Approach for Extracting Shared Features
  from Heterogeneous Data without Central Server</div>
<div id='2403.14371v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T12:59:24Z</div><div>Authors: Fei Li, Chu Kiong Loo, Wei Shiung Liew, Xiaofeng Liu</div><div style='padding-top: 10px; width: 80ex'>In federated learning, data heterogeneity significantly impacts performance.
A typical solution involves segregating these parameters into shared and
personalized components, a concept also relevant in multi-task learning.
Addressing this, we propose "Loop Improvement" (LI), a novel method enhancing
this separation and feature extraction without necessitating a central server
or data interchange among participants. Our experiments reveal LI's superiority
in several aspects: In personalized federated learning environments, LI
consistently outperforms the advanced FedALA algorithm in accuracy across
diverse scenarios. Additionally, LI's feature extractor closely matches the
performance achieved when aggregating data from all clients. In global model
contexts, employing LI with stacked personalized layers and an additional
network also yields comparable results to combined client data scenarios.
Furthermore, LI's adaptability extends to multi-task learning, streamlining the
extraction of common features across tasks and obviating the need for
simultaneous training. This approach not only enhances individual task
performance but also achieves accuracy levels on par with classic multi-task
learning methods where all tasks are trained simultaneously. LI integrates a
loop topology with layer-wise and end-to-end training, compatible with various
neural network models. This paper also delves into the theoretical
underpinnings of LI's effectiveness, offering insights into its potential
applications. The code is on https://github.com/axedge1983/LI</div><div><a href='http://arxiv.org/abs/2403.14371v1'>2403.14371v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.08977v2")'>FedLoGe: Joint Local and Generic Federated Learning under Long-tailed
  Data</div>
<div id='2401.08977v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-17T05:04:33Z</div><div>Authors: Zikai Xiao, Zihan Chen, Liyinglan Liu, Yang Feng, Jian Wu, Wanlu Liu, Joey Tianyi Zhou, Howard Hao Yang, Zuozhu Liu</div><div style='padding-top: 10px; width: 80ex'>Federated Long-Tailed Learning (Fed-LT), a paradigm wherein data collected
from decentralized local clients manifests a globally prevalent long-tailed
distribution, has garnered considerable attention in recent times. In the
context of Fed-LT, existing works have predominantly centered on addressing the
data imbalance issue to enhance the efficacy of the generic global model while
neglecting the performance at the local level. In contrast, conventional
Personalized Federated Learning (pFL) techniques are primarily devised to
optimize personalized local models under the presumption of a balanced global
data distribution. This paper introduces an approach termed Federated Local and
Generic Model Training in Fed-LT (FedLoGe), which enhances both local and
generic model performance through the integration of representation learning
and classifier alignment within a neural collapse framework. Our investigation
reveals the feasibility of employing a shared backbone as a foundational
framework for capturing overarching global trends, while concurrently employing
individualized classifiers to encapsulate distinct refinements stemming from
each client's local features. Building upon this discovery, we establish the
Static Sparse Equiangular Tight Frame Classifier (SSE-C), inspired by neural
collapse principles that naturally prune extraneous noisy features and foster
the acquisition of potent data representations. Furthermore, leveraging
insights from imbalance neural collapse's classifier norm patterns, we develop
Global and Local Adaptive Feature Realignment (GLA-FR) via an auxiliary global
classifier and personalized Euclidean norm transfer to align global features
with client preferences. Extensive experimental results on CIFAR-10/100-LT,
ImageNet, and iNaturalist demonstrate the advantage of our method over
state-of-the-art pFL and Fed-LT approaches.</div><div><a href='http://arxiv.org/abs/2401.08977v2'>2401.08977v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12852v1")'>CCFC++: Enhancing Federated Clustering through Feature Decorrelation</div>
<div id='2402.12852v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T09:31:03Z</div><div>Authors: Jie Yan, Jing Liu, Yi-Zi Ning, Zhong-Yuan Zhang</div><div style='padding-top: 10px; width: 80ex'>In federated clustering, multiple data-holding clients collaboratively group
data without exchanging raw data. This field has seen notable advancements
through its marriage with contrastive learning, exemplified by
Cluster-Contrastive Federated Clustering (CCFC). However, CCFC suffers from
heterogeneous data across clients, leading to poor and unrobust performance.
Our study conducts both empirical and theoretical analyses to understand the
impact of heterogeneous data on CCFC. Findings indicate that increased data
heterogeneity exacerbates dimensional collapse in CCFC, evidenced by increased
correlations across multiple dimensions of the learned representations. To
address this, we introduce a decorrelation regularizer to CCFC. Benefiting from
the regularizer, the improved method effectively mitigates the detrimental
effects of data heterogeneity, and achieves superior performance, as evidenced
by a marked increase in NMI scores, with the gain reaching as high as 0.32 in
the most pronounced case.</div><div><a href='http://arxiv.org/abs/2402.12852v1'>2402.12852v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.06634v1")'>CCFC: Bridging Federated Clustering and Contrastive Learning</div>
<div id='2401.06634v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-12T15:26:44Z</div><div>Authors: Jie Yan, Jing Liu, Zhong-Yuan Zhang</div><div style='padding-top: 10px; width: 80ex'>Federated clustering, an essential extension of centralized clustering for
federated scenarios, enables multiple data-holding clients to collaboratively
group data while keeping their data locally. In centralized scenarios,
clustering driven by representation learning has made significant advancements
in handling high-dimensional complex data. However, the combination of
federated clustering and representation learning remains underexplored. To
bridge this, we first tailor a cluster-contrastive model for learning
clustering-friendly representations. Then, we harness this model as the
foundation for proposing a new federated clustering method, named
cluster-contrastive federated clustering (CCFC). Benefiting from representation
learning, the clustering performance of CCFC even double those of the best
baseline methods in some cases. Compared to the most related baseline, the
benefit results in substantial NMI score improvements of up to 0.4155 on the
most conspicuous case. Moreover, CCFC also shows superior performance in
handling device failures from a practical viewpoint.</div><div><a href='http://arxiv.org/abs/2401.06634v1'>2401.06634v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.18888v2")'>Uncertainty-Based Extensible Codebook for Discrete Federated Learning in
  Heterogeneous Data Silos</div>
<div id='2402.18888v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T06:13:10Z</div><div>Authors: Tianyi Zhang, Yu Cao, Dianbo Liu</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL), aimed at leveraging vast distributed datasets,
confronts a crucial challenge: the heterogeneity of data across different
silos. While previous studies have explored discrete representations to enhance
model generalization across minor distributional shifts, these approaches often
struggle to adapt to new data silos with significantly divergent distributions.
In response, we have identified that models derived from FL exhibit markedly
increased uncertainty when applied to data silos with unfamiliar distributions.
Consequently, we propose an innovative yet straightforward iterative framework,
termed Uncertainty-Based Extensible-Codebook Federated Learning (UEFL). This
framework dynamically maps latent features to trainable discrete vectors,
assesses the uncertainty, and specifically extends the discretization
dictionary or codebook for silos exhibiting high uncertainty. Our approach aims
to simultaneously enhance accuracy and reduce uncertainty by explicitly
addressing the diversity of data distributions, all while maintaining minimal
computational overhead in environments characterized by heterogeneous data
silos. Through experiments conducted on five datasets, our method has
demonstrated its superiority, achieving significant improvements in accuracy
(by 3%--22.1%) and uncertainty reduction (by 38.83%--96.24%), thereby
outperforming contemporary state-of-the-art methods. The source code is
available at https://github.com/destiny301/uefl.</div><div><a href='http://arxiv.org/abs/2402.18888v2'>2402.18888v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.09048v1")'>Taming Cross-Domain Representation Variance in Federated Prototype
  Learning with Heterogeneous Data Domains</div>
<div id='2403.09048v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T02:36:16Z</div><div>Authors: Lei Wang, Jieming Bian, Letian Zhang, Chen Chen, Jie Xu</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) allows collaborative machine learning training
without sharing private data. While most FL methods assume identical data
domains across clients, real-world scenarios often involve heterogeneous data
domains. Federated Prototype Learning (FedPL) addresses this issue, using mean
feature vectors as prototypes to enhance model generalization. However,
existing FedPL methods create the same number of prototypes for each client,
leading to cross-domain performance gaps and disparities for clients with
varied data distributions. To mitigate cross-domain feature representation
variance, we introduce FedPLVM, which establishes variance-aware dual-level
prototypes clustering and employs a novel $\alpha$-sparsity prototype loss. The
dual-level prototypes clustering strategy creates local clustered prototypes
based on private data features, then performs global prototypes clustering to
reduce communication complexity and preserve local data privacy. The
$\alpha$-sparsity prototype loss aligns samples from underrepresented domains,
enhancing intra-class similarity and reducing inter-class similarity.
Evaluations on Digit-5, Office-10, and DomainNet datasets demonstrate our
method's superiority over existing approaches.</div><div><a href='http://arxiv.org/abs/2403.09048v1'>2403.09048v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.03230v1")'>FedTGP: Trainable Global Prototypes with Adaptive-Margin-Enhanced
  Contrastive Learning for Data and Model Heterogeneity in Federated Learning</div>
<div id='2401.03230v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-06T14:43:47Z</div><div>Authors: Jianqing Zhang, Yang Liu, Yang Hua, Jian Cao</div><div style='padding-top: 10px; width: 80ex'>Recently, Heterogeneous Federated Learning (HtFL) has attracted attention due
to its ability to support heterogeneous models and data. To reduce the high
communication cost of transmitting model parameters, a major challenge in HtFL,
prototype-based HtFL methods are proposed to solely share class
representatives, a.k.a, prototypes, among heterogeneous clients while
maintaining the privacy of clients' models. However, these prototypes are
naively aggregated into global prototypes on the server using weighted
averaging, resulting in suboptimal global knowledge which negatively impacts
the performance of clients. To overcome this challenge, we introduce a novel
HtFL approach called FedTGP, which leverages our Adaptive-margin-enhanced
Contrastive Learning (ACL) to learn Trainable Global Prototypes (TGP) on the
server. By incorporating ACL, our approach enhances prototype separability
while preserving semantic meaning. Extensive experiments with twelve
heterogeneous models demonstrate that our FedTGP surpasses state-of-the-art
methods by up to 9.08% in accuracy while maintaining the communication and
privacy advantages of prototype-based HtFL. Our code is available at
https://github.com/TsingZ0/FedTGP.</div><div><a href='http://arxiv.org/abs/2401.03230v1'>2401.03230v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.07558v1")'>FedRFQ: Prototype-Based Federated Learning with Reduced Redundancy,
  Minimal Failure, and Enhanced Quality</div>
<div id='2401.07558v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T09:50:27Z</div><div>Authors: Biwei Yan, Hongliang Zhang, Minghui Xu, Dongxiao Yu, Xiuzhen Cheng</div><div style='padding-top: 10px; width: 80ex'>Federated learning is a powerful technique that enables collaborative
learning among different clients. Prototype-based federated learning is a
specific approach that improves the performance of local models under non-IID
(non-Independently and Identically Distributed) settings by integrating class
prototypes. However, prototype-based federated learning faces several
challenges, such as prototype redundancy and prototype failure, which limit its
accuracy. It is also susceptible to poisoning attacks and server malfunctions,
which can degrade the prototype quality. To address these issues, we propose
FedRFQ, a prototype-based federated learning approach that aims to reduce
redundancy, minimize failures, and improve \underline{q}uality. FedRFQ
leverages a SoftPool mechanism, which effectively mitigates prototype
redundancy and prototype failure on non-IID data. Furthermore, we introduce the
BFT-detect, a BFT (Byzantine Fault Tolerance) detectable aggregation algorithm,
to ensure the security of FedRFQ against poisoning attacks and server
malfunctions. Finally, we conduct experiments on three different datasets,
namely MNIST, FEMNIST, and CIFAR-10, and the results demonstrate that FedRFQ
outperforms existing baselines in terms of accuracy when handling non-IID data.</div><div><a href='http://arxiv.org/abs/2401.07558v1'>2401.07558v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.06432v2")'>Heterogeneous LoRA for Federated Fine-tuning of On-Device Foundation
  Models</div>
<div id='2401.06432v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-12T07:52:07Z</div><div>Authors: Yae Jee Cho, Luyang Liu, Zheng Xu, Aldi Fahrezi, Gauri Joshi</div><div style='padding-top: 10px; width: 80ex'>Foundation models (FMs) adapt well to specific domains or tasks with
fine-tuning, and federated learning (FL) enables the potential for
privacy-preserving fine-tuning of the FMs with on-device local data. For
federated fine-tuning of FMs, we consider the FMs with small to medium
parameter sizes of single digit billion at maximum, referred to as on-device
FMs (ODFMs) that can be deployed on devices for inference but can only be
fine-tuned with parameter efficient methods. In our work, we tackle the data
and system heterogeneity problem of federated fine-tuning of ODFMs by proposing
a novel method using heterogeneous low-rank approximations (LoRAs), namely
HetLoRA. First, we show that the naive approach of using homogeneous LoRA ranks
across devices face a trade-off between overfitting and slow convergence, and
thus propose HetLoRA, which allows heterogeneous ranks across client devices
and efficiently aggregates and distributes these heterogeneous LoRA modules. By
applying rank self-pruning locally and sparsity-weighted aggregation at the
server, HetLoRA combines the advantages of high and low-rank LoRAs, which
achieves improved convergence speed and final performance compared to
homogeneous LoRA. Furthermore, HetLoRA offers enhanced computation efficiency
compared to full fine-tuning, making it suitable for federated fine-tuning
across heterogeneous devices.</div><div><a href='http://arxiv.org/abs/2401.06432v2'>2401.06432v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.18372v2")'>FedUV: Uniformity and Variance for Heterogeneous Federated Learning</div>
<div id='2402.18372v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T15:53:15Z</div><div>Authors: Ha Min Son, Moon-Hyun Kim, Tai-Myoung Chung, Chao Huang, Xin Liu</div><div style='padding-top: 10px; width: 80ex'>Federated learning is a promising framework to train neural networks with
widely distributed data. However, performance degrades heavily with
heterogeneously distributed data. Recent work has shown this is due to the
final layer of the network being most prone to local bias, some finding success
freezing the final layer as an orthogonal classifier. We investigate the
training dynamics of the classifier by applying SVD to the weights motivated by
the observation that freezing weights results in constant singular values. We
find that there are differences when training in IID and non-IID settings.
Based on this finding, we introduce two regularization terms for local training
to continuously emulate IID settings: (1) variance in the dimension-wise
probability distribution of the classifier and (2) hyperspherical uniformity of
representations of the encoder. These regularizations promote local models to
act as if it were in an IID setting regardless of the local data distribution,
thus offsetting proneness to bias while being flexible to the data. On
extensive experiments in both label-shift and feature-shift settings, we verify
that our method achieves highest performance by a large margin especially in
highly non-IID cases in addition to being scalable to larger models and
datasets.</div><div><a href='http://arxiv.org/abs/2402.18372v2'>2402.18372v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.02347v1")'>On the Convergence of Federated Learning Algorithms without Data
  Similarity</div>
<div id='2403.02347v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T23:20:19Z</div><div>Authors: Ali Beikmohammadi, Sarit Khirirat, Sindri Magnússon</div><div style='padding-top: 10px; width: 80ex'>Data similarity assumptions have traditionally been relied upon to understand
the convergence behaviors of federated learning methods. Unfortunately, this
approach often demands fine-tuning step sizes based on the level of data
similarity. When data similarity is low, these small step sizes result in an
unacceptably slow convergence speed for federated methods. In this paper, we
present a novel and unified framework for analyzing the convergence of
federated learning algorithms without the need for data similarity conditions.
Our analysis centers on an inequality that captures the influence of step sizes
on algorithmic convergence performance. By applying our theorems to well-known
federated algorithms, we derive precise expressions for three widely used step
size schedules: fixed, diminishing, and step-decay step sizes, which are
independent of data similarity conditions. Finally, we conduct comprehensive
evaluations of the performance of these federated learning algorithms,
employing the proposed step size strategies to train deep neural network models
on benchmark datasets under varying data similarity conditions. Our findings
demonstrate significant improvements in convergence speed and overall
performance, marking a substantial advancement in federated learning research.</div><div><a href='http://arxiv.org/abs/2403.02347v1'>2403.02347v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12945v1")'>Stochastic Approximation Approach to Federated Machine Learning</div>
<div id='2402.12945v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T12:00:25Z</div><div>Authors: Srihari P V, Bharath Bhikkaji</div><div style='padding-top: 10px; width: 80ex'>This paper examines Federated learning (FL) in a Stochastic Approximation
(SA) framework. FL is a collaborative way to train neural network models across
various participants or clients without centralizing their data. Each client
will train a model on their respective data and send the weights across to a
the server periodically for aggregation. The server aggregates these weights
which are then used by the clients to re-initialize their neural network and
continue the training. SA is an iterative algorithm that uses approximate
sample gradients and tapering step size to locate a minimizer of a cost
function. In this paper the clients use a stochastic approximation iterate to
update the weights of its neural network. It is shown that the aggregated
weights track an autonomous ODE. Numerical simulations are performed and the
results are compared with standard algorithms like FedAvg and FedProx. It is
observed that the proposed algorithm is robust and gives more reliable
estimates of the weights, in particular when the clients data are not
identically distributed.</div><div><a href='http://arxiv.org/abs/2402.12945v1'>2402.12945v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.15263v1")'>Federated Bayesian Deep Learning: The Application of Statistical
  Aggregation Methods to Bayesian Models</div>
<div id='2403.15263v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-22T15:02:24Z</div><div>Authors: John Fischer, Marko Orescanin, Justin Loomis, Patrick McClure</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) is an approach to training machine learning models
that takes advantage of multiple distributed datasets while maintaining data
privacy and reducing communication costs associated with sharing local
datasets. Aggregation strategies have been developed to pool or fuse the
weights and biases of distributed deterministic models; however, modern
deterministic deep learning (DL) models are often poorly calibrated and lack
the ability to communicate a measure of epistemic uncertainty in prediction,
which is desirable for remote sensing platforms and safety-critical
applications. Conversely, Bayesian DL models are often well calibrated and
capable of quantifying and communicating a measure of epistemic uncertainty
along with a competitive prediction accuracy. Unfortunately, because the
weights and biases in Bayesian DL models are defined by a probability
distribution, simple application of the aggregation methods associated with FL
schemes for deterministic models is either impossible or results in sub-optimal
performance. In this work, we use independent and identically distributed (IID)
and non-IID partitions of the CIFAR-10 dataset and a fully variational
ResNet-20 architecture to analyze six different aggregation strategies for
Bayesian DL models. Additionally, we analyze the traditional federated
averaging approach applied to an approximate Bayesian Monte Carlo dropout model
as a lightweight alternative to more complex variational inference methods in
FL. We show that aggregation strategy is a key hyperparameter in the design of
a Bayesian FL system with downstream effects on accuracy, calibration,
uncertainty quantification, training stability, and client compute
requirements.</div><div><a href='http://arxiv.org/abs/2403.15263v1'>2403.15263v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03871v1")'>Decoupled Vertical Federated Learning for Practical Training on
  Vertically Partitioned Data</div>
<div id='2403.03871v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T17:23:28Z</div><div>Authors: Avi Amalanshu, Yash Sirvi, David I. Inouye</div><div style='padding-top: 10px; width: 80ex'>Vertical Federated Learning (VFL) is an emergent distributed machine learning
paradigm wherein owners of disjoint features of a common set of entities
collaborate to learn a global model without sharing data. In VFL, a host client
owns data labels for each entity and learns a final representation based on
intermediate local representations from all guest clients. Therefore, the host
is a single point of failure and label feedback can be used by malicious guest
clients to infer private features. Requiring all participants to remain active
and trustworthy throughout the entire training process is generally impractical
and altogether infeasible outside of controlled environments. We propose
Decoupled VFL (DVFL), a blockwise learning approach to VFL. By training each
model on its own objective, DVFL allows for decentralized aggregation and
isolation between feature learning and label supervision. With these
properties, DVFL is fault tolerant and secure. We implement DVFL to train split
neural networks and show that model performance is comparable to VFL on a
variety of classification datasets.</div><div><a href='http://arxiv.org/abs/2403.03871v1'>2403.03871v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.14598v1")'>Brain-inspired Distributed Memorization Learning for Efficient
  Feature-free Unsupervised Domain Adaptation</div>
<div id='2402.14598v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-04T09:58:17Z</div><div>Authors: Jianming Lv, Depin Liang, Zequan Liang, Yaobin Zhang, Sijun Xia</div><div style='padding-top: 10px; width: 80ex'>Compared with gradient based artificial neural networks, biological neural
networks usually show a more powerful generalization ability to quickly adapt
to unknown environments without using any gradient back-propagation procedure.
Inspired by the distributed memory mechanism of human brains, we propose a
novel gradient-free Distributed Memorization Learning mechanism, namely DML, to
support quick domain adaptation of transferred models. In particular, DML
adopts randomly connected neurons to memorize the association of input signals,
which are propagated as impulses, and makes the final decision by associating
the distributed memories based on their confidence. More importantly, DML is
able to perform reinforced memorization based on unlabeled data to quickly
adapt to a new domain without heavy fine-tuning of deep features, which makes
it very suitable for deploying on edge devices. Experiments based on four
cross-domain real-world datasets show that DML can achieve superior performance
of real-time domain adaptation compared with traditional gradient based MLP
with more than 10% improvement of accuracy while reducing 87% of the timing
cost of optimization.</div><div><a href='http://arxiv.org/abs/2402.14598v1'>2402.14598v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.01350v3")'>pFedMoE: Data-Level Personalization with Mixture of Experts for
  Model-Heterogeneous Personalized Federated Learning</div>
<div id='2402.01350v3' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T12:09:20Z</div><div>Authors: Liping Yi, Han Yu, Chao Ren, Heng Zhang, Gang Wang, Xiaoguang Liu, Xiaoxiao Li</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) has been widely adopted for collaborative training on
decentralized data. However, it faces the challenges of data, system, and model
heterogeneity. This has inspired the emergence of model-heterogeneous
personalized federated learning (MHPFL). Nevertheless, the problem of ensuring
data and model privacy, while achieving good model performance and keeping
communication and computation costs low remains open in MHPFL. To address this
problem, we propose a model-heterogeneous personalized Federated learning with
Mixture of Experts (pFedMoE) method. It assigns a shared homogeneous small
feature extractor and a local gating network for each client's local
heterogeneous large model. Firstly, during local training, the local
heterogeneous model's feature extractor acts as a local expert for personalized
feature (representation) extraction, while the shared homogeneous small feature
extractor serves as a global expert for generalized feature extraction. The
local gating network produces personalized weights for extracted
representations from both experts on each data sample. The three models form a
local heterogeneous MoE. The weighted mixed representation fuses generalized
and personalized features and is processed by the local heterogeneous large
model's header with personalized prediction information. The MoE and prediction
header are updated simultaneously. Secondly, the trained local homogeneous
small feature extractors are sent to the server for cross-client information
fusion via aggregation. Overall, pFedMoE enhances local model personalization
at a fine-grained data level, while supporting model heterogeneity.</div><div><a href='http://arxiv.org/abs/2402.01350v3'>2402.01350v3</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01070v1")'>FedShift: Tackling Dual Heterogeneity Problem of Federated Learning via
  Weight Shift Aggregation</div>
<div id='2402.01070v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T00:03:51Z</div><div>Authors: Jungwon Seo, Chunming Rong, Minhoe Kim</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) offers a compelling method for training machine
learning models with a focus on preserving data privacy. The presence of system
heterogeneity and statistical heterogeneity, recognized challenges in FL,
arises from the diversity of client hardware, network, and dataset
distribution. This diversity can critically affect the training pace and the
performance of models. While many studies address either system or statistical
heterogeneity by introducing communication-efficient or stable convergence
algorithms, addressing these challenges in isolation often leads to compromises
due to unaddressed heterogeneity. In response, this paper introduces FedShift,
a novel algorithm designed to enhance both the training speed and the models'
accuracy in a dual heterogeneity scenario. Our solution can improve client
engagement through quantization and mitigate the adverse effects on performance
typically associated with quantization by employing a shifting technique. This
technique has proven to enhance accuracy by an average of 3.9% in diverse
heterogeneity environments.</div><div><a href='http://arxiv.org/abs/2402.01070v1'>2402.01070v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.09904v1")'>FedComLoc: Communication-Efficient Distributed Training of Sparse and
  Quantized Models</div>
<div id='2403.09904v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T22:29:59Z</div><div>Authors: Kai Yi, Georg Meinhardt, Laurent Condat, Peter Richtárik</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) has garnered increasing attention due to its unique
characteristic of allowing heterogeneous clients to process their private data
locally and interact with a central server, while being respectful of privacy.
A critical bottleneck in FL is the communication cost. A pivotal strategy to
mitigate this burden is \emph{Local Training}, which involves running multiple
local stochastic gradient descent iterations between communication phases. Our
work is inspired by the innovative \emph{Scaffnew} algorithm, which has
considerably advanced the reduction of communication complexity in FL. We
introduce FedComLoc (Federated Compressed and Local Training), integrating
practical and effective compression into \emph{Scaffnew} to further enhance
communication efficiency. Extensive experiments, using the popular TopK
compressor and quantization, demonstrate its prowess in substantially reducing
communication overheads in heterogeneous settings.</div><div><a href='http://arxiv.org/abs/2403.09904v1'>2403.09904v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04348v1")'>LoCoDL: Communication-Efficient Distributed Learning with Local Training
  and Compression</div>
<div id='2403.04348v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T09:22:50Z</div><div>Authors: Laurent Condat, Artavazd Maranjyan, Peter Richtárik</div><div style='padding-top: 10px; width: 80ex'>In Distributed optimization and Learning, and even more in the modern
framework of federated learning, communication, which is slow and costly, is
critical. We introduce LoCoDL, a communication-efficient algorithm that
leverages the two popular and effective techniques of Local training, which
reduces the communication frequency, and Compression, in which short bitstreams
are sent instead of full-dimensional vectors of floats. LoCoDL works with a
large class of unbiased compressors that includes widely-used sparsification
and quantization methods. LoCoDL provably benefits from local training and
compression and enjoys a doubly-accelerated communication complexity, with
respect to the condition number of the functions and the model dimension, in
the general heterogenous regime with strongly convex functions. This is
confirmed in practice, with LoCoDL outperforming existing algorithms.</div><div><a href='http://arxiv.org/abs/2403.04348v1'>2403.04348v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.10774v1")'>Error Feedback Reloaded: From Quadratic to Arithmetic Mean of Smoothness
  Constants</div>
<div id='2402.10774v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-16T15:55:59Z</div><div>Authors: Peter Richtárik, Elnur Gasanov, Konstantin Burlachenko</div><div style='padding-top: 10px; width: 80ex'>Error Feedback (EF) is a highly popular and immensely effective mechanism for
fixing convergence issues which arise in distributed training methods (such as
distributed GD or SGD) when these are enhanced with greedy communication
compression techniques such as TopK. While EF was proposed almost a decade ago
(Seide et al., 2014), and despite concentrated effort by the community to
advance the theoretical understanding of this mechanism, there is still a lot
to explore. In this work we study a modern form of error feedback called EF21
(Richtarik et al., 2021) which offers the currently best-known theoretical
guarantees, under the weakest assumptions, and also works well in practice. In
particular, while the theoretical communication complexity of EF21 depends on
the quadratic mean of certain smoothness parameters, we improve this dependence
to their arithmetic mean, which is always smaller, and can be substantially
smaller, especially in heterogeneous data regimes. We take the reader on a
journey of our discovery process. Starting with the idea of applying EF21 to an
equivalent reformulation of the underlying problem which (unfortunately)
requires (often impractical) machine cloning, we continue to the discovery of a
new weighted version of EF21 which can (fortunately) be executed without any
cloning, and finally circle back to an improved analysis of the original EF21
method. While this development applies to the simplest form of EF21, our
approach naturally extends to more elaborate variants involving stochastic
gradients and partial participation. Further, our technique improves the
best-known theory of EF21 in the rare features regime (Richtarik et al., 2023).
Finally, we validate our theoretical findings with suitable experiments.</div><div><a href='http://arxiv.org/abs/2402.10774v1'>2402.10774v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01160v1")'>Truncated Non-Uniform Quantization for Distributed SGD</div>
<div id='2402.01160v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T05:59:48Z</div><div>Authors: Guangfeng Yan, Tan Li, Yuanzhang Xiao, Congduan Li, Linqi Song</div><div style='padding-top: 10px; width: 80ex'>To address the communication bottleneck challenge in distributed learning,
our work introduces a novel two-stage quantization strategy designed to enhance
the communication efficiency of distributed Stochastic Gradient Descent (SGD).
The proposed method initially employs truncation to mitigate the impact of
long-tail noise, followed by a non-uniform quantization of the post-truncation
gradients based on their statistical characteristics. We provide a
comprehensive convergence analysis of the quantized distributed SGD,
establishing theoretical guarantees for its performance. Furthermore, by
minimizing the convergence error, we derive optimal closed-form solutions for
the truncation threshold and non-uniform quantization levels under given
communication constraints. Both theoretical insights and extensive experimental
evaluations demonstrate that our proposed algorithm outperforms existing
quantization schemes, striking a superior balance between communication
efficiency and convergence performance.</div><div><a href='http://arxiv.org/abs/2402.01160v1'>2402.01160v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01798v1")'>Improved Quantization Strategies for Managing Heavy-tailed Gradients in
  Distributed Learning</div>
<div id='2402.01798v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T06:14:31Z</div><div>Authors: Guangfeng Yan, Tan Li, Yuanzhang Xiao, Hanxu Hou, Linqi Song</div><div style='padding-top: 10px; width: 80ex'>Gradient compression has surfaced as a key technique to address the challenge
of communication efficiency in distributed learning. In distributed deep
learning, however, it is observed that gradient distributions are heavy-tailed,
with outliers significantly influencing the design of compression strategies.
Existing parameter quantization methods experience performance degradation when
this heavy-tailed feature is ignored. In this paper, we introduce a novel
compression scheme specifically engineered for heavy-tailed gradients, which
effectively combines gradient truncation with quantization. This scheme is
adeptly implemented within a communication-limited distributed Stochastic
Gradient Descent (SGD) framework. We consider a general family of heavy-tail
gradients that follow a power-law distribution, we aim to minimize the error
resulting from quantization, thereby determining optimal values for two
critical parameters: the truncation threshold and the quantization density. We
provide a theoretical analysis on the convergence error bound under both
uniform and non-uniform quantization scenarios. Comparative experiments with
other benchmarks demonstrate the effectiveness of our proposed method in
managing the heavy-tailed gradients in a distributed learning environment.</div><div><a href='http://arxiv.org/abs/2402.01798v1'>2402.01798v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.11857v1")'>Communication-Efficient Distributed Learning with Local Immediate Error
  Compensation</div>
<div id='2402.11857v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-19T05:59:09Z</div><div>Authors: Yifei Cheng, Li Shen, Linli Xu, Xun Qian, Shiwei Wu, Yiming Zhou, Tie Zhang, Dacheng Tao, Enhong Chen</div><div style='padding-top: 10px; width: 80ex'>Gradient compression with error compensation has attracted significant
attention with the target of reducing the heavy communication overhead in
distributed learning. However, existing compression methods either perform only
unidirectional compression in one iteration with higher communication cost, or
bidirectional compression with slower convergence rate. In this work, we
propose the Local Immediate Error Compensated SGD (LIEC-SGD) optimization
algorithm to break the above bottlenecks based on bidirectional compression and
carefully designed compensation approaches. Specifically, the bidirectional
compression technique is to reduce the communication cost, and the compensation
technique compensates the local compression error to the model update
immediately while only maintaining the global error variable on the server
throughout the iterations to boost its efficacy. Theoretically, we prove that
LIEC-SGD is superior to previous works in either the convergence rate or the
communication cost, which indicates that LIEC-SGD could inherit the dual
advantages from unidirectional compression and bidirectional compression.
Finally, experiments of training deep neural networks validate the
effectiveness of the proposed LIEC-SGD algorithm.</div><div><a href='http://arxiv.org/abs/2402.11857v1'>2402.11857v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.06677v1")'>Streamlining in the Riemannian Realm: Efficient Riemannian Optimization
  with Loopless Variance Reduction</div>
<div id='2403.06677v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-11T12:49:37Z</div><div>Authors: Yury Demidovich, Grigory Malinovsky, Peter Richtárik</div><div style='padding-top: 10px; width: 80ex'>In this study, we investigate stochastic optimization on Riemannian
manifolds, focusing on the crucial variance reduction mechanism used in both
Euclidean and Riemannian settings. Riemannian variance-reduced methods usually
involve a double-loop structure, computing a full gradient at the start of each
loop. Determining the optimal inner loop length is challenging in practice, as
it depends on strong convexity or smoothness constants, which are often unknown
or hard to estimate. Motivated by Euclidean methods, we introduce the
Riemannian Loopless SVRG (R-LSVRG) and PAGE (R-PAGE) methods. These methods
replace the outer loop with probabilistic gradient computation triggered by a
coin flip in each iteration, ensuring simpler proofs, efficient hyperparameter
selection, and sharp convergence guarantees. Using R-PAGE as a framework for
non-convex Riemannian optimization, we demonstrate its applicability to various
important settings. For example, we derive Riemannian MARINA (R-MARINA) for
distributed settings with communication compression, providing the best
theoretical communication complexity guarantees for non-convex distributed
optimization over Riemannian manifolds. Experimental results support our
theoretical findings.</div><div><a href='http://arxiv.org/abs/2403.06677v1'>2403.06677v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.09356v2")'>Swing: Short-cutting Rings for Higher Bandwidth Allreduce</div>
<div id='2401.09356v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-17T17:24:36Z</div><div>Authors: Daniele De Sensi, Tommaso Bonato, David Saam, Torsten Hoefler</div><div style='padding-top: 10px; width: 80ex'>The allreduce collective operation accounts for a significant fraction of the
runtime of workloads running on distributed systems. One factor determining its
performance is the distance between communicating nodes, especially on networks
like torus, where a higher distance implies multiple messages being forwarded
on the same link, thus reducing the allreduce bandwidth. Torus networks are
widely used on systems optimized for machine learning workloads (e.g., Google
TPUs and Amazon Trainium devices), as well as on some of the Top500
supercomputers. To improve allreduce performance on torus networks we introduce
Swing, a new algorithm that keeps a low distance between communicating nodes by
swinging between torus directions. Our analysis and experimental evaluation
show that Swing outperforms by up to 3x existing allreduce algorithms for
vectors ranging from 32B to 128MiB, on different types of torus and torus-like
topologies, regardless of their shape and size.</div><div><a href='http://arxiv.org/abs/2401.09356v2'>2401.09356v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.05518v1")'>Correlated Quantization for Faster Nonconvex Distributed Optimization</div>
<div id='2401.05518v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-10T19:29:17Z</div><div>Authors: Andrei Panferov, Yury Demidovich, Ahmad Rammal, Peter Richtárik</div><div style='padding-top: 10px; width: 80ex'>Quantization (Alistarh et al., 2017) is an important (stochastic) compression
technique that reduces the volume of transmitted bits during each communication
round in distributed model training. Suresh et al. (2022) introduce correlated
quantizers and show their advantages over independent counterparts by analyzing
distributed SGD communication complexity. We analyze the forefront distributed
non-convex optimization algorithm MARINA (Gorbunov et al., 2022) utilizing the
proposed correlated quantizers and show that it outperforms the original MARINA
and distributed SGD of Suresh et al. (2022) with regard to the communication
complexity. We significantly refine the original analysis of MARINA without any
additional assumptions using the weighted Hessian variance (Tyurin et al.,
2022), and then we expand the theoretical framework of MARINA to accommodate a
substantially broader range of potentially correlated and biased compressors,
thus dilating the applicability of the method beyond the conventional
independent unbiased compressor setup. Extensive experimental results
corroborate our theoretical findings.</div><div><a href='http://arxiv.org/abs/2401.05518v1'>2401.05518v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.10423v1")'>Quantization Avoids Saddle Points in Distributed Optimization</div>
<div id='2403.10423v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-15T15:58:20Z</div><div>Authors: Yanan Bo, Yongqiang Wang</div><div style='padding-top: 10px; width: 80ex'>Distributed nonconvex optimization underpins key functionalities of numerous
distributed systems, ranging from power systems, smart buildings, cooperative
robots, vehicle networks to sensor networks. Recently, it has also merged as a
promising solution to handle the enormous growth in data and model sizes in
deep learning. A fundamental problem in distributed nonconvex optimization is
avoiding convergence to saddle points, which significantly degrade optimization
accuracy. We discover that the process of quantization, which is necessary for
all digital communications, can be exploited to enable saddle-point avoidance.
More specifically, we propose a stochastic quantization scheme and prove that
it can effectively escape saddle points and ensure convergence to a
second-order stationary point in distributed nonconvex optimization. With an
easily adjustable quantization granularity, the approach allows a user to
control the number of bits sent per iteration and, hence, to aggressively
reduce the communication overhead. Numerical experimental results using
distributed optimization and learning problems on benchmark datasets confirm
the effectiveness of the approach.</div><div><a href='http://arxiv.org/abs/2403.10423v1'>2403.10423v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14716v1")'>Distributed Learning based on 1-Bit Gradient Coding in the Presence of
  Stragglers</div>
<div id='2403.14716v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-19T06:48:40Z</div><div>Authors: Chengxi Li, Mikael Skoglund</div><div style='padding-top: 10px; width: 80ex'>This paper considers the problem of distributed learning (DL) in the presence
of stragglers. For this problem, DL methods based on gradient coding have been
widely investigated, which redundantly distribute the training data to the
workers to guarantee convergence when some workers are stragglers. However,
these methods require the workers to transmit real-valued vectors during the
process of learning, which induces very high communication burden. To overcome
this drawback, we propose a novel DL method based on 1-bit gradient coding
(1-bit GCDL), where 1-bit data encoded from the locally computed gradients are
transmitted by the workers to reduce the communication overhead. We
theoretically provide the convergence guarantees of the proposed method for
both the convex loss functions and nonconvex loss functions. It is shown
empirically that 1-bit GC-DL outperforms the baseline methods, which attains
better learning performance under the same communication overhead.</div><div><a href='http://arxiv.org/abs/2403.14716v1'>2403.14716v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01340v1")'>SignSGD with Federated Defense: Harnessing Adversarial Attacks through
  Gradient Sign Decoding</div>
<div id='2402.01340v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T11:53:27Z</div><div>Authors: Chanho Park, Namyoon Lee</div><div style='padding-top: 10px; width: 80ex'>Distributed learning is an effective approach to accelerate model training
using multiple workers. However, substantial communication delays emerge
between workers and a parameter server due to massive costs associated with
communicating gradients. SignSGD with majority voting (signSGD-MV) is a simple
yet effective optimizer that reduces communication costs through one-bit
quantization, yet the convergence rates considerably decrease as adversarial
workers increase. In this paper, we show that the convergence rate is invariant
as the number of adversarial workers increases, provided that the number of
adversarial workers is smaller than that of benign workers. The key idea
showing this counter-intuitive result is our novel signSGD with federated
defense (signSGD-FD). Unlike the traditional approaches, signSGD-FD exploits
the gradient information sent by adversarial workers with the proper weights,
which are obtained through gradient sign decoding. Experimental results
demonstrate signSGD-FD achieves superior convergence rates over traditional
algorithms in various adversarial attack scenarios.</div><div><a href='http://arxiv.org/abs/2402.01340v1'>2402.01340v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.02951v1")'>Dynamic Byzantine-Robust Learning: Adapting to Switching Byzantine
  Workers</div>
<div id='2402.02951v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T12:26:01Z</div><div>Authors: Ron Dorfman, Naseem Yehya, Kfir Y. Levy</div><div style='padding-top: 10px; width: 80ex'>Byzantine-robust learning has emerged as a prominent fault-tolerant
distributed machine learning framework. However, most techniques consider the
static setting, wherein the identity of Byzantine machines remains fixed during
the learning process. This assumption does not capture real-world dynamic
Byzantine behaviors, which may include transient malfunctions or targeted
temporal attacks. Addressing this limitation, we propose $\textsf{DynaBRO}$ --
a new method capable of withstanding $\mathcal{O}(\sqrt{T})$ rounds of
Byzantine identity alterations (where $T$ is the total number of training
rounds), while matching the asymptotic convergence rate of the static setting.
Our method combines a multi-level Monte Carlo (MLMC) gradient estimation
technique with robust aggregation of worker updates and incorporates a
fail-safe filter to limit bias from dynamic Byzantine strategies. Additionally,
by leveraging an adaptive learning rate, our approach eliminates the need for
knowing the percentage of Byzantine workers.</div><div><a href='http://arxiv.org/abs/2402.02951v1'>2402.02951v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.05895v1")'>Binary Linear Tree Commitment-based Ownership Protection for Distributed
  Machine Learning</div>
<div id='2401.05895v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-11T13:11:24Z</div><div>Authors: Tianxiu Xie, Keke Gai, Jing Yu, Liehuang Zhu</div><div style='padding-top: 10px; width: 80ex'>Distributed machine learning enables parallel training of extensive datasets
by delegating computing tasks across multiple workers. Despite the cost
reduction benefits of distributed machine learning, the dissemination of final
model weights often leads to potential conflicts over model ownership as
workers struggle to substantiate their involvement in the training computation.
To address the above ownership issues and prevent accidental failures and
malicious attacks, verifying the computational integrity and effectiveness of
workers becomes particularly crucial in distributed machine learning. In this
paper, we proposed a novel binary linear tree commitment-based ownership
protection model to ensure computational integrity with limited overhead and
concise proof. Due to the frequent updates of parameters during training, our
commitment scheme introduces a maintainable tree structure to reduce the costs
of updating proofs. Distinguished from SNARK-based verifiable computation, our
model achieves efficient proof aggregation by leveraging inner product
arguments. Furthermore, proofs of model weights are watermarked by worker
identity keys to prevent commitments from being forged or duplicated. The
performance analysis and comparison with SNARK-based hash commitments validate
the efficacy of our model in preserving computational integrity within
distributed machine learning.</div><div><a href='http://arxiv.org/abs/2401.05895v1'>2401.05895v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.09603v2")'>Optimistic Verifiable Training by Controlling Hardware Nondeterminism</div>
<div id='2403.09603v2' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T17:44:35Z</div><div>Authors: Megha Srivastava, Simran Arora, Dan Boneh</div><div style='padding-top: 10px; width: 80ex'>The increasing compute demands of AI systems has led to the emergence of
services that train models on behalf of clients lacking necessary resources.
However, ensuring correctness of training and guarding against potential
training-time attacks, such as data poisoning, poses challenges. Existing works
on verifiable training largely fall into two classes: proof-based systems,
which struggle to scale due to requiring cryptographic techniques, and
"optimistic" methods that consider a trusted third-party auditor who replicates
the training process. A key challenge with the latter is that hardware
nondeterminism between GPU types during training prevents an auditor from
replicating the training process exactly, and such schemes are therefore
non-robust. We propose a method that combines training in a higher precision
than the target model, rounding after intermediate computation steps, and
storing rounding decisions based on an adaptive thresholding procedure, to
successfully control for nondeterminism. Across three different NVIDIA GPUs
(A40, Titan XP, RTX 2080 Ti), we achieve exact training replication at FP32
precision for both full-training and fine-tuning of ResNet-50 (23M) and GPT-2
(117M) models. Our verifiable training scheme significantly decreases the
storage and time costs compared to proof-based systems.</div><div><a href='http://arxiv.org/abs/2403.09603v2'>2403.09603v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.10816v1")'>TernaryVote: Differentially Private, Communication Efficient, and
  Byzantine Resilient Distributed Optimization on Heterogeneous Data</div>
<div id='2402.10816v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-16T16:41:14Z</div><div>Authors: Richeng Jin, Yujie Gu, Kai Yue, Xiaofan He, Zhaoyang Zhang, Huaiyu Dai</div><div style='padding-top: 10px; width: 80ex'>Distributed training of deep neural networks faces three critical challenges:
privacy preservation, communication efficiency, and robustness to fault and
adversarial behaviors. Although significant research efforts have been devoted
to addressing these challenges independently, their synthesis remains less
explored. In this paper, we propose TernaryVote, which combines a ternary
compressor and the majority vote mechanism to realize differential privacy,
gradient compression, and Byzantine resilience simultaneously. We theoretically
quantify the privacy guarantee through the lens of the emerging f-differential
privacy (DP) and the Byzantine resilience of the proposed algorithm.
Particularly, in terms of privacy guarantees, compared to the existing
sign-based approach StoSign, the proposed method improves the dimension
dependence on the gradient size and enjoys privacy amplification by mini-batch
sampling while ensuring a comparable convergence rate. We also prove that
TernaryVote is robust when less than 50% of workers are blind attackers, which
matches that of SIGNSGD with majority vote. Extensive experimental results
validate the effectiveness of the proposed algorithm.</div><div><a href='http://arxiv.org/abs/2402.10816v1'>2402.10816v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16687v1")'>Revisiting Gradient Pruning: A Dual Realization for Defending against
  Gradient Attacks</div>
<div id='2401.16687v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T02:18:30Z</div><div>Authors: Lulu Xue, Shengshan Hu, Ruizhi Zhao, Leo Yu Zhang, Shengqing Hu, Lichao Sun, Dezhong Yao</div><div style='padding-top: 10px; width: 80ex'>Collaborative learning (CL) is a distributed learning framework that aims to
protect user privacy by allowing users to jointly train a model by sharing
their gradient updates only. However, gradient inversion attacks (GIAs), which
recover users' training data from shared gradients, impose severe privacy
threats to CL. Existing defense methods adopt different techniques, e.g.,
differential privacy, cryptography, and perturbation defenses, to defend
against the GIAs. Nevertheless, all current defense methods suffer from a poor
trade-off between privacy, utility, and efficiency. To mitigate the weaknesses
of existing solutions, we propose a novel defense method, Dual Gradient Pruning
(DGP), based on gradient pruning, which can improve communication efficiency
while preserving the utility and privacy of CL. Specifically, DGP slightly
changes gradient pruning with a stronger privacy guarantee. And DGP can also
significantly improve communication efficiency with a theoretical analysis of
its convergence and generalization. Our extensive experiments show that DGP can
effectively defend against the most powerful GIAs and reduce the communication
cost without sacrificing the model's utility.</div><div><a href='http://arxiv.org/abs/2401.16687v1'>2401.16687v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09478v1")'>Data Reconstruction Attacks and Defenses: A Systematic Evaluation</div>
<div id='2402.09478v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T05:06:34Z</div><div>Authors: Sheng Liu, Zihan Wang, Qi Lei</div><div style='padding-top: 10px; width: 80ex'>Reconstruction attacks and defenses are essential in understanding the data
leakage problem in machine learning. However, prior work has centered around
empirical observations of gradient inversion attacks, lacks theoretical
groundings, and was unable to disentangle the usefulness of defending methods
versus the computational limitation of attacking methods. In this work, we
propose a strong reconstruction attack in the setting of federated learning.
The attack reconstructs intermediate features and nicely integrates with and
outperforms most of the previous methods. On this stronger attack, we
thoroughly investigate both theoretically and empirically the effect of the
most common defense methods. Our findings suggest that among various defense
mechanisms, such as gradient clipping, dropout, additive noise, local
aggregation, etc., gradient pruning emerges as the most effective strategy to
defend against state-of-the-art attacks.</div><div><a href='http://arxiv.org/abs/2402.09478v1'>2402.09478v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12861v1")'>Bounding Reconstruction Attack Success of Adversaries Without Data
  Priors</div>
<div id='2402.12861v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T09:52:30Z</div><div>Authors: Alexander Ziller, Anneliese Riess, Kristian Schwethelm, Tamara T. Mueller, Daniel Rueckert, Georgios Kaissis</div><div style='padding-top: 10px; width: 80ex'>Reconstruction attacks on machine learning (ML) models pose a strong risk of
leakage of sensitive data. In specific contexts, an adversary can (almost)
perfectly reconstruct training data samples from a trained model using the
model's gradients. When training ML models with differential privacy (DP),
formal upper bounds on the success of such reconstruction attacks can be
provided. So far, these bounds have been formulated under worst-case
assumptions that might not hold high realistic practicality. In this work, we
provide formal upper bounds on reconstruction success under realistic
adversarial settings against ML models trained with DP and support these bounds
with empirical results. With this, we show that in realistic scenarios, (a) the
expected reconstruction success can be bounded appropriately in different
contexts and by different metrics, which (b) allows for a more educated choice
of a privacy parameter.</div><div><a href='http://arxiv.org/abs/2402.12861v1'>2402.12861v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.10001v1")'>Privacy Attacks in Decentralized Learning</div>
<div id='2402.10001v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-15T15:06:33Z</div><div>Authors: Abdellah El Mrini, Edwige Cyffers, Aurélien Bellet</div><div style='padding-top: 10px; width: 80ex'>Decentralized Gradient Descent (D-GD) allows a set of users to perform
collaborative learning without sharing their data by iteratively averaging
local model updates with their neighbors in a network graph. The absence of
direct communication between non-neighbor nodes might lead to the belief that
users cannot infer precise information about the data of others. In this work,
we demonstrate the opposite, by proposing the first attack against D-GD that
enables a user (or set of users) to reconstruct the private data of other users
outside their immediate neighborhood. Our approach is based on a reconstruction
attack against the gossip averaging protocol, which we then extend to handle
the additional challenges raised by D-GD. We validate the effectiveness of our
attack on real graphs and datasets, showing that the number of users
compromised by a single or a handful of attackers is often surprisingly large.
We empirically investigate some of the factors that affect the performance of
the attack, namely the graph topology, the number of attackers, and their
position in the graph.</div><div><a href='http://arxiv.org/abs/2402.10001v1'>2402.10001v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07471v1")'>Differentially Private Decentralized Learning with Random Walks</div>
<div id='2402.07471v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-12T08:16:58Z</div><div>Authors: Edwige Cyffers, Aurélien Bellet, Jalaj Upadhyay</div><div style='padding-top: 10px; width: 80ex'>The popularity of federated learning comes from the possibility of better
scalability and the ability for participants to keep control of their data,
improving data security and sovereignty. Unfortunately, sharing model updates
also creates a new privacy attack surface. In this work, we characterize the
privacy guarantees of decentralized learning with random walk algorithms, where
a model is updated by traveling from one node to another along the edges of a
communication graph. Using a recent variant of differential privacy tailored to
the study of decentralized algorithms, namely Pairwise Network Differential
Privacy, we derive closed-form expressions for the privacy loss between each
pair of nodes where the impact of the communication topology is captured by
graph theoretic quantities. Our results further reveal that random walk
algorithms tends to yield better privacy guarantees than gossip algorithms for
nodes close from each other. We supplement our theoretical results with
empirical evaluation on synthetic and real-world graphs and datasets.</div><div><a href='http://arxiv.org/abs/2402.07471v1'>2402.07471v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.00157v1")'>Privacy-Preserving Distributed Optimization and Learning</div>
<div id='2403.00157v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T22:18:05Z</div><div>Authors: Ziqin Chen, Yongqiang Wang</div><div style='padding-top: 10px; width: 80ex'>Distributed optimization and learning has recently garnered great attention
due to its wide applications in sensor networks, smart grids, machine learning,
and so forth. Despite rapid development, existing distributed optimization and
learning algorithms require each agent to exchange messages with its neighbors,
which may expose sensitive information and raise significant privacy concerns.
In this survey paper, we overview privacy-preserving distributed optimization
and learning methods. We first discuss cryptography, differential privacy, and
other techniques that can be used for privacy preservation and indicate their
pros and cons for privacy protection in distributed optimization and learning.
We believe that among these approaches, differential privacy is most promising
due to its low computational and communication complexities, which are
extremely appealing for modern learning based applications with high dimensions
of optimization variables. We then introduce several differential-privacy
algorithms that can simultaneously ensure privacy and optimization accuracy.
Moreover, we provide example applications in several machine learning problems
to confirm the real-world effectiveness of these algorithms. Finally, we
highlight some challenges in this research domain and discuss future
directions.</div><div><a href='http://arxiv.org/abs/2403.00157v1'>2403.00157v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01546v1")'>Privacy-Preserving Distributed Learning for Residential Short-Term Load
  Forecasting</div>
<div id='2402.01546v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T16:39:08Z</div><div>Authors: Yi Dong, Yingjie Wang, Mariana Gama, Mustafa A. Mustafa, Geert Deconinck, Xiaowei Huang</div><div style='padding-top: 10px; width: 80ex'>In the realm of power systems, the increasing involvement of residential
users in load forecasting applications has heightened concerns about data
privacy. Specifically, the load data can inadvertently reveal the daily
routines of residential users, thereby posing a risk to their property
security. While federated learning (FL) has been employed to safeguard user
privacy by enabling model training without the exchange of raw data, these FL
models have shown vulnerabilities to emerging attack techniques, such as Deep
Leakage from Gradients and poisoning attacks. To counteract these, we initially
employ a Secure-Aggregation (SecAgg) algorithm that leverages multiparty
computation cryptographic techniques to mitigate the risk of gradient leakage.
However, the introduction of SecAgg necessitates the deployment of additional
sub-center servers for executing the multiparty computation protocol, thereby
escalating computational complexity and reducing system robustness, especially
in scenarios where one or more sub-centers are unavailable. To address these
challenges, we introduce a Markovian Switching-based distributed training
framework, the convergence of which is substantiated through rigorous
theoretical analysis. The Distributed Markovian Switching (DMS) topology shows
strong robustness towards the poisoning attacks as well. Case studies employing
real-world power system load data validate the efficacy of our proposed
algorithm. It not only significantly minimizes communication complexity but
also maintains accuracy levels comparable to traditional FL methods, thereby
enhancing the scalability of our load forecasting algorithm.</div><div><a href='http://arxiv.org/abs/2402.01546v1'>2402.01546v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.06388v1")'>A Zero Trust Framework for Realization and Defense Against Generative AI
  Attacks in Power Grid</div>
<div id='2403.06388v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-11T02:47:21Z</div><div>Authors: Md. Shirajum Munir, Sravanthi Proddatoori, Manjushree Muralidhara, Walid Saad, Zhu Han, Sachin Shetty</div><div style='padding-top: 10px; width: 80ex'>Understanding the potential of generative AI (GenAI)-based attacks on the
power grid is a fundamental challenge that must be addressed in order to
protect the power grid by realizing and validating risk in new attack vectors.
In this paper, a novel zero trust framework for a power grid supply chain
(PGSC) is proposed. This framework facilitates early detection of potential
GenAI-driven attack vectors (e.g., replay and protocol-type attacks),
assessment of tail risk-based stability measures, and mitigation of such
threats. First, a new zero trust system model of PGSC is designed and
formulated as a zero-trust problem that seeks to guarantee for a stable PGSC by
realizing and defending against GenAI-driven cyber attacks. Second, in which a
domain-specific generative adversarial networks (GAN)-based attack generation
mechanism is developed to create a new vulnerability cyberspace for further
understanding that threat. Third, tail-based risk realization metrics are
developed and implemented for quantifying the extreme risk of a potential
attack while leveraging a trust measurement approach for continuous validation.
Fourth, an ensemble learning-based bootstrap aggregation scheme is devised to
detect the attacks that are generating synthetic identities with convincing
user and distributed energy resources device profiles. Experimental results
show the efficacy of the proposed zero trust framework that achieves an
accuracy of 95.7% on attack vector generation, a risk measure of 9.61% for a
95% stable PGSC, and a 99% confidence in defense against GenAI-driven attack.</div><div><a href='http://arxiv.org/abs/2403.06388v1'>2403.06388v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.02573v1")'>Learning-augmented Online Minimization of Age of Information and
  Transmission Costs</div>
<div id='2403.02573v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-05T01:06:25Z</div><div>Authors: Zhongdong Liu, Keyuan Zhang, Bin Li, Yin Sun, Y. Thomas Hou, Bo Ji</div><div style='padding-top: 10px; width: 80ex'>We consider a discrete-time system where a resource-constrained source (e.g.,
a small sensor) transmits its time-sensitive data to a destination over a
time-varying wireless channel. Each transmission incurs a fixed transmission
cost (e.g., energy cost), and no transmission results in a staleness cost
represented by the Age-of-Information. The source must balance the tradeoff
between transmission and staleness costs. To address this challenge, we develop
a robust online algorithm to minimize the sum of transmission and staleness
costs, ensuring a worst-case performance guarantee. While online algorithms are
robust, they are usually overly conservative and may have a poor average
performance in typical scenarios. In contrast, by leveraging historical data
and prediction models, machine learning (ML) algorithms perform well in average
cases. However, they typically lack worst-case performance guarantees. To
achieve the best of both worlds, we design a learning-augmented online
algorithm that exhibits two desired properties: (i) consistency: closely
approximating the optimal offline algorithm when the ML prediction is accurate
and trusted; (ii) robustness: ensuring worst-case performance guarantee even ML
predictions are inaccurate. Finally, we perform extensive simulations to show
that our online algorithm performs well empirically and that our
learning-augmented algorithm achieves both consistency and robustness.</div><div><a href='http://arxiv.org/abs/2403.02573v1'>2403.02573v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.10265v1")'>The Best Time for an Update: Risk-Sensitive Minimization of Age-Based
  Metrics</div>
<div id='2401.10265v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-03T15:02:40Z</div><div>Authors: Wanja de Sombre, Andrea Ortiz, Frank Aurzada, Anja Klein</div><div style='padding-top: 10px; width: 80ex'>Popular methods to quantify transmitted data quality are the Age of
Information (AoI), the Query Age of Information (QAoI), and the Age of
Incorrect Information (AoII). We consider these metrics in a point-to-point
wireless communication system, where the transmitter monitors a process and
sends status updates to a receiver. The challenge is to decide on the best time
for an update, balancing the transmission energy and the age-based metric at
the receiver. Due to the inherent risk of high age-based metric values causing
complications such as unstable system states, we introduce the new concept of
risky states to denote states with high age-based metric. We use this new
notion of risky states to quantify and minimize this risk of experiencing high
age-based metrics by directly deriving the frequency of risky states as a novel
risk-metric. Building on this foundation, we introduce two risk-sensitive
strategies for AoI, QAoI and AoII. The first strategy uses system knowledge,
i.e., channel quality and packet arrival probability, to find an optimal
strategy that transmits when the age-based metric exceeds a tunable threshold.
A lower threshold leads to higher risk-sensitivity. The second strategy uses an
enhanced Q-learning approach and balances the age-based metric, the
transmission energy and the frequency of risky states without requiring
knowledge about the system. Numerical results affirm our risk-sensitive
strategies' high effectiveness.</div><div><a href='http://arxiv.org/abs/2401.10265v1'>2401.10265v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.02780v1")'>Data Collaboration Analysis Over Matrix Manifolds</div>
<div id='2403.02780v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-05T08:52:16Z</div><div>Authors: Keiyu Nosaka, Akiko Yoshise</div><div style='padding-top: 10px; width: 80ex'>The effectiveness of machine learning (ML) algorithms is deeply intertwined
with the quality and diversity of their training datasets. Improved datasets,
marked by superior quality, enhance the predictive accuracy and broaden the
applicability of models across varied scenarios. Researchers often integrate
data from multiple sources to mitigate biases and limitations of single-source
datasets. However, this extensive data amalgamation raises significant ethical
concerns, particularly regarding user privacy and the risk of unauthorized data
disclosure. Various global legislative frameworks have been established to
address these privacy issues. While crucial for safeguarding privacy, these
regulations can complicate the practical deployment of ML technologies.
Privacy-Preserving Machine Learning (PPML) addresses this challenge by
safeguarding sensitive information, from health records to geolocation data,
while enabling the secure use of this data in developing robust ML models.
Within this realm, the Non-Readily Identifiable Data Collaboration (NRI-DC)
framework emerges as an innovative approach, potentially resolving the 'data
island' issue among institutions through non-iterative communication and robust
privacy protections. However, in its current state, the NRI-DC framework faces
model performance instability due to theoretical unsteadiness in creating
collaboration functions. This study establishes a rigorous theoretical
foundation for these collaboration functions and introduces new formulations
through optimization problems on matrix manifolds and efficient solutions.
Empirical analyses demonstrate that the proposed approach, particularly the
formulation over orthogonal matrix manifolds, significantly enhances
performance, maintaining consistency and efficiency without compromising
communication efficiency or privacy protections.</div><div><a href='http://arxiv.org/abs/2403.02780v1'>2403.02780v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.08156v3")'>Group Decision-Making among Privacy-Aware Agents</div>
<div id='2402.08156v3' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T01:38:01Z</div><div>Authors: Marios Papachristou, M. Amin Rahimian</div><div style='padding-top: 10px; width: 80ex'>How can individuals exchange information to learn from each other despite
their privacy needs and security concerns? For example, consider individuals
deliberating a contentious topic and being concerned about divulging their
private experiences. Preserving individual privacy and enabling efficient
social learning are both important desiderata but seem fundamentally at odds
with each other and very hard to reconcile. We do so by controlling information
leakage using rigorous statistical guarantees that are based on differential
privacy (DP). Our agents use log-linear rules to update their beliefs after
communicating with their neighbors. Adding DP randomization noise to beliefs
provides communicating agents with plausible deniability with regard to their
private information and their network neighborhoods. We consider two learning
environments one for distributed maximum-likelihood estimation given a finite
number of private signals and another for online learning from an infinite,
intermittent signal stream. Noisy information aggregation in the finite case
leads to interesting tradeoffs between rejecting low-quality states and making
sure all high-quality states are accepted in the algorithm output. Our results
flesh out the nature of the trade-offs in both cases between the quality of the
group decision outcomes, learning accuracy, communication cost, and the level
of privacy protections that the agents are afforded.</div><div><a href='http://arxiv.org/abs/2402.08156v3'>2402.08156v3</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.11795v1")'>Low-Cost Privacy-Aware Decentralized Learning</div>
<div id='2403.11795v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-18T13:53:17Z</div><div>Authors: Sayan Biswas, Davide Frey, Romaric Gaudel, Anne-Marie Kermarrec, Dimitri Lerévérend, Rafael Pires, Rishi Sharma, François Taïani</div><div style='padding-top: 10px; width: 80ex'>This paper introduces ZIP-DL, a novel privacy-aware decentralized learning
(DL) algorithm that relies on adding correlated noise to each model update
during the model training process. This technique ensures that the added noise
almost neutralizes itself during the aggregation process due to its
correlation, thus minimizing the impact on model accuracy. In addition, ZIP-DL
does not require multiple communication rounds for noise cancellation,
addressing the common trade-off between privacy protection and communication
overhead. We provide theoretical guarantees for both convergence speed and
privacy guarantees, thereby making ZIP-DL applicable to practical scenarios.
Our extensive experimental study shows that ZIP-DL achieves the best trade-off
between vulnerability and accuracy. In particular, ZIP-DL (i) reduces the
effectiveness of a linkability attack by up to 52 points compared to baseline
DL, and (ii) achieves up to 37 more accuracy points for the same vulnerability
under membership inference attacks against a privacy-preserving competitor</div><div><a href='http://arxiv.org/abs/2403.11795v1'>2403.11795v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.13779v1")'>Faster Convergence with Less Communication: Broadcast-Based Subgraph
  Sampling for Decentralized Learning over Wireless Networks</div>
<div id='2401.13779v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T20:00:23Z</div><div>Authors: Daniel Pérez Herrera, Zheng Chen, Erik G. Larsson</div><div style='padding-top: 10px; width: 80ex'>Consensus-based decentralized stochastic gradient descent (D-SGD) is a widely
adopted algorithm for decentralized training of machine learning models across
networked agents. A crucial part of D-SGD is the consensus-based model
averaging, which heavily relies on information exchange and fusion among the
nodes. Specifically, for consensus averaging over wireless networks,
communication coordination is necessary to determine when and how a node can
access the channel and transmit (or receive) information to (or from) its
neighbors. In this work, we propose $\texttt{BASS}$, a broadcast-based subgraph
sampling method designed to accelerate the convergence of D-SGD while
considering the actual communication cost per iteration. $\texttt{BASS}$
creates a set of mixing matrix candidates that represent sparser subgraphs of
the base topology. In each consensus iteration, one mixing matrix is sampled,
leading to a specific scheduling decision that activates multiple
collision-free subsets of nodes. The sampling occurs in a probabilistic manner,
and the elements of the mixing matrices, along with their sampling
probabilities, are jointly optimized. Simulation results demonstrate that
$\texttt{BASS}$ enables faster convergence with fewer transmission slots
compared to existing link-based scheduling methods. In conclusion, the inherent
broadcasting nature of wireless channels offers intrinsic advantages in
accelerating the convergence of decentralized optimization and learning.</div><div><a href='http://arxiv.org/abs/2401.13779v1'>2401.13779v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.03083v1")'>Energy-efficient Decentralized Learning via Graph Sparsification</div>
<div id='2401.03083v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-05T23:00:38Z</div><div>Authors: Xusheng Zhang, Cho-Chun Chiu, Ting He</div><div style='padding-top: 10px; width: 80ex'>This work aims at improving the energy efficiency of decentralized learning
by optimizing the mixing matrix, which controls the communication demands
during the learning process. Through rigorous analysis based on a
state-of-the-art decentralized learning algorithm, the problem is formulated as
a bi-level optimization, with the lower level solved by graph sparsification. A
solution with guaranteed performance is proposed for the special case of
fully-connected base topology and a greedy heuristic is proposed for the
general case. Simulations based on real topology and dataset show that the
proposed solution can lower the energy consumption at the busiest node by
54%-76% while maintaining the quality of the trained model.</div><div><a href='http://arxiv.org/abs/2401.03083v1'>2401.03083v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.11166v1")'>Pencil: Private and Extensible Collaborative Learning without the
  Non-Colluding Assumption</div>
<div id='2403.11166v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-17T10:26:41Z</div><div>Authors: Xuanqi Liu, Zhuotao Liu, Qi Li, Ke Xu, Mingwei Xu</div><div style='padding-top: 10px; width: 80ex'>The escalating focus on data privacy poses significant challenges for
collaborative neural network training, where data ownership and model
training/deployment responsibilities reside with distinct entities. Our
community has made substantial contributions to addressing this challenge,
proposing various approaches such as federated learning (FL) and
privacy-preserving machine learning based on cryptographic constructs like
homomorphic encryption (HE) and secure multiparty computation (MPC). However,
FL completely overlooks model privacy, and HE has limited extensibility
(confined to only one data provider). While the state-of-the-art MPC frameworks
provide reasonable throughput and simultaneously ensure model/data privacy,
they rely on a critical non-colluding assumption on the computing servers, and
relaxing this assumption is still an open problem.
  In this paper, we present Pencil, the first private training framework for
collaborative learning that simultaneously offers data privacy, model privacy,
and extensibility to multiple data providers, without relying on the
non-colluding assumption. Our fundamental design principle is to construct the
n-party collaborative training protocol based on an efficient two-party
protocol, and meanwhile ensuring that switching to different data providers
during model training introduces no extra cost. We introduce several novel
cryptographic protocols to realize this design principle and conduct a rigorous
security and privacy analysis. Our comprehensive evaluations of Pencil
demonstrate that (i) models trained in plaintext and models trained privately
using Pencil exhibit nearly identical test accuracies; (ii) The training
overhead of Pencil is greatly reduced: Pencil achieves 10 ~ 260x higher
throughput and 2 orders of magnitude less communication than prior art; (iii)
Pencil is resilient against both existing and adaptive (white-box) attacks.</div><div><a href='http://arxiv.org/abs/2403.11166v1'>2403.11166v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14111v1")'>HETAL: Efficient Privacy-preserving Transfer Learning with Homomorphic
  Encryption</div>
<div id='2403.14111v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T03:47:26Z</div><div>Authors: Seewoo Lee, Garam Lee, Jung Woo Kim, Junbum Shin, Mun-Kyu Lee</div><div style='padding-top: 10px; width: 80ex'>Transfer learning is a de facto standard method for efficiently training
machine learning models for data-scarce problems by adding and fine-tuning new
classification layers to a model pre-trained on large datasets. Although
numerous previous studies proposed to use homomorphic encryption to resolve the
data privacy issue in transfer learning in the machine learning as a service
setting, most of them only focused on encrypted inference. In this study, we
present HETAL, an efficient Homomorphic Encryption based Transfer Learning
algorithm, that protects the client's privacy in training tasks by encrypting
the client data using the CKKS homomorphic encryption scheme. HETAL is the
first practical scheme that strictly provides encrypted training, adopting
validation-based early stopping and achieving the accuracy of nonencrypted
training. We propose an efficient encrypted matrix multiplication algorithm,
which is 1.8 to 323 times faster than prior methods, and a highly precise
softmax approximation algorithm with increased coverage. The experimental
results for five well-known benchmark datasets show total training times of
567-3442 seconds, which is less than an hour.</div><div><a href='http://arxiv.org/abs/2403.14111v1'>2403.14111v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09059v1")'>I can't see it but I can Fine-tune it: On Encrypted Fine-tuning of
  Transformers using Fully Homomorphic Encryption</div>
<div id='2402.09059v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T10:15:43Z</div><div>Authors: Prajwal Panzade, Daniel Takabi, Zhipeng Cai</div><div style='padding-top: 10px; width: 80ex'>In today's machine learning landscape, fine-tuning pretrained transformer
models has emerged as an essential technique, particularly in scenarios where
access to task-aligned training data is limited. However, challenges surface
when data sharing encounters obstacles due to stringent privacy regulations or
user apprehension regarding personal information disclosure. Earlier works
based on secure multiparty computation (SMC) and fully homomorphic encryption
(FHE) for privacy-preserving machine learning (PPML) focused more on
privacy-preserving inference than privacy-preserving training. In response, we
introduce BlindTuner, a privacy-preserving fine-tuning system that enables
transformer training exclusively on homomorphically encrypted data for image
classification. Our extensive experimentation validates BlindTuner's
effectiveness by demonstrating comparable accuracy to non-encrypted models.
Notably, our findings highlight a substantial speed enhancement of 1.5x to 600x
over previous work in this domain.</div><div><a href='http://arxiv.org/abs/2402.09059v1'>2402.09059v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.05126v2")'>Efficient Fine-Tuning with Domain Adaptation for Privacy-Preserving
  Vision Transformer</div>
<div id='2401.05126v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-10T12:46:31Z</div><div>Authors: Teru Nagamori, Sayaka Shiota, Hitoshi Kiya</div><div style='padding-top: 10px; width: 80ex'>We propose a novel method for privacy-preserving deep neural networks (DNNs)
with the Vision Transformer (ViT). The method allows us not only to train
models and test with visually protected images but to also avoid the
performance degradation caused from the use of encrypted images, whereas
conventional methods cannot avoid the influence of image encryption. A domain
adaptation method is used to efficiently fine-tune ViT with encrypted images.
In experiments, the method is demonstrated to outperform conventional methods
in an image classification task on the CIFAR-10 and ImageNet datasets in terms
of classification accuracy.</div><div><a href='http://arxiv.org/abs/2401.05126v2'>2401.05126v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01296v1")'>Bi-CryptoNets: Leveraging Different-Level Privacy for Encrypted
  Inference</div>
<div id='2402.01296v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T10:35:05Z</div><div>Authors: Man-Jie Yuan, Zheng Zou, Wei Gao</div><div style='padding-top: 10px; width: 80ex'>Privacy-preserving neural networks have attracted increasing attention in
recent years, and various algorithms have been developed to keep the balance
between accuracy, computational complexity and information security from the
cryptographic view. This work takes a different view from the input data and
structure of neural networks. We decompose the input data (e.g., some images)
into sensitive and insensitive segments according to importance and privacy.
The sensitive segment includes some important and private information such as
human faces and we take strong homomorphic encryption to keep security, whereas
the insensitive one contains some background and we add perturbations. We
propose the bi-CryptoNets, i.e., plaintext and ciphertext branches, to deal
with two segments, respectively, and ciphertext branch could utilize the
information from plaintext branch by unidirectional connections. We adopt
knowledge distillation for our bi-CryptoNets by transferring representations
from a well-trained teacher neural network. Empirical studies show the
effectiveness and decrease of inference latency for our bi-CryptoNets.</div><div><a href='http://arxiv.org/abs/2402.01296v1'>2402.01296v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.08024v1")'>xMLP: Revolutionizing Private Inference with Exclusive Square Activation</div>
<div id='2403.08024v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T18:46:56Z</div><div>Authors: Jiajie Li, Jinjun Xiong</div><div style='padding-top: 10px; width: 80ex'>Private Inference (PI) enables deep neural networks (DNNs) to work on private
data without leaking sensitive information by exploiting cryptographic
primitives such as multi-party computation (MPC) and homomorphic encryption
(HE). However, the use of non-linear activations such as ReLU in DNNs can lead
to impractically high PI latency in existing PI systems, as ReLU requires the
use of costly MPC computations, such as Garbled Circuits. Since square
activations can be processed by Beaver's triples hundreds of times faster
compared to ReLU, they are more friendly to PI tasks, but using them leads to a
notable drop in model accuracy. This paper starts by exploring the reason for
such an accuracy drop after using square activations, and concludes that this
is due to an "information compounding" effect. Leveraging this insight, we
propose xMLP, a novel DNN architecture that uses square activations exclusively
while maintaining parity in both accuracy and efficiency with ReLU-based DNNs.
Our experiments on CIFAR-100 and ImageNet show that xMLP models consistently
achieve better performance than ResNet models with fewer activation layers and
parameters while maintaining consistent performance with its ReLU-based
variants. Remarkably, when compared to state-of-the-art PI Models, xMLP
demonstrates superior performance, achieving a 0.58% increase in accuracy with
7x faster PI speed. Moreover, it delivers a significant accuracy improvement of
4.96% while maintaining the same PI latency. When offloading PI to the GPU,
xMLP is up to 700x faster than the previous state-of-the-art PI model with
comparable accuracy.</div><div><a href='http://arxiv.org/abs/2403.08024v1'>2403.08024v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.02320v2")'>Spin: An Efficient Secure Computation Framework with GPU Acceleration</div>
<div id='2402.02320v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-04T02:12:15Z</div><div>Authors: Wuxuan Jiang, Xiangjun Song, Shenbai Hong, Haijun Zhang, Wenxin Liu, Bo Zhao, Wei Xu, Yi Li</div><div style='padding-top: 10px; width: 80ex'>Accuracy and efficiency remain challenges for multi-party computation (MPC)
frameworks. Spin is a GPU-accelerated MPC framework that supports multiple
computation parties and a dishonest majority adversarial setup. We propose
optimized protocols for non-linear functions that are critical for machine
learning, as well as several novel optimizations specific to attention that is
the fundamental unit of Transformer models, allowing Spin to perform
non-trivial CNNs training and Transformer inference without sacrificing
security. At the backend level, Spin leverages GPU, CPU, and RDMA-enabled smart
network cards for acceleration. Comprehensive evaluations demonstrate that Spin
can be up to $2\times$ faster than the state-of-the-art for deep neural network
training. For inference on a Transformer model with 18.9 million parameters,
our attention-specific optimizations enable Spin to achieve better efficiency,
less communication, and better accuracy.</div><div><a href='http://arxiv.org/abs/2402.02320v2'>2402.02320v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.16002v1")'>Post-Quantum Cryptography Neural Network</div>
<div id='2402.16002v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-25T06:19:04Z</div><div>Authors: Abel C. H. Chen</div><div style='padding-top: 10px; width: 80ex'>In recent years, quantum computers and Shor quantum algorithm have posed a
threat to current mainstream asymmetric cryptography methods (e.g. RSA and
Elliptic Curve Cryptography (ECC)). Therefore, it is necessary to construct a
Post-Quantum Cryptography (PQC) method to resist quantum computing attacks.
Therefore, this study proposes a PQC-based neural network that maps a
code-based PQC method to a neural network structure and enhances the security
of ciphertexts with non-linear activation functions, random perturbation of
ciphertexts, and uniform distribution of ciphertexts. In practical experiments,
this study uses cellular network signals as a case study to demonstrate that
encryption and decryption can be performed by the proposed PQC-based neural
network with the uniform distribution of ciphertexts. In the future, the
proposed PQC-based neural network could be applied to various applications.</div><div><a href='http://arxiv.org/abs/2402.16002v1'>2402.16002v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.14840v1")'>GuardML: Efficient Privacy-Preserving Machine Learning Services Through
  Hybrid Homomorphic Encryption</div>
<div id='2401.14840v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-26T13:12:52Z</div><div>Authors: Eugene Frimpong, Khoa Nguyen, Mindaugas Budzys, Tanveer Khan, Antonis Michalas</div><div style='padding-top: 10px; width: 80ex'>Machine Learning (ML) has emerged as one of data science's most
transformative and influential domains. However, the widespread adoption of ML
introduces privacy-related concerns owing to the increasing number of malicious
attacks targeting ML models. To address these concerns, Privacy-Preserving
Machine Learning (PPML) methods have been introduced to safeguard the privacy
and security of ML models. One such approach is the use of Homomorphic
Encryption (HE). However, the significant drawbacks and inefficiencies of
traditional HE render it impractical for highly scalable scenarios.
Fortunately, a modern cryptographic scheme, Hybrid Homomorphic Encryption
(HHE), has recently emerged, combining the strengths of symmetric cryptography
and HE to surmount these challenges. Our work seeks to introduce HHE to ML by
designing a PPML scheme tailored for end devices. We leverage HHE as the
fundamental building block to enable secure learning of classification outcomes
over encrypted data, all while preserving the privacy of the input data and ML
model. We demonstrate the real-world applicability of our construction by
developing and evaluating an HHE-based PPML application for classifying heart
disease based on sensitive ECG data. Notably, our evaluations revealed a slight
reduction in accuracy compared to inference on plaintext data. Additionally,
both the analyst and end devices experience minimal communication and
computation costs, underscoring the practical viability of our approach. The
successful integration of HHE into PPML provides a glimpse into a more secure
and privacy-conscious future for machine learning on relatively constrained end
devices.</div><div><a href='http://arxiv.org/abs/2401.14840v1'>2401.14840v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.17136v1")'>Systematically Assessing the Security Risks of AI/ML-enabled Connected
  Healthcare Systems</div>
<div id='2401.17136v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T16:15:55Z</div><div>Authors: Mohammed Elnawawy, Mohammadreza Hallajiyan, Gargi Mitra, Shahrear Iqbal, Karthik Pattabiraman</div><div style='padding-top: 10px; width: 80ex'>The adoption of machine-learning-enabled systems in the healthcare domain is
on the rise. While the use of ML in healthcare has several benefits, it also
expands the threat surface of medical systems. We show that the use of ML in
medical systems, particularly connected systems that involve interfacing the ML
engine with multiple peripheral devices, has security risks that might cause
life-threatening damage to a patient's health in case of adversarial
interventions. These new risks arise due to security vulnerabilities in the
peripheral devices and communication channels. We present a case study where we
demonstrate an attack on an ML-enabled blood glucose monitoring system by
introducing adversarial data points during inference. We show that an adversary
can achieve this by exploiting a known vulnerability in the Bluetooth
communication channel connecting the glucose meter with the ML-enabled app. We
further show that state-of-the-art risk assessment techniques are not adequate
for identifying and assessing these new risks. Our study highlights the need
for novel risk analysis methods for analyzing the security of AI-enabled
connected health devices.</div><div><a href='http://arxiv.org/abs/2401.17136v1'>2401.17136v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.00568v1")'>Secure Supervised Learning-Based Smart Home Authentication Framework</div>
<div id='2402.00568v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T13:01:47Z</div><div>Authors: K. Swapna Sudha, N. Jeyanthi, Celestine Iwendi</div><div style='padding-top: 10px; width: 80ex'>The Smart home possesses the capability of facilitating home services to
their users with the systematic advance in The Internet of Things (IoT) and
information and communication technologies (ICT) in recent decades. The home
service offered by the smart devices helps the users in utilize maximized level
of comfort for the objective of improving life quality. As the user and smart
devices communicate through an insecure channel, the smart home environment is
prone to security and privacy problems. A secure authentication protocol needs
to be established between the smart devices and the user, such that a situation
for device authentication can be made feasible in smart home environments. Most
of the existing smart home authentication protocols were identified to fail in
facilitating a secure mutual authentication and increases the possibility of
lunching the attacks of session key disclosure, impersonation and stolen smart
device. In this paper, Secure Supervised Learning-based Smart Home
Authentication Framework (SSL-SHAF) is proposed as are liable mutual
authentication that can be contextually imposed for better security. The formal
analysis of the proposed SSL-SHAF confirmed better resistance against session
key disclosure, impersonation and stolen smart device attacks. The results of
SSL-SHAF confirmed minimized computational costs and security compared to the
baseline protocols considered for investigation.</div><div><a href='http://arxiv.org/abs/2402.00568v1'>2402.00568v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.07809v1")'>Optimal Data Splitting in Distributed Optimization for Machine Learning</div>
<div id='2401.07809v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T16:30:12Z</div><div>Authors: Daniil Medyakov, Gleb Molodtsov, Aleksandr Beznosikov, Alexander Gasnikov</div><div style='padding-top: 10px; width: 80ex'>The distributed optimization problem has become increasingly relevant
recently. It has a lot of advantages such as processing a large amount of data
in less time compared to non-distributed methods. However, most distributed
approaches suffer from a significant bottleneck - the cost of communications.
Therefore, a large amount of research has recently been directed at solving
this problem. One such approach uses local data similarity. In particular,
there exists an algorithm provably optimally exploiting the similarity
property. But this result, as well as results from other works solve the
communication bottleneck by focusing only on the fact that communication is
significantly more expensive than local computing and does not take into
account the various capacities of network devices and the different
relationship between communication time and local computing expenses. We
consider this setup and the objective of this study is to achieve an optimal
ratio of distributed data between the server and local machines for any costs
of communications and local computations. The running times of the network are
compared between uniform and optimal distributions. The superior theoretical
performance of our solutions is experimentally validated.</div><div><a href='http://arxiv.org/abs/2401.07809v1'>2401.07809v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.02734v1")'>FedNS: A Fast Sketching Newton-Type Algorithm for Federated Learning</div>
<div id='2401.02734v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-05T10:06:41Z</div><div>Authors: Jian Li, Yong Liu, Wei Wang, Haoran Wu, Weiping Wang</div><div style='padding-top: 10px; width: 80ex'>Recent Newton-type federated learning algorithms have demonstrated linear
convergence with respect to the communication rounds. However, communicating
Hessian matrices is often unfeasible due to their quadratic communication
complexity. In this paper, we introduce a novel approach to tackle this issue
while still achieving fast convergence rates. Our proposed method, named as
Federated Newton Sketch methods (FedNS), approximates the centralized Newton's
method by communicating the sketched square-root Hessian instead of the exact
Hessian. To enhance communication efficiency, we reduce the sketch size to
match the effective dimension of the Hessian matrix. We provide convergence
analysis based on statistical learning for the federated Newton sketch
approaches. Specifically, our approaches reach super-linear convergence rates
w.r.t. the communication rounds for the first time. We validate the
effectiveness of our algorithms through various experiments, which coincide
with our theoretical findings.</div><div><a href='http://arxiv.org/abs/2401.02734v1'>2401.02734v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.14211v3")'>Communication-Efficient Federated Learning through Adaptive Weight
  Clustering and Server-Side Distillation</div>
<div id='2401.14211v3' style='display: none; margin-left: 20px'><div>Date: 2024-01-25T14:49:15Z</div><div>Authors: Vasileios Tsouvalas, Aaqib Saeed, Tanir Ozcelebi, Nirvana Meratnia</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) is a promising technique for the collaborative
training of deep neural networks across multiple devices while preserving data
privacy. Despite its potential benefits, FL is hindered by excessive
communication costs due to repeated server-client communication during
training. To address this challenge, model compression techniques, such as
sparsification and weight clustering are applied, which often require modifying
the underlying model aggregation schemes or involve cumbersome hyperparameter
tuning, with the latter not only adjusts the model's compression rate but also
limits model's potential for continuous improvement over growing data. In this
paper, we propose FedCompress, a novel approach that combines dynamic weight
clustering and server-side knowledge distillation to reduce communication costs
while learning highly generalizable models. Through a comprehensive evaluation
on diverse public datasets, we demonstrate the efficacy of our approach
compared to baselines in terms of communication costs and inference speed.</div><div><a href='http://arxiv.org/abs/2401.14211v3'>2401.14211v3</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.12329v1")'>FedFisher: Leveraging Fisher Information for One-Shot Federated Learning</div>
<div id='2403.12329v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-19T00:03:40Z</div><div>Authors: Divyansh Jhunjhunwala, Shiqiang Wang, Gauri Joshi</div><div style='padding-top: 10px; width: 80ex'>Standard federated learning (FL) algorithms typically require multiple rounds
of communication between the server and the clients, which has several
drawbacks, including requiring constant network connectivity, repeated
investment of computational resources, and susceptibility to privacy attacks.
One-Shot FL is a new paradigm that aims to address this challenge by enabling
the server to train a global model in a single round of communication. In this
work, we present FedFisher, a novel algorithm for one-shot FL that makes use of
Fisher information matrices computed on local client models, motivated by a
Bayesian perspective of FL. First, we theoretically analyze FedFisher for
two-layer over-parameterized ReLU neural networks and show that the error of
our one-shot FedFisher global model becomes vanishingly small as the width of
the neural networks and amount of local training at clients increases. Next, we
propose practical variants of FedFisher using the diagonal Fisher and K-FAC
approximation for the full Fisher and highlight their communication and compute
efficiency for FL. Finally, we conduct extensive experiments on various
datasets, which show that these variants of FedFisher consistently improve over
competing baselines.</div><div><a href='http://arxiv.org/abs/2403.12329v1'>2403.12329v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.18949v1")'>Improving Group Connectivity for Generalization of Federated Deep
  Learning</div>
<div id='2402.18949v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T08:27:01Z</div><div>Authors: Zexi Li, Jie Lin, Zhiqi Li, Didi Zhu, Chao Wu</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) involves multiple heterogeneous clients
collaboratively training a global model via iterative local updates and model
fusion. The generalization of FL's global model has a large gap compared with
centralized training, which is its bottleneck for broader applications. In this
paper, we study and improve FL's generalization through a fundamental
``connectivity'' perspective, which means how the local models are connected in
the parameter region and fused into a generalized global model. The term
``connectivity'' is derived from linear mode connectivity (LMC), studying the
interpolated loss landscape of two different solutions (e.g., modes) of neural
networks. Bridging the gap between LMC and FL, in this paper, we leverage fixed
anchor models to empirically and theoretically study the transitivity property
of connectivity from two models (LMC) to a group of models (model fusion in
FL). Based on the findings, we propose FedGuCci and FedGuCci+, improving group
connectivity for better generalization. It is shown that our methods can boost
the generalization of FL under client heterogeneity across various tasks (4 CV
datasets and 6 NLP datasets), models (both convolutional and
transformer-based), and training paradigms (both from-scratch and
pretrain-finetune).</div><div><a href='http://arxiv.org/abs/2402.18949v1'>2402.18949v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.01417v1")'>Asyn2F: An Asynchronous Federated Learning Framework with Bidirectional
  Model Aggregation</div>
<div id='2403.01417v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-03T07:12:37Z</div><div>Authors: Tien-Dung Cao, Nguyen T. Vuong, Thai Q. Le, Hoang V. N. Dao, Tram Truong-Huu</div><div style='padding-top: 10px; width: 80ex'>In federated learning, the models can be trained synchronously or
asynchronously. Many research works have focused on developing an aggregation
method for the server to aggregate multiple local models into the global model
with improved performance. They ignore the heterogeneity of the training
workers, which causes the delay in the training of the local models, leading to
the obsolete information issue. In this paper, we design and develop Asyn2F, an
Asynchronous Federated learning Framework with bidirectional model aggregation.
By bidirectional model aggregation, Asyn2F, on one hand, allows the server to
asynchronously aggregate multiple local models and results in a new global
model. On the other hand, it allows the training workers to aggregate the new
version of the global model into the local model, which is being trained even
in the middle of a training epoch. We develop Asyn2F considering the practical
implementation requirements such as using cloud services for model storage and
message queuing protocols for communications. Extensive experiments with
different datasets show that the models trained by Asyn2F achieve higher
performance compared to the state-of-the-art techniques. The experiments also
demonstrate the effectiveness, practicality, and scalability of Asyn2F, making
it ready for deployment in real scenarios.</div><div><a href='http://arxiv.org/abs/2403.01417v1'>2403.01417v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.04472v2")'>A Survey on Efficient Federated Learning Methods for Foundation Model
  Training</div>
<div id='2401.04472v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-09T10:22:23Z</div><div>Authors: Herbert Woisetschläger, Alexander Isenko, Shiqiang Wang, Ruben Mayer, Hans-Arno Jacobsen</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) has become an established technique to facilitate
privacy-preserving collaborative training across a multitude of clients.
However, new approaches to FL often discuss their contributions involving small
deep-learning models only and focus on training full models on clients. In the
wake of Foundation Models (FM), the reality is different for many deep learning
applications. Typically, FMs have already been pre-trained across a wide
variety of tasks and can be fine-tuned to specific downstream tasks over
significantly smaller datasets than required for full model training. However,
access to such datasets is often challenging. By its design, FL can help to
open data silos. With this survey, we introduce a novel taxonomy focused on
computational and communication efficiency, the vital elements to make use of
FMs in FL systems. We discuss the benefits and drawbacks of parameter-efficient
fine-tuning (PEFT) for FL applications, elaborate on the readiness of FL
frameworks to work with FMs and provide future research opportunities on how to
evaluate generative models in FL as well as the interplay of privacy and PEFT.</div><div><a href='http://arxiv.org/abs/2401.04472v2'>2401.04472v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.17202v1")'>FedBRB: An Effective Solution to the Small-to-Large Scenario in
  Device-Heterogeneity Federated Learning</div>
<div id='2402.17202v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T04:50:13Z</div><div>Authors: Ziyue Xu, Mingfeng Xu, Tianchi Liao, Zibin Zheng, Chuan Chen</div><div style='padding-top: 10px; width: 80ex'>Recently, the success of large models has demonstrated the importance of
scaling up model size. This has spurred interest in exploring collaborative
training of large-scale models from federated learning perspective. Due to
computational constraints, many institutions struggle to train a large-scale
model locally. Thus, training a larger global model using only smaller local
models has become an important scenario (i.e., the \textbf{small-to-large
scenario}). Although recent device-heterogeneity federated learning approaches
have started to explore this area, they face limitations in fully covering the
parameter space of the global model. In this paper, we propose a method called
\textbf{FedBRB} (\underline{B}lock-wise \underline{R}olling and weighted
\underline{B}roadcast) based on the block concept. FedBRB can uses small local
models to train all blocks of the large global model, and broadcasts the
trained parameters to the entire space for faster information interaction.
Experiments demonstrate FedBRB yields substantial performance gains, achieving
state-of-the-art results in this scenario. Moreover, FedBRB using only minimal
local models can even surpass baselines using larger local models.</div><div><a href='http://arxiv.org/abs/2402.17202v1'>2402.17202v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01862v1")'>Parametric Feature Transfer: One-shot Federated Learning with Foundation
  Models</div>
<div id='2402.01862v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T19:34:46Z</div><div>Authors: Mahdi Beitollahi, Alex Bie, Sobhan Hemati, Leo Maxime Brunswic, Xu Li, Xi Chen, Guojun Zhang</div><div style='padding-top: 10px; width: 80ex'>In one-shot federated learning (FL), clients collaboratively train a global
model in a single round of communication. Existing approaches for one-shot FL
enhance communication efficiency at the expense of diminished accuracy. This
paper introduces FedPFT (Federated Learning with Parametric Feature Transfer),
a methodology that harnesses the transferability of foundation models to
enhance both accuracy and communication efficiency in one-shot FL. The approach
involves transferring per-client parametric models (specifically, Gaussian
mixtures) of features extracted from foundation models. Subsequently, each
parametric model is employed to generate synthetic features for training a
classifier head. Experimental results on eight datasets demonstrate that FedPFT
enhances the communication-accuracy frontier in both centralized and
decentralized FL scenarios, as well as across diverse data-heterogeneity
settings such as covariate shift and task shift, with improvements of up to
20.6%. Additionally, FedPFT adheres to the data minimization principle of FL,
as clients do not send real features. We demonstrate that sending real features
is vulnerable to potent reconstruction attacks. Moreover, we show that FedPFT
is amenable to formal privacy guarantees via differential privacy,
demonstrating favourable privacy-accuracy tradeoffs.</div><div><a href='http://arxiv.org/abs/2402.01862v1'>2402.01862v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07002v1")'>Clients Collaborate: Flexible Differentially Private Federated Learning
  with Guaranteed Improvement of Utility-Privacy Trade-off</div>
<div id='2402.07002v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-10T17:39:34Z</div><div>Authors: Yuecheng Li, Tong Wang, Chuan Chen, Jian Lou, Bin Chen, Lei Yang, Zibin Zheng</div><div style='padding-top: 10px; width: 80ex'>To defend against privacy leakage of user data, differential privacy is
widely used in federated learning, but it is not free. The addition of noise
randomly disrupts the semantic integrity of the model and this disturbance
accumulates with increased communication rounds. In this paper, we introduce a
novel federated learning framework with rigorous privacy guarantees, named
FedCEO, designed to strike a trade-off between model utility and user privacy
by letting clients ''Collaborate with Each Other''. Specifically, we perform
efficient tensor low-rank proximal optimization on stacked local model
parameters at the server, demonstrating its capability to flexibly truncate
high-frequency components in spectral space. This implies that our FedCEO can
effectively recover the disrupted semantic information by smoothing the global
semantic space for different privacy settings and continuous training
processes. Moreover, we improve the SOTA utility-privacy trade-off bound by an
order of $\sqrt{d}$, where $d$ is the input dimension. We illustrate our
theoretical results with experiments on representative image datasets. It
observes significant performance improvements and strict privacy guarantees
under different privacy settings.</div><div><a href='http://arxiv.org/abs/2402.07002v1'>2402.07002v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16350v1")'>FedFair^3: Unlocking Threefold Fairness in Federated Learning</div>
<div id='2401.16350v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T17:56:15Z</div><div>Authors: Simin Javaherian, Sanjeev Panta, Shelby Williams, Md Sirajul Islam, Li Chen</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) is an emerging paradigm in machine learning without
exposing clients' raw data. In practical scenarios with numerous clients,
encouraging fair and efficient client participation in federated learning is of
utmost importance, which is also challenging given the heterogeneity in data
distribution and device properties. Existing works have proposed different
client-selection methods that consider fairness; however, they fail to select
clients with high utilities while simultaneously achieving fair accuracy
levels. In this paper, we propose a fair client-selection approach that unlocks
threefold fairness in federated learning. In addition to having a fair
client-selection strategy, we enforce an equitable number of rounds for client
participation and ensure a fair accuracy distribution over the clients. The
experimental results demonstrate that FedFair^3, in comparison to the
state-of-the-art baselines, achieves 18.15% less accuracy variance on the IID
data and 54.78% on the non-IID data, without decreasing the global accuracy.
Furthermore, it shows 24.36% less wall-clock training time on average.</div><div><a href='http://arxiv.org/abs/2401.16350v1'>2401.16350v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.04993v1")'>AdaFed: Fair Federated Learning via Adaptive Common Descent Direction</div>
<div id='2401.04993v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-10T08:22:15Z</div><div>Authors: Shayan Mohajer Hamidi, En-Hui Yang</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) is a promising technology via which some edge
devices/clients collaboratively train a machine learning model orchestrated by
a server. Learning an unfair model is known as a critical problem in federated
learning, where the trained model may unfairly advantage or disadvantage some
of the devices. To tackle this problem, in this work, we propose AdaFed. The
goal of AdaFed is to find an updating direction for the server along which (i)
all the clients' loss functions are decreasing; and (ii) more importantly, the
loss functions for the clients with larger values decrease with a higher rate.
AdaFed adaptively tunes this common direction based on the values of local
gradients and loss functions. We validate the effectiveness of AdaFed on a
suite of federated datasets, and demonstrate that AdaFed outperforms
state-of-the-art fair FL methods.</div><div><a href='http://arxiv.org/abs/2401.04993v1'>2401.04993v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.02225v1")'>Rethinking the Starting Point: Enhancing Performance and Fairness of
  Federated Learning via Collaborative Pre-Training</div>
<div id='2402.02225v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-03T17:58:43Z</div><div>Authors: Yun-Wei Chu, Dong-Jun Han, Seyyedali Hosseinalipour, Christopher G. Brinton</div><div style='padding-top: 10px; width: 80ex'>Most existing federated learning (FL) methodologies have assumed training
begins from a randomly initialized model. Recently, several studies have
empirically demonstrated that leveraging a pre-trained model can offer
advantageous initializations for FL. In this paper, we propose a collaborative
pre-training approach, CoPreFL, which strategically designs a pre-trained model
to serve as a good initialization for any downstream FL task. The key idea of
our pre-training algorithm is a meta-learning procedure which mimics downstream
distributed scenarios, enabling it to adapt to any unforeseen FL task.
CoPreFL's pre-training optimization procedure also strikes a balance between
average performance and fairness, with the aim of addressing these competing
challenges in downstream FL tasks through intelligent initializations.
Extensive experimental results validate that our pre-training method provides a
robust initialization for any unseen downstream FL task, resulting in enhanced
average performance and more equitable predictions.</div><div><a href='http://arxiv.org/abs/2402.02225v1'>2402.02225v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15070v1")'>Enhancing One-Shot Federated Learning Through Data and Ensemble
  Co-Boosting</div>
<div id='2402.15070v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-23T03:15:10Z</div><div>Authors: Rong Dai, Yonggang Zhang, Ang Li, Tongliang Liu, Xun Yang, Bo Han</div><div style='padding-top: 10px; width: 80ex'>One-shot Federated Learning (OFL) has become a promising learning paradigm,
enabling the training of a global server model via a single communication
round. In OFL, the server model is aggregated by distilling knowledge from all
client models (the ensemble), which are also responsible for synthesizing
samples for distillation. In this regard, advanced works show that the
performance of the server model is intrinsically related to the quality of the
synthesized data and the ensemble model. To promote OFL, we introduce a novel
framework, Co-Boosting, in which synthesized data and the ensemble model
mutually enhance each other progressively. Specifically, Co-Boosting leverages
the current ensemble model to synthesize higher-quality samples in an
adversarial manner. These hard samples are then employed to promote the quality
of the ensemble model by adjusting the ensembling weights for each client
model. Consequently, Co-Boosting periodically achieves high-quality data and
ensemble models. Extensive experiments demonstrate that Co-Boosting can
substantially outperform existing baselines under various settings. Moreover,
Co-Boosting eliminates the need for adjustments to the client's local training,
requires no additional data or model transmission, and allows client models to
have heterogeneous architectures.</div><div><a href='http://arxiv.org/abs/2402.15070v1'>2402.15070v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.10478v1")'>Budgeted Online Model Selection and Fine-Tuning via Federated Learning</div>
<div id='2401.10478v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-19T04:02:49Z</div><div>Authors: Pouya M. Ghari, Yanning Shen</div><div style='padding-top: 10px; width: 80ex'>Online model selection involves selecting a model from a set of candidate
models 'on the fly' to perform prediction on a stream of data. The choice of
candidate models henceforth has a crucial impact on the performance. Although
employing a larger set of candidate models naturally leads to more flexibility
in model selection, this may be infeasible in cases where prediction tasks are
performed on edge devices with limited memory. Faced with this challenge, the
present paper proposes an online federated model selection framework where a
group of learners (clients) interacts with a server with sufficient memory such
that the server stores all candidate models. However, each client only chooses
to store a subset of models that can be fit into its memory and performs its
own prediction task using one of the stored models. Furthermore, employing the
proposed algorithm, clients and the server collaborate to fine-tune models to
adapt them to a non-stationary environment. Theoretical analysis proves that
the proposed algorithm enjoys sub-linear regret with respect to the best model
in hindsight. Experiments on real datasets demonstrate the effectiveness of the
proposed algorithm.</div><div><a href='http://arxiv.org/abs/2401.10478v1'>2401.10478v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.05890v1")'>Towards Efficient Replay in Federated Incremental Learning</div>
<div id='2403.05890v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-09T12:04:56Z</div><div>Authors: Yichen Li, Qunwei Li, Haozhao Wang, Ruixuan Li, Wenliang Zhong, Guannan Zhang</div><div style='padding-top: 10px; width: 80ex'>In Federated Learning (FL), the data in each client is typically assumed
fixed or static. However, data often comes in an incremental manner in
real-world applications, where the data domain may increase dynamically. In
this work, we study catastrophic forgetting with data heterogeneity in
Federated Incremental Learning (FIL) scenarios where edge clients may lack
enough storage space to retain full data. We propose to employ a simple,
generic framework for FIL named Re-Fed, which can coordinate each client to
cache important samples for replay. More specifically, when a new task arrives,
each client first caches selected previous samples based on their global and
local importance. Then, the client trains the local model with both the cached
samples and the samples from the new task. Theoretically, we analyze the
ability of Re-Fed to discover important samples for replay thus alleviating the
catastrophic forgetting problem. Moreover, we empirically show that Re-Fed
achieves competitive performance compared to state-of-the-art methods.</div><div><a href='http://arxiv.org/abs/2403.05890v1'>2403.05890v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03448v1")'>Decentralized Sporadic Federated Learning: A Unified Methodology with
  Generalized Convergence Guarantees</div>
<div id='2402.03448v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T19:02:19Z</div><div>Authors: Shahryar Zehtabi, Dong-Jun Han, Rohit Parasnis, Seyyedali Hosseinalipour, Christopher G. Brinton</div><div style='padding-top: 10px; width: 80ex'>Decentralized Federated Learning (DFL) has received significant recent
research attention, capturing settings where both model updates and model
aggregations -- the two key FL processes -- are conducted by the clients. In
this work, we propose Decentralized Sporadic Federated Learning
($\texttt{DSpodFL}$), a DFL methodology which generalizes the notion of
sporadicity in both of these processes, modeling the impact of different forms
of heterogeneity that manifest in realistic DFL settings. $\texttt{DSpodFL}$
unifies many of the prominent decentralized optimization methods, e.g.,
distributed gradient descent (DGD), randomized gossip (RG), and decentralized
federated averaging (DFedAvg), under a single modeling framework. We
analytically characterize the convergence behavior of $\texttt{DSpodFL}$,
showing, among other insights, that we can match a geometric convergence rate
to a finite optimality gap under more general assumptions than in existing
works. Through experiments, we demonstrate that $\texttt{DSpodFL}$ achieves
significantly improved training speeds and robustness to variations in system
parameters compared to the state-of-the-art.</div><div><a href='http://arxiv.org/abs/2402.03448v1'>2402.03448v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13216v1")'>On Principled Local Optimization Methods for Federated Learning</div>
<div id='2401.13216v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T03:57:45Z</div><div>Authors: Honglin Yuan</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL), a distributed learning paradigm that scales
on-device learning collaboratively, has emerged as a promising approach for
decentralized AI applications. Local optimization methods such as Federated
Averaging (FedAvg) are the most prominent methods for FL applications. Despite
their simplicity and popularity, the theoretical understanding of local
optimization methods is far from clear. This dissertation aims to advance the
theoretical foundation of local methods in the following three directions.
  First, we establish sharp bounds for FedAvg, the most popular algorithm in
Federated Learning. We demonstrate how FedAvg may suffer from a notion we call
iterate bias, and how an additional third-order smoothness assumption may
mitigate this effect and lead to better convergence rates. We explain this
phenomenon from a Stochastic Differential Equation (SDE) perspective.
  Second, we propose Federated Accelerated Stochastic Gradient Descent (FedAc),
the first principled acceleration of FedAvg, which provably improves the
convergence rate and communication efficiency. Our technique uses on a
potential-based perturbed iterate analysis, a novel stability analysis of
generalized accelerated SGD, and a strategic tradeoff between acceleration and
stability.
  Third, we study the Federated Composite Optimization problem, which extends
the classic smooth setting by incorporating a shared non-smooth regularizer. We
show that direct extensions of FedAvg may suffer from the "curse of primal
averaging," resulting in slow convergence. As a solution, we propose a new
primal-dual algorithm, Federated Dual Averaging, which overcomes the curse of
primal averaging by employing a novel inter-client dual averaging procedure.</div><div><a href='http://arxiv.org/abs/2401.13216v1'>2401.13216v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.13247v1")'>Decentralized Federated Learning: Model Update Tracking Under Imperfect
  Information Sharing</div>
<div id='2403.13247v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-20T02:17:47Z</div><div>Authors: Vishnu Pandi Chellapandi, Antesh Upadhyay, Abolfazl Hashemi, Stanislaw H. Żak</div><div style='padding-top: 10px; width: 80ex'>A novel Decentralized Noisy Model Update Tracking Federated Learning
algorithm (FedNMUT) is proposed, which is tailored to function efficiently in
the presence of noisy communication channels that reflect imperfect information
exchange. This algorithm uses gradient tracking to minimize the impact of data
heterogeneity while minimizing communication overhead. The proposed algorithm
incorporates noise into its parameters to mimic the conditions of noisy
communication channels, thereby enabling consensus among clients through a
communication graph topology in such challenging environments. FedNMUT
prioritizes parameter sharing and noise incorporation to increase the
resilience of decentralized learning systems against noisy communications.
Through theoretical and empirical validation, it is demonstrated that the
performance of FedNMUT is superior compared to the existing state-of-the-art
methods and conventional parameter-mixing approaches in dealing with imperfect
information sharing. This proves the capability of the proposed algorithm to
counteract the negative effects of communication noise in a decentralized
learning framework.</div><div><a href='http://arxiv.org/abs/2403.13247v1'>2403.13247v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03292v1")'>Averaging Rate Scheduler for Decentralized Learning on Heterogeneous
  Data</div>
<div id='2403.03292v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-05T19:47:51Z</div><div>Authors: Sai Aparna Aketi, Sakshi Choudhary, Kaushik Roy</div><div style='padding-top: 10px; width: 80ex'>State-of-the-art decentralized learning algorithms typically require the data
distribution to be Independent and Identically Distributed (IID). However, in
practical scenarios, the data distribution across the agents can have
significant heterogeneity. In this work, we propose averaging rate scheduling
as a simple yet effective way to reduce the impact of heterogeneity in
decentralized learning. Our experiments illustrate the superiority of the
proposed method (~3% improvement in test accuracy) compared to the conventional
approach of employing a constant averaging rate.</div><div><a href='http://arxiv.org/abs/2403.03292v1'>2403.03292v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.07448v2")'>Formal Logic Enabled Personalized Federated Learning Through Property
  Inference</div>
<div id='2401.07448v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T03:25:37Z</div><div>Authors: Ziyan An, Taylor T. Johnson, Meiyi Ma</div><div style='padding-top: 10px; width: 80ex'>Recent advancements in federated learning (FL) have greatly facilitated the
development of decentralized collaborative applications, particularly in the
domain of Artificial Intelligence of Things (AIoT). However, a critical aspect
missing from the current research landscape is the ability to enable
data-driven client models with symbolic reasoning capabilities. Specifically,
the inherent heterogeneity of participating client devices poses a significant
challenge, as each client exhibits unique logic reasoning properties. Failing
to consider these device-specific specifications can result in critical
properties being missed in the client predictions, leading to suboptimal
performance. In this work, we propose a new training paradigm that leverages
temporal logic reasoning to address this issue. Our approach involves enhancing
the training process by incorporating mechanically generated logic expressions
for each FL client. Additionally, we introduce the concept of aggregation
clusters and develop a partitioning algorithm to effectively group clients
based on the alignment of their temporal reasoning properties. We evaluate the
proposed method on two tasks: a real-world traffic volume prediction task
consisting of sensory data from fifteen states and a smart city multi-task
prediction utilizing synthetic data. The evaluation results exhibit clear
improvements, with performance accuracy improved by up to 54% across all
sequential prediction models.</div><div><a href='http://arxiv.org/abs/2401.07448v2'>2401.07448v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12876v1")'>Federated Multi-Task Learning on Non-IID Data Silos: An Experimental
  Study</div>
<div id='2402.12876v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T10:13:44Z</div><div>Authors: Yuwen Yang, Yuxiang Lu, Suizhi Huang, Shalayiding Sirejiding, Hongtao Lu, Yue Ding</div><div style='padding-top: 10px; width: 80ex'>The innovative Federated Multi-Task Learning (FMTL) approach consolidates the
benefits of Federated Learning (FL) and Multi-Task Learning (MTL), enabling
collaborative model training on multi-task learning datasets. However, a
comprehensive evaluation method, integrating the unique features of both FL and
MTL, is currently absent in the field. This paper fills this void by
introducing a novel framework, FMTL-Bench, for systematic evaluation of the
FMTL paradigm. This benchmark covers various aspects at the data, model, and
optimization algorithm levels, and comprises seven sets of comparative
experiments, encapsulating a wide array of non-independent and identically
distributed (Non-IID) data partitioning scenarios. We propose a systematic
process for comparing baselines of diverse indicators and conduct a case study
on communication expenditure, time, and energy consumption. Through our
exhaustive experiments, we aim to provide valuable insights into the strengths
and limitations of existing baseline methods, contributing to the ongoing
discourse on optimal FMTL application in practical scenarios. The source code
will be made available for results replication.</div><div><a href='http://arxiv.org/abs/2402.12876v1'>2402.12876v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12010v1")'>Training Green AI Models Using Elite Samples</div>
<div id='2402.12010v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-19T10:03:46Z</div><div>Authors: Mohammed Alswaitti, Roberto Verdecchia, Grégoire Danoy, Pascal Bouvry, Johnatan Pecero</div><div style='padding-top: 10px; width: 80ex'>The substantial increase in AI model training has considerable environmental
implications, mandating more energy-efficient and sustainable AI practices. On
the one hand, data-centric approaches show great potential towards training
energy-efficient AI models. On the other hand, instance selection methods
demonstrate the capability of training AI models with minimised training sets
and negligible performance degradation. Despite the growing interest in both
topics, the impact of data-centric training set selection on energy efficiency
remains to date unexplored. This paper presents an evolutionary-based sampling
framework aimed at (i) identifying elite training samples tailored for datasets
and model pairs, (ii) comparing model performance and energy efficiency gains
against typical model training practice, and (iii) investigating the
feasibility of this framework for fostering sustainable model training
practices. To evaluate the proposed framework, we conducted an empirical
experiment including 8 commonly used AI classification models and 25 publicly
available datasets. The results showcase that by considering 10% elite training
samples, the models' performance can show a 50% improvement and remarkable
energy savings of 98% compared to the common training practice.</div><div><a href='http://arxiv.org/abs/2402.12010v1'>2402.12010v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.10158v1")'>DISTINQT: A Distributed Privacy Aware Learning Framework for QoS
  Prediction for Future Mobile and Wireless Networks</div>
<div id='2401.10158v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T13:00:48Z</div><div>Authors: Nikolaos Koursioumpas, Lina Magoula, Ioannis Stavrakakis, Nancy Alonistioti, M. A. Gutierrez-Estevez, Ramin Khalili</div><div style='padding-top: 10px; width: 80ex'>Beyond 5G and 6G networks are expected to support new and challenging use
cases and applications that depend on a certain level of Quality of Service
(QoS) to operate smoothly. Predicting the QoS in a timely manner is of high
importance, especially for safety-critical applications as in the case of
vehicular communications. Although until recent years the QoS prediction has
been carried out by centralized Artificial Intelligence (AI) solutions, a
number of privacy, computational, and operational concerns have emerged.
Alternative solutions have been surfaced (e.g. Split Learning, Federated
Learning), distributing AI tasks of reduced complexity across nodes, while
preserving the privacy of the data. However, new challenges rise when it comes
to scalable distributed learning approaches, taking into account the
heterogeneous nature of future wireless networks. The current work proposes
DISTINQT, a privacy-aware distributed learning framework for QoS prediction.
Our framework supports multiple heterogeneous nodes, in terms of data types and
model architectures, by sharing computations across them. This, enables the
incorporation of diverse knowledge into a sole learning process that will
enhance the robustness and generalization capabilities of the final QoS
prediction model. DISTINQT also contributes to data privacy preservation by
encoding any raw input data into a non-linear latent representation before any
transmission. Evaluation results showcase that our framework achieves a
statistically identical performance compared to its centralized version and an
average performance improvement of up to 65% against six state-of-the-art
centralized baseline solutions in the Tele-Operated Driving use case.</div><div><a href='http://arxiv.org/abs/2401.10158v1'>2401.10158v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.03159v1")'>Distributed client selection with multi-objective in federated learning
  assisted Internet of Vehicles</div>
<div id='2401.03159v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-06T08:28:55Z</div><div>Authors: Narisu Cha, Long Chang</div><div style='padding-top: 10px; width: 80ex'>Federated learning is an emerging distributed machine learning framework in
the Internet of Vehicles (IoV). In IoV, millions of vehicles are willing to
train the model to share their knowledge. Maintaining an active state means the
participants must update their state to the FL server in a fixed interval and
participate to next round. However, the cost by maintaining an active state is
very large when there are a huge number of participating vehicles. In this
paper, we proposed a distributed client selection scheme to reduce the cost of
maintaining the active state for all participants. The clients with the highest
evaluation are elected among the neighbours. In the evaluator, four variables
are considered including sample quantity, throughput available, computational
capability and the quality of the local dataset. We adopted fuzzy logic as the
evaluator since the closed-form solution over four variables does not exist.
Extensive simulation results show our proposal approximates the centralized
client selection in terms of accuracy and can significantly reduce the
communication overhead.</div><div><a href='http://arxiv.org/abs/2401.03159v1'>2401.03159v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13366v2")'>Mitigating System Bias in Resource Constrained Asynchronous Federated
  Learning Systems</div>
<div id='2401.13366v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T10:51:15Z</div><div>Authors: Jikun Gao, Ioannis Mavromatis, Peizheng Li, Pietro Carnelli, Aftab Khan</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) systems face performance challenges in dealing with
heterogeneous devices and non-identically distributed data across clients. We
propose a dynamic global model aggregation method within Asynchronous Federated
Learning (AFL) deployments to address these issues. Our aggregation method
scores and adjusts the weighting of client model updates based on their upload
frequency to accommodate differences in device capabilities. Additionally, we
also immediately provide an updated global model to clients after they upload
their local models to reduce idle time and improve training efficiency. We
evaluate our approach within an AFL deployment consisting of 10 simulated
clients with heterogeneous compute constraints and non-IID data. The simulation
results, using the FashionMNIST dataset, demonstrate over 10% and 19%
improvement in global model accuracy compared to state-of-the-art methods
PAPAYA and FedAsync, respectively. Our dynamic aggregation method allows
reliable global model training despite limiting client resources and
statistical data heterogeneity. This improves robustness and scalability for
real-world FL deployments.</div><div><a href='http://arxiv.org/abs/2401.13366v2'>2401.13366v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.00116v1")'>Federated Linear Contextual Bandits with Heterogeneous Clients</div>
<div id='2403.00116v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T20:39:31Z</div><div>Authors: Ethan Blaser, Chuanhao Li, Hongning Wang</div><div style='padding-top: 10px; width: 80ex'>The demand for collaborative and private bandit learning across multiple
agents is surging due to the growing quantity of data generated from
distributed systems. Federated bandit learning has emerged as a promising
framework for private, efficient, and decentralized online learning. However,
almost all previous works rely on strong assumptions of client homogeneity,
i.e., all participating clients shall share the same bandit model; otherwise,
they all would suffer linear regret. This greatly restricts the application of
federated bandit learning in practice. In this work, we introduce a new
approach for federated bandits for heterogeneous clients, which clusters
clients for collaborative bandit learning under the federated learning setting.
Our proposed algorithm achieves non-trivial sub-linear regret and communication
cost for all clients, subject to the communication protocol under federated
learning that at anytime only one model can be shared by the server.</div><div><a href='http://arxiv.org/abs/2403.00116v1'>2403.00116v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03531v1")'>Fairness and Privacy Guarantees in Federated Contextual Bandits</div>
<div id='2402.03531v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T21:38:23Z</div><div>Authors: Sambhav Solanki, Shweta Jain, Sujit Gujar</div><div style='padding-top: 10px; width: 80ex'>This paper considers the contextual multi-armed bandit (CMAB) problem with
fairness and privacy guarantees in a federated environment. We consider
merit-based exposure as the desired fair outcome, which provides exposure to
each action in proportion to the reward associated. We model the algorithm's
effectiveness using fairness regret, which captures the difference between fair
optimal policy and the policy output by the algorithm. Applying fair CMAB
algorithm to each agent individually leads to fairness regret linear in the
number of agents. We propose that collaborative -- federated learning can be
more effective and provide the algorithm Fed-FairX-LinUCB that also ensures
differential privacy. The primary challenge in extending the existing privacy
framework is designing the communication protocol for communicating required
information across agents. A naive protocol can either lead to weaker privacy
guarantees or higher regret. We design a novel communication protocol that
allows for (i) Sub-linear theoretical bounds on fairness regret for
Fed-FairX-LinUCB and comparable bounds for the private counterpart,
Priv-FairX-LinUCB (relative to single-agent learning), (ii) Effective use of
privacy budget in Priv-FairX-LinUCB. We demonstrate the efficacy of our
proposed algorithm with extensive simulations-based experiments. We show that
both Fed-FairX-LinUCB and Priv-FairX-LinUCB achieve near-optimal fairness
regret.</div><div><a href='http://arxiv.org/abs/2402.03531v1'>2402.03531v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.08522v1")'>Fairness Auditing with Multi-Agent Collaboration</div>
<div id='2402.08522v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T15:24:46Z</div><div>Authors: Martijn de Vos, Akash Dhasade, Jade Garcia Bourrée, Anne-Marie Kermarrec, Erwan Le Merrer, Benoit Rottembourg, Gilles Tredan</div><div style='padding-top: 10px; width: 80ex'>Existing work in fairness audits assumes that agents operate independently.
In this paper, we consider the case of multiple agents auditing the same
platform for different tasks. Agents have two levers: their collaboration
strategy, with or without coordination beforehand, and their sampling method.
We theoretically study their interplay when agents operate independently or
collaborate. We prove that, surprisingly, coordination can sometimes be
detrimental to audit accuracy, whereas uncoordinated collaboration generally
yields good results. Experimentation on real-world datasets confirms this
observation, as the audit accuracy of uncoordinated collaboration matches that
of collaborative optimal sampling.</div><div><a href='http://arxiv.org/abs/2402.08522v1'>2402.08522v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.16312v1")'>Federated Contextual Cascading Bandits with Asynchronous Communication
  and Heterogeneous Users</div>
<div id='2402.16312v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T05:31:14Z</div><div>Authors: Hantao Yang, Xutong Liu, Zhiyong Wang, Hong Xie, John C. S. Lui, Defu Lian, Enhong Chen</div><div style='padding-top: 10px; width: 80ex'>We study the problem of federated contextual combinatorial cascading bandits,
where $|\mathcal{U}|$ agents collaborate under the coordination of a central
server to provide tailored recommendations to the $|\mathcal{U}|$ corresponding
users. Existing works consider either a synchronous framework, necessitating
full agent participation and global synchronization, or assume user homogeneity
with identical behaviors. We overcome these limitations by considering (1)
federated agents operating in an asynchronous communication paradigm, where no
mandatory synchronization is required and all agents communicate independently
with the server, (2) heterogeneous user behaviors, where users can be
stratified into $J \le |\mathcal{U}|$ latent user clusters, each exhibiting
distinct preferences. For this setting, we propose a UCB-type algorithm with
delicate communication protocols. Through theoretical analysis, we give
sub-linear regret bounds on par with those achieved in the synchronous
framework, while incurring only logarithmic communication costs. Empirical
evaluation on synthetic and real-world datasets validates our algorithm's
superior performance in terms of regrets and communication costs.</div><div><a href='http://arxiv.org/abs/2402.16312v1'>2402.16312v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.15874v1")'>Rethinking Personalized Federated Learning with Clustering-based Dynamic
  Graph Propagation</div>
<div id='2401.15874v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T04:14:02Z</div><div>Authors: Jiaqi Wang, Yuzhong Chen, Yuhang Wu, Mahashweta Das, Hao Yang, Fenglong Ma</div><div style='padding-top: 10px; width: 80ex'>Most existing personalized federated learning approaches are based on
intricate designs, which often require complex implementation and tuning. In
order to address this limitation, we propose a simple yet effective
personalized federated learning framework. Specifically, during each
communication round, we group clients into multiple clusters based on their
model training status and data distribution on the server side. We then
consider each cluster center as a node equipped with model parameters and
construct a graph that connects these nodes using weighted edges. Additionally,
we update the model parameters at each node by propagating information across
the entire graph. Subsequently, we design a precise personalized model
distribution strategy to allow clients to obtain the most suitable model from
the server side. We conduct experiments on three image benchmark datasets and
create synthetic structured datasets with three types of typologies.
Experimental results demonstrate the effectiveness of the proposed work.</div><div><a href='http://arxiv.org/abs/2401.15874v1'>2401.15874v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.10846v1")'>FedD2S: Personalized Data-Free Federated Knowledge Distillation</div>
<div id='2402.10846v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-16T17:36:51Z</div><div>Authors: Kawa Atapour, S. Jamal Seyedmohammadi, Jamshid Abouei, Arash Mohammadi, Konstantinos N. Plataniotis</div><div style='padding-top: 10px; width: 80ex'>This paper addresses the challenge of mitigating data heterogeneity among
clients within a Federated Learning (FL) framework. The model-drift issue,
arising from the noniid nature of client data, often results in suboptimal
personalization of a global model compared to locally trained models for each
client. To tackle this challenge, we propose a novel approach named FedD2S for
Personalized Federated Learning (pFL), leveraging knowledge distillation.
FedD2S incorporates a deep-to-shallow layer-dropping mechanism in the data-free
knowledge distillation process to enhance local model personalization. Through
extensive simulations on diverse image datasets-FEMNIST, CIFAR10, CINIC0, and
CIFAR100-we compare FedD2S with state-of-the-art FL baselines. The proposed
approach demonstrates superior performance, characterized by accelerated
convergence and improved fairness among clients. The introduced layer-dropping
technique effectively captures personalized knowledge, resulting in enhanced
performance compared to alternative FL models. Moreover, we investigate the
impact of key hyperparameters, such as the participation ratio and
layer-dropping rate, providing valuable insights into the optimal configuration
for FedD2S. The findings demonstrate the efficacy of adaptive layer-dropping in
the knowledge distillation process to achieve enhanced personalization and
performance across diverse datasets and tasks.</div><div><a href='http://arxiv.org/abs/2402.10846v1'>2402.10846v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.16918v1")'>m2mKD: Module-to-Module Knowledge Distillation for Modular Transformers</div>
<div id='2402.16918v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T04:47:32Z</div><div>Authors: Ka Man Lo, Yiming Liang, Wenyu Du, Yuantao Fan, Zili Wang, Wenhao Huang, Lei Ma, Jie Fu</div><div style='padding-top: 10px; width: 80ex'>Modular neural architectures are gaining increasing attention due to their
powerful capability for generalization and sample-efficient adaptation to new
domains. However, training modular models, particularly in the early stages,
poses challenges due to the optimization difficulties arising from their
intrinsic sparse connectivity. Leveraging the knowledge from monolithic models,
using techniques such as knowledge distillation, is likely to facilitate the
training of modular models and enable them to integrate knowledge from multiple
models pretrained on diverse sources. Nevertheless, conventional knowledge
distillation approaches are not tailored to modular models and can fail when
directly applied due to the unique architectures and the enormous number of
parameters involved. Motivated by these challenges, we propose a general
module-to-module knowledge distillation (m2mKD) method for transferring
knowledge between modules. Our approach involves teacher modules split from a
pretrained monolithic model, and student modules of a modular model. m2mKD
separately combines these modules with a shared meta model and encourages the
student module to mimic the behaviour of the teacher module. We evaluate the
effectiveness of m2mKD on two distinct modular neural architectures: Neural
Attentive Circuits (NACs) and Vision Mixture-of-Experts (V-MoE). By applying
m2mKD to NACs, we achieve significant improvements in IID accuracy on
Tiny-ImageNet (up to 5.6%) and OOD robustness on Tiny-ImageNet-R (up to 4.2%).
On average, we observe a 1% gain in both ImageNet and ImageNet-R. The
V-MoE-Base model trained using m2mKD also achieves 3.5% higher accuracy than
end-to-end training on ImageNet. The experimental results demonstrate that our
method offers a promising solution for connecting modular networks with
pretrained monolithic models. Code is available at
https://github.com/kamanphoebe/m2mKD.</div><div><a href='http://arxiv.org/abs/2402.16918v1'>2402.16918v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14976v1")'>Unsupervised Domain Adaptation within Deep Foundation Latent Spaces</div>
<div id='2402.14976v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T21:25:20Z</div><div>Authors: Dmitry Kangin, Plamen Angelov</div><div style='padding-top: 10px; width: 80ex'>The vision transformer-based foundation models, such as ViT or Dino-V2, are
aimed at solving problems with little or no finetuning of features. Using a
setting of prototypical networks, we analyse to what extent such foundation
models can solve unsupervised domain adaptation without finetuning over the
source or target domain. Through quantitative analysis, as well as qualitative
interpretations of decision making, we demonstrate that the suggested method
can improve upon existing baselines, as well as showcase the limitations of
such approach yet to be solved.</div><div><a href='http://arxiv.org/abs/2402.14976v1'>2402.14976v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.16685v1")'>Communication-Efficient Multimodal Federated Learning: Joint Modality
  and Client Selection</div>
<div id='2401.16685v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T02:16:19Z</div><div>Authors: Liangqi Yuan, Dong-Jun Han, Su Wang, Devesh Upadhyay, Christopher G. Brinton</div><div style='padding-top: 10px; width: 80ex'>Multimodal federated learning (FL) aims to enrich model training in FL
settings where clients are collecting measurements across multiple modalities.
However, key challenges to multimodal FL remain unaddressed, particularly in
heterogeneous network settings where: (i) the set of modalities collected by
each client will be diverse, and (ii) communication limitations prevent clients
from uploading all their locally trained modality models to the server. In this
paper, we propose multimodal Federated learning with joint Modality and Client
selection (mmFedMC), a new FL methodology that can tackle the above-mentioned
challenges in multimodal settings. The joint selection algorithm incorporates
two main components: (a) A modality selection methodology for each client,
which weighs (i) the impact of the modality, gauged by Shapley value analysis,
(ii) the modality model size as a gauge of communication overhead, against
(iii) the frequency of modality model updates, denoted recency, to enhance
generalizability. (b) A client selection strategy for the server based on the
local loss of modality model at each client. Experiments on five real-world
datasets demonstrate the ability of mmFedMC to achieve comparable accuracy to
several baselines while reducing the communication overhead by over 20x. A demo
video of our methodology is available at https://liangqiy.com/mmfedmc/.</div><div><a href='http://arxiv.org/abs/2401.16685v1'>2401.16685v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13898v1")'>Cross-Modal Prototype based Multimodal Federated Learning under Severely
  Missing Modality</div>
<div id='2401.13898v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-25T02:25:23Z</div><div>Authors: Huy Q. Le, Chu Myaet Thwal, Yu Qiao, Ye Lin Tun, Minh N. H. Nguyen, Choong Seon Hong</div><div style='padding-top: 10px; width: 80ex'>Multimodal federated learning (MFL) has emerged as a decentralized machine
learning paradigm, allowing multiple clients with different modalities to
collaborate on training a machine learning model across diverse data sources
without sharing their private data. However, challenges, such as data
heterogeneity and severely missing modalities, pose crucial hindrances to the
robustness of MFL, significantly impacting the performance of global model. The
absence of a modality introduces misalignment during the local training phase,
stemming from zero-filling in the case of clients with missing modalities.
Consequently, achieving robust generalization in global model becomes
imperative, especially when dealing with clients that have incomplete data. In
this paper, we propose Multimodal Federated Cross Prototype Learning (MFCPL), a
novel approach for MFL under severely missing modalities by conducting the
complete prototypes to provide diverse modality knowledge in modality-shared
level with the cross-modal regularization and modality-specific level with
cross-modal contrastive mechanism. Additionally, our approach introduces the
cross-modal alignment to provide regularization for modality-specific features,
thereby enhancing overall performance, particularly in scenarios involving
severely missing modalities. Through extensive experiments on three multimodal
datasets, we demonstrate the effectiveness of MFCPL in mitigating these
challenges and improving the overall performance.</div><div><a href='http://arxiv.org/abs/2401.13898v1'>2401.13898v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.09428v1")'>Borrowing Treasures from Neighbors: In-Context Learning for Multimodal
  Learning with Missing Modalities and Data Scarcity</div>
<div id='2403.09428v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T14:19:48Z</div><div>Authors: Zhuo Zhi, Ziquan Liu, Moe Elbadawi, Adam Daneshmend, Mine Orlu, Abdul Basit, Andreas Demosthenous, Miguel Rodrigues</div><div style='padding-top: 10px; width: 80ex'>Multimodal machine learning with missing modalities is an increasingly
relevant challenge arising in various applications such as healthcare. This
paper extends the current research into missing modalities to the low-data
regime, i.e., a downstream task has both missing modalities and limited sample
size issues. This problem setting is particularly challenging and also
practical as it is often expensive to get full-modality data and sufficient
annotated training samples. We propose to use retrieval-augmented in-context
learning to address these two crucial issues by unleashing the potential of a
transformer's in-context learning ability. Diverging from existing methods,
which primarily belong to the parametric paradigm and often require sufficient
training samples, our work exploits the value of the available full-modality
data, offering a novel perspective on resolving the challenge. The proposed
data-dependent framework exhibits a higher degree of sample efficiency and is
empirically demonstrated to enhance the classification model's performance on
both full- and missing-modality data in the low-data regime across various
multimodal learning tasks. When only 1% of the training data are available, our
proposed method demonstrates an average improvement of 6.1% over a recent
strong baseline across various datasets and missing states. Notably, our method
also reduces the performance gap between full-modality and missing-modality
data compared with the baseline.</div><div><a href='http://arxiv.org/abs/2403.09428v1'>2403.09428v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.05308v1")'>Strategic Client Selection to Address Non-IIDness in HAPS-enabled FL
  Networks</div>
<div id='2401.05308v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-10T18:22:00Z</div><div>Authors: Amin Farajzadeh, Animesh Yadav, Halim Yanikomeroglu</div><div style='padding-top: 10px; width: 80ex'>The deployment of federated learning (FL) within vertical heterogeneous
networks, such as those enabled by high-altitude platform station (HAPS),
offers the opportunity to engage a wide array of clients, each endowed with
distinct communication and computational capabilities. This diversity not only
enhances the training accuracy of FL models but also hastens their convergence.
Yet, applying FL in these expansive networks presents notable challenges,
particularly the significant non-IIDness in client data distributions. Such
data heterogeneity often results in slower convergence rates and reduced
effectiveness in model training performance. Our study introduces a client
selection strategy tailored to address this issue, leveraging user network
traffic behaviour. This strategy involves the prediction and classification of
clients based on their network usage patterns while prioritizing user privacy.
By strategically selecting clients whose data exhibit similar patterns for
participation in FL training, our approach fosters a more uniform and
representative data distribution across the network. Our simulations
demonstrate that this targeted client selection methodology significantly
reduces the training loss of FL models in HAPS networks, thereby effectively
tackling a crucial challenge in implementing large-scale FL systems.</div><div><a href='http://arxiv.org/abs/2401.05308v1'>2401.05308v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.01493v1")'>Free Lunch for Federated Remote Sensing Target Fine-Grained
  Classification: A Parameter-Efficient Framework</div>
<div id='2401.01493v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-03T01:45:00Z</div><div>Authors: Shengchao Chen, Ting Shu, Huan Zhao, Jiahao Wang, Sufen Ren, Lina Yang</div><div style='padding-top: 10px; width: 80ex'>Remote Sensing Target Fine-grained Classification (TFGC) is of great
significance in both military and civilian fields. Due to location differences,
growth in data size, and centralized server storage constraints, these data are
usually stored under different databases across regions/countries. However,
privacy laws and national security concerns constrain researchers from
accessing these sensitive remote sensing images for further analysis.
Additionally, low-resource remote sensing devices encounter challenges in terms
of communication overhead and efficiency when dealing with the ever-increasing
data and model scales. To solve the above challenges, this paper proposes a
novel Privacy-Reserving TFGC Framework based on Federated Learning, dubbed
PRFL. The proposed framework allows each client to learn global and local
knowledge to enhance the local representation of private data in environments
with extreme statistical heterogeneity (non. Independent and Identically
Distributed, IID). Thus, it provides highly customized models to clients with
differentiated data distributions. Moreover, the framework minimizes
communication overhead and improves efficiency while ensuring satisfactory
performance, thereby enhancing robustness and practical applicability under
resource-scarce conditions. We demonstrate the effectiveness of the proposed
PRFL on the classical TFGC task by leveraging four public datasets.</div><div><a href='http://arxiv.org/abs/2401.01493v1'>2401.01493v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15541v1")'>Stitching Satellites to the Edge: Pervasive and Efficient Federated LEO
  Satellite Learning</div>
<div id='2401.15541v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-28T02:01:26Z</div><div>Authors: Mohamed Elmahallawy, Tie Luo</div><div style='padding-top: 10px; width: 80ex'>In the ambitious realm of space AI, the integration of federated learning
(FL) with low Earth orbit (LEO) satellite constellations holds immense promise.
However, many challenges persist in terms of feasibility, learning efficiency,
and convergence. These hurdles stem from the bottleneck in communication,
characterized by sporadic and irregular connectivity between LEO satellites and
ground stations, coupled with the limited computation capability of satellite
edge computing (SEC). This paper proposes a novel FL-SEC framework that
empowers LEO satellites to execute large-scale machine learning (ML) tasks
onboard efficiently. Its key components include i) personalized learning via
divide-and-conquer, which identifies and eliminates redundant satellite images
and converts complex multi-class classification problems to simple binary
classification, enabling rapid and energy-efficient training of lightweight ML
models suitable for IoT/edge devices on satellites; ii) orbital model
retraining, which generates an aggregated "orbital model" per orbit and
retrains it before sending to the ground station, significantly reducing the
required communication rounds. We conducted experiments using Jetson Nano, an
edge device closely mimicking the limited compute on LEO satellites, and a real
satellite dataset. The results underscore the effectiveness of our approach,
highlighting SEC's ability to run lightweight ML models on real and
high-resolution satellite imagery. Our approach dramatically reduces FL
convergence time by nearly 30 times, and satellite energy consumption down to
as low as 1.38 watts, all while maintaining an exceptional accuracy of up to
96%.</div><div><a href='http://arxiv.org/abs/2401.15541v1'>2401.15541v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09105v1")'>Scheduling for On-Board Federated Learning with Satellite Clusters</div>
<div id='2402.09105v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T11:26:30Z</div><div>Authors: Nasrin Razmi, Bho Matthiesen, Armin Dekorsy, Petar Popovski</div><div style='padding-top: 10px; width: 80ex'>Mega-constellations of small satellites have evolved into a source of massive
amount of valuable data. To manage this data efficiently, on-board federated
learning (FL) enables satellites to train a machine learning (ML) model
collaboratively without having to share the raw data. This paper introduces a
scheme for scheduling on-board FL for constellations connected with intra-orbit
inter-satellite links. The proposed scheme utilizes the predictable visibility
pattern between satellites and ground station (GS), both at the individual
satellite level and cumulatively within the entire orbit, to mitigate
intermittent connectivity and best use of available time. To this end, two
distinct schedulers are employed: one for coordinating the FL procedures among
orbits, and the other for controlling those within each orbit. These two
schedulers cooperatively determine the appropriate time to perform global
updates in GS and then allocate suitable duration to satellites within each
orbit for local training, proportional to usable time until next global update.
This scheme leads to improved test accuracy within a shorter time.</div><div><a href='http://arxiv.org/abs/2402.09105v1'>2402.09105v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.00685v2")'>Communication-Efficient Federated Learning for LEO Satellite Networks
  Integrated with HAPs Using Hybrid NOMA-OFDM</div>
<div id='2401.00685v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-01T07:07:27Z</div><div>Authors: Mohamed Elmahallawy, Tie Luo, Khaled Ramadan</div><div style='padding-top: 10px; width: 80ex'>Space AI has become increasingly important and sometimes even necessary for
government, businesses, and society. An active research topic under this
mission is integrating federated learning (FL) with satellite communications
(SatCom) so that numerous low Earth orbit (LEO) satellites can collaboratively
train a machine learning model. However, the special communication environment
of SatCom leads to a very slow FL training process up to days and weeks. This
paper proposes NomaFedHAP, a novel FL-SatCom approach tailored to LEO
satellites, that (1) utilizes high-altitude platforms (HAPs) as distributed
parameter servers (PS) to enhance satellite visibility, and (2) introduces
non-orthogonal multiple access (NOMA) into LEO to enable fast and
bandwidth-efficient model transmissions. In addition, NomaFedHAP includes (3) a
new communication topology that exploits HAPs to bridge satellites among
different orbits to mitigate the Doppler shift, and (4) a new FL model
aggregation scheme that optimally balances models between different orbits and
shells. Moreover, we (5) derive a closed-form expression of the outage
probability for satellites in near and far shells, as well as for the entire
system. Our extensive simulations have validated the mathematical analysis and
demonstrated the superior performance of NomaFedHAP in achieving fast and
efficient FL model convergence with high accuracy as compared to the
state-of-the-art.</div><div><a href='http://arxiv.org/abs/2401.00685v2'>2401.00685v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.13410v1")'>How to Forget Clients in Federated Online Learning to Rank?</div>
<div id='2401.13410v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T12:11:41Z</div><div>Authors: Shuyi Wang, Bing Liu, Guido Zuccon</div><div style='padding-top: 10px; width: 80ex'>Data protection legislation like the European Union's General Data Protection
Regulation (GDPR) establishes the \textit{right to be forgotten}: a user
(client) can request contributions made using their data to be removed from
learned models. In this paper, we study how to remove the contributions made by
a client participating in a Federated Online Learning to Rank (FOLTR) system.
In a FOLTR system, a ranker is learned by aggregating local updates to the
global ranking model. Local updates are learned in an online manner at a
client-level using queries and implicit interactions that have occurred within
that specific client. By doing so, each client's local data is not shared with
other clients or with a centralised search service, while at the same time
clients can benefit from an effective global ranking model learned from
contributions of each client in the federation.
  In this paper, we study an effective and efficient unlearning method that can
remove a client's contribution without compromising the overall ranker
effectiveness and without needing to retrain the global ranker from scratch. A
key challenge is how to measure whether the model has unlearned the
contributions from the client $c^*$ that has requested removal. For this, we
instruct $c^*$ to perform a poisoning attack (add noise to this client updates)
and then we measure whether the impact of the attack is lessened when the
unlearning process has taken place. Through experiments on four datasets, we
demonstrate the effectiveness and efficiency of the unlearning strategy under
different combinations of parameter settings.</div><div><a href='http://arxiv.org/abs/2401.13410v1'>2401.13410v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00219v1")'>FedCore: Straggler-Free Federated Learning with Distributed Coresets</div>
<div id='2402.00219v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-31T22:40:49Z</div><div>Authors: Hongpeng Guo, Haotian Gu, Xiaoyang Wang, Bo Chen, Eun Kyung Lee, Tamar Eilam, Deming Chen, Klara Nahrstedt</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) is a machine learning paradigm that allows multiple
clients to collaboratively train a shared model while keeping their data
on-premise. However, the straggler issue, due to slow clients, often hinders
the efficiency and scalability of FL. This paper presents FedCore, an algorithm
that innovatively tackles the straggler problem via the decentralized selection
of coresets, representative subsets of a dataset. Contrary to existing
centralized coreset methods, FedCore creates coresets directly on each client
in a distributed manner, ensuring privacy preservation in FL. FedCore
translates the coreset optimization problem into a more tractable k-medoids
clustering problem and operates distributedly on each client. Theoretical
analysis confirms FedCore's convergence, and practical evaluations demonstrate
an 8x reduction in FL training time, without compromising model accuracy. Our
extensive evaluations also show that FedCore generalizes well to existing FL
frameworks.</div><div><a href='http://arxiv.org/abs/2402.00219v1'>2402.00219v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07295v1")'>Training Heterogeneous Client Models using Knowledge Distillation in
  Serverless Federated Learning</div>
<div id='2402.07295v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-11T20:15:52Z</div><div>Authors: Mohak Chadha, Pulkit Khera, Jianfeng Gu, Osama Abboud, Michael Gerndt</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) is an emerging machine learning paradigm that enables
the collaborative training of a shared global model across distributed clients
while keeping the data decentralized. Recent works on designing systems for
efficient FL have shown that utilizing serverless computing technologies,
particularly Function-as-a-Service (FaaS) for FL, can enhance resource
efficiency, reduce training costs, and alleviate the complex infrastructure
management burden on data holders. However, existing serverless FL systems
implicitly assume a uniform global model architecture across all participating
clients during training. This assumption fails to address fundamental
challenges in practical FL due to the resource and statistical data
heterogeneity among FL clients. To address these challenges and enable
heterogeneous client models in serverless FL, we utilize Knowledge Distillation
(KD) in this paper. Towards this, we propose novel optimized serverless
workflows for two popular conventional federated KD techniques, i.e., FedMD and
FedDF. We implement these workflows by introducing several extensions to an
open-source serverless FL system called FedLess. Moreover, we comprehensively
evaluate the two strategies on multiple datasets across varying levels of
client data heterogeneity using heterogeneous client models with respect to
accuracy, fine-grained training times, and costs. Results from our experiments
demonstrate that serverless FedDF is more robust to extreme non-IID data
distributions, is faster, and leads to lower costs than serverless FedMD. In
addition, compared to the original implementation, our optimizations for
particular steps in FedMD and FedDF lead to an average speedup of 3.5x and
1.76x across all datasets.</div><div><a href='http://arxiv.org/abs/2402.07295v1'>2402.07295v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13236v1")'>How to Collaborate: Towards Maximizing the Generalization Performance in
  Cross-Silo Federated Learning</div>
<div id='2401.13236v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T05:41:34Z</div><div>Authors: Yuchang Sun, Marios Kountouris, Jun Zhang</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) has attracted vivid attention as a privacy-preserving
distributed learning framework. In this work, we focus on cross-silo FL, where
clients become the model owners after training and are only concerned about the
model's generalization performance on their local data. Due to the data
heterogeneity issue, asking all the clients to join a single FL training
process may result in model performance degradation. To investigate the
effectiveness of collaboration, we first derive a generalization bound for each
client when collaborating with others or when training independently. We show
that the generalization performance of a client can be improved only by
collaborating with other clients that have more training data and similar data
distribution. Our analysis allows us to formulate a client utility maximization
problem by partitioning clients into multiple collaborating groups. A
hierarchical clustering-based collaborative training (HCCT) scheme is then
proposed, which does not need to fix in advance the number of groups. We
further analyze the convergence of HCCT for general non-convex loss functions
which unveils the effect of data similarity among clients. Extensive
simulations show that HCCT achieves better generalization performance than
baseline schemes, whereas it degenerates to independent training and
conventional FL in specific scenarios.</div><div><a href='http://arxiv.org/abs/2401.13236v1'>2401.13236v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.13989v1")'>FedADMM-InSa: An Inexact and Self-Adaptive ADMM for Federated Learning</div>
<div id='2402.13989v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-21T18:19:20Z</div><div>Authors: Yongcun Song, Ziqi Wang, Enrique Zuazua</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) is a promising framework for learning from
distributed data while maintaining privacy. The development of efficient FL
algorithms encounters various challenges, including heterogeneous data and
systems, limited communication capacities, and constrained local computational
resources. Recently developed FedADMM methods show great resilience to both
data and system heterogeneity. However, they still suffer from performance
deterioration if the hyperparameters are not carefully tuned. To address this
issue, we propose an inexact and self-adaptive FedADMM algorithm, termed
FedADMM-InSa. First, we design an inexactness criterion for the clients' local
updates to eliminate the need for empirically setting the local training
accuracy. This inexactness criterion can be assessed by each client
independently based on its unique condition, thereby reducing the local
computational cost and mitigating the undesirable straggle effect. The
convergence of the resulting inexact ADMM is proved under the assumption of
strongly convex loss functions. Additionally, we present a self-adaptive scheme
that dynamically adjusts each client's penalty parameter, enhancing algorithm
robustness by mitigating the need for empirical penalty parameter choices for
each client. Extensive numerical experiments on both synthetic and real-world
datasets are conducted. As validated by some numerical tests, our proposed
algorithm can reduce the clients' local computational load significantly and
also accelerate the learning process compared to the vanilla FedADMM.</div><div><a href='http://arxiv.org/abs/2402.13989v1'>2402.13989v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07011v2")'>FedImpro: Measuring and Improving Client Update in Federated Learning</div>
<div id='2402.07011v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-10T18:14:57Z</div><div>Authors: Zhenheng Tang, Yonggang Zhang, Shaohuai Shi, Xinmei Tian, Tongliang Liu, Bo Han, Xiaowen Chu</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) models often experience client drift caused by
heterogeneous data, where the distribution of data differs across clients. To
address this issue, advanced research primarily focuses on manipulating the
existing gradients to achieve more consistent client models. In this paper, we
present an alternative perspective on client drift and aim to mitigate it by
generating improved local models. First, we analyze the generalization
contribution of local training and conclude that this generalization
contribution is bounded by the conditional Wasserstein distance between the
data distribution of different clients. Then, we propose FedImpro, to construct
similar conditional distributions for local training. Specifically, FedImpro
decouples the model into high-level and low-level components, and trains the
high-level portion on reconstructed feature distributions. This approach
enhances the generalization contribution and reduces the dissimilarity of
gradients in FL. Experimental results show that FedImpro can help FL defend
against data heterogeneity and enhance the generalization performance of the
model.</div><div><a href='http://arxiv.org/abs/2402.07011v2'>2402.07011v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.04928v1")'>Relaxed Contrastive Learning for Federated Learning</div>
<div id='2401.04928v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-10T04:55:24Z</div><div>Authors: Seonguk Seo, Jinkyu Kim, Geeho Kim, Bohyung Han</div><div style='padding-top: 10px; width: 80ex'>We propose a novel contrastive learning framework to effectively address the
challenges of data heterogeneity in federated learning. We first analyze the
inconsistency of gradient updates across clients during local training and
establish its dependence on the distribution of feature representations,
leading to the derivation of the supervised contrastive learning (SCL)
objective to mitigate local deviations. In addition, we show that a na\"ive
adoption of SCL in federated learning leads to representation collapse,
resulting in slow convergence and limited performance gains. To address this
issue, we introduce a relaxed contrastive learning loss that imposes a
divergence penalty on excessively similar sample pairs within each class. This
strategy prevents collapsed representations and enhances feature
transferability, facilitating collaborative training and leading to significant
performance improvements. Our framework outperforms all existing federated
learning approaches by huge margins on the standard benchmarks through
extensive experimental results.</div><div><a href='http://arxiv.org/abs/2401.04928v1'>2401.04928v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09941v1")'>FedLion: Faster Adaptive Federated Optimization with Fewer Communication</div>
<div id='2402.09941v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-15T13:41:23Z</div><div>Authors: Zhiwei Tang, Tsung-Hui Chang</div><div style='padding-top: 10px; width: 80ex'>In Federated Learning (FL), a framework to train machine learning models
across distributed data, well-known algorithms like FedAvg tend to have slow
convergence rates, resulting in high communication costs during training. To
address this challenge, we introduce FedLion, an adaptive federated
optimization algorithm that seamlessly incorporates key elements from the
recently proposed centralized adaptive algorithm, Lion (Chen et al. 2o23), into
the FL framework. Through comprehensive evaluations on two widely adopted FL
benchmarks, we demonstrate that FedLion outperforms previous state-of-the-art
adaptive algorithms, including FAFED (Wu et al. 2023) and FedDA. Moreover,
thanks to the use of signed gradients in local training, FedLion substantially
reduces data transmission requirements during uplink communication when
compared to existing adaptive algorithms, further reducing communication costs.
Last but not least, this work also includes a novel theoretical analysis,
showcasing that FedLion attains faster convergence rate than established FL
algorithms like FedAvg.</div><div><a href='http://arxiv.org/abs/2402.09941v1'>2402.09941v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.11041v1")'>FAGH: Accelerating Federated Learning with Approximated Global Hessian</div>
<div id='2403.11041v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-16T23:24:03Z</div><div>Authors: Mrinmay Sen, A. K. Qin, Krishna Mohan C</div><div style='padding-top: 10px; width: 80ex'>In federated learning (FL), the significant communication overhead due to the
slow convergence speed of training the global model poses a great challenge.
Specifically, a large number of communication rounds are required to achieve
the convergence in FL. One potential solution is to employ the Newton-based
optimization method for training, known for its quadratic convergence rate.
However, the existing Newton-based FL training methods suffer from either
memory inefficiency or high computational costs for local clients or the
server. To address this issue, we propose an FL with approximated global
Hessian (FAGH) method to accelerate FL training. FAGH leverages the first
moment of the approximated global Hessian and the first moment of the global
gradient to train the global model. By harnessing the approximated global
Hessian curvature, FAGH accelerates the convergence of global model training,
leading to the reduced number of communication rounds and thus the shortened
training time. Experimental results verify FAGH's effectiveness in decreasing
the number of communication rounds and the time required to achieve the
pre-specified objectives of the global model performance in terms of training
and test losses as well as test accuracy. Notably, FAGH outperforms several
state-of-the-art FL training methods.</div><div><a href='http://arxiv.org/abs/2403.11041v1'>2403.11041v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.11198v1")'>Achieving Linear Speedup in Asynchronous Federated Learning with
  Heterogeneous Clients</div>
<div id='2402.11198v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-17T05:22:46Z</div><div>Authors: Xiaolu Wang, Zijian Li, Shi Jin, Jun Zhang</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) is an emerging distributed training paradigm that
aims to learn a common global model without exchanging or transferring the data
that are stored locally at different clients. The Federated Averaging
(FedAvg)-based algorithms have gained substantial popularity in FL to reduce
the communication overhead, where each client conducts multiple localized
iterations before communicating with a central server. In this paper, we focus
on FL where the clients have diverse computation and/or communication
capabilities. Under this circumstance, FedAvg can be less efficient since it
requires all clients that participate in the global aggregation in a round to
initiate iterations from the latest global model, and thus the synchronization
among fast clients and straggler clients can severely slow down the overall
training process. To address this issue, we propose an efficient asynchronous
federated learning (AFL) framework called Delayed Federated Averaging
(DeFedAvg). In DeFedAvg, the clients are allowed to perform local training with
different stale global models at their own paces. Theoretical analyses
demonstrate that DeFedAvg achieves asymptotic convergence rates that are on par
with the results of FedAvg for solving nonconvex problems. More importantly,
DeFedAvg is the first AFL algorithm that provably achieves the desirable linear
speedup property, which indicates its high scalability. Additionally, we carry
out extensive numerical experiments using real datasets to validate the
efficiency and scalability of our approach when training deep neural networks.</div><div><a href='http://arxiv.org/abs/2402.11198v1'>2402.11198v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04206v1")'>GRAWA: Gradient-based Weighted Averaging for Distributed Training of
  Deep Learning Models</div>
<div id='2403.04206v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T04:22:34Z</div><div>Authors: Tolga Dimlioglu, Anna Choromanska</div><div style='padding-top: 10px; width: 80ex'>We study distributed training of deep learning models in time-constrained
environments. We propose a new algorithm that periodically pulls workers
towards the center variable computed as a weighted average of workers, where
the weights are inversely proportional to the gradient norms of the workers
such that recovering the flat regions in the optimization landscape is
prioritized. We develop two asynchronous variants of the proposed algorithm
that we call Model-level and Layer-level Gradient-based Weighted Averaging
(resp. MGRAWA and LGRAWA), which differ in terms of the weighting scheme that
is either done with respect to the entire model or is applied layer-wise. On
the theoretical front, we prove the convergence guarantee for the proposed
approach in both convex and non-convex settings. We then experimentally
demonstrate that our algorithms outperform the competitor methods by achieving
faster convergence and recovering better quality and flatter local optima. We
also carry out an ablation study to analyze the scalability of the proposed
algorithms in more crowded distributed training environments. Finally, we
report that our approach requires less frequent communication and fewer
distributed updates compared to the state-of-the-art baselines.</div><div><a href='http://arxiv.org/abs/2403.04206v1'>2403.04206v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.02447v1")'>Breaking MLPerf Training: A Case Study on Optimizing BERT</div>
<div id='2402.02447v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-04T11:12:17Z</div><div>Authors: Yongdeok Kim, Jaehyung Ahn, Myeongwoo Kim, Changin Choi, Heejae Kim, Narankhuu Tuvshinjargal, Seungwon Lee, Yanzi Zhang, Yuan Pei, Xiongzhan Linghu, Jingkun Ma, Lin Chen, Yuehua Dai, Sungjoo Yoo</div><div style='padding-top: 10px; width: 80ex'>Speeding up the large-scale distributed training is challenging in that it
requires improving various components of training including load balancing,
communication, optimizers, etc. We present novel approaches for fast
large-scale training of BERT model which individually ameliorates each
component thereby leading to a new level of BERT training performance. Load
balancing is imperative in distributed BERT training since its training
datasets are characterized by samples with various lengths. Communication cost,
which is proportional to the scale of distributed training, needs to be hidden
by useful computation. In addition, the optimizers, e.g., ADAM, LAMB, etc.,
need to be carefully re-evaluated in the context of large-scale distributed
training. We propose two new ideas, (1) local presorting based on dataset
stratification for load balancing and (2) bucket-wise gradient clipping before
allreduce which allows us to benefit from the overlap of gradient computation
and synchronization as well as the fast training of gradient clipping before
allreduce. We also re-evaluate existing optimizers via hyperparameter
optimization and utilize ADAM, which also contributes to fast training via
larger batches than existing methods. Our proposed methods, all combined, give
the fastest MLPerf BERT training of 25.1 (22.3) seconds on 1,024 NVIDIA A100
GPUs, which is 1.33x (1.13x) and 1.57x faster than the other top two (one)
submissions to MLPerf v1.1 (v2.0). Our implementation and evaluation results
are available at MLPerf v1.1~v2.1.</div><div><a href='http://arxiv.org/abs/2402.02447v1'>2402.02447v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.13781v1")'>Preserving Near-Optimal Gradient Sparsification Cost for Scalable
  Distributed Deep Learning</div>
<div id='2402.13781v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-21T13:00:44Z</div><div>Authors: Daegun Yoon, Sangyoon Oh</div><div style='padding-top: 10px; width: 80ex'>Communication overhead is a major obstacle to scaling distributed training
systems. Gradient sparsification is a potential optimization approach to reduce
the communication volume without significant loss of model fidelity. However,
existing gradient sparsification methods have low scalability owing to
inefficient design of their algorithms, which raises the communication overhead
significantly. In particular, gradient build-up and inadequate sparsity control
methods degrade the sparsification performance considerably. Moreover,
communication traffic increases drastically owing to workload imbalance of
gradient selection between workers.
  To address these challenges, we propose a novel gradient sparsification
scheme called ExDyna. In ExDyna, the gradient tensor of the model comprises
fined-grained blocks, and contiguous blocks are grouped into non-overlapping
partitions. Each worker selects gradients in its exclusively allocated
partition so that gradient build-up never occurs. To balance the workload of
gradient selection between workers, ExDyna adjusts the topology of partitions
by comparing the workloads of adjacent partitions. In addition, ExDyna supports
online threshold scaling, which estimates the accurate threshold of gradient
selection on-the-fly. Accordingly, ExDyna can satisfy the user-required
sparsity level during a training period regardless of models and datasets.
Therefore, ExDyna can enhance the scalability of distributed training systems
by preserving near-optimal gradient sparsification cost. In experiments, ExDyna
outperformed state-of-the-art sparsifiers in terms of training speed and
sparsification performance while achieving high accuracy.</div><div><a href='http://arxiv.org/abs/2402.13781v1'>2402.13781v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.07496v1")'>Low-Rank Gradient Compression with Error Feedback for MIMO Wireless
  Federated Learning</div>
<div id='2401.07496v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T06:30:06Z</div><div>Authors: Mingzhao Guo, Dongzhu Liu, Osvaldo Simeone, Dingzhu Wen</div><div style='padding-top: 10px; width: 80ex'>This paper presents a novel approach to enhance the communication efficiency
of federated learning (FL) in multiple input and multiple output (MIMO)
wireless systems. The proposed method centers on a low-rank matrix
factorization strategy for local gradient compression based on alternating
least squares, along with over-the-air computation and error feedback. The
proposed protocol, termed over-the-air low-rank compression (Ota-LC), is
demonstrated to have lower computation cost and lower communication overhead as
compared to existing benchmarks while guaranteeing the same inference
performance. As an example, when targeting a test accuracy of 80% on the
Cifar-10 dataset, Ota-LC achieves a reduction in total communication costs of
at least 30% when contrasted with benchmark schemes, while also reducing the
computational complexity order by a factor equal to the sum of the dimension of
the gradients.</div><div><a href='http://arxiv.org/abs/2401.07496v1'>2401.07496v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15166v1")'>Convergence Analysis of Split Federated Learning on Heterogeneous Data</div>
<div id='2402.15166v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-23T07:59:23Z</div><div>Authors: Pengchao Han, Chao Huang, Geng Tian, Ming Tang, Xin Liu</div><div style='padding-top: 10px; width: 80ex'>Split federated learning (SFL) is a recent distributed approach for
collaborative model training among multiple clients. In SFL, a global model is
typically split into two parts, where clients train one part in a parallel
federated manner, and a main server trains the other. Despite the recent
research on SFL algorithm development, the convergence analysis of SFL is
missing in the literature, and this paper aims to fill this gap. The analysis
of SFL can be more challenging than that of federated learning (FL), due to the
potential dual-paced updates at the clients and the main server. We provide
convergence analysis of SFL for strongly convex and general convex objectives
on heterogeneous data. The convergence rates are $O(1/T)$ and
$O(1/\sqrt[3]{T})$, respectively, where $T$ denotes the total number of rounds
for SFL training. We further extend the analysis to non-convex objectives and
where some clients may be unavailable during training. Numerical experiments
validate our theoretical results and show that SFL outperforms FL and split
learning (SL) when data is highly heterogeneous across a large number of
clients.</div><div><a href='http://arxiv.org/abs/2402.15166v1'>2402.15166v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.18018v1")'>Communication Efficient ConFederated Learning: An Event-Triggered SAGA
  Approach</div>
<div id='2402.18018v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-28T03:27:10Z</div><div>Authors: Bin Wang, Jun Fang, Hongbin Li, Yonina C. Eldar</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) is a machine learning paradigm that targets model
training without gathering the local data dispersed over various data sources.
Standard FL, which employs a single server, can only support a limited number
of users, leading to degraded learning capability. In this work, we consider a
multi-server FL framework, referred to as \emph{Confederated Learning} (CFL),
in order to accommodate a larger number of users. A CFL system is composed of
multiple networked edge servers, with each server connected to an individual
set of users. Decentralized collaboration among servers is leveraged to harness
all users' data for model training. Due to the potentially massive number of
users involved, it is crucial to reduce the communication overhead of the CFL
system. We propose a stochastic gradient method for distributed learning in the
CFL framework. The proposed method incorporates a conditionally-triggered user
selection (CTUS) mechanism as the central component to effectively reduce
communication overhead. Relying on a delicately designed triggering condition,
the CTUS mechanism allows each server to select only a small number of users to
upload their gradients, without significantly jeopardizing the convergence
performance of the algorithm. Our theoretical analysis reveals that the
proposed algorithm enjoys a linear convergence rate. Simulation results show
that it achieves substantial improvement over state-of-the-art algorithms in
terms of communication efficiency.</div><div><a href='http://arxiv.org/abs/2402.18018v1'>2402.18018v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04037v1")'>OCD-FL: A Novel Communication-Efficient Peer Selection-based
  Decentralized Federated Learning</div>
<div id='2403.04037v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T20:34:08Z</div><div>Authors: Nizar Masmoudi, Wael Jaafar</div><div style='padding-top: 10px; width: 80ex'>The conjunction of edge intelligence and the ever-growing Internet-of-Things
(IoT) network heralds a new era of collaborative machine learning, with
federated learning (FL) emerging as the most prominent paradigm. With the
growing interest in these learning schemes, researchers started addressing some
of their most fundamental limitations. Indeed, conventional FL with a central
aggregator presents a single point of failure and a network bottleneck. To
bypass this issue, decentralized FL where nodes collaborate in a peer-to-peer
network has been proposed. Despite the latter's efficiency, communication costs
and data heterogeneity remain key challenges in decentralized FL. In this
context, we propose a novel scheme, called opportunistic
communication-efficient decentralized federated learning, a.k.a., OCD-FL,
consisting of a systematic FL peer selection for collaboration, aiming to
achieve maximum FL knowledge gain while reducing energy consumption.
Experimental results demonstrate the capability of OCD-FL to achieve similar or
better performances than the fully collaborative FL, while significantly
reducing consumed energy by at least 30% and up to 80%.</div><div><a href='http://arxiv.org/abs/2403.04037v1'>2403.04037v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.12356v1")'>Efficient Collaborations through Weight-Driven Coalition Dynamics in
  Federated Learning Systems</div>
<div id='2401.12356v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-22T20:50:01Z</div><div>Authors: Mohammed El Hanjri, Hamza Reguieg, Adil Attiaoui, Amine Abouaomar, Abdellatif Kobbane, Mohamed El Kamili</div><div style='padding-top: 10px; width: 80ex'>In the era of the Internet of Things (IoT), decentralized paradigms for
machine learning are gaining prominence. In this paper, we introduce a
federated learning model that capitalizes on the Euclidean distance between
device model weights to assess their similarity and disparity. This is
foundational for our system, directing the formation of coalitions among
devices based on the closeness of their model weights. Furthermore, the concept
of a barycenter, representing the average of model weights, helps in the
aggregation of updates from multiple devices. We evaluate our approach using
homogeneous and heterogeneous data distribution, comparing it against
traditional federated learning averaging algorithm. Numerical results
demonstrate its potential in offering structured, outperformed and
communication-efficient model for IoT-based machine learning.</div><div><a href='http://arxiv.org/abs/2401.12356v1'>2401.12356v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.07903v1")'>Multiple Access in the Era of Distributed Computing and Edge
  Intelligence</div>
<div id='2403.07903v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T11:04:04Z</div><div>Authors: Nikos G. Evgenidis, Nikos A. Mitsiou, Vasiliki I. Koutsioumpa, Sotiris A. Tegos, Panagiotis D. Diamantoulakis, George K. Karagiannidis</div><div style='padding-top: 10px; width: 80ex'>This paper focuses on the latest research and innovations in fundamental
next-generation multiple access (NGMA) techniques and the coexistence with
other key technologies for the sixth generation (6G) of wireless networks. In
more detail, we first examine multi-access edge computing (MEC), which is
critical to meeting the growing demand for data processing and computational
capacity at the edge of the network, as well as network slicing. We then
explore over-the-air (OTA) computing, which is considered to be an approach
that provides fast and efficient computation of various functions. We also
explore semantic communications, identified as an effective way to improve
communication systems by focusing on the exchange of meaningful information,
thus minimizing unnecessary data and increasing efficiency. The
interrelationship between machine learning (ML) and multiple access
technologies is also reviewed, with an emphasis on federated learning,
federated distillation, split learning, reinforcement learning, and the
development of ML-based multiple access protocols. Finally, the concept of
digital twinning and its role in network management is discussed, highlighting
how virtual replication of physical networks can lead to improvements in
network efficiency and reliability.</div><div><a href='http://arxiv.org/abs/2403.07903v1'>2403.07903v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.07573v1")'>Towards a Dynamic Future with Adaptable Computing and Network
  Convergence (ACNC)</div>
<div id='2403.07573v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T12:03:16Z</div><div>Authors: Masoud Shokrnezhad, Hao Yu, Tarik Taleb, Richard Li, Kyunghan Lee, Jaeseung Song, Cedric Westphal</div><div style='padding-top: 10px; width: 80ex'>In the context of advancing 6G, a substantial paradigm shift is anticipated,
highlighting comprehensive everything-to-everything interactions characterized
by numerous connections and stringent adherence to Quality of
Service/Experience (QoS/E) prerequisites. The imminent challenge stems from
resource scarcity, prompting a deliberate transition to Computing-Network
Convergence (CNC) as an auspicious approach for joint resource orchestration.
While CNC-based mechanisms have garnered attention, their effectiveness in
realizing future services, particularly in use cases like the Metaverse, may
encounter limitations due to the continually changing nature of users,
services, and resources. Hence, this paper presents the concept of Adaptable
CNC (ACNC) as an autonomous Machine Learning (ML)-aided mechanism crafted for
the joint orchestration of computing and network resources, catering to dynamic
and voluminous user requests with stringent requirements. ACNC encompasses two
primary functionalities: state recognition and context detection. Given the
intricate nature of the user-service-computing-network space, the paper employs
dimension reduction to generate live, holistic, abstract system states in a
hierarchical structure. To address the challenges posed by dynamic changes,
Continual Learning (CL) is employed, classifying the system state into contexts
controlled by dedicated ML agents, enabling them to operate efficiently. These
two functionalities are intricately linked within a closed loop overseen by the
End-to-End (E2E) orchestrator to allocate resources. The paper introduces the
components of ACNC, proposes a Metaverse scenario to exemplify ACNC's role in
resource provisioning with Segment Routing v6 (SRv6), outlines ACNC's workflow,
details a numerical analysis for efficiency assessment, and concludes with
discussions on relevant challenges and potential avenues for future research.</div><div><a href='http://arxiv.org/abs/2403.07573v1'>2403.07573v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.05158v1")'>Adaptive Split Learning over Energy-Constrained Wireless Edge Networks</div>
<div id='2403.05158v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-08T08:51:37Z</div><div>Authors: Zuguang Li, Wen Wu, Shaohua Wu, Wei Wang</div><div style='padding-top: 10px; width: 80ex'>Split learning (SL) is a promising approach for training artificial
intelligence (AI) models, in which devices collaborate with a server to train
an AI model in a distributed manner, based on a same fixed split point.
However, due to the device heterogeneity and variation of channel conditions,
this way is not optimal in training delay and energy consumption. In this
paper, we design an adaptive split learning (ASL) scheme which can dynamically
select split points for devices and allocate computing resource for the server
in wireless edge networks. We formulate an optimization problem to minimize the
average training latency subject to long-term energy consumption constraint.
The difficulties in solving this problem are the lack of future information and
mixed integer programming (MIP). To solve it, we propose an online algorithm
leveraging the Lyapunov theory, named OPEN, which decomposes it into a new MIP
problem only with the current information. Then, a two-layer optimization
method is proposed to solve the MIP problem. Extensive simulation results
demonstrate that the ASL scheme can reduce the average training delay and
energy consumption by 53.7% and 22.1%, respectively, as compared to the
existing SL schemes.</div><div><a href='http://arxiv.org/abs/2403.05158v1'>2403.05158v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.06308v1")'>A Semantic-Aware Multiple Access Scheme for Distributed, Dynamic
  6G-Based Applications</div>
<div id='2401.06308v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-12T00:32:38Z</div><div>Authors: Hamidreza Mazandarani, Masoud Shokrnezhad, Tarik Taleb</div><div style='padding-top: 10px; width: 80ex'>The emergence of the semantic-aware paradigm presents opportunities for
innovative services, especially in the context of 6G-based applications.
Although significant progress has been made in semantic extraction techniques,
the incorporation of semantic information into resource allocation
decision-making is still in its early stages, lacking consideration of the
requirements and characteristics of future systems. In response, this paper
introduces a novel formulation for the problem of multiple access to the
wireless spectrum. It aims to optimize the utilization-fairness trade-off,
using the $\alpha$-fairness metric, while accounting for user data correlation
by introducing the concepts of self- and assisted throughputs. Initially, the
problem is analyzed to identify its optimal solution. Subsequently, a
Semantic-Aware Multi-Agent Double and Dueling Deep Q-Learning (SAMA-D3QL)
technique is proposed. This method is grounded in Model-free Multi-Agent Deep
Reinforcement Learning (MADRL), enabling the user equipment to autonomously
make decisions regarding wireless spectrum access based solely on their local
individual observations. The efficiency of the proposed technique is evaluated
through two scenarios: single-channel and multi-channel. The findings
illustrate that, across a spectrum of $\alpha$ values, association matrices,
and channels, SAMA-D3QL consistently outperforms alternative approaches. This
establishes it as a promising candidate for facilitating the realization of
future federated, dynamically evolving applications.</div><div><a href='http://arxiv.org/abs/2401.06308v1'>2401.06308v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.17773v1")'>SINR-Aware Deep Reinforcement Learning for Distributed Dynamic Channel
  Allocation in Cognitive Interference Networks</div>
<div id='2402.17773v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-17T20:03:02Z</div><div>Authors: Yaniv Cohen, Tomer Gafni, Ronen Greenberg, Kobi Cohen</div><div style='padding-top: 10px; width: 80ex'>We consider the problem of dynamic channel allocation (DCA) in cognitive
communication networks with the goal of maximizing a global
signal-to-interference-plus-noise ratio (SINR) measure under a specified target
quality of service (QoS)-SINR for each network. The shared bandwidth is
partitioned into K channels with frequency separation. In contrast to the
majority of existing studies that assume perfect orthogonality or a one- to-one
user-channel allocation mapping, this paper focuses on real-world systems
experiencing inter-carrier interference (ICI) and channel reuse by multiple
large-scale networks. This realistic scenario significantly increases the
problem dimension, rendering existing algorithms inefficient. We propose a
novel multi-agent reinforcement learning (RL) framework for distributed DCA,
named Channel Allocation RL To Overlapped Networks (CARLTON). The CARLTON
framework is based on the Centralized Training with Decentralized Execution
(CTDE) paradigm, utilizing the DeepMellow value-based RL algorithm. To ensure
robust performance in the interference-laden environment we address, CARLTON
employs a low-dimensional representation of observations, generating a QoS-type
measure while maximizing a global SINR measure and ensuring the target QoS-SINR
for each network. Our results demonstrate exceptional performance and robust
generalization, showcasing superior efficiency compared to alternative
state-of-the-art methods, while achieving a marginally diminished performance
relative to a fully centralized approach.</div><div><a href='http://arxiv.org/abs/2402.17773v1'>2402.17773v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00879v1")'>Graph Representation Learning for Contention and Interference Management
  in Wireless Networks</div>
<div id='2402.00879v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T22:23:06Z</div><div>Authors: Zhouyou Gu, Branka Vucetic, Kishore Chikkam, Pasquale Aliberti, Wibowo Hardjawana</div><div style='padding-top: 10px; width: 80ex'>Restricted access window (RAW) in Wi-Fi 802.11ah networks manages contention
and interference by grouping users and allocating periodic time slots for each
group's transmissions. We will find the optimal user grouping decisions in RAW
to maximize the network's worst-case user throughput. We review existing user
grouping approaches and highlight their performance limitations in the above
problem. We propose formulating user grouping as a graph construction problem
where vertices represent users and edge weights indicate the contention and
interference. This formulation leverages the graph's max cut to group users and
optimizes edge weights to construct the optimal graph whose max cut yields the
optimal grouping decisions. To achieve this optimal graph construction, we
design an actor-critic graph representation learning (AC-GRL) algorithm.
Specifically, the actor neural network (NN) is trained to estimate the optimal
graph's edge weights using path losses between users and access points. A graph
cut procedure uses semidefinite programming to solve the max cut efficiently
and return the grouping decisions for the given weights. The critic NN
approximates user throughput achieved by the above-returned decisions and is
used to improve the actor. Additionally, we present an architecture that uses
the online-measured throughput and path losses to fine-tune the decisions in
response to changes in user populations and their locations. Simulations show
that our methods achieve $30\%\sim80\%$ higher worst-case user throughput than
the existing approaches and that the proposed architecture can further improve
the worst-case user throughput by $5\%\sim30\%$ while ensuring timely updates
of grouping decisions.</div><div><a href='http://arxiv.org/abs/2402.00879v1'>2402.00879v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.01665v1")'>Knowledge-Driven Deep Learning Paradigms for Wireless Network
  Optimization in 6G</div>
<div id='2402.01665v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T07:47:30Z</div><div>Authors: Ruijin Sun, Nan Cheng, Changle Li, Fangjiong Chen, Wen Chen</div><div style='padding-top: 10px; width: 80ex'>In the sixth-generation (6G) networks, newly emerging diversified services of
massive users in dynamic network environments are required to be satisfied by
multi-dimensional heterogeneous resources. The resulting large-scale
complicated network optimization problems are beyond the capability of
model-based theoretical methods due to the overwhelming computational
complexity and the long processing time. Although with fast online inference
and universal approximation ability, data-driven deep learning (DL) heavily
relies on abundant training data and lacks interpretability. To address these
issues, a new paradigm called knowledge-driven DL has emerged, aiming to
integrate proven domain knowledge into the construction of neural networks,
thereby exploiting the strengths of both methods. This article provides a
systematic review of knowledge-driven DL in wireless networks. Specifically, a
holistic framework of knowledge-driven DL in wireless networks is proposed,
where knowledge sources, knowledge representation, knowledge integration and
knowledge application are forming as a closed loop. Then, a detailed taxonomy
of knowledge integration approaches, including knowledge-assisted,
knowledge-fused, and knowledge-embedded DL, is presented. Several open issues
for future research are also discussed. The insights offered in this article
provide a basic principle for the design of network optimization that
incorporates communication-specific domain knowledge and DL, facilitating the
realization of intelligent 6G networks.</div><div><a href='http://arxiv.org/abs/2402.01665v1'>2402.01665v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13206v1")'>Self-Improving Interference Management Based on Deep Learning With
  Uncertainty Quantification</div>
<div id='2401.13206v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T03:28:48Z</div><div>Authors: Hyun-Suk Lee, Do-Yup Kim, Kyungsik Min</div><div style='padding-top: 10px; width: 80ex'>This paper presents a groundbreaking self-improving interference management
framework tailored for wireless communications, integrating deep learning with
uncertainty quantification to enhance overall system performance. Our approach
addresses the computational challenges inherent in traditional
optimization-based algorithms by harnessing deep learning models to predict
optimal interference management solutions. A significant breakthrough of our
framework is its acknowledgment of the limitations inherent in data-driven
models, particularly in scenarios not adequately represented by the training
dataset. To overcome these challenges, we propose a method for uncertainty
quantification, accompanied by a qualifying criterion, to assess the
trustworthiness of model predictions. This framework strategically alternates
between model-generated solutions and traditional algorithms, guided by a
criterion that assesses the prediction credibility based on quantified
uncertainties. Experimental results validate the framework's efficacy,
demonstrating its superiority over traditional deep learning models, notably in
scenarios underrepresented in the training dataset. This work marks a
pioneering endeavor in harnessing self-improving deep learning for interference
management, through the lens of uncertainty quantification.</div><div><a href='http://arxiv.org/abs/2401.13206v1'>2401.13206v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.07255v1")'>Deep Learning-Assisted Parallel Interference Cancellation for Grant-Free
  NOMA in Machine-Type Communication</div>
<div id='2403.07255v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T02:24:37Z</div><div>Authors: Yongjeong Oh, Jaehong Jo, Byonghyo Shim, Yo-Seb Jeon</div><div style='padding-top: 10px; width: 80ex'>In this paper, we present a novel approach for joint activity detection (AD),
channel estimation (CE), and data detection (DD) in uplink grant-free
non-orthogonal multiple access (NOMA) systems. Our approach employs an
iterative and parallel interference removal strategy inspired by parallel
interference cancellation (PIC), enhanced with deep learning to jointly tackle
the AD, CE, and DD problems. Based on this approach, we develop three PIC
frameworks, each of which is designed for either coherent or non-coherence
schemes. The first framework performs joint AD and CE using received pilot
signals in the coherent scheme. Building upon this framework, the second
framework utilizes both the received pilot and data signals for CE, further
enhancing the performances of AD, CE, and DD in the coherent scheme. The third
framework is designed to accommodate the non-coherent scheme involving a small
number of data bits, which simultaneously performs AD and DD. Through joint
loss functions and interference cancellation modules, our approach supports
end-to-end training, contributing to enhanced performances of AD, CE, and DD
for both coherent and non-coherent schemes. Simulation results demonstrate the
superiority of our approach over traditional techniques, exhibiting enhanced
performances of AD, CE, and DD while maintaining lower computational
complexity.</div><div><a href='http://arxiv.org/abs/2403.07255v1'>2403.07255v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12595v1")'>Truncated Polynomial Expansion-Based Detection in Massive MIMO: A
  Model-Driven Deep Learning Approach</div>
<div id='2402.12595v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-19T23:19:15Z</div><div>Authors: Kazem Izadinasab, Ahmed Wagdy Shaban, Oussama Damen</div><div style='padding-top: 10px; width: 80ex'>In this paper, we propose a deep learning (DL)-based approach for efficiently
computing the inverse of Hermitian matrices using truncated polynomial
expansion (TPE). Our model-driven approach involves optimizing the coefficients
of the TPE during an offline training procedure for a given number of TPE
terms. We apply this method to signal detection in uplink massive
multiple-input multiple-output (MIMO) systems, where the matrix inverse
operation required by linear detectors, such as zero-forcing (ZF) and minimum
mean square error (MMSE), is approximated using TPE. Our simulation results
demonstrate that the proposed learned TPE-based method outperforms the
conventional TPE method with optimal coefficients in terms of asymptotic
convergence speed and reduces the computational complexity of the online
detection stage, albeit at the expense of the offline training stage. However,
the limited number of trainable parameters leads to a swift offline training
process.</div><div><a href='http://arxiv.org/abs/2402.12595v1'>2402.12595v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03771v1")'>Joint Sparsity Pattern Learning Based Channel Estimation for Massive
  MIMO-OTFS Systems</div>
<div id='2403.03771v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T15:05:39Z</div><div>Authors: Kuo Meng, Shaoshi Yang, Xiao-Yang Wang, Yan Bu, Yurong Tang, Jianhua Zhang, Lajos Hanzo</div><div style='padding-top: 10px; width: 80ex'>We propose a channel estimation scheme based on joint sparsity pattern
learning (JSPL) for massive multi-input multi-output (MIMO) orthogonal
time-frequency-space (OTFS) modulation aided systems. By exploiting the
potential joint sparsity of the delay-Doppler-angle (DDA) domain channel, the
channel estimation problem is transformed into a sparse recovery problem. To
solve it, we first apply the spike and slab prior model to iteratively estimate
the support set of the channel matrix, and a higher-accuracy parameter update
rule relying on the identified support set is introduced into the iteration.
Then the specific values of the channel elements corresponding to the support
set are estimated by the orthogonal matching pursuit (OMP) method. Both our
simulation results and analysis demonstrate that the proposed JSPL channel
estimation scheme achieves an improved performance over the representative
state-of-the-art baseline schemes, despite its reduced pilot overhead.</div><div><a href='http://arxiv.org/abs/2403.03771v1'>2403.03771v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.12627v1")'>Blind Channel Estimation and Joint Symbol Detection with Data-Driven
  Factor Graphs</div>
<div id='2401.12627v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-23T10:26:15Z</div><div>Authors: Luca Schmid, Tomer Raviv, Nir Shlezinger, Laurent Schmalen</div><div style='padding-top: 10px; width: 80ex'>We investigate the application of the factor graph framework for blind joint
channel estimation and symbol detection on time-variant linear inter-symbol
interference channels. In particular, we consider the expectation maximization
(EM) algorithm for maximum likelihood estimation, which typically suffers from
high complexity as it requires the computation of the symbol-wise posterior
distributions in every iteration. We address this issue by efficiently
approximating the posteriors using the belief propagation (BP) algorithm on a
suitable factor graph. By interweaving the iterations of BP and EM, the
detection complexity can be further reduced to a single BP iteration per EM
step. In addition, we propose a data-driven version of our algorithm that
introduces momentum in the BP updates and learns a suitable EM parameter update
schedule, thereby significantly improving the performance-complexity tradeoff
with a few offline training samples. Our numerical experiments demonstrate the
excellent performance of the proposed blind detector and show that it even
outperforms coherent BP detection in high signal-to-noise scenarios.</div><div><a href='http://arxiv.org/abs/2401.12627v1'>2401.12627v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.12106v1")'>Circular Belief Propagation for Approximate Probabilistic Inference</div>
<div id='2403.12106v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-17T15:59:39Z</div><div>Authors: Vincent Bouttier, Renaud Jardri, Sophie Deneve</div><div style='padding-top: 10px; width: 80ex'>Belief Propagation (BP) is a simple probabilistic inference algorithm,
consisting of passing messages between nodes of a graph representing a
probability distribution. Its analogy with a neural network suggests that it
could have far-ranging applications for neuroscience and artificial
intelligence. Unfortunately, it is only exact when applied to cycle-free
graphs, which restricts the potential of the algorithm. In this paper, we
propose Circular Belief Propagation (CBP), an extension of BP which limits the
detrimental effects of message reverberation caused by cycles by learning to
detect and cancel spurious correlations and belief amplifications. We show in
numerical experiments involving binary probabilistic graphs that CBP far
outperforms BP and reaches good performance compared to that of previously
proposed algorithms.</div><div><a href='http://arxiv.org/abs/2403.12106v1'>2403.12106v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.09440v1")'>Extreme Learning Machine-based Channel Estimation in IRS-Assisted
  Multi-User ISAC System</div>
<div id='2402.09440v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T14:15:11Z</div><div>Authors: Yu Liu, Ibrahim Al-Nahhal, Octavia A. Dobre, Fanggang Wang, Hyundong Shin</div><div style='padding-top: 10px; width: 80ex'>Multi-user integrated sensing and communication (ISAC) assisted by
intelligent reflecting surface (IRS) has been recently investigated to provide
a high spectral and energy efficiency transmission. This paper proposes a
practical channel estimation approach for the first time to an IRS-assisted
multiuser ISAC system. The estimation problem in such a system is challenging
since the sensing and communication (SAC) signals interfere with each other,
and the passive IRS lacks signal processing ability. A two-stage approach is
proposed to transfer the overall estimation problem into sub-ones, successively
including the direct and reflected channels estimation. Based on this scheme,
the ISAC base station (BS) estimates all the SAC channels associated with the
target and uplink users, while each downlink user estimates the downlink
communication channels individually. Considering a low-cost demand of the ISAC
BS and downlink users, the proposed two-stage approach is realized by an
efficient neural network (NN) framework that contains two different extreme
learning machine (ELM) structures to estimate the above SAC channels. Moreover,
two types of input-output pairs to train the ELMs are carefully devised, which
impact the estimation accuracy and computational complexity under different
system parameters. Simulation results reveal a substantial performance
improvement achieved by the proposed ELM-based approach over the least-squares
and NN-based benchmarks, with reduced training complexity and faster training
speed.</div><div><a href='http://arxiv.org/abs/2402.09440v1'>2402.09440v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09439v1")'>Deep-Learning-Based Channel Estimation for IRS-Assisted ISAC System</div>
<div id='2402.09439v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T14:14:39Z</div><div>Authors: Yu Liu, Ibrahim Al-Nahhal, Octavia A. Dobre, Fanggang Wang</div><div style='padding-top: 10px; width: 80ex'>Integrated sensing and communication (ISAC) and intelligent reflecting
surface (IRS) are viewed as promising technologies for future generations of
wireless networks. This paper investigates the channel estimation problem in an
IRS-assisted ISAC system. A deep-learning framework is proposed to estimate the
sensing and communication (S&amp;C) channels in such a system. Considering
different propagation environments of the S&amp;C channels, two deep neural network
(DNN) architectures are designed to realize this framework. The first DNN is
devised at the ISAC base station for estimating the sensing channel, while the
second DNN architecture is assigned to each downlink user equipment to estimate
its communication channel. Moreover, the input-output pairs to train the DNNs
are carefully designed. Simulation results show the superiority of the proposed
estimation approach compared to the benchmark scheme under various
signal-to-noise ratio conditions and system parameters.</div><div><a href='http://arxiv.org/abs/2402.09439v1'>2402.09439v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09441v1")'>Deep-Learning Channel Estimation for IRS-Assisted Integrated Sensing and
  Communication System</div>
<div id='2402.09441v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T14:15:48Z</div><div>Authors: Yu Liu, Ibrahim Al-Nahhal, Octavia A. Dobre, Fanggang Wang</div><div style='padding-top: 10px; width: 80ex'>Integrated sensing and communication (ISAC), and intelligent reflecting
surface (IRS) are envisioned as revolutionary technologies to enhance spectral
and energy efficiencies for next wireless system generations. For the first
time, this paper focuses on the channel estimation problem in an IRS-assisted
ISAC system. This problem is challenging due to the lack of signal processing
capacity in passive IRS, as well as the presence of mutual interference between
sensing and communication (SAC) signals in ISAC systems. A three-stage approach
is proposed to decouple the estimation problem into sub-ones, including the
estimation of the direct SAC channels in the first stage, reflected
communication channel in the second stage, and reflected sensing channel in the
third stage. The proposed three-stage approach is based on a deep-learning
framework, which involves two different convolutional neural network (CNN)
architectures to estimate the channels at the full-duplex ISAC base station.
Furthermore, two types of input-output pairs to train the CNNs are carefully
designed, which affect the estimation performance under various signal-to-noise
ratio conditions and system parameters. Simulation results validate the
superiority of the proposed estimation approach compared to the least-squares
baseline scheme, and its computational complexity is also analyzed.</div><div><a href='http://arxiv.org/abs/2402.09441v1'>2402.09441v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.03059v1")'>Reliability-Optimized User Admission Control for URLLC Traffic: A Neural
  Contextual Bandit Approach</div>
<div id='2401.03059v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-05T20:26:08Z</div><div>Authors: Omid Semiari, Hosein Nikopour, Shilpa Talwar</div><div style='padding-top: 10px; width: 80ex'>Ultra-reliable low-latency communication (URLLC) is the cornerstone for a
broad range of emerging services in next-generation wireless networks. URLLC
fundamentally relies on the network's ability to proactively determine whether
sufficient resources are available to support the URLLC traffic, and thus,
prevent so-called cell overloads. Nonetheless, achieving accurate
quality-of-service (QoS) predictions for URLLC user equipment (UEs) and
preventing cell overloads are very challenging tasks. This is due to dependency
of the QoS metrics (latency and reliability) on traffic and channel statistics,
users' mobility, and interdependent performance across UEs. In this paper, a
new QoS-aware UE admission control approach is developed to proactively
estimate QoS for URLLC UEs, prior to associating them with a cell, and
accordingly, admit only a subset of UEs that do not lead to a cell overload. To
this end, an optimization problem is formulated to find an efficient UE
admission control policy, cognizant of UEs' QoS requirements and cell-level
load dynamics. To solve this problem, a new machine learning based method is
proposed that builds on (deep) neural contextual bandits, a suitable framework
for dealing with nonlinear bandit problems. In fact, the UE admission
controller is treated as a bandit agent that observes a set of network
measurements (context) and makes admission control decisions based on
context-dependent QoS (reward) predictions. The simulation results show that
the proposed scheme can achieve near-optimal performance and yield substantial
gains in terms of cell-level service reliability and efficient resource
utilization.</div><div><a href='http://arxiv.org/abs/2401.03059v1'>2401.03059v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.16904v1")'>Selective Task offloading for Maximum Inference Accuracy and Energy
  efficient Real-Time IoT Sensing Systems</div>
<div id='2402.16904v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-24T18:46:06Z</div><div>Authors: Abdelkarim Ben Sada, Amar Khelloufi, Abdenacer Naouri, Huansheng Ning, Sahraoui Dhelim</div><div style='padding-top: 10px; width: 80ex'>The recent advancements in small-size inference models facilitated AI
deployment on the edge. However, the limited resource nature of edge devices
poses new challenges especially for real-time applications. Deploying multiple
inference models (or a single tunable model) varying in size and therefore
accuracy and power consumption, in addition to an edge server inference model,
can offer a dynamic system in which the allocation of inference models to
inference jobs is performed according to the current resource conditions.
Therefore, in this work, we tackle the problem of selectively allocating
inference models to jobs or offloading them to the edge server to maximize
inference accuracy under time and energy constraints. This problem is shown to
be an instance of the unbounded multidimensional knapsack problem which is
considered a strongly NP-hard problem. We propose a lightweight hybrid genetic
algorithm (LGSTO) to solve this problem. We introduce a termination condition
and neighborhood exploration techniques for faster evolution of populations. We
compare LGSTO with the Naive and Dynamic programming solutions. In addition to
classic genetic algorithms using different reproduction methods including
NSGA-II, and finally we compare to other evolutionary methods such as Particle
swarm optimization (PSO) and Ant colony optimization (ACO). Experiment results
show that LGSTO performed 3 times faster than the fastest comparable schemes
while producing schedules with higher average accuracy.</div><div><a href='http://arxiv.org/abs/2402.16904v1'>2402.16904v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15767v1")'>A Centralized Reinforcement Learning Framework for Adaptive Clustering
  with Low Control Overhead in IoT Networks</div>
<div id='2401.15767v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-28T21:08:45Z</div><div>Authors: F. Fernando Jurado-Lasso, J. F. Jurado, Xenofon Fafoutis</div><div style='padding-top: 10px; width: 80ex'>Wireless Sensor Networks (WSNs) play a pivotal role in enabling Internet of
Things (IoT) devices with sensing and actuation capabilities. Operating in
remote and resource-constrained environments, these IoT devices face challenges
related to energy consumption, crucial for network longevity. Clustering
protocols have emerged as an effective solution to alleviate energy burdens on
IoT devices. This paper introduces Low-Energy Adaptive Clustering Hierarchy
with Reinforcement Learning-based Controller (LEACH-RLC), a novel clustering
protocol that employs a Mixed Integer Linear Programming (MILP) for strategic
selection of cluster heads (CHs) and node-to-cluster assignments. Additionally,
it integrates a Reinforcement Learning (RL) agent to minimize control overhead
by learning optimal timings for generating new clusters. Addressing key
research questions, LEACH-RLC seeks to balance control overhead reduction
without compromising overall network performance. Through extensive
simulations, this paper investigates the frequency and opportune moments for
generating new clustering solutions. Results demonstrate the superior
performance of LEACH-RLC over conventional LEACH and LEACH-C, showcasing
enhanced network lifetime, reduced average energy consumption, and minimized
control overhead. The proposed protocol contributes to advancing the efficiency
and adaptability of WSNs, addressing critical challenges in IoT deployments.</div><div><a href='http://arxiv.org/abs/2401.15767v1'>2401.15767v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.08861v1")'>Semi-Supervised Learning Approach for Efficient Resource Allocation with
  Network Slicing in O-RAN</div>
<div id='2401.08861v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-16T22:23:27Z</div><div>Authors: Salar Nouri, Mojdeh Karbalaee Motalleb, Vahid Shah-Mansouri, Seyed Pooya Shariatpanahi</div><div style='padding-top: 10px; width: 80ex'>The Open Radio Access Network (O-RAN) technology has emerged as a promising
solution for network operators, providing them with an open and favorable
environment. Ensuring effective coordination of x-applications (xAPPs) is
crucial to enhance flexibility and optimize network performance within the
O-RAN. In this paper, we introduce an innovative approach to the resource
allocation problem, aiming to coordinate multiple independent xAPPs for network
slicing and resource allocation in O-RAN. Our proposed method focuses on
maximizing the weighted throughput among user equipments (UE), as well as
allocating physical resource blocks (PRBs). We prioritize two service types,
namely enhanced Mobile Broadband and Ultra Reliable Low Latency Communication.
To achieve this, we have designed two xAPPs: a power control xAPP for each UE
and a PRB allocation xAPP. The proposed method consists of a two-part training
phase, where the first part uses supervised learning with a Variational
Autoencoder trained to regress the power transmission as well as the user
association and PRB allocation decisions, and the second part uses unsupervised
learning with a contrastive loss approach to improve the generalization and
robustness of the model. We evaluate the performance of our proposed method by
comparing its results to those obtained from an exhaustive search algorithm,
deep Q-network algorithm, and by reporting performance metrics for the
regression task. We also evaluate the proposed model's performance in different
scenarios among the service types. The results show that the proposed method is
a more efficient and effective solution for network slicing problems compared
to state-of-the-art methods.</div><div><a href='http://arxiv.org/abs/2401.08861v1'>2401.08861v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.06938v2")'>Efficient Resource Scheduling for Distributed Infrastructures Using
  Negotiation Capabilities</div>
<div id='2402.06938v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-10T12:26:20Z</div><div>Authors: Junjie Chu, Prashant Singh, Salman Toor</div><div style='padding-top: 10px; width: 80ex'>In the past few decades, the rapid development of information and internet
technologies has spawned massive amounts of data and information. The
information explosion drives many enterprises or individuals to seek to rent
cloud computing infrastructure to put their applications in the cloud. However,
the agreements reached between cloud computing providers and clients are often
not efficient. Many factors affect the efficiency, such as the idleness of the
providers' cloud computing infrastructure, and the additional cost to the
clients. One possible solution is to introduce a comprehensive, bargaining game
(a type of negotiation), and schedule resources according to the negotiation
results. We propose an agent-based auto-negotiation system for resource
scheduling based on fuzzy logic. The proposed method can complete a one-to-one
auto-negotiation process and generate optimal offers for the provider and
client. We compare the impact of different member functions, fuzzy rule sets,
and negotiation scenario cases on the offers to optimize the system. It can be
concluded that our proposed method can utilize resources more efficiently and
is interpretable, highly flexible, and customizable. We successfully train
machine learning models to replace the fuzzy negotiation system to improve
processing speed. The article also highlights possible future improvements to
the proposed system and machine learning models. All the codes and data are
available in the open-source repository.</div><div><a href='http://arxiv.org/abs/2402.06938v2'>2402.06938v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.09141v1")'>Uncertainty Estimation in Multi-Agent Distributed Learning for
  AI-Enabled Edge Devices</div>
<div id='2403.09141v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T07:40:32Z</div><div>Authors: Gleb Radchenko, Victoria Andrea Fill</div><div style='padding-top: 10px; width: 80ex'>Initially considered as low-power units with limited autonomous processing,
Edge IoT devices have seen a paradigm shift with the introduction of FPGAs and
AI accelerators. This advancement has vastly amplified their computational
capabilities, emphasizing the practicality of edge AI. Such progress introduces
new challenges of optimizing AI tasks for the limitations of energy and network
resources typical in Edge computing environments. Our study explores methods
that enable distributed data processing through AI-enabled edge devices,
enhancing collaborative learning capabilities. A key focus of our research is
the challenge of determining confidence levels in learning outcomes,
considering the spatial and temporal variability of data sets encountered by
independent agents. To address this issue, we investigate the application of
Bayesian neural networks, proposing a novel approach to manage uncertainty in
distributed learning environments.</div><div><a href='http://arxiv.org/abs/2403.09141v1'>2403.09141v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.11603v1")'>Fair Distributed Cooperative Bandit Learning on Networks for Intelligent
  Internet of Things Systems (Technical Report)</div>
<div id='2403.11603v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-18T09:25:59Z</div><div>Authors: Ziqun Chen, Kechao Cai, Jinbei Zhang, Zhigang Yu</div><div style='padding-top: 10px; width: 80ex'>In intelligent Internet of Things (IoT) systems, edge servers within a
network exchange information with their neighbors and collect data from sensors
to complete delivered tasks. In this paper, we propose a multiplayer
multi-armed bandit model for intelligent IoT systems to facilitate data
collection and incorporate fairness considerations. In our model, we establish
an effective communication protocol that helps servers cooperate with their
neighbors. Then we design a distributed cooperative bandit algorithm, DC-ULCB,
enabling servers to collaboratively select sensors to maximize data rates while
maintaining fairness in their choices. We conduct an analysis of the reward
regret and fairness regret of DC-ULCB, and prove that both regrets have
logarithmic instance-dependent upper bounds. Additionally, through extensive
simulations, we validate that DC-ULCB outperforms existing algorithms in
maximizing reward and ensuring fairness.</div><div><a href='http://arxiv.org/abs/2403.11603v1'>2403.11603v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.10087v1")'>Decentralized Covert Routing in Heterogeneous Networks Using
  Reinforcement Learning</div>
<div id='2402.10087v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-31T23:51:14Z</div><div>Authors: Justin Kong, Terrence J. Moore, Fikadu T. Dagefu</div><div style='padding-top: 10px; width: 80ex'>This letter investigates covert routing communications in a heterogeneous
network where a source transmits confidential data to a destination with the
aid of relaying nodes where each transmitter judiciously chooses one modality
among multiple communication modalities. We develop a novel reinforcement
learning-based covert routing algorithm that finds a route from the source to
the destination where each node identifies its next hop and modality only based
on the local feedback information received from its neighboring nodes. We show
based on numerical simulations that the proposed covert routing strategy has
only negligible performance loss compared to the optimal centralized routing
scheme.</div><div><a href='http://arxiv.org/abs/2402.10087v1'>2402.10087v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.10921v1")'>Push- and Pull-based Effective Communication in Cyber-Physical Systems</div>
<div id='2401.10921v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T10:06:17Z</div><div>Authors: Pietro Talli, Federico Mason, Federico Chiariotti, Andrea Zanella</div><div style='padding-top: 10px; width: 80ex'>In Cyber Physical Systems (CPSs), two groups of actors interact toward the
maximization of system performance: the sensors, observing and disseminating
the system state, and the actuators, performing physical decisions based on the
received information. While it is generally assumed that sensors periodically
transmit updates, returning the feedback signal only when necessary, and
consequently adapting the physical decisions to the communication policy, can
significantly improve the efficiency of the system. In particular, the choice
between push-based communication, in which updates are initiated autonomously
by the sensors, and pull-based communication, in which they are requested by
the actuators, is a key design step. In this work, we propose an analytical
model for optimizing push- and pull-based communication in CPSs, observing that
the policy optimality coincides with Value of Information (VoI) maximization.
Our results also highlight that, despite providing a better optimal solution,
implementable push-based communication strategies may underperform even in
relatively simple scenarios.</div><div><a href='http://arxiv.org/abs/2401.10921v1'>2401.10921v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.00881v1")'>FedRDMA: Communication-Efficient Cross-Silo Federated LLM via Chunked
  RDMA Transmission</div>
<div id='2403.00881v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-01T09:14:10Z</div><div>Authors: Zeling Zhang, Dongqi Cai, Yiran Zhang, Mengwei Xu, Shangguang Wang, Ao Zhou</div><div style='padding-top: 10px; width: 80ex'>Communication overhead is a significant bottleneck in federated learning
(FL), which has been exaggerated with the increasing size of AI models. In this
paper, we propose FedRDMA, a communication-efficient cross-silo FL system that
integrates RDMA into the FL communication protocol. To overcome the limitations
of RDMA in wide-area networks (WANs), FedRDMA divides the updated model into
chunks and designs a series of optimization techniques to improve the
efficiency and robustness of RDMA-based communication. We implement FedRDMA
atop the industrial federated learning framework and evaluate it on a
real-world cross-silo FL scenario. The experimental results show that \sys can
achieve up to 3.8$\times$ speedup in communication efficiency compared to
traditional TCP/IP-based FL systems.</div><div><a href='http://arxiv.org/abs/2403.00881v1'>2403.00881v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.12780v1")'>Tackling Byzantine Clients in Federated Learning</div>
<div id='2402.12780v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T07:40:11Z</div><div>Authors: Youssef Allouah, Sadegh Farhadkhani, Rachid GuerraouI, Nirupam Gupta, Rafael Pinot, Geovani Rizk, Sasha Voitovych</div><div style='padding-top: 10px; width: 80ex'>The possibility of adversarial (a.k.a., {\em Byzantine}) clients makes
federated learning (FL) prone to arbitrary manipulation. The natural approach
to robustify FL against adversarial clients is to replace the simple averaging
operation at the server in the standard $\mathsf{FedAvg}$ algorithm by a
\emph{robust averaging rule}. While a significant amount of work has been
devoted to studying the convergence of federated {\em robust averaging} (which
we denote by $\mathsf{FedRo}$), prior work has largely ignored the impact of
{\em client subsampling} and {\em local steps}, two fundamental FL
characteristics. While client subsampling increases the effective fraction of
Byzantine clients, local steps increase the drift between the local updates
computed by honest (i.e., non-Byzantine) clients. Consequently, a careless
deployment of $\mathsf{FedRo}$ could yield poor performance. We validate this
observation by presenting an in-depth analysis of $\mathsf{FedRo}$ tightly
analyzing the impact of client subsampling and local steps. Specifically, we
present a sufficient condition on client subsampling for nearly-optimal
convergence of $\mathsf{FedRo}$ (for smooth non-convex loss). Also, we show
that the rate of improvement in learning accuracy {\em diminishes} with respect
to the number of clients subsampled, as soon as the sample size exceeds a
threshold value. Interestingly, we also observe that under a careful choice of
step-sizes, the learning error due to Byzantine clients decreases with the
number of local steps. We validate our theory by experiments on the FEMNIST and
CIFAR-$10$ image classification tasks.</div><div><a href='http://arxiv.org/abs/2402.12780v1'>2402.12780v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.13374v1")'>Byzantine-resilient Federated Learning With Adaptivity to Data
  Heterogeneity</div>
<div id='2403.13374v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-20T08:15:08Z</div><div>Authors: Shiyuan Zuo, Xingrun Yan, Rongfei Fan, Han Hu, Hangguan Shan, Tony Q. S. Quek</div><div style='padding-top: 10px; width: 80ex'>This paper deals with federated learning (FL) in the presence of malicious
Byzantine attacks and data heterogeneity. A novel Robust Average Gradient
Algorithm (RAGA) is proposed, which leverages the geometric median for
aggregation and can freely select the round number for local updating.
Different from most existing resilient approaches, which perform convergence
analysis based on strongly-convex loss function or homogeneously distributed
dataset, we conduct convergence analysis for not only strongly-convex but also
non-convex loss function over heterogeneous dataset. According to our
theoretical analysis, as long as the fraction of dataset from malicious users
is less than half, RAGA can achieve convergence at rate
$\mathcal{O}({1}/{T^{2/3- \delta}})$ where $T$ is the iteration number and
$\delta \in (0, 2/3)$ for non-convex loss function, and at linear rate for
strongly-convex loss function. Moreover, stationary point or global optimal
solution is proved to obtainable as data heterogeneity vanishes. Experimental
results corroborate the robustness of RAGA to Byzantine attacks and verifies
the advantage of RAGA over baselines on convergence performance under various
intensity of Byzantine attacks, for heterogeneous dataset.</div><div><a href='http://arxiv.org/abs/2403.13374v1'>2403.13374v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03945v1")'>SPEAR:Exact Gradient Inversion of Batches in Federated Learning</div>
<div id='2403.03945v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T18:52:39Z</div><div>Authors: Dimitar I. Dimitrov, Maximilian Baader, Mark Niklas Müller, Martin Vechev</div><div style='padding-top: 10px; width: 80ex'>Federated learning is a popular framework for collaborative machine learning
where multiple clients only share gradient updates on their local data with the
server and not the actual data. Unfortunately, it was recently shown that
gradient inversion attacks can reconstruct this data from these shared
gradients. Existing attacks enable exact reconstruction only for a batch size
of $b=1$ in the important honest-but-curious setting, with larger batches
permitting only approximate reconstruction. In this work, we propose \emph{the
first algorithm reconstructing whole batches with $b &gt;1$ exactly}. This
approach combines mathematical insights into the explicit low-rank structure of
gradients with a sampling-based algorithm. Crucially, we leverage ReLU-induced
gradient sparsity to precisely filter out large numbers of incorrect samples,
making a final reconstruction step tractable. We provide an efficient GPU
implementation for fully connected networks and show that it recovers batches
of $b \lesssim 25$ elements exactly while being tractable for large network
widths and depths.</div><div><a href='http://arxiv.org/abs/2403.03945v1'>2403.03945v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09095v1")'>FedSiKD: Clients Similarity and Knowledge Distillation: Addressing
  Non-i.i.d. and Constraints in Federated Learning</div>
<div id='2402.09095v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T11:16:50Z</div><div>Authors: Yousef Alsenani, Rahul Mishra, Khaled R. Ahmed, Atta Ur Rahman</div><div style='padding-top: 10px; width: 80ex'>In recent years, federated learning (FL) has emerged as a promising technique
for training machine learning models in a decentralized manner while also
preserving data privacy. The non-independent and identically distributed
(non-i.i.d.) nature of client data, coupled with constraints on client or edge
devices, presents significant challenges in FL. Furthermore, learning across a
high number of communication rounds can be risky and potentially unsafe for
model exploitation. Traditional FL approaches may suffer from these challenges.
Therefore, we introduce FedSiKD, which incorporates knowledge distillation (KD)
within a similarity-based federated learning framework. As clients join the
system, they securely share relevant statistics about their data distribution,
promoting intra-cluster homogeneity. This enhances optimization efficiency and
accelerates the learning process, effectively transferring knowledge between
teacher and student models and addressing device constraints. FedSiKD
outperforms state-of-the-art algorithms by achieving higher accuracy, exceeding
by 25\% and 18\% for highly skewed data at $\alpha = {0.1,0.5}$ on the HAR and
MNIST datasets, respectively. Its faster convergence is illustrated by a 17\%
and 20\% increase in accuracy within the first five rounds on the HAR and MNIST
datasets, respectively, highlighting its early-stage learning proficiency. Code
is publicly available and hosted on GitHub (https://github.com/SimuEnv/FedSiKD)</div><div><a href='http://arxiv.org/abs/2402.09095v1'>2402.09095v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.11892v1")'>KnFu: Effective Knowledge Fusion</div>
<div id='2403.11892v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-18T15:49:48Z</div><div>Authors: S. Jamal Seyedmohammadi, S. Kawa Atapour, Jamshid Abouei, Arash Mohammadi</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) has emerged as a prominent alternative to the
traditional centralized learning approach. Generally speaking, FL is a
decentralized approach that allows for collaborative training of Machine
Learning (ML) models across multiple local nodes, ensuring data privacy and
security while leveraging diverse datasets. Conventional FL, however, is
susceptible to gradient inversion attacks, restrictively enforces a uniform
architecture on local models, and suffers from model heterogeneity (model
drift) due to non-IID local datasets. To mitigate some of these challenges, the
new paradigm of Federated Knowledge Distillation (FKD) has emerged. FDK is
developed based on the concept of Knowledge Distillation (KD), which involves
extraction and transfer of a large and well-trained teacher model's knowledge
to lightweight student models. FKD, however, still faces the model drift issue.
Intuitively speaking, not all knowledge is universally beneficial due to the
inherent diversity of data among local nodes. This calls for innovative
mechanisms to evaluate the relevance and effectiveness of each client's
knowledge for others, to prevent propagation of adverse knowledge. In this
context, the paper proposes Effective Knowledge Fusion (KnFu) algorithm that
evaluates knowledge of local models to only fuse semantic neighbors' effective
knowledge for each client. The KnFu is a personalized effective knowledge
fusion scheme for each client, that analyzes effectiveness of different local
models' knowledge prior to the aggregation phase. Comprehensive experiments
were performed on MNIST and CIFAR10 datasets illustrating effectiveness of the
proposed KnFu in comparison to its state-of-the-art counterparts. A key
conclusion of the work is that in scenarios with large and highly heterogeneous
local datasets, local training could be preferable to knowledge fusion-based
solutions.</div><div><a href='http://arxiv.org/abs/2403.11892v1'>2403.11892v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14922v1")'>Practical Insights into Knowledge Distillation for Pre-Trained Models</div>
<div id='2402.14922v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T19:07:08Z</div><div>Authors: Norah Alballa, Marco Canini</div><div style='padding-top: 10px; width: 80ex'>This research investigates the enhancement of knowledge distillation (KD)
processes in pre-trained models, an emerging field in knowledge transfer with
significant implications for distributed training and federated learning
environments. These environments benefit from reduced communication demands and
accommodate various model architectures. Despite the adoption of numerous KD
approaches for transferring knowledge among pre-trained models, a comprehensive
understanding of KD's application in these scenarios is lacking. Our study
conducts an extensive comparison of multiple KD techniques, including standard
KD, tuned KD (via optimized temperature and weight parameters), deep mutual
learning, and data partitioning KD. We assess these methods across various data
distribution strategies to identify the most effective contexts for each.
Through detailed examination of hyperparameter tuning, informed by extensive
grid search evaluations, we pinpoint when adjustments are crucial to enhance
model performance. This paper sheds light on optimal hyperparameter settings
for distinct data partitioning scenarios and investigates KD's role in
improving federated learning by minimizing communication rounds and expediting
the training process. By filling a notable void in current research, our
findings serve as a practical framework for leveraging KD in pre-trained models
within collaborative and federated learning frameworks.</div><div><a href='http://arxiv.org/abs/2402.14922v1'>2402.14922v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.06974v2")'>Non-linear Fusion in Federated Learning: A Hypernetwork Approach to
  Federated Domain Generalization</div>
<div id='2402.06974v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-10T15:42:03Z</div><div>Authors: Marc Bartholet, Taehyeon Kim, Ami Beuret, Se-Young Yun, Joachim M. Buhmann</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) has emerged as a promising paradigm in which multiple
clients collaboratively train a shared global model while preserving data
privacy. To create a robust and practicable FL framework, it is crucial to
extend its ability to generalize well to unseen domains - a problem referred to
as federated Domain Generalization (FDG), being still under-explored. We
propose an innovative federated algorithm, termed hFedF for hypernetwork-based
Federated Fusion, designed to bridge the performance gap between generalization
and personalization, capable of addressing various degrees of domain shift.
Essentially, the hypernetwork supports a non-linear fusion of client models
enabling a comprehensive understanding of the underlying data distribution. We
encompass an extensive discussion and provide novel insights into the tradeoff
between personalization and generalization in FL. The proposed algorithm
outperforms strong benchmarks on three widely-used data sets for DG in an
exceeding number of cases.</div><div><a href='http://arxiv.org/abs/2402.06974v2'>2402.06974v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.08506v1")'>DiPrompT: Disentangled Prompt Tuning for Multiple Latent Domain
  Generalization in Federated Learning</div>
<div id='2403.08506v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-11T15:58:15Z</div><div>Authors: Sikai Bai, Jie Zhang, Shuaicheng Li, Song Guo, Jingcai Guo, Jun Hou, Tao Han, Xiaocheng Lu</div><div style='padding-top: 10px; width: 80ex'>Federated learning (FL) has emerged as a powerful paradigm for learning from
decentralized data, and federated domain generalization further considers the
test dataset (target domain) is absent from the decentralized training data
(source domains). However, most existing FL methods assume that domain labels
are provided during training, and their evaluation imposes explicit constraints
on the number of domains, which must strictly match the number of clients.
Because of the underutilization of numerous edge devices and additional
cross-client domain annotations in the real world, such restrictions may be
impractical and involve potential privacy leaks. In this paper, we propose an
efficient and novel approach, called Disentangled Prompt Tuning (DiPrompT), a
method that tackles the above restrictions by learning adaptive prompts for
domain generalization in a distributed manner. Specifically, we first design
two types of prompts, i.e., global prompt to capture general knowledge across
all clients and domain prompts to capture domain-specific knowledge. They
eliminate the restriction on the one-to-one mapping between source domains and
local clients. Furthermore, a dynamic query metric is introduced to
automatically search the suitable domain label for each sample, which includes
two-substep text-image alignments based on prompt tuning without
labor-intensive annotation. Extensive experiments on multiple datasets
demonstrate that our DiPrompT achieves superior domain generalization
performance over state-of-the-art FL methods when domain labels are not
provided, and even outperforms many centralized learning methods using domain
labels.</div><div><a href='http://arxiv.org/abs/2403.08506v1'>2403.08506v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.08327v1")'>Learn What You Need in Personalized Federated Learning</div>
<div id='2401.08327v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-16T12:45:15Z</div><div>Authors: Kexin Lv, Rui Ye, Xiaolin Huang, Jie Yang, Siheng Chen</div><div style='padding-top: 10px; width: 80ex'>Personalized federated learning aims to address data heterogeneity across
local clients in federated learning. However, current methods blindly
incorporate either full model parameters or predefined partial parameters in
personalized federated learning. They fail to customize the collaboration
manner according to each local client's data characteristics, causing
unpleasant aggregation results. To address this essential issue, we propose
$\textit{Learn2pFed}$, a novel algorithm-unrolling-based personalized federated
learning framework, enabling each client to adaptively select which part of its
local model parameters should participate in collaborative training. The key
novelty of the proposed $\textit{Learn2pFed}$ is to optimize each local model
parameter's degree of participant in collaboration as learnable parameters via
algorithm unrolling methods. This approach brings two benefits: 1)
mathmatically determining the participation degree of local model parameters in
the federated collaboration, and 2) obtaining more stable and improved
solutions. Extensive experiments on various tasks, including regression,
forecasting, and image classification, demonstrate that $\textit{Learn2pFed}$
significantly outperforms previous personalized federated learning methods.</div><div><a href='http://arxiv.org/abs/2401.08327v1'>2401.08327v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.16091v1")'>Bayesian Neural Network For Personalized Federated Learning Parameter
  Selection</div>
<div id='2402.16091v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-25T13:37:53Z</div><div>Authors: Mengen Luo, Ercan Engin Kuruoglu</div><div style='padding-top: 10px; width: 80ex'>Federated learning's poor performance in the presence of heterogeneous data
remains one of the most pressing issues in the field. Personalized federated
learning departs from the conventional paradigm in which all clients employ the
same model, instead striving to discover an individualized model for each
client to address the heterogeneity in the data. One of such approach involves
personalizing specific layers of neural networks. However, prior endeavors have
not provided a dependable rationale, and some have selected personalized layers
that are entirely distinct and conflicting. In this work, we take a step
further by proposing personalization at the elemental level, rather than the
traditional layer-level personalization. To select personalized parameters, we
introduce Bayesian neural networks and rely on the uncertainty they offer to
guide our selection of personalized parameters. Finally, we validate our
algorithm's efficacy on several real-world datasets, demonstrating that our
proposed approach outperforms existing baselines.</div><div><a href='http://arxiv.org/abs/2402.16091v1'>2402.16091v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.16911v1")'>Trustworthy Personalized Bayesian Federated Learning via Posterior
  Fine-Tune</div>
<div id='2402.16911v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-25T13:28:08Z</div><div>Authors: Mengen Luo, Chi Xu, Ercan Engin Kuruoglu</div><div style='padding-top: 10px; width: 80ex'>Performance degradation owing to data heterogeneity and low output
interpretability are the most significant challenges faced by federated
learning in practical applications. Personalized federated learning diverges
from traditional approaches, as it no longer seeks to train a single model, but
instead tailors a unique personalized model for each client. However, previous
work focused only on personalization from the perspective of neural network
parameters and lack of robustness and interpretability. In this work, we
establish a novel framework for personalized federated learning, incorporating
Bayesian methodology which enhances the algorithm's ability to quantify
uncertainty. Furthermore, we introduce normalizing flow to achieve
personalization from the parameter posterior perspective and theoretically
analyze the impact of normalizing flow on out-of-distribution (OOD) detection
for Bayesian neural networks. Finally, we evaluated our approach on
heterogeneous datasets, and the experimental results indicate that the new
algorithm not only improves accuracy but also outperforms the baseline
significantly in OOD detection due to the reliable output of the Bayesian
approach.</div><div><a href='http://arxiv.org/abs/2402.16911v1'>2402.16911v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.17124v1")'>Spectral Co-Distillation for Personalized Federated Learning</div>
<div id='2401.17124v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T16:01:38Z</div><div>Authors: Zihan Chen, Howard H. Yang, Tony Q. S. Quek, Kai Fong Ernest Chong</div><div style='padding-top: 10px; width: 80ex'>Personalized federated learning (PFL) has been widely investigated to address
the challenge of data heterogeneity, especially when a single generic model is
inadequate in satisfying the diverse performance requirements of local clients
simultaneously. Existing PFL methods are inherently based on the idea that the
relations between the generic global and personalized local models are captured
by the similarity of model weights. Such a similarity is primarily based on
either partitioning the model architecture into generic versus personalized
components, or modeling client relationships via model weights. To better
capture similar (yet distinct) generic versus personalized model
representations, we propose \textit{spectral distillation}, a novel
distillation method based on model spectrum information. Building upon spectral
distillation, we also introduce a co-distillation framework that establishes a
two-way bridge between generic and personalized model training. Moreover, to
utilize the local idle time in conventional PFL, we propose a wait-free local
training protocol. Through extensive experiments on multiple datasets over
diverse heterogeneous data settings, we demonstrate the outperformance and
efficacy of our proposed spectral co-distillation method, as well as our
wait-free training protocol.</div><div><a href='http://arxiv.org/abs/2401.17124v1'>2401.17124v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.09284v1")'>DA-PFL: Dynamic Affinity Aggregation for Personalized Federated Learning</div>
<div id='2403.09284v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T11:12:10Z</div><div>Authors: Xu Yang, Jiyuan Feng, Songyue Guo, Ye Wang, Ye Ding, Binxing Fang, Qing Liao</div><div style='padding-top: 10px; width: 80ex'>Personalized federated learning becomes a hot research topic that can learn a
personalized learning model for each client. Existing personalized federated
learning models prefer to aggregate similar clients with similar data
distribution to improve the performance of learning models. However,
similaritybased personalized federated learning methods may exacerbate the
class imbalanced problem. In this paper, we propose a novel Dynamic
Affinity-based Personalized Federated Learning model (DA-PFL) to alleviate the
class imbalanced problem during federated learning. Specifically, we build an
affinity metric from a complementary perspective to guide which clients should
be aggregated. Then we design a dynamic aggregation strategy to dynamically
aggregate clients based on the affinity metric in each round to reduce the
class imbalanced risk. Extensive experiments show that the proposed DA-PFL
model can significantly improve the accuracy of each client in three real-world
datasets with state-of-the-art comparison methods.</div><div><a href='http://arxiv.org/abs/2403.09284v1'>2403.09284v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14430v1")'>Robust Training of Federated Models with Extremely Label Deficiency</div>
<div id='2402.14430v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T10:19:34Z</div><div>Authors: Yonggang Zhang, Zhiqin Yang, Xinmei Tian, Nannan Wang, Tongliang Liu, Bo Han</div><div style='padding-top: 10px; width: 80ex'>Federated semi-supervised learning (FSSL) has emerged as a powerful paradigm
for collaboratively training machine learning models using distributed data
with label deficiency. Advanced FSSL methods predominantly focus on training a
single model on each client. However, this approach could lead to a discrepancy
between the objective functions of labeled and unlabeled data, resulting in
gradient conflicts. To alleviate gradient conflict, we propose a novel
twin-model paradigm, called Twin-sight, designed to enhance mutual guidance by
providing insights from different perspectives of labeled and unlabeled data.
In particular, Twin-sight concurrently trains a supervised model with a
supervised objective function while training an unsupervised model using an
unsupervised objective function. To enhance the synergy between these two
models, Twin-sight introduces a neighbourhood-preserving constraint, which
encourages the preservation of the neighbourhood relationship among data
features extracted by both models. Our comprehensive experiments on four
benchmark datasets provide substantial evidence that Twin-sight can
significantly outperform state-of-the-art methods across various experimental
settings, demonstrating the efficacy of the proposed Twin-sight.</div><div><a href='http://arxiv.org/abs/2402.14430v1'>2402.14430v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.02329v1")'>Not all Minorities are Equal: Empty-Class-Aware Distillation for
  Heterogeneous Federated Learning</div>
<div id='2401.02329v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-04T16:06:31Z</div><div>Authors: Kuangpu Guo, Yuhe Ding, Jian Liang, Ran He, Zilei Wang, Tieniu Tan</div><div style='padding-top: 10px; width: 80ex'>Data heterogeneity, characterized by disparities in local data distribution
across clients, poses a significant challenge in federated learning.
Substantial efforts have been devoted to addressing the heterogeneity in local
label distribution. As minority classes suffer from worse accuracy due to
overfitting on local imbalanced data, prior methods often incorporate
class-balanced learning techniques during local training. Despite the improved
mean accuracy across all classes, we observe that empty classes-referring to
categories absent from a client's data distribution-are still not well
recognized. This paper introduces FedED, a novel approach in heterogeneous
federated learning that integrates both empty-class distillation and logit
suppression simultaneously. Specifically, empty-class distillation leverages
knowledge distillation during local training on each client to retain essential
information related to empty classes from the global model. Moreover, logit
suppression directly penalizes network logits for non-label classes,
effectively addressing misclassifications in minority classes that may be
biased toward majority classes. Extensive experiments validate the efficacy of
FedED, surpassing previous state-of-the-art methods across diverse datasets
with varying degrees of label distribution shift.</div><div><a href='http://arxiv.org/abs/2401.02329v1'>2401.02329v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03333v1")'>Solution Simplex Clustering for Heterogeneous Federated Learning</div>
<div id='2403.03333v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-05T21:34:23Z</div><div>Authors: Dennis Grinwald, Philipp Wiesner, Shinichi Nakajima</div><div style='padding-top: 10px; width: 80ex'>We tackle a major challenge in federated learning (FL) -- achieving good
performance under highly heterogeneous client distributions. The difficulty
partially arises from two seemingly contradictory goals: learning a common
model by aggregating the information from clients, and learning local
personalized models that should be adapted to each local distribution. In this
work, we propose Solution Simplex Clustered Federated Learning (SosicFL) for
dissolving such contradiction. Based on the recent ideas of learning solution
simplices, SosicFL assigns a subregion in a simplex to each client, and
performs FL to learn a common solution simplex. This allows the client models
to possess their characteristics within the degrees of freedom in the solution
simplex, and at the same time achieves the goal of learning a global common
model. Our experiments show that SosicFL improves the performance and
accelerates the training process for global and personalized FL with minimal
computational overhead.</div><div><a href='http://arxiv.org/abs/2403.03333v1'>2403.03333v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.02586v1")'>Federated Learning for distribution skewed data using sample weights</div>
<div id='2401.02586v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-05T00:46:11Z</div><div>Authors: Hung Nguyen, Peiyuan Wu, Morris Chang</div><div style='padding-top: 10px; width: 80ex'>One of the most challenging issues in federated learning is that the data is
often not independent and identically distributed (nonIID). Clients are
expected to contribute the same type of data and drawn from one global
distribution. However, data are often collected in different ways from
different resources. Thus, the data distributions among clients might be
different from the underlying global distribution. This creates a weight
divergence issue and reduces federated learning performance. This work focuses
on improving federated learning performance for skewed data distribution across
clients. The main idea is to adjust the client distribution closer to the
global distribution using sample weights. Thus, the machine learning model
converges faster with higher accuracy. We start from the fundamental concept of
empirical risk minimization and theoretically derive a solution for adjusting
the distribution skewness using sample weights. To determine sample weights, we
implicitly exchange density information by leveraging a neural network-based
density estimation model, MADE. The clients data distribution can then be
adjusted without exposing their raw data. Our experiment results on three
real-world datasets show that the proposed method not only improves federated
learning accuracy but also significantly reduces communication costs compared
to the other experimental methods.</div><div><a href='http://arxiv.org/abs/2401.02586v1'>2401.02586v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.10646v1")'>Empowering HWNs with Efficient Data Labeling: A Clustered Federated
  Semi-Supervised Learning Approach</div>
<div id='2401.10646v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-19T11:47:49Z</div><div>Authors: Moqbel Hamood, Abdullatif Albaseer, Mohamed Abdallah, Ala Al-Fuqaha</div><div style='padding-top: 10px; width: 80ex'>Clustered Federated Multitask Learning (CFL) has gained considerable
attention as an effective strategy for overcoming statistical challenges,
particularly when dealing with non independent and identically distributed (non
IID) data across multiple users. However, much of the existing research on CFL
operates under the unrealistic premise that devices have access to accurate
ground truth labels. This assumption becomes especially problematic in
hierarchical wireless networks (HWNs), where edge networks contain a large
amount of unlabeled data, resulting in slower convergence rates and increased
processing times, particularly when dealing with two layers of model
aggregation. To address these issues, we introduce a novel framework, Clustered
Federated Semi-Supervised Learning (CFSL), designed for more realistic HWN
scenarios. Our approach leverages a best-performing specialized model
algorithm, wherein each device is assigned a specialized model that is highly
adept at generating accurate pseudo-labels for unlabeled data, even when the
data stems from diverse environments. We validate the efficacy of CFSL through
extensive experiments, comparing it with existing methods highlighted in recent
literature. Our numerical results demonstrate that CFSL significantly improves
upon key metrics such as testing accuracy, labeling accuracy, and labeling
latency under varying proportions of labeled and unlabeled data while also
accommodating the non-IID nature of the data and the unique characteristics of
wireless edge networks.</div><div><a href='http://arxiv.org/abs/2401.10646v1'>2401.10646v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.13246v1")'>Divide-Conquer Transformer Learning for Predicting Electric Vehicle
  Charging Events Using Smart Meter Data</div>
<div id='2403.13246v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-20T02:17:16Z</div><div>Authors: Fucai Ke, Hao Wang</div><div style='padding-top: 10px; width: 80ex'>Predicting electric vehicle (EV) charging events is crucial for load
scheduling and energy management, promoting seamless transportation
electrification and decarbonization. While prior studies have focused on EV
charging demand prediction, primarily for public charging stations using
historical charging data, home charging prediction is equally essential.
However, existing prediction methods may not be suitable due to the
unavailability of or limited access to home charging data. To address this
research gap, inspired by the concept of non-intrusive load monitoring (NILM),
we develop a home charging prediction method using historical smart meter data.
Different from NILM detecting EV charging that has already occurred, our method
provides predictive information of future EV charging occurrences, thus
enhancing its utility for charging management. Specifically, our method,
leverages a self-attention mechanism-based transformer model, employing a
``divide-conquer'' strategy, to process historical meter data to effectively
and learn EV charging representation for charging occurrence prediction. Our
method enables prediction at one-minute interval hour-ahead. Experimental
results demonstrate the effectiveness of our method, achieving consistently
high accuracy of over 96.81\% across different prediction time spans. Notably,
our method achieves high prediction performance solely using smart meter data,
making it a practical and suitable solution for grid operators.</div><div><a href='http://arxiv.org/abs/2403.13246v1'>2403.13246v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.06298v1")'>Analysis of Total Variation Minimization for Clustered Federated
  Learning</div>
<div id='2403.06298v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-10T20:07:14Z</div><div>Authors: A. Jung</div><div style='padding-top: 10px; width: 80ex'>A key challenge in federated learning applications is the statistical
heterogeneity of local datasets. Clustered federated learning addresses this
challenge by identifying clusters of local datasets that are approximately
homogeneous. One recent approach to clustered federated learning is generalized
total variation minimization (GTVMin). This approach requires a similarity
graph which can be obtained by domain expertise or in a data-driven fashion via
graph learning techniques. Under a widely applicable clustering assumption, we
derive an upper bound the deviation between GTVMin solutions and their
cluster-wise averages. This bound provides valuable insights into the
effectiveness and robustness of GTVMin in addressing statistical heterogeneity
within federated learning environments.</div><div><a href='http://arxiv.org/abs/2403.06298v1'>2403.06298v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.07756v1")'>Joint Probability Selection and Power Allocation for Federated Learning</div>
<div id='2401.07756v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T15:09:47Z</div><div>Authors: Ouiame Marnissi, Hajar EL Hammouti, El Houcine Bergou</div><div style='padding-top: 10px; width: 80ex'>In this paper, we study the performance of federated learning over wireless
networks, where devices with a limited energy budget train a machine learning
model. The federated learning performance depends on the selection of the
clients participating in the learning at each round. Most existing studies
suggest deterministic approaches for the client selection, resulting in
challenging optimization problems that are usually solved using heuristics, and
therefore without guarantees on the quality of the final solution. We formulate
a new probabilistic approach to jointly select clients and allocate power
optimally so that the expected number of participating clients is maximized. To
solve the problem, a new alternating algorithm is proposed, where at each step,
the closed-form solutions for user selection probabilities and power
allocations are obtained. Our numerical results show that the proposed approach
achieves a significant performance in terms of energy consumption, completion
time and accuracy as compared to the studied benchmarks.</div><div><a href='http://arxiv.org/abs/2401.07756v1'>2401.07756v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.09267v1")'>Risk-Aware Accelerated Wireless Federated Learning with Heterogeneous
  Clients</div>
<div id='2401.09267v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-17T15:15:52Z</div><div>Authors: Mohamed Ads, Hesham ElSawy, Hossam S. Hassanein</div><div style='padding-top: 10px; width: 80ex'>Wireless Federated Learning (FL) is an emerging distributed machine learning
paradigm, particularly gaining momentum in domains with confidential and
private data on mobile clients. However, the location-dependent performance, in
terms of transmission rates and susceptibility to transmission errors, poses
major challenges for wireless FL's convergence speed and accuracy. The
challenge is more acute for hostile environments without a metric that
authenticates the data quality and security profile of the clients. In this
context, this paper proposes a novel risk-aware accelerated FL framework that
accounts for the clients heterogeneity in the amount of possessed data,
transmission rates, transmission errors, and trustworthiness. Classifying
clients according to their location-dependent performance and trustworthiness
profiles, we propose a dynamic risk-aware global model aggregation scheme that
allows clients to participate in descending order of their transmission rates
and an ascending trustworthiness constraint. In particular, the transmission
rate is the dominant participation criterion for initial rounds to accelerate
the convergence speed. Our model then progressively relaxes the transmission
rate restriction to explore more training data at cell-edge clients. The
aggregation rounds incorporate a debiasing factor that accounts for
transmission errors. Risk-awareness is enabled by a validation set, where the
base station eliminates non-trustworthy clients at the fine-tuning stage. The
proposed scheme is benchmarked against a conservative scheme (i.e., only
allowing trustworthy devices) and an aggressive scheme (i.e., oblivious to the
trust metric). The numerical results highlight the superiority of the proposed
scheme in terms of accuracy and convergence speed when compared to both
benchmarks.</div><div><a href='http://arxiv.org/abs/2401.09267v1'>2401.09267v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.08578v1")'>FedLPS: Heterogeneous Federated Learning for Multiple Tasks with Local
  Parameter Sharing</div>
<div id='2402.08578v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T16:30:30Z</div><div>Authors: Yongzhe Jia, Xuyun Zhang, Amin Beheshti, Wanchun Dou</div><div style='padding-top: 10px; width: 80ex'>Federated Learning (FL) has emerged as a promising solution in Edge Computing
(EC) environments to process the proliferation of data generated by edge
devices. By collaboratively optimizing the global machine learning models on
distributed edge devices, FL circumvents the need for transmitting raw data and
enhances user privacy. Despite practical successes, FL still confronts
significant challenges including constrained edge device resources, multiple
tasks deployment, and data heterogeneity. However, existing studies focus on
mitigating the FL training costs of each single task whereas neglecting the
resource consumption across multiple tasks in heterogeneous FL scenarios. In
this paper, we propose Heterogeneous Federated Learning with Local Parameter
Sharing (FedLPS) to fill this gap. FedLPS leverages principles from transfer
learning to facilitate the deployment of multiple tasks on a single device by
dividing the local model into a shareable encoder and task-specific encoders.
To further reduce resource consumption, a channel-wise model pruning algorithm
that shrinks the footprint of local models while accounting for both data and
system heterogeneity is employed in FedLPS. Additionally, a novel heterogeneous
model aggregation algorithm is proposed to aggregate the heterogeneous
predictors in FedLPS. We implemented the proposed FedLPS on a real FL platform
and compared it with state-of-the-art (SOTA) FL frameworks. The experimental
results on five popular datasets and two modern DNN models illustrate that the
proposed FedLPS significantly outperforms the SOTA FL frameworks by up to 4.88%
and reduces the computational resource consumption by 21.3%. Our code is
available at:https://github.com/jyzgh/FedLPS.</div><div><a href='http://arxiv.org/abs/2402.08578v1'>2402.08578v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.11464v1")'>FedSPU: Personalized Federated Learning for Resource-constrained Devices
  with Stochastic Parameter Update</div>
<div id='2403.11464v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-18T04:31:38Z</div><div>Authors: Ziru Niu, Hai Dong, A. K. Qin</div><div style='padding-top: 10px; width: 80ex'>Personalized Federated Learning (PFL) is widely employed in IoT applications
to handle high-volume, non-iid client data while ensuring data privacy.
However, heterogeneous edge devices owned by clients may impose varying degrees
of resource constraints, causing computation and communication bottlenecks for
PFL. Federated Dropout has emerged as a popular strategy to address this
challenge, wherein only a subset of the global model, i.e. a
\textit{sub-model}, is trained on a client's device, thereby reducing
computation and communication overheads. Nevertheless, the dropout-based
model-pruning strategy may introduce bias, particularly towards non-iid local
data. When biased sub-models absorb highly divergent parameters from other
clients, performance degradation becomes inevitable. In response, we propose
federated learning with stochastic parameter update (FedSPU). Unlike dropout
that tailors the global model to small-size local sub-models, FedSPU maintains
the full model architecture on each device but randomly freezes a certain
percentage of neurons in the local model during training while updating the
remaining neurons. This approach ensures that a portion of the local model
remains personalized, thereby enhancing the model's robustness against biased
parameters from other clients. Experimental results demonstrate that FedSPU
outperforms federated dropout by 7.57\% on average in terms of accuracy.
Furthermore, an introduced early stopping scheme leads to a significant
reduction of the training time by \(24.8\%\sim70.4\%\) while maintaining high
accuracy.</div><div><a href='http://arxiv.org/abs/2403.11464v1'>2403.11464v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04430v1")'>On-demand Quantization for Green Federated Generative Diffusion in
  Mobile Edge Networks</div>
<div id='2403.04430v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T12:00:33Z</div><div>Authors: Bingkun Lai, Jiayi He, Jiawen Kang, Gaolei Li, Minrui Xu, Tao zhang, Shengli Xie</div><div style='padding-top: 10px; width: 80ex'>Generative Artificial Intelligence (GAI) shows remarkable productivity and
creativity in Mobile Edge Networks, such as the metaverse and the Industrial
Internet of Things. Federated learning is a promising technique for effectively
training GAI models in mobile edge networks due to its data distribution.
However, there is a notable issue with communication consumption when training
large GAI models like generative diffusion models in mobile edge networks.
Additionally, the substantial energy consumption associated with training
diffusion-based models, along with the limited resources of edge devices and
complexities of network environments, pose challenges for improving the
training efficiency of GAI models. To address this challenge, we propose an
on-demand quantized energy-efficient federated diffusion approach for mobile
edge networks. Specifically, we first design a dynamic quantized federated
diffusion training scheme considering various demands from the edge devices.
Then, we study an energy efficiency problem based on specific quantization
requirements. Numerical results show that our proposed method significantly
reduces system energy consumption and transmitted model size compared to both
baseline federated diffusion and fixed quantized federated diffusion methods
while effectively maintaining reasonable quality and diversity of generated
data.</div><div><a href='http://arxiv.org/abs/2403.04430v1'>2403.04430v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.18587v1")'>At the Dawn of Generative AI Era: A Tutorial-cum-Survey on New Frontiers
  in 6G Wireless Intelligence</div>
<div id='2402.18587v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T06:23:25Z</div><div>Authors: Abdulkadir Celik, Ahmed M. Eltawil</div><div style='padding-top: 10px; width: 80ex'>The majority of data-driven wireless research leans heavily on discriminative
AI (DAI) that requires vast real-world datasets. Unlike the DAI, Generative AI
(GenAI) pertains to generative models (GMs) capable of discerning the
underlying data distribution, patterns, and features of the input data. This
makes GenAI a crucial asset in wireless domain wherein real-world data is often
scarce, incomplete, costly to acquire, and hard to model or comprehend. With
these appealing attributes, GenAI can replace or supplement DAI methods in
various capacities. Accordingly, this combined tutorial-survey paper commences
with preliminaries of 6G and wireless intelligence by outlining candidate 6G
applications and services, presenting a taxonomy of state-of-the-art DAI
models, exemplifying prominent DAI use cases, and elucidating the multifaceted
ways through which GenAI enhances DAI. Subsequently, we present a tutorial on
GMs by spotlighting seminal examples such as generative adversarial networks,
variational autoencoders, flow-based GMs, diffusion-based GMs, generative
transformers, large language models, to name a few. Contrary to the prevailing
belief that GenAI is a nascent trend, our exhaustive review of approximately
120 technical papers demonstrates the scope of research across core wireless
research areas, including physical layer design; network optimization,
organization, and management; network traffic analytics; cross-layer network
security; and localization &amp; positioning. Furthermore, we outline the central
role of GMs in pioneering areas of 6G network research, including
semantic/THz/near-field communications, ISAC, extremely large antenna arrays,
digital twins, AI-generated content services, mobile edge computing and edge
AI, adversarial ML, and trustworthy AI. Lastly, we shed light on the
multifarious challenges ahead, suggesting potential strategies and promising
remedies.</div><div><a href='http://arxiv.org/abs/2402.18587v1'>2402.18587v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.19319v1")'>Attacks Against Mobility Prediction in 5G Networks</div>
<div id='2402.19319v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T16:24:19Z</div><div>Authors: Syafiq Al Atiiq, Yachao Yuan, Christian Gehrmann, Jakob Sternby, Luis Barriga</div><div style='padding-top: 10px; width: 80ex'>The $5^{th}$ generation of mobile networks introduces a new Network Function
(NF) that was not present in previous generations, namely the Network Data
Analytics Function (NWDAF). Its primary objective is to provide advanced
analytics services to various entities within the network and also towards
external application services in the 5G ecosystem. One of the key use cases of
NWDAF is mobility trajectory prediction, which aims to accurately support
efficient mobility management of User Equipment (UE) in the network by
allocating ``just in time'' necessary network resources. In this paper, we show
that there are potential mobility attacks that can compromise the accuracy of
these predictions. In a semi-realistic scenario with 10,000 subscribers, we
demonstrate that an adversary equipped with the ability to hijack cellular
mobile devices and clone them can significantly reduce the prediction accuracy
from 75\% to 40\% using just 100 adversarial UEs. While a defense mechanism
largely depends on the attack and the mobility types in a particular area, we
prove that a basic KMeans clustering is effective in distinguishing legitimate
and adversarial UEs.</div><div><a href='http://arxiv.org/abs/2402.19319v1'>2402.19319v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00831v1")'>A YANG-aided Unified Strategy for Black Hole Detection for Backbone
  Networks</div>
<div id='2402.00831v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T18:17:37Z</div><div>Authors: Elif Ak, Kiymet Kaya, Eren Ozaltun, Sule Gunduz Oguducu, Berk Canberk</div><div style='padding-top: 10px; width: 80ex'>Despite the crucial importance of addressing Black Hole failures in Internet
backbone networks, effective detection strategies in backbone networks are
lacking. This is largely because previous research has been centered on Mobile
Ad-hoc Networks (MANETs), which operate under entirely different dynamics,
protocols, and topologies, making their findings not directly transferable to
backbone networks. Furthermore, detecting Black Hole failures in backbone
networks is particularly challenging. It requires a comprehensive range of
network data due to the wide variety of conditions that need to be considered,
making data collection and analysis far from straightforward. Addressing this
gap, our study introduces a novel approach for Black Hole detection in backbone
networks using specialized Yet Another Next Generation (YANG) data models with
Black Hole-sensitive Metric Matrix (BHMM) analysis. This paper details our
method of selecting and analyzing four YANG models relevant to Black Hole
detection in ISP networks, focusing on routing protocols and ISP-specific
configurations. Our BHMM approach derived from these models demonstrates a 10%
improvement in detection accuracy and a 13% increase in packet delivery rate,
highlighting the efficiency of our approach. Additionally, we evaluate the
Machine Learning approach leveraged with BHMM analysis in two different network
settings, a commercial ISP network, and a scientific research-only network
topology. This evaluation also demonstrates the practical applicability of our
method, yielding significantly improved prediction outcomes in both
environments.</div><div><a href='http://arxiv.org/abs/2402.00831v1'>2402.00831v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.13101v1")'>AdaptSFL: Adaptive Split Federated Learning in Resource-constrained Edge
  Networks</div>
<div id='2403.13101v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-19T19:05:24Z</div><div>Authors: Zheng Lin, Guanqiao Qu, Wei Wei, Xianhao Chen, Kin K. Leung</div><div style='padding-top: 10px; width: 80ex'>The increasing complexity of deep neural networks poses significant barriers
to democratizing them to resource-limited edge devices. To address this
challenge, split federated learning (SFL) has emerged as a promising solution
by of floading the primary training workload to a server via model partitioning
while enabling parallel training among edge devices. However, although system
optimization substantially influences the performance of SFL under
resource-constrained systems, the problem remains largely uncharted. In this
paper, we provide a convergence analysis of SFL which quantifies the impact of
model splitting (MS) and client-side model aggregation (MA) on the learning
performance, serving as a theoretical foundation. Then, we propose AdaptSFL, a
novel resource-adaptive SFL framework, to expedite SFL under
resource-constrained edge computing systems. Specifically, AdaptSFL adaptively
controls client-side MA and MS to balance communication-computing latency and
training convergence. Extensive simulations across various datasets validate
that our proposed AdaptSFL framework takes considerably less time to achieve a
target accuracy than benchmarks, demonstrating the effectiveness of the
proposed strategies.</div><div><a href='http://arxiv.org/abs/2403.13101v1'>2403.13101v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.10092v1")'>Workflow Optimization for Parallel Split Learning</div>
<div id='2402.10092v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T14:16:10Z</div><div>Authors: Joana Tirana, Dimitra Tsigkari, George Iosifidis, Dimitris Chatzopoulos</div><div style='padding-top: 10px; width: 80ex'>Split learning (SL) has been recently proposed as a way to enable
resource-constrained devices to train multi-parameter neural networks (NNs) and
participate in federated learning (FL). In a nutshell, SL splits the NN model
into parts, and allows clients (devices) to offload the largest part as a
processing task to a computationally powerful helper. In parallel SL, multiple
helpers can process model parts of one or more clients, thus, considerably
reducing the maximum training time over all clients (makespan). In this paper,
we focus on orchestrating the workflow of this operation, which is critical in
highly heterogeneous systems, as our experiments show. In particular, we
formulate the joint problem of client-helper assignments and scheduling
decisions with the goal of minimizing the training makespan, and we prove that
it is NP-hard. We propose a solution method based on the decomposition of the
problem by leveraging its inherent symmetry, and a second one that is fully
scalable. A wealth of numerical evaluations using our testbed's measurements
allow us to build a solution strategy comprising these methods. Moreover, we
show that this strategy finds a near-optimal solution, and achieves a shorter
makespan than the baseline scheme by up to 52.3%.</div><div><a href='http://arxiv.org/abs/2402.10092v1'>2402.10092v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.10616v1")'>DiPaCo: Distributed Path Composition</div>
<div id='2403.10616v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-15T18:26:51Z</div><div>Authors: Arthur Douillard, Qixuan Feng, Andrei A. Rusu, Adhiguna Kuncoro, Yani Donchev, Rachita Chhaparia, Ionel Gog, Marc'Aurelio Ranzato, Jiajun Shen, Arthur Szlam</div><div style='padding-top: 10px; width: 80ex'>Progress in machine learning (ML) has been fueled by scaling neural network
models. This scaling has been enabled by ever more heroic feats of engineering,
necessary for accommodating ML approaches that require high bandwidth
communication between devices working in parallel. In this work, we propose a
co-designed modular architecture and training approach for ML models, dubbed
DIstributed PAth COmposition (DiPaCo). During training, DiPaCo distributes
computation by paths through a set of shared modules. Together with a Local-SGD
inspired optimization (DiLoCo) that keeps modules in sync with drastically
reduced communication, Our approach facilitates training across poorly
connected and heterogeneous workers, with a design that ensures robustness to
worker failures and preemptions. At inference time, only a single path needs to
be executed for each input, without the need for any model compression. We
consider this approach as a first prototype towards a new paradigm of
large-scale learning, one that is less synchronous and more modular. Our
experiments on the widely used C4 benchmark show that, for the same amount of
training steps but less wall-clock time, DiPaCo exceeds the performance of a 1
billion-parameter dense transformer language model by choosing one of 256
possible paths, each with a size of 150 million parameters.</div><div><a href='http://arxiv.org/abs/2403.10616v1'>2403.10616v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03699v1")'>Model Parallelism on Distributed Infrastructure: A Literature Review
  from Theory to LLM Case-Studies</div>
<div id='2403.03699v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T13:29:00Z</div><div>Authors: Felix Brakel, Uraz Odyurt, Ana-Lucia Varbanescu</div><div style='padding-top: 10px; width: 80ex'>Neural networks have become a cornerstone of machine learning. As the trend
for these to get more and more complex continues, so does the underlying
hardware and software infrastructure for training and deployment. In this
survey we answer three research questions: "What types of model parallelism
exist?", "What are the challenges of model parallelism?", and "What is a modern
use-case of model parallelism?" We answer the first question by looking at how
neural networks can be parallelised and expressing these as operator graphs
while exploring the available dimensions. The dimensions along which neural
networks can be parallelised are intra-operator and inter-operator. We answer
the second question by collecting and listing both implementation challenges
for the types of parallelism, as well as the problem of optimally partitioning
the operator graph. We answer the last question by collecting and listing how
parallelism is applied in modern multi-billion parameter transformer networks,
to the extend that this is possible with the limited information shared about
these networks.</div><div><a href='http://arxiv.org/abs/2403.03699v1'>2403.03699v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.00860v1")'>Parallel Algorithms for Exact Enumeration of Deep Neural Network
  Activation Regions</div>
<div id='2403.00860v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T20:48:39Z</div><div>Authors: Sabrina Drammis, Bowen Zheng, Karthik Srinivasan, Robert C. Berwick, Nancy A. Lynch, Robert Ajemian</div><div style='padding-top: 10px; width: 80ex'>A feedforward neural network using rectified linear units constructs a
mapping from inputs to outputs by partitioning its input space into a set of
convex regions where points within a region share a single affine
transformation. In order to understand how neural networks work, when and why
they fail, and how they compare to biological intelligence, we need to
understand the organization and formation of these regions. Step one is to
design and implement algorithms for exact region enumeration in networks beyond
toy examples.
  In this work, we present parallel algorithms for exact enumeration in deep
(and shallow) neural networks. Our work has three main contributions: (1) we
present a novel algorithm framework and parallel algorithms for region
enumeration; (2) we implement one of our algorithms on a variety of network
architectures and experimentally show how the number of regions dictates
runtime; and (3) we show, using our algorithm's output, how the dimension of a
region's affine transformation impacts further partitioning of the region by
deeper layers.
  To our knowledge, we run our implemented algorithm on networks larger than
all of the networks used in the existing region enumeration literature.
Further, we experimentally demonstrate the importance of parallelism for region
enumeration of any reasonably sized network.</div><div><a href='http://arxiv.org/abs/2403.00860v1'>2403.00860v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03460v1")'>Breaking the Curse of Dimensionality with Distributed Neural Computation</div>
<div id='2402.03460v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T19:11:57Z</div><div>Authors: Haitz Sáez de Ocáriz Borde, Takashi Furuya, Anastasis Kratsios, Marc T. Law</div><div style='padding-top: 10px; width: 80ex'>We present a theoretical approach to overcome the curse of dimensionality
using a neural computation algorithm which can be distributed across several
machines. Our modular distributed deep learning paradigm, termed \textit{neural
pathways}, can achieve arbitrary accuracy while only loading a small number of
parameters into GPU VRAM. Formally, we prove that for every error level
$\varepsilon&gt;0$ and every Lipschitz function $f:[0,1]^n\to \mathbb{R}$, one can
construct a neural pathways model which uniformly approximates $f$ to
$\varepsilon$ accuracy over $[0,1]^n$ while only requiring networks of
$\mathcal{O}(\varepsilon^{-1})$ parameters to be loaded in memory and
$\mathcal{O}(\varepsilon^{-1}\log(\varepsilon^{-1}))$ to be loaded during the
forward pass. This improves the optimal bounds for traditional non-distributed
deep learning models, namely ReLU MLPs, which need
$\mathcal{O}(\varepsilon^{-n/2})$ parameters to achieve the same accuracy. The
only other available deep learning model that breaks the curse of
dimensionality is MLPs with super-expressive activation functions. However, we
demonstrate that these models have an infinite VC dimension, even with bounded
depth and width restrictions, unlike the neural pathways model. This implies
that only the latter generalizes. Our analysis is validated experimentally in
both regression and classification tasks, demonstrating that our model exhibits
superior performance compared to larger centralized benchmarks.</div><div><a href='http://arxiv.org/abs/2402.03460v1'>2402.03460v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.11163v1")'>A Selective Review on Statistical Methods for Massive Data Computation:
  Distributed Computing, Subsampling, and Minibatch Techniques</div>
<div id='2403.11163v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-17T10:09:54Z</div><div>Authors: Xuetong Li, Yuan Gao, Hong Chang, Danyang Huang, Yingying Ma, Rui Pan, Haobo Qi, Feifei Wang, Shuyuan Wu, Ke Xu, Jing Zhou, Xuening Zhu, Yingqiu Zhu, Hansheng Wang</div><div style='padding-top: 10px; width: 80ex'>This paper presents a selective review of statistical computation methods for
massive data analysis. A huge amount of statistical methods for massive data
computation have been rapidly developed in the past decades. In this work, we
focus on three categories of statistical computation methods: (1) distributed
computing, (2) subsampling methods, and (3) minibatch gradient techniques. The
first class of literature is about distributed computing and focuses on the
situation, where the dataset size is too huge to be comfortably handled by one
single computer. In this case, a distributed computation system with multiple
computers has to be utilized. The second class of literature is about
subsampling methods and concerns about the situation, where the sample size of
dataset is small enough to be placed on one single computer but too large to be
easily processed by its memory as a whole. The last class of literature studies
those minibatch gradient related optimization techniques, which have been
extensively used for optimizing various deep learning models.</div><div><a href='http://arxiv.org/abs/2403.11163v1'>2403.11163v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.09268v1")'>Transformers, parallel computation, and logarithmic depth</div>
<div id='2402.09268v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T15:54:55Z</div><div>Authors: Clayton Sanford, Daniel Hsu, Matus Telgarsky</div><div style='padding-top: 10px; width: 80ex'>We show that a constant number of self-attention layers can efficiently
simulate, and be simulated by, a constant number of communication rounds of
Massively Parallel Computation. As a consequence, we show that logarithmic
depth is sufficient for transformers to solve basic computational tasks that
cannot be efficiently solved by several other neural sequence models and
sub-quadratic transformer approximations. We thus establish parallelism as a
key distinguishing property of transformers.</div><div><a href='http://arxiv.org/abs/2402.09268v1'>2402.09268v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15883v2")'>Fusion Encoder Networks</div>
<div id='2402.15883v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-24T19:06:41Z</div><div>Authors: Stephen Pasteris, Chris Hicks, Vasilios Mavroudis</div><div style='padding-top: 10px; width: 80ex'>In this paper we present fusion encoder networks (FENs): a class of
algorithms for creating neural networks that map sequences to outputs. The
resulting neural network has only logarithmic depth (alleviating the
degradation of data as it propagates through the network) and can process
sequences in linear time (or in logarithmic time with a linear number of
processors). The crucial property of FENs is that they learn by training a
quasi-linear number of constant-depth feed-forward neural networks in parallel.
The fact that these networks have constant depth means that backpropagation
works well. We note that currently the performance of FENs is only conjectured
as we are yet to implement them.</div><div><a href='http://arxiv.org/abs/2402.15883v2'>2402.15883v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.01728v1")'>Ravnest: Decentralized Asynchronous Training on Heterogeneous Devices</div>
<div id='2401.01728v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-03T13:07:07Z</div><div>Authors: Anirudh Rajiv Menon, Unnikrishnan Menon, Kailash Ahirwar</div><div style='padding-top: 10px; width: 80ex'>Modern deep learning models, growing larger and more complex, have
demonstrated exceptional generalization and accuracy due to training on huge
datasets. This trend is expected to continue. However, the increasing size of
these models poses challenges in training, as traditional centralized methods
are limited by memory constraints at such scales. This paper proposes an
asynchronous decentralized training paradigm for large modern deep learning
models that harnesses the compute power of regular heterogeneous PCs with
limited resources connected across the internet to achieve favourable
performance metrics. Ravnest facilitates decentralized training by efficiently
organizing compute nodes into clusters with similar data transfer rates and
compute capabilities, without necessitating that each node hosts the entire
model. These clusters engage in $\textit{Zero-Bubble Asynchronous Model
Parallel}$ training, and a $\textit{Parallel Multi-Ring All-Reduce}$ method is
employed to effectively execute global parameter averaging across all clusters.
We have framed our asynchronous SGD loss function as a block structured
optimization problem with delayed updates and derived an optimal convergence
rate of $O\left(\frac{1}{\sqrt{K}}\right)$. We further discuss linear speedup
with respect to the number of participating clusters and the bound on the
staleness parameter.</div><div><a href='http://arxiv.org/abs/2401.01728v1'>2401.01728v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.07585v1")'>Communication Optimization for Distributed Training: Architecture,
  Advances, and Opportunities</div>
<div id='2403.07585v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T12:15:57Z</div><div>Authors: Yunze Wei, Tianshuo Hu, Cong Liang, Yong Cui</div><div style='padding-top: 10px; width: 80ex'>The past few years have witnessed the flourishing of large-scale deep neural
network models with ever-growing parameter numbers. Training such large-scale
models typically requires massive memory and computing resources that exceed
those of a single GPU, necessitating distributed training. As GPU performance
has rapidly evolved in recent years, computation time has shrunk, thereby
increasing the proportion of communication in the overall training time.
Therefore, optimizing communication for distributed training has become an
urgent issue. In this article, we briefly introduce the general architecture of
distributed deep neural network training and analyze relationships among
Parallelization Strategy, Collective Communication Library, and Network from
the perspective of communication optimization, which forms a three-layer
paradigm. We then review current representative research advances with this
three-layer paradigm. We find that layers in the current three-layer paradigm
are relatively independent, but there is a rich design space for cross-layer
collaborative optimization in distributed training scenarios. Therefore, we
further advocate a communication-efficient five-layer paradigm underlining
opportunities for collaboration designs and look forward to the perspectives of
"Vertical", "Horizontal", "Intra-Inter" and "Host-Net" collaboration designs.
We hope this article can shed some light on future research on communication
optimization for distributed training.</div><div><a href='http://arxiv.org/abs/2403.07585v1'>2403.07585v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16492v1")'>GPU Cluster Scheduling for Network-Sensitive Deep Learning</div>
<div id='2401.16492v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T19:06:08Z</div><div>Authors: Aakash Sharma, Vivek M. Bhasi, Sonali Singh, George Kesidis, Mahmut T. Kandemir, Chita R. Das</div><div style='padding-top: 10px; width: 80ex'>We propose a novel GPU-cluster scheduler for distributed DL (DDL) workloads
that enables proximity based consolidation of GPU resources based on the DDL
jobs' sensitivities to the anticipated communication-network delays. Our
scheduler consists of three major components: (i) a classical delay scheduling
algorithm to facilitate job placement and consolidation; (ii) a
network-sensitive job preemption strategy; and (iii) an "auto-tuner" mechanism
to optimize delay timers for effective delay scheduling. Additionally, to
enable a cost-effective methodology for large-scale experiments, we develop a
data-driven DDL cluster simulation platform. Employing the simulation platform
we compare against several state-of-the-art alternatives on real-world workload
traces to demonstrate the benefits of our design. Our scheduler can provide
improvement of up to 69% in end-to-end Makespan for training all jobs compared
to the prevailing consolidation-based scheduling methods, while reducing the
average job completion time by up to 83% and minimizing the communication
overheads by up to 98% under congested networking conditions.</div><div><a href='http://arxiv.org/abs/2401.16492v1'>2401.16492v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09589v1")'>MLTCP: Congestion Control for DNN Training</div>
<div id='2402.09589v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T21:33:18Z</div><div>Authors: Sudarsanan Rajasekaran, Sanjoli Narang, Anton A. Zabreyko, Manya Ghobadi</div><div style='padding-top: 10px; width: 80ex'>We present MLTCP, a technique to augment today's congestion control
algorithms to accelerate DNN training jobs in shared GPU clusters. MLTCP
enables the communication phases of jobs that compete for network bandwidth to
interleave with each other, thereby utilizing the network efficiently. At the
heart of MLTCP lies a very simple principle based on a key conceptual insight:
DNN training flows should scale their congestion window size based on the
number of bytes sent at each training iteration. We show that integrating this
principle into today's congestion control protocols is straightforward: by
adding 30-60 lines of code to Reno, CUBIC, or DCQCN, MLTCP stabilizes flows of
different jobs into an interleaved state within a few training iterations,
regardless of the number of competing flows or the start time of each flow. Our
experiments with popular DNN training jobs demonstrate that enabling MLTCP
accelerates the average and 99th percentile training iteration time by up to 2x
and 4x, respectively.</div><div><a href='http://arxiv.org/abs/2402.09589v1'>2402.09589v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.07529v1")'>Accelerating Distributed Deep Learning using Lossless Homomorphic
  Compression</div>
<div id='2402.07529v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-12T09:57:47Z</div><div>Authors: Haoyu Li, Yuchen Xu, Jiayi Chen, Rohit Dwivedula, Wenfei Wu, Keqiang He, Aditya Akella, Daehyeok Kim</div><div style='padding-top: 10px; width: 80ex'>As deep neural networks (DNNs) grow in complexity and size, the resultant
increase in communication overhead during distributed training has become a
significant bottleneck, challenging the scalability of distributed training
systems. Existing solutions, while aiming to mitigate this bottleneck through
worker-level compression and in-network aggregation, fall short due to their
inability to efficiently reconcile the trade-offs between compression
effectiveness and computational overhead, hindering overall performance and
scalability. In this paper, we introduce a novel compression algorithm that
effectively merges worker-level compression with in-network aggregation. Our
solution is both homomorphic, allowing for efficient in-network aggregation
without CPU/GPU processing, and lossless, ensuring no compromise on training
accuracy. Theoretically optimal in compression and computational efficiency,
our approach is empirically validated across diverse DNN models such as NCF,
LSTM, VGG19, and BERT-base, showing up to a 6.33$\times$ improvement in
aggregation throughput and a 3.74$\times$ increase in per-iteration training
speed.</div><div><a href='http://arxiv.org/abs/2402.07529v1'>2402.07529v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.07788v1")'>Activations and Gradients Compression for Model-Parallel Training</div>
<div id='2401.07788v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T15:54:54Z</div><div>Authors: Mikhail Rudakov, Aleksandr Beznosikov, Yaroslav Kholodov, Alexander Gasnikov</div><div style='padding-top: 10px; width: 80ex'>Large neural networks require enormous computational clusters of machines.
Model-parallel training, when the model architecture is partitioned
sequentially between workers, is a popular approach for training modern models.
Information compression can be applied to decrease workers communication time,
as it is often a bottleneck in such systems. This work explores how
simultaneous compression of activations and gradients in model-parallel
distributed training setup affects convergence. We analyze compression methods
such as quantization and TopK compression, and also experiment with error
compensation techniques. Moreover, we employ TopK with AQ-SGD per-batch error
feedback approach. We conduct experiments on image classification and language
model fine-tuning tasks. Our findings demonstrate that gradients require milder
compression rates than activations. We observe that $K=10\%$ is the lowest TopK
compression level, which does not harm model convergence severely. Experiments
also show that models trained with TopK perform well only when compression is
also applied during inference. We find that error feedback techniques do not
improve model-parallel training compared to plain compression, but allow model
inference without compression with almost no quality drop. Finally, when
applied with the AQ-SGD approach, TopK stronger than with $ K=30\%$ worsens
model performance significantly.</div><div><a href='http://arxiv.org/abs/2401.07788v1'>2401.07788v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.11202v3")'>PartIR: Composing SPMD Partitioning Strategies for Machine Learning</div>
<div id='2401.11202v3' style='display: none; margin-left: 20px'><div>Date: 2024-01-20T10:30:31Z</div><div>Authors: Sami Alabed, Daniel Belov, Bart Chrzaszcz, Juliana Franco, Dominik Grewe, Dougal Maclaurin, James Molloy, Tom Natan, Tamara Norman, Xiaoyue Pan, Adam Paszke, Norman A. Rink, Michael Schaarschmidt, Timur Sitdikov, Agnieszka Swietlik, Dimitrios Vytiniotis, Joel Wee</div><div style='padding-top: 10px; width: 80ex'>Training of modern large neural networks (NN) requires a combination of
parallelization strategies encompassing data, model, or optimizer sharding.
When strategies increase in complexity, it becomes necessary for partitioning
tools to be 1) expressive, allowing the composition of simpler strategies, and
2) predictable to estimate performance analytically. We present PartIR, our
design for a NN partitioning system. PartIR is focused on an incremental
approach to rewriting and is hardware-and-runtime agnostic. We present a simple
but powerful API for composing sharding strategies and a simulator to validate
them. The process is driven by high-level programmer-issued partitioning
tactics, which can be both manual and automatic. Importantly, the tactics are
specified separately from the model code, making them easy to change. We
evaluate PartIR on several different models to demonstrate its predictability,
expressibility, and ability to reach peak performance..</div><div><a href='http://arxiv.org/abs/2401.11202v3'>2401.11202v3</a></div>
</div></div>
    <div><a href="arxiv_6.html">Prev (6)</a></div>
    <div><a href="arxiv_8.html">Next (8)</a></div>
    