
<!doctype html>
<meta charset="utf-8">
<style>
body { margin: 20px; }
</style>
<script>
function toggle(arxiv) {
  let elt = document.getElementById(arxiv);
  console.log(elt, elt.style.display);
  if(elt.style.display == "block") {
    elt.style.display = "none";
  } else {
    elt.style.display = "block";
  }
}
</script>
<div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.12630v1")'>FAST: An Optimization Framework for Fast Additive Segmentation in
  Transparent ML</div>
<div id='2402.12630v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T01:22:04Z</div><div>Authors: Brian Liu, Rahul Mazumder</div><div style='padding-top: 10px; width: 80ex'>We present FAST, an optimization framework for fast additive segmentation.
FAST segments piecewise constant shape functions for each feature in a dataset
to produce transparent additive models. The framework leverages a novel
optimization procedure to fit these models $\sim$2 orders of magnitude faster
than existing state-of-the-art methods, such as explainable boosting machines
\citep{nori2019interpretml}. We also develop new feature selection algorithms
in the FAST framework to fit parsimonious models that perform well. Through
experiments and case studies, we show that FAST improves the computational
efficiency and interpretability of additive models.</div><div><a href='http://arxiv.org/abs/2402.12630v1'>2402.12630v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.04682v1")'>Mixture of multilayer stochastic block models for multiview clustering</div>
<div id='2401.04682v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-09T17:15:47Z</div><div>Authors: Kylliann De Santiago, Marie Szafranski, Christophe Ambroise</div><div style='padding-top: 10px; width: 80ex'>In this work, we propose an original method for aggregating multiple
clustering coming from different sources of information. Each partition is
encoded by a co-membership matrix between observations. Our approach uses a
mixture of multilayer Stochastic Block Models (SBM) to group co-membership
matrices with similar information into components and to partition observations
into different clusters, taking into account their specificities within the
components. The identifiability of the model parameters is established and a
variational Bayesian EM algorithm is proposed for the estimation of these
parameters. The Bayesian framework allows for selecting an optimal number of
clusters and components. The proposed approach is compared using synthetic data
with consensus clustering and tensor-based algorithms for community detection
in large-scale complex networks. Finally, the method is utilized to analyze
global food trading networks, leading to structures of interest.</div><div><a href='http://arxiv.org/abs/2401.04682v1'>2401.04682v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.02229v3")'>Vanilla Bayesian Optimization Performs Great in High Dimensions</div>
<div id='2402.02229v3' style='display: none; margin-left: 20px'><div>Date: 2024-02-03T18:19:46Z</div><div>Authors: Carl Hvarfner, Erik Orm Hellsten, Luigi Nardi</div><div style='padding-top: 10px; width: 80ex'>High-dimensional problems have long been considered the Achilles' heel of
Bayesian optimization algorithms. Spurred by the curse of dimensionality, a
large collection of algorithms aim to make it more performant in this setting,
commonly by imposing various simplifying assumptions on the objective. In this
paper, we identify the degeneracies that make vanilla Bayesian optimization
poorly suited to high-dimensional tasks, and further show how existing
algorithms address these degeneracies through the lens of lowering the model
complexity. Moreover, we propose an enhancement to the prior assumptions that
are typical to vanilla Bayesian optimization algorithms, which reduces the
complexity to manageable levels without imposing structural restrictions on the
objective. Our modification - a simple scaling of the Gaussian process
lengthscale prior with the dimensionality - reveals that standard Bayesian
optimization works drastically better than previously thought in high
dimensions, clearly outperforming existing state-of-the-art algorithms on
multiple commonly considered real-world high-dimensional tasks.</div><div><a href='http://arxiv.org/abs/2402.02229v3'>2402.02229v3</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07356v2")'>A Novel Gaussian Min-Max Theorem and its Applications</div>
<div id='2402.07356v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-12T01:11:49Z</div><div>Authors: Danil Akhtiamov, David Bosch, Reza Ghane, K Nithin Varma, Babak Hassibi</div><div style='padding-top: 10px; width: 80ex'>A celebrated result by Gordon allows one to compare the min-max behavior of
two Gaussian processes if certain inequality conditions are met. The
consequences of this result include the Gaussian min-max (GMT) and convex
Gaussian min-max (CGMT) theorems which have had far-reaching implications in
high-dimensional statistics, machine learning, non-smooth optimization, and
signal processing. Both theorems rely on a pair of Gaussian processes, first
identified by Slepian, that satisfy Gordon's comparison inequalities. To date,
no other pair of Gaussian processes satisfying these inequalities has been
discovered. In this paper, we identify such a new pair. The resulting theorems
extend the classical GMT and CGMT Theorems from the case where the underlying
Gaussian matrix in the primary process has iid rows to where it has independent
but non-identically-distributed ones. The new CGMT is applied to the problems
of multi-source Gaussian regression, as well as to binary classification of
general Gaussian mixture models.</div><div><a href='http://arxiv.org/abs/2402.07356v2'>2402.07356v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15432v1")'>Universal Lower Bounds and Optimal Rates: Achieving Minimax Clustering
  Error in Sub-Exponential Mixture Models</div>
<div id='2402.15432v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-23T16:51:17Z</div><div>Authors: Maximilien Dreveton, Alperen Gözeten, Matthias Grossglauser, Patrick Thiran</div><div style='padding-top: 10px; width: 80ex'>Clustering is a pivotal challenge in unsupervised machine learning and is
often investigated through the lens of mixture models. The optimal error rate
for recovering cluster labels in Gaussian and sub-Gaussian mixture models
involves ad hoc signal-to-noise ratios. Simple iterative algorithms, such as
Lloyd's algorithm, attain this optimal error rate. In this paper, we first
establish a universal lower bound for the error rate in clustering any mixture
model, expressed through a Chernoff divergence, a more versatile measure of
model information than signal-to-noise ratios. We then demonstrate that
iterative algorithms attain this lower bound in mixture models with
sub-exponential tails, notably emphasizing location-scale mixtures featuring
Laplace-distributed errors. Additionally, for datasets better modelled by
Poisson or Negative Binomial mixtures, we study mixture models whose
distributions belong to an exponential family. In such mixtures, we establish
that Bregman hard clustering, a variant of Lloyd's algorithm employing a
Bregman divergence, is rate optimal.</div><div><a href='http://arxiv.org/abs/2402.15432v1'>2402.15432v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03695v1")'>Spectral Phase Transition and Optimal PCA in Block-Structured Spiked
  models</div>
<div id='2403.03695v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T13:23:55Z</div><div>Authors: Pierre Mergny, Justin Ko, Florent Krzakala</div><div style='padding-top: 10px; width: 80ex'>We discuss the inhomogeneous spiked Wigner model, a theoretical framework
recently introduced to study structured noise in various learning scenarios,
through the prism of random matrix theory, with a specific focus on its
spectral properties. Our primary objective is to find an optimal spectral
method and to extend the celebrated \cite{BBP} (BBP) phase transition criterion
-- well-known in the homogeneous case -- to our inhomogeneous,
block-structured, Wigner model. We provide a thorough rigorous analysis of a
transformed matrix and show that the transition for the appearance of 1) an
outlier outside the bulk of the limiting spectral distribution and 2) a
positive overlap between the associated eigenvector and the signal, occurs
precisely at the optimal threshold, making the proposed spectral method optimal
within the class of iterative methods for the inhomogeneous Wigner problem.</div><div><a href='http://arxiv.org/abs/2403.03695v1'>2403.03695v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.03206v1")'>A Robbins--Monro Sequence That Can Exploit Prior Information For Faster
  Convergence</div>
<div id='2401.03206v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-06T12:42:58Z</div><div>Authors: Siwei Liu, Ke Ma, Stephan M. Goetz</div><div style='padding-top: 10px; width: 80ex'>We propose a new method to improve the convergence speed of the Robbins-Monro
algorithm by introducing prior information about the target point into the
Robbins-Monro iteration. We achieve the incorporation of prior information
without the need of a -- potentially wrong -- regression model, which would
also entail additional constraints. We show that this prior-information
Robbins-Monro sequence is convergent for a wide range of prior distributions,
even wrong ones, such as Gaussian, weighted sum of Gaussians, e.g., in a kernel
density estimate, as well as bounded arbitrary distribution functions greater
than zero. We furthermore analyse the sequence numerically to understand its
performance and the influence of parameters. The results demonstrate that the
prior-information Robbins-Monro sequence converges faster than the standard
one, especially during the first steps, which are particularly important for
applications where the number of function measurements is limited, and when the
noise of observing the underlying function is large. We finally propose a rule
to select the parameters of the sequence.</div><div><a href='http://arxiv.org/abs/2401.03206v1'>2401.03206v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03104v1")'>High-dimensional Bayesian Optimization via Covariance Matrix Adaptation
  Strategy</div>
<div id='2402.03104v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T15:32:10Z</div><div>Authors: Lam Ngo, Huong Ha, Jeffrey Chan, Vu Nguyen, Hongyu Zhang</div><div style='padding-top: 10px; width: 80ex'>Bayesian Optimization (BO) is an effective method for finding the global
optimum of expensive black-box functions. However, it is well known that
applying BO to high-dimensional optimization problems is challenging. To
address this issue, a promising solution is to use a local search strategy that
partitions the search domain into local regions with high likelihood of
containing the global optimum, and then use BO to optimize the objective
function within these regions. In this paper, we propose a novel technique for
defining the local regions using the Covariance Matrix Adaptation (CMA)
strategy. Specifically, we use CMA to learn a search distribution that can
estimate the probabilities of data points being the global optimum of the
objective function. Based on this search distribution, we then define the local
regions consisting of data points with high probabilities of being the global
optimum. Our approach serves as a meta-algorithm as it can incorporate existing
black-box BO optimizers, such as BO, TuRBO, and BAxUS, to find the global
optimum of the objective function within our derived local regions. We evaluate
our proposed method on various benchmark synthetic and real-world problems. The
results demonstrate that our method outperforms existing state-of-the-art
techniques.</div><div><a href='http://arxiv.org/abs/2402.03104v1'>2402.03104v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15146v1")'>Convergence Analysis of Blurring Mean Shift</div>
<div id='2402.15146v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-23T07:05:09Z</div><div>Authors: Ryoya Yamasaki, Toshiyuki Tanaka</div><div style='padding-top: 10px; width: 80ex'>Blurring mean shift (BMS) algorithm, a variant of the mean shift algorithm,
is a kernel-based iterative method for data clustering, where data points are
clustered according to their convergent points via iterative blurring. In this
paper, we analyze convergence properties of the BMS algorithm by leveraging its
interpretation as an optimization procedure, which is known but has been
underutilized in existing convergence studies. Whereas existing results on
convergence properties applicable to multi-dimensional data only cover the case
where all the blurred data point sequences converge to a single point, this
study provides a convergence guarantee even when those sequences can converge
to multiple points, yielding multiple clusters. This study also shows that the
convergence of the BMS algorithm is fast by further leveraging geometrical
characterization of the convergent points.</div><div><a href='http://arxiv.org/abs/2402.15146v1'>2402.15146v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.16237v1")'>Active Level Set Estimation for Continuous Search Space with Theoretical
  Guarantee</div>
<div id='2402.16237v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T01:46:56Z</div><div>Authors: Giang Ngo, Dang Nguyen, Dat Phan-Trong, Sunil Gupta</div><div style='padding-top: 10px; width: 80ex'>A common problem encountered in many real-world applications is level set
estimation where the goal is to determine the region in the function domain
where the function is above or below a given threshold. When the function is
black-box and expensive to evaluate, the level sets need to be found in a
minimum set of function evaluations. Existing methods often assume a discrete
search space with a finite set of data points for function evaluations and
estimating the level sets. When applied to a continuous search space, these
methods often need to first discretize the space which leads to poor results
while needing high computational time. While some methods cater for the
continuous setting, they still lack a proper guarantee for theoretical
convergence. To address this problem, we propose a novel algorithm that does
not need any discretization and can directly work in continuous search spaces.
Our method suggests points by constructing an acquisition function that is
defined as a measure of confidence of the function being higher or lower than
the given threshold. A theoretical analysis for the convergence of the
algorithm to an accurate solution is provided. On multiple synthetic and
real-world datasets, our algorithm successfully outperforms state-of-the-art
methods.</div><div><a href='http://arxiv.org/abs/2402.16237v1'>2402.16237v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.07207v1")'>Tracking Dynamic Gaussian Density with a Theoretically Optimal Sliding
  Window Approach</div>
<div id='2403.07207v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-11T23:21:26Z</div><div>Authors: Yinsong Wang, Yu Ding, Shahin Shahrampour</div><div style='padding-top: 10px; width: 80ex'>Dynamic density estimation is ubiquitous in many applications, including
computer vision and signal processing. One popular method to tackle this
problem is the "sliding window" kernel density estimator. There exist various
implementations of this method that use heuristically defined weight sequences
for the observed data. The weight sequence, however, is a key aspect of the
estimator affecting the tracking performance significantly. In this work, we
study the exact mean integrated squared error (MISE) of "sliding window"
Gaussian Kernel Density Estimators for evolving Gaussian densities. We provide
a principled guide for choosing the optimal weight sequence by theoretically
characterizing the exact MISE, which can be formulated as constrained quadratic
programming. We present empirical evidence with synthetic datasets to show that
our weighting scheme indeed improves the tracking performance compared to
heuristic approaches.</div><div><a href='http://arxiv.org/abs/2403.07207v1'>2403.07207v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.13300v1")'>Kernel Multigrid: Accelerate Back-fitting via Sparse Gaussian Process
  Regression</div>
<div id='2403.13300v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-20T04:57:27Z</div><div>Authors: Lu Zou, Liang Ding</div><div style='padding-top: 10px; width: 80ex'>Additive Gaussian Processes (GPs) are popular approaches for nonparametric
feature selection. The common training method for these models is Bayesian
Back-fitting. However, the convergence rate of Back-fitting in training
additive GPs is still an open problem. By utilizing a technique called Kernel
Packets (KP), we prove that the convergence rate of Back-fitting is no faster
than $(1-\mathcal{O}(\frac{1}{n}))^t$, where $n$ and $t$ denote the data size
and the iteration number, respectively. Consequently, Back-fitting requires a
minimum of $\mathcal{O}(n\log n)$ iterations to achieve convergence. Based on
KPs, we further propose an algorithm called Kernel Multigrid (KMG). This
algorithm enhances Back-fitting by incorporating a sparse Gaussian Process
Regression (GPR) to process the residuals subsequent to each Back-fitting
iteration. It is applicable to additive GPs with both structured and scattered
data. Theoretically, we prove that KMG reduces the required iterations to
$\mathcal{O}(\log n)$ while preserving the time and space complexities at
$\mathcal{O}(n\log n)$ and $\mathcal{O}(n)$ per iteration, respectively.
Numerically, by employing a sparse GPR with merely 10 inducing points, KMG can
produce accurate approximations of high-dimensional targets within 5
iterations.</div><div><a href='http://arxiv.org/abs/2403.13300v1'>2403.13300v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03648v1")'>Multilinear Kernel Regression and Imputation via Manifold Learning</div>
<div id='2402.03648v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-06T02:50:42Z</div><div>Authors: Duc Thien Nguyen, Konstantinos Slavakis</div><div style='padding-top: 10px; width: 80ex'>This paper introduces a novel nonparametric framework for data imputation,
coined multilinear kernel regression and imputation via the manifold assumption
(MultiL-KRIM). Motivated by manifold learning, MultiL-KRIM models data features
as a point cloud located in or close to a user-unknown smooth manifold embedded
in a reproducing kernel Hilbert space. Unlike typical manifold-learning routes,
which seek low-dimensional patterns via regularizers based on graph-Laplacian
matrices, MultiL-KRIM builds instead on the intuitive concept of tangent spaces
to manifolds and incorporates collaboration among point-cloud neighbors
(regressors) directly into the data-modeling term of the loss function.
Multiple kernel functions are allowed to offer robustness and rich
approximation properties, while multiple matrix factors offer low-rank
modeling, integrate dimensionality reduction, and streamline computations with
no need of training data. Two important application domains showcase the
functionality of MultiL-KRIM: time-varying-graph-signal (TVGS) recovery, and
reconstruction of highly accelerated dynamic-magnetic-resonance-imaging (dMRI)
data. Extensive numerical tests on real and synthetic data demonstrate
MultiL-KRIM's remarkable speedups over its predecessors, and outperformance
over prevalent "shallow" data-imputation techniques, with a more intuitive and
explainable pipeline than deep-image-prior methods.</div><div><a href='http://arxiv.org/abs/2402.03648v1'>2402.03648v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.08245v1")'>Optimizing $k$ in $k$NN Graphs with Graph Learning Perspective</div>
<div id='2401.08245v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-16T09:59:36Z</div><div>Authors: Asuka Tamaru, Junya Hara, Hiroshi Higashi, Yuichi Tanaka, Antonio Ortega</div><div style='padding-top: 10px; width: 80ex'>In this paper, we propose a method, based on graph signal processing, to
optimize the choice of $k$ in $k$-nearest neighbor graphs ($k$NNGs). $k$NN is
one of the most popular approaches and is widely used in machine learning and
signal processing. The parameter $k$ represents the number of neighbors that
are connected to the target node; however, its appropriate selection is still a
challenging problem. Therefore, most $k$NNGs use ad hoc selection methods for
$k$. In the proposed method, we assume that a different $k$ can be chosen for
each node. We formulate a discrete optimization problem to seek the best $k$
with a constraint on the sum of distances of the connected nodes. The optimal
$k$ values are efficiently obtained without solving a complex optimization.
Furthermore, we reveal that the proposed method is closely related to existing
graph learning methods. In experiments on real datasets, we demonstrate that
the $k$NNGs obtained with our method are sparse and can determine an
appropriate variable number of edges per node. We validate the effectiveness of
the proposed method for point cloud denoising, comparing our denoising
performance with achievable graph construction methods that can be scaled to
typical point cloud sizes (e.g., thousands of nodes).</div><div><a href='http://arxiv.org/abs/2401.08245v1'>2401.08245v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.09608v1")'>Exact, Fast and Expressive Poisson Point Processes via Squared Neural
  Families</div>
<div id='2402.09608v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T22:32:00Z</div><div>Authors: Russell Tsuchida, Cheng Soon Ong, Dino Sejdinovic</div><div style='padding-top: 10px; width: 80ex'>We introduce squared neural Poisson point processes (SNEPPPs) by
parameterising the intensity function by the squared norm of a two layer neural
network. When the hidden layer is fixed and the second layer has a single
neuron, our approach resembles previous uses of squared Gaussian process or
kernel methods, but allowing the hidden layer to be learnt allows for
additional flexibility. In many cases of interest, the integrated intensity
function admits a closed form and can be computed in quadratic time in the
number of hidden neurons. We enumerate a far more extensive number of such
cases than has previously been discussed. Our approach is more memory and time
efficient than naive implementations of squared or exponentiated kernel methods
or Gaussian processes. Maximum likelihood and maximum a posteriori estimates in
a reparameterisation of the final layer of the intensity function can be
obtained by solving a (strongly) convex optimisation problem using projected
gradient descent. We demonstrate SNEPPPs on real, and synthetic benchmarks, and
provide a software implementation. https://github.com/RussellTsuchida/snefy</div><div><a href='http://arxiv.org/abs/2402.09608v1'>2402.09608v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.11199v1")'>Projected Belief Networks With Discriminative Alignment for Acoustic
  Event Classification: Rivaling State of the Art CNNs</div>
<div id='2401.11199v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-20T10:27:04Z</div><div>Authors: Paul M. Baggenstoss, Kevin Wilkinghoff, Felix Govaers, Frank Kurth</div><div style='padding-top: 10px; width: 80ex'>The projected belief network (PBN) is a generative stochastic network with
tractable likelihood function based on a feed-forward neural network (FFNN).
The generative function operates by "backing up" through the FFNN. The PBN is
two networks in one, a FFNN that operates in the forward direction, and a
generative network that operates in the backward direction. Both networks
co-exist based on the same parameter set, have their own cost functions, and
can be separately or jointly trained. The PBN therefore has the potential to
possess the best qualities of both discriminative and generative classifiers.
To realize this potential, a separate PBN is trained on each class, maximizing
the generative likelihood function for the given class, while minimizing the
discriminative cost for the FFNN against "all other classes". This technique,
called discriminative alignment (PBN-DA), aligns the contours of the likelihood
function to the decision boundaries and attains vastly improved classification
performance, rivaling that of state of the art discriminative networks. The
method may be further improved using a hidden Markov model (HMM) as a component
of the PBN, called PBN-DA-HMM. This paper provides a comprehensive treatment of
PBN, PBN-DA, and PBN-DA-HMM. In addition, the results of two new classification
experiments are provided. The first experiment uses air-acoustic events, and
the second uses underwater acoustic data consisting of marine mammal calls. In
both experiments, PBN-DA-HMM attains comparable or better performance as a
state of the art CNN, and attain a factor of two error reduction when combined
with the CNN.</div><div><a href='http://arxiv.org/abs/2401.11199v1'>2401.11199v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.17089v1")'>Learning high-dimensional targets by two-parameter models and gradient
  flow</div>
<div id='2402.17089v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T23:56:11Z</div><div>Authors: Dmitry Yarotsky</div><div style='padding-top: 10px; width: 80ex'>We explore the theoretical possibility of learning $d$-dimensional targets
with $W$-parameter models by gradient flow (GF) when $W&lt;d$. Our main result
shows that if the targets are described by a particular $d$-dimensional
probability distribution, then there exist models with as few as two parameters
that can learn the targets with arbitrarily high success probability. On the
other hand, we show that for $W&lt;d$ there is necessarily a large subset of
GF-non-learnable targets. In particular, the set of learnable targets is not
dense in $\mathbb R^d$, and any subset of $\mathbb R^d$ homeomorphic to the
$W$-dimensional sphere contains non-learnable targets. Finally, we observe that
the model in our main theorem on almost guaranteed two-parameter learning is
constructed using a hierarchical procedure and as a result is not expressible
by a single elementary function. We show that this limitation is essential in
the sense that such learnability can be ruled out for a large class of
elementary functions.</div><div><a href='http://arxiv.org/abs/2402.17089v1'>2402.17089v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.02697v1")'>Noise misleads rotation invariant algorithms on sparse targets</div>
<div id='2403.02697v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-05T06:25:19Z</div><div>Authors: Manfred K. Warmuth, Wojciech Kotłowski, Matt Jones, Ehsan Amid</div><div style='padding-top: 10px; width: 80ex'>It is well known that the class of rotation invariant algorithms are
suboptimal even for learning sparse linear problems when the number of examples
is below the "dimension" of the problem. This class includes any gradient
descent trained neural net with a fully-connected input layer (initialized with
a rotationally symmetric distribution). The simplest sparse problem is learning
a single feature out of $d$ features. In that case the classification error or
regression loss grows with $1-k/n$ where $k$ is the number of examples seen.
These lower bounds become vacuous when the number of examples $k$ reaches the
dimension $d$.
  We show that when noise is added to this sparse linear problem, rotation
invariant algorithms are still suboptimal after seeing $d$ or more examples. We
prove this via a lower bound for the Bayes optimal algorithm on a rotationally
symmetrized problem. We then prove much lower upper bounds on the same problem
for simple non-rotation invariant algorithms. Finally we analyze the gradient
flow trajectories of many standard optimization algorithms in some simple cases
and show how they veer toward or away from the sparse targets.
  We believe that our trajectory categorization will be useful in designing
algorithms that can exploit sparse targets and our method for proving lower
bounds will be crucial for analyzing other families of algorithms that admit
different classes of invariances.</div><div><a href='http://arxiv.org/abs/2403.02697v1'>2403.02697v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.06560v1")'>Sliced-Wasserstein Distances and Flows on Cartan-Hadamard Manifolds</div>
<div id='2403.06560v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-11T10:01:21Z</div><div>Authors: Clément Bonet, Lucas Drumetz, Nicolas Courty</div><div style='padding-top: 10px; width: 80ex'>While many Machine Learning methods were developed or transposed on
Riemannian manifolds to tackle data with known non Euclidean geometry, Optimal
Transport (OT) methods on such spaces have not received much attention. The
main OT tool on these spaces is the Wasserstein distance which suffers from a
heavy computational burden. On Euclidean spaces, a popular alternative is the
Sliced-Wasserstein distance, which leverages a closed-form solution of the
Wasserstein distance in one dimension, but which is not readily available on
manifolds. In this work, we derive general constructions of Sliced-Wasserstein
distances on Cartan-Hadamard manifolds, Riemannian manifolds with non-positive
curvature, which include among others Hyperbolic spaces or the space of
Symmetric Positive Definite matrices. Then, we propose different applications.
Additionally, we derive non-parametric schemes to minimize these new distances
by approximating their Wasserstein gradient flows.</div><div><a href='http://arxiv.org/abs/2403.06560v1'>2403.06560v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.00953v1")'>Families of costs with zero and nonnegative MTW tensor in optimal
  transport</div>
<div id='2401.00953v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-01T20:33:27Z</div><div>Authors: Du Nguyen</div><div style='padding-top: 10px; width: 80ex'>We compute explicitly the MTW tensor (or cross curvature) for the optimal
transport problem on $\mathbb{R}^n$ with a cost function of form $\mathsf{c}(x,
y) = \mathsf{u}(x^{\mathfrak{t}}y)$, where $\mathsf{u}$ is a scalar function
with inverse $\mathsf{s}$, $x^{\ft}y$ is a nondegenerate bilinear pairing of
vectors $x, y$ belonging to an open subset of $\mathbb{R}^n$. The condition
that the MTW-tensor vanishes on null vectors under the Kim-McCann metric is a
fourth-order nonlinear ODE, which could be reduced to a linear ODE of the form
$\mathsf{s}^{(2)} - S\mathsf{s}^{(1)} + P\mathsf{s} = 0$ with constant
coefficients $P$ and $S$. The resulting inverse functions include {\it Lambert}
and {\it generalized inverse hyperbolic\slash trigonometric} functions. The
square Euclidean metric and $\log$-type costs are equivalent to instances of
these solutions. The optimal map for the family is also explicit. For cost
functions of a similar form on a hyperboloid model of the hyperbolic space and
unit sphere, we also express this tensor in terms of algebraic expressions in
derivatives of $\mathsf{s}$ using the Gauss-Codazzi equation, obtaining new
families of strictly regular costs for these manifolds, including new families
of {\it power function costs}. We analyze the $\sinh$-type hyperbolic cost,
providing examples of $\mathsf{c}$-convex functions and divergence.</div><div><a href='http://arxiv.org/abs/2401.00953v1'>2401.00953v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.07389v1")'>A Rapid Review of Clustering Algorithms</div>
<div id='2401.07389v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-14T23:19:53Z</div><div>Authors: Hui Yin, Amir Aryani, Stephen Petrie, Aishwarya Nambissan, Aland Astudillo, Shengyuan Cao</div><div style='padding-top: 10px; width: 80ex'>Clustering algorithms aim to organize data into groups or clusters based on
the inherent patterns and similarities within the data. They play an important
role in today's life, such as in marketing and e-commerce, healthcare, data
organization and analysis, and social media. Numerous clustering algorithms
exist, with ongoing developments introducing new ones. Each algorithm possesses
its own set of strengths and weaknesses, and as of now, there is no universally
applicable algorithm for all tasks. In this work, we analyzed existing
clustering algorithms and classify mainstream algorithms across five different
dimensions: underlying principles and characteristics, data point assignment to
clusters, dataset capacity, predefined cluster numbers and application area.
This classification facilitates researchers in understanding clustering
algorithms from various perspectives and helps them identify algorithms
suitable for solving specific tasks. Finally, we discussed the current trends
and potential future directions in clustering algorithms. We also identified
and discussed open challenges and unresolved issues in the field.</div><div><a href='http://arxiv.org/abs/2401.07389v1'>2401.07389v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.05479v1")'>The recursive scheme of clustering</div>
<div id='2401.05479v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-10T18:08:32Z</div><div>Authors: Alicja Miniak-Górecka, Krzysztof Podlaski, Tomasz Gwizdałła</div><div style='padding-top: 10px; width: 80ex'>The problem of data clustering is one of the most important in data analysis.
It can be problematic when dealing with experimental data characterized by
measurement uncertainties and errors. Our paper proposes a recursive scheme for
clustering data obtained in geographical (climatological) experiments. The
discussion of results obtained by k-means and SOM methods with the developed
recursive procedure is presented. We show that the clustering using the new
approach gives more acceptable results when compared to experts assessments.</div><div><a href='http://arxiv.org/abs/2401.05479v1'>2401.05479v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14332v2")'>From Large to Small Datasets: Size Generalization for Clustering
  Algorithm Selection</div>
<div id='2402.14332v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T06:53:35Z</div><div>Authors: Vaggos Chatziafratis, Ishani Karmarkar, Ellen Vitercik</div><div style='padding-top: 10px; width: 80ex'>In clustering algorithm selection, we are given a massive dataset and must
efficiently select which clustering algorithm to use. We study this problem in
a semi-supervised setting, with an unknown ground-truth clustering that we can
only access through expensive oracle queries. Ideally, the clustering
algorithm's output will be structurally close to the ground truth. We approach
this problem by introducing a notion of size generalization for clustering
algorithm accuracy. We identify conditions under which we can (1) subsample the
massive clustering instance, (2) evaluate a set of candidate algorithms on the
smaller instance, and (3) guarantee that the algorithm with the best accuracy
on the small instance will have the best accuracy on the original big instance.
We provide theoretical size generalization guarantees for three classic
clustering algorithms: single-linkage, k-means++, and (a smoothed variant of)
Gonzalez's k-centers heuristic. We validate our theoretical analysis with
empirical results, observing that on real-world clustering instances, we can
use a subsample of as little as 5% of the data to identify which algorithm is
best on the full dataset.</div><div><a href='http://arxiv.org/abs/2402.14332v2'>2402.14332v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.07091v1")'>Optimization of Inter-group Criteria for Clustering with Minimum Size
  Constraints</div>
<div id='2401.07091v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-13T14:59:12Z</div><div>Authors: Eduardo S. Laber, Lucas Murtinho</div><div style='padding-top: 10px; width: 80ex'>Internal measures that are used to assess the quality of a clustering usually
take into account intra-group and/or inter-group criteria. There are many
papers in the literature that propose algorithms with provable approximation
guarantees for optimizing the former. However, the optimization of inter-group
criteria is much less understood.
  Here, we contribute to the state-of-the-art of this literature by devising
algorithms with provable guarantees for the maximization of two natural
inter-group criteria, namely the minimum spacing and the minimum spanning tree
spacing. The former is the minimum distance between points in different groups
while the latter captures separability through the cost of the minimum spanning
tree that connects all groups. We obtain results for both the unrestricted
case, in which no constraint on the clusters is imposed, and for the
constrained case where each group is required to have a minimum number of
points. Our constraint is motivated by the fact that the popular Single
Linkage, which optimizes both criteria in the unrestricted case, produces
clusterings with many tiny groups.
  To complement our work, we present an empirical study with 10 real datasets,
providing evidence that our methods work very well in practical settings.</div><div><a href='http://arxiv.org/abs/2401.07091v1'>2401.07091v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.10365v1")'>Scalable Algorithms for Individual Preference Stable Clustering</div>
<div id='2403.10365v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-15T14:58:27Z</div><div>Authors: Ron Mosenzon, Ali Vakilian</div><div style='padding-top: 10px; width: 80ex'>In this paper, we study the individual preference (IP) stability, which is an
notion capturing individual fairness and stability in clustering. Within this
setting, a clustering is $\alpha$-IP stable when each data point's average
distance to its cluster is no more than $\alpha$ times its average distance to
any other cluster. In this paper, we study the natural local search algorithm
for IP stable clustering. Our analysis confirms a $O(\log n)$-IP stability
guarantee for this algorithm, where $n$ denotes the number of points in the
input. Furthermore, by refining the local search approach, we show it runs in
an almost linear time, $\tilde{O}(nk)$.</div><div><a href='http://arxiv.org/abs/2403.10365v1'>2403.10365v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15062v1")'>Expert with Clustering: Hierarchical Online Preference Learning
  Framework</div>
<div id='2401.15062v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-26T18:44:49Z</div><div>Authors: Tianyue Zhou, Jung-Hoon Cho, Babak Rahimi Ardabili, Hamed Tabkhi, Cathy Wu</div><div style='padding-top: 10px; width: 80ex'>Emerging mobility systems are increasingly capable of recommending options to
mobility users, to guide them towards personalized yet sustainable system
outcomes. Even more so than the typical recommendation system, it is crucial to
minimize regret, because 1) the mobility options directly affect the lives of
the users, and 2) the system sustainability relies on sufficient user
participation. In this study, we consider accelerating user preference learning
by exploiting a low-dimensional latent space that captures the mobility
preferences of users. We introduce a hierarchical contextual bandit framework
named Expert with Clustering (EWC), which integrates clustering techniques and
prediction with expert advice. EWC efficiently utilizes hierarchical user
information and incorporates a novel Loss-guided Distance metric. This metric
is instrumental in generating more representative cluster centroids. In a
recommendation scenario with $N$ users, $T$ rounds per user, and $K$ options,
our algorithm achieves a regret bound of $O(N\sqrt{T\log K} + NT)$. This bound
consists of two parts: the first term is the regret from the Hedge algorithm,
and the second term depends on the average loss from clustering. The algorithm
performs with low regret, especially when a latent hierarchical structure
exists among users. This regret bound underscores the theoretical and
experimental efficacy of EWC, particularly in scenarios that demand rapid
learning and adaptation. Experimental results highlight that EWC can
substantially reduce regret by 27.57% compared to the LinUCB baseline. Our work
offers a data-efficient approach to capturing both individual and collective
behaviors, making it highly applicable to contexts with hierarchical
structures. We expect the algorithm to be applicable to other settings with
layered nuances of user preferences and information.</div><div><a href='http://arxiv.org/abs/2401.15062v1'>2401.15062v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.12100v1")'>Learning Time Slot Preferences via Mobility Tree for Next POI
  Recommendation</div>
<div id='2403.12100v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-17T08:43:12Z</div><div>Authors: Tianhao Huang, Xuan Pan, Xiangrui Cai, Ying Zhang, Xiaojie Yuan</div><div style='padding-top: 10px; width: 80ex'>Next Point-of-Interests (POIs) recommendation task aims to provide a dynamic
ranking of POIs based on users' current check-in trajectories. The
recommendation performance of this task is contingent upon a comprehensive
understanding of users' personalized behavioral patterns through Location-based
Social Networks (LBSNs) data. While prior studies have adeptly captured
sequential patterns and transitional relationships within users' check-in
trajectories, a noticeable gap persists in devising a mechanism for discerning
specialized behavioral patterns during distinct time slots, such as noon,
afternoon, or evening. In this paper, we introduce an innovative data structure
termed the ``Mobility Tree'', tailored for hierarchically describing users'
check-in records. The Mobility Tree encompasses multi-granularity time slot
nodes to learn user preferences across varying temporal periods. Meanwhile, we
propose the Mobility Tree Network (MTNet), a multitask framework for
personalized preference learning based on Mobility Trees. We develop a
four-step node interaction operation to propagate feature information from the
leaf nodes to the root node. Additionally, we adopt a multitask training
strategy to push the model towards learning a robust representation. The
comprehensive experimental results demonstrate the superiority of MTNet over
ten state-of-the-art next POI recommendation models across three real-world
LBSN datasets, substantiating the efficacy of time slot preference learning
facilitated by Mobility Tree.</div><div><a href='http://arxiv.org/abs/2403.12100v1'>2403.12100v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.03388v2")'>Delivery Optimized Discovery in Behavioral User Segmentation under
  Budget Constraint</div>
<div id='2402.03388v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-04T10:18:33Z</div><div>Authors: Harshita Chopra, Atanu R. Sinha, Sunav Choudhary, Ryan A. Rossi, Paavan Kumar Indela, Veda Pranav Parwatala, Srinjayee Paul, Aurghya Maiti</div><div style='padding-top: 10px; width: 80ex'>Users' behavioral footprints online enable firms to discover behavior-based
user segments (or, segments) and deliver segment specific messages to users.
Following the discovery of segments, delivery of messages to users through
preferred media channels like Facebook and Google can be challenging, as only a
portion of users in a behavior segment find match in a medium, and only a
fraction of those matched actually see the message (exposure). Even high
quality discovery becomes futile when delivery fails. Many sophisticated
algorithms exist for discovering behavioral segments; however, these ignore the
delivery component. The problem is compounded because (i) the discovery is
performed on the behavior data space in firms' data (e.g., user clicks), while
the delivery is predicated on the static data space (e.g., geo, age) as defined
by media; and (ii) firms work under budget constraint. We introduce a
stochastic optimization based algorithm for delivery optimized discovery of
behavioral user segmentation and offer new metrics to address the joint
optimization. We leverage optimization under a budget constraint for delivery
combined with a learning-based component for discovery. Extensive experiments
on a public dataset from Google and a proprietary dataset show the
effectiveness of our approach by simultaneously improving delivery metrics,
reducing budget spend and achieving strong predictive performance in discovery.</div><div><a href='http://arxiv.org/abs/2402.03388v2'>2402.03388v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.05669v1")'>Spectral Clustering of Categorical and Mixed-type Data via Extra Graph
  Nodes</div>
<div id='2403.05669v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-08T20:49:49Z</div><div>Authors: Dylan Soemitro, Jeova Farias Sales Rocha Neto</div><div style='padding-top: 10px; width: 80ex'>Clustering data objects into homogeneous groups is one of the most important
tasks in data mining. Spectral clustering is arguably one of the most important
algorithms for clustering, as it is appealing for its theoretical soundness and
is adaptable to many real-world data settings. For example, mixed data, where
the data is composed of numerical and categorical features, is typically
handled via numerical discretization, dummy coding, or similarity computation
that takes into account both data types. This paper explores a more natural way
to incorporate both numerical and categorical information into the spectral
clustering algorithm, avoiding the need for data preprocessing or the use of
sophisticated similarity functions. We propose adding extra nodes corresponding
to the different categories the data may belong to and show that it leads to an
interpretable clustering objective function. Furthermore, we demonstrate that
this simple framework leads to a linear-time spectral clustering algorithm for
categorical-only data. Finally, we compare the performance of our algorithms
against other related methods and show that it provides a competitive
alternative to them in terms of performance and runtime.</div><div><a href='http://arxiv.org/abs/2403.05669v1'>2403.05669v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.10927v1")'>Debiasing and a local analysis for population clustering using
  semidefinite programming</div>
<div id='2401.10927v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-16T03:14:24Z</div><div>Authors: Shuheng Zhou</div><div style='padding-top: 10px; width: 80ex'>In this paper, we consider the problem of partitioning a small data sample of
size $n$ drawn from a mixture of $2$ sub-gaussian distributions. In particular,
we analyze computational efficient algorithms proposed by the same author, to
partition data into two groups approximately according to their population of
origin given a small sample. This work is motivated by the application of
clustering individuals according to their population of origin using $p$
markers, when the divergence between any two of the populations is small. We
build upon the semidefinite relaxation of an integer quadratic program that is
formulated essentially as finding the maximum cut on a graph, where edge
weights in the cut represent dissimilarity scores between two nodes based on
their $p$ features. Here we use $\Delta^2 :=p \gamma$ to denote the $\ell_2^2$
distance between two centers (mean vectors), namely, $\mu^{(1)}$, $\mu^{(2)}$
$\in$ $\mathbb{R}^p$. The goal is to allow a full range of tradeoffs between
$n, p, \gamma$ in the sense that partial recovery (success rate $&lt; 100\%$) is
feasible once the signal to noise ratio $s^2 := \min\{np \gamma^2, \Delta^2\}$
is lower bounded by a constant. Importantly, we prove that the
misclassification error decays exponentially with respect to the SNR $s^2$.
This result was introduced earlier without a full proof. We therefore present
the full proof in the present work. Finally, for balanced partitions, we
consider a variant of the SDP1, and show that the new estimator has a superb
debiasing property. This is novel to the best of our knowledge.</div><div><a href='http://arxiv.org/abs/2401.10927v1'>2401.10927v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14332v1")'>A Differentially Private Clustering Algorithm for Well-Clustered Graphs</div>
<div id='2403.14332v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T11:57:16Z</div><div>Authors: Weiqiang He, Hendrik Fichtenberger, Pan Peng</div><div style='padding-top: 10px; width: 80ex'>We study differentially private (DP) algorithms for recovering clusters in
well-clustered graphs, which are graphs whose vertex set can be partitioned
into a small number of sets, each inducing a subgraph of high inner conductance
and small outer conductance. Such graphs have widespread application as a
benchmark in the theoretical analysis of spectral clustering. We provide an
efficient ($\epsilon$,$\delta$)-DP algorithm tailored specifically for such
graphs. Our algorithm draws inspiration from the recent work of Chen et al.,
who developed DP algorithms for recovery of stochastic block models in cases
where the graph comprises exactly two nearly-balanced clusters. Our algorithm
works for well-clustered graphs with $k$ nearly-balanced clusters, and the
misclassification ratio almost matches the one of the best-known non-private
algorithms. We conduct experimental evaluations on datasets with known ground
truth clusters to substantiate the prowess of our algorithm. We also show that
any (pure) $\epsilon$-DP algorithm would result in substantial error.</div><div><a href='http://arxiv.org/abs/2403.14332v1'>2403.14332v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.09510v1")'>Community Detection in the Multi-View Stochastic Block Model</div>
<div id='2401.09510v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-17T13:39:38Z</div><div>Authors: Yexin Zhang, Zhongtian Ma, Qiaosheng Zhang, Zhen Wang, Xuelong Li</div><div style='padding-top: 10px; width: 80ex'>This paper considers the problem of community detection on multiple
potentially correlated graphs from an information-theoretical perspective. We
first put forth a random graph model, called the multi-view stochastic block
model (MVSBM), designed to generate correlated graphs on the same set of nodes
(with cardinality $n$). The $n$ nodes are partitioned into two disjoint
communities of equal size. The presence or absence of edges in the graphs for
each pair of nodes depends on whether the two nodes belong to the same
community or not. The objective for the learner is to recover the hidden
communities with observed graphs. Our technical contributions are two-fold: (i)
We establish an information-theoretic upper bound (Theorem~1) showing that
exact recovery of community is achievable when the model parameters of MVSBM
exceed a certain threshold. (ii) Conversely, we derive an information-theoretic
lower bound (Theorem~2) showing that when the model parameters of MVSBM fall
below the aforementioned threshold, then for any estimator, the expected number
of misclassified nodes will always be greater than one. Our results for the
MVSBM recover several prior results for community detection in the standard SBM
as well as in multiple independent SBMs as special cases.</div><div><a href='http://arxiv.org/abs/2401.09510v1'>2401.09510v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.15095v1")'>The Umeyama algorithm for matching correlated Gaussian geometric models
  in the low-dimensional regime</div>
<div id='2402.15095v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-23T04:58:54Z</div><div>Authors: Shuyang Gong, Zhangsong Li</div><div style='padding-top: 10px; width: 80ex'>Motivated by the problem of matching two correlated random geometric graphs,
we study the problem of matching two Gaussian geometric models correlated
through a latent node permutation. Specifically, given an unknown permutation
$\pi^*$ on $\{1,\ldots,n\}$ and given $n$ i.i.d. pairs of correlated Gaussian
vectors $\{X_{\pi^*(i)},Y_i\}$ in $\mathbb{R}^d$ with noise parameter $\sigma$,
we consider two types of (correlated) weighted complete graphs with edge
weights given by $A_{i,j}=\langle X_i,X_j \rangle$, $B_{i,j}=\langle Y_i,Y_j
\rangle$. The goal is to recover the hidden vertex correspondence $\pi^*$ based
on the observed matrices $A$ and $B$. For the low-dimensional regime where
$d=O(\log n)$, Wang, Wu, Xu, and Yolou [WWXY22+] established the information
thresholds for exact and almost exact recovery in matching correlated Gaussian
geometric models. They also conducted numerical experiments for the classical
Umeyama algorithm. In our work, we prove that this algorithm achieves exact
recovery of $\pi^*$ when the noise parameter $\sigma=o(d^{-3}n^{-2/d})$, and
almost exact recovery when $\sigma=o(d^{-3}n^{-1/d})$. Our results approach the
information thresholds up to a $\operatorname{poly}(d)$ factor in the
low-dimensional regime.</div><div><a href='http://arxiv.org/abs/2402.15095v1'>2402.15095v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09591v1")'>Reconstructing the Geometry of Random Geometric Graphs</div>
<div id='2402.09591v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T21:34:44Z</div><div>Authors: Han Huang, Pakawut Jiradilok, Elchanan Mossel</div><div style='padding-top: 10px; width: 80ex'>Random geometric graphs are random graph models defined on metric spaces.
Such a model is defined by first sampling points from a metric space and then
connecting each pair of sampled points with probability that depends on their
distance, independently among pairs. In this work, we show how to efficiently
reconstruct the geometry of the underlying space from the sampled graph under
the manifold assumption, i.e., assuming that the underlying space is a low
dimensional manifold and that the connection probability is a strictly
decreasing function of the Euclidean distance between the points in a given
embedding of the manifold in $\mathbb{R}^N$. Our work complements a large body
of work on manifold learning, where the goal is to recover a manifold from
sampled points sampled in the manifold along with their (approximate)
distances.</div><div><a href='http://arxiv.org/abs/2402.09591v1'>2402.09591v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.06671v1")'>Untangling Gaussian Mixtures</div>
<div id='2403.06671v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-11T12:42:31Z</div><div>Authors: Eva Fluck, Sandra Kiefer, Christoph Standke</div><div style='padding-top: 10px; width: 80ex'>Tangles were originally introduced as a concept to formalize regions of high
connectivity in graphs. In recent years, they have also been discovered as a
link between structural graph theory and data science: when interpreting
similarity in data sets as connectivity between points, finding clusters in the
data essentially amounts to finding tangles in the underlying graphs. This
paper further explores the potential of tangles in data sets as a means for a
formal study of clusters. Real-world data often follow a normal distribution.
Accounting for this, we develop a quantitative theory of tangles in data sets
drawn from Gaussian mixtures. To this end, we equip the data with a graph
structure that models similarity between the points and allows us to apply
tangle theory to the data. We provide explicit conditions under which tangles
associated with the marginal Gaussian distributions exist asymptotically almost
surely. This can be considered as a sufficient formal criterion for the
separabability of clusters in the data.</div><div><a href='http://arxiv.org/abs/2403.06671v1'>2403.06671v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.10242v2")'>Signed Diverse Multiplex Networks: Clustering and Inference</div>
<div id='2402.10242v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T19:37:30Z</div><div>Authors: Marianna Pensky</div><div style='padding-top: 10px; width: 80ex'>The paper introduces a Signed Generalized Random Dot Product Graph (SGRDPG)
model, which is a variant of the Generalized Random Dot Product Graph (GRDPG),
where, in addition, edges can be positive or negative. The setting is extended
to a multiplex version, where all layers have the same collection of nodes and
follow the SGRDPG. The only common feature of the layers of the network is that
they can be partitioned into groups with common subspace structures, while
otherwise matrices of connection probabilities can be all different. The
setting above is extremely flexible and includes a variety of existing
multiplex network models as its particular cases. The paper fulfills two
objectives. First, it shows that keeping signs of the edges in the process of
network construction leads to a better precision of estimation and clustering
and, hence, is beneficial for tackling real world problems such as, for
example, analysis of brain networks. Second, by employing novel algorithms, our
paper ensures strongly consistent clustering of layers and high accuracy of
subspace estimation. In addition to theoretical guarantees, both of those
features are demonstrated using numerical simulations and a real data example.</div><div><a href='http://arxiv.org/abs/2402.10242v2'>2402.10242v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.07493v1")'>Signed graphs in data sciences via communicability geometry</div>
<div id='2403.07493v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T10:32:35Z</div><div>Authors: Fernando Diaz-Diaz, Ernesto Estrada</div><div style='padding-top: 10px; width: 80ex'>Signed graphs are an emergent way of representing data in a variety of
contexts were conflicting interactions exist. These include data from
biological, ecological, and social systems. Here we propose the concept of
communicability geometry for signed graphs, proving that metrics in this space,
such as the communicability distance and angles, are Euclidean and spherical.
We then apply these metrics to solve several problems in data analysis of
signed graphs in a unified way. They include the partitioning of signed graphs,
dimensionality reduction, finding hierarchies of alliances in signed networks
as well as the quantification of the degree of polarization between the
existing factions in systems represented by this type of graphs.</div><div><a href='http://arxiv.org/abs/2403.07493v1'>2403.07493v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.14810v1")'>Cyclic Group Projection for Enumerating Quasi-Cyclic Codes Trapping Sets</div>
<div id='2401.14810v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-26T12:16:55Z</div><div>Authors: Vasiliy Usatyuk, Yury Kuznetsov, Sergey Egorov</div><div style='padding-top: 10px; width: 80ex'>This paper introduces a novel approach to enumerate and assess Trapping sets
in quasi-cyclic codes, those with circulant sizes that are non-prime numbers.
Leveraging the quasi-cyclic properties, the method employs a tabular technique
to streamline the importance sampling step for estimating the pseudo-codeword
weight of Trapping sets. The presented methodology draws on the mathematical
framework established in the provided theorem, which elucidates the behavior of
projection and lifting transformations on pseudo-codewords</div><div><a href='http://arxiv.org/abs/2401.14810v1'>2401.14810v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.05831v2")'>Silhouette Aggregation: From Micro to Macro</div>
<div id='2401.05831v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-11T10:57:29Z</div><div>Authors: Georgios Vardakas, John Pavlopoulos, Aristidis Likas</div><div style='padding-top: 10px; width: 80ex'>Silhouette coefficient is an established internal clustering evaluation
measure that produces a score per data point, assessing the quality of its
clustering assignment. To assess the quality of the clustering of the whole
dataset, the scores of all the points in the dataset are either (micro)
averaged into a single value or averaged at the cluster level and then (macro)
averaged. As we illustrate in this work, by using a synthetic example, the
micro-averaging strategy is sensitive both to cluster imbalance and outliers
(background noise) while macro-averaging is far more robust to both.
Furthermore, the latter allows cluster-balanced sampling which yields robust
computation of the silhouette score. By conducting an experimental study on
eight real-world datasets, estimating the ground truth number of clusters, we
show that both coefficients, micro and macro, should be considered.</div><div><a href='http://arxiv.org/abs/2401.05831v2'>2401.05831v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.14439v1")'>Incremental Affinity Propagation based on Cluster Consolidation and
  Stratification</div>
<div id='2401.14439v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-25T14:20:00Z</div><div>Authors: Silvana Castano, Alfio Ferrara, Stefano Montanelli, Francesco Periti</div><div style='padding-top: 10px; width: 80ex'>Modern data mining applications require to perform incremental clustering
over dynamic datasets by tracing temporal changes over the resulting clusters.
In this paper, we propose A-Posteriori affinity Propagation (APP), an
incremental extension of Affinity Propagation (AP) based on cluster
consolidation and cluster stratification to achieve faithfulness and
forgetfulness. APP enforces incremental clustering where i) new arriving
objects are dynamically consolidated into previous clusters without the need to
re-execute clustering over the entire dataset of objects, and ii) a faithful
sequence of clustering results is produced and maintained over time, while
allowing to forget obsolete clusters with decremental learning functionalities.
Four popular labeled datasets are used to test the performance of APP with
respect to benchmark clustering performances obtained by conventional AP and
Incremental Affinity Propagation based on Nearest neighbor Assignment (IAPNA)
algorithms. Experimental results show that APP achieves comparable clustering
performance while enforcing scalability at the same time.</div><div><a href='http://arxiv.org/abs/2401.14439v1'>2401.14439v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.14992v1")'>Graph-based Active Learning for Entity Cluster Repair</div>
<div id='2401.14992v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-26T16:42:49Z</div><div>Authors: Victor Christen, Daniel Obraczka, Marvin Hofer, Martin Franke, Erhard Rahm</div><div style='padding-top: 10px; width: 80ex'>Cluster repair methods aim to determine errors in clusters and modify them so
that each cluster consists of records representing the same entity. Current
cluster repair methodologies primarily assume duplicate-free data sources,
where each record from one source corresponds to a unique record from another.
However, real-world data often deviates from this assumption due to quality
issues. Recent approaches apply clustering methods in combination with link
categorization methods so they can be applied to data sources with duplicates.
Nevertheless, the results do not show a clear picture since the quality highly
varies depending on the configuration and dataset. In this study, we introduce
a novel approach for cluster repair that utilizes graph metrics derived from
the underlying similarity graphs. These metrics are pivotal in constructing a
classification model to distinguish between correct and incorrect edges. To
address the challenge of limited training data, we integrate an active learning
mechanism tailored to cluster-specific attributes. The evaluation shows that
the method outperforms existing cluster repair methods without distinguishing
between duplicate-free or dirty data sources. Notably, our modified active
learning strategy exhibits enhanced performance when dealing with datasets
containing duplicates, showcasing its effectiveness in such scenarios.</div><div><a href='http://arxiv.org/abs/2401.14992v1'>2401.14992v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.13595v1")'>A cutting plane algorithm for globally solving low dimensional k-means
  clustering problems</div>
<div id='2402.13595v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-21T07:55:33Z</div><div>Authors: Martin Ryner, Jan Kronqvist, Johan Karlsson</div><div style='padding-top: 10px; width: 80ex'>Clustering is one of the most fundamental tools in data science and machine
learning, and k-means clustering is one of the most common such methods. There
is a variety of approximate algorithms for the k-means problem, but computing
the globally optimal solution is in general NP-hard. In this paper we consider
the k-means problem for instances with low dimensional data and formulate it as
a structured concave assignment problem. This allows us to exploit the low
dimensional structure and solve the problem to global optimality within
reasonable time for large data sets with several clusters. The method builds on
iteratively solving a small concave problem and a large linear programming
problem. This gives a sequence of feasible solutions along with bounds which we
show converges to zero optimality gap. The paper combines methods from global
optimization theory to accelerate the procedure, and we provide numerical
results on their performance.</div><div><a href='http://arxiv.org/abs/2402.13595v1'>2402.13595v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04322v1")'>Memetic Differential Evolution Methods for Semi-Supervised Clustering</div>
<div id='2403.04322v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T08:37:36Z</div><div>Authors: Pierluigi Mansueto, Fabio Schoen</div><div style='padding-top: 10px; width: 80ex'>In this paper, we deal with semi-supervised Minimum Sum-of-Squares Clustering
(MSSC) problems where background knowledge is given in the form of
instance-level constraints. In particular, we take into account "must-link" and
"cannot-link" constraints, each of which indicates if two dataset points should
be associated to the same or to a different cluster. The presence of such
constraints makes the problem at least as hard as its unsupervised version: it
is no more true that each point is associated to its nearest cluster center,
thus requiring some modifications in crucial operations, such as the assignment
step. In this scenario, we propose a novel memetic strategy based on the
Differential Evolution paradigm, directly extending a state-of-the-art
framework recently proposed in the unsupervised clustering literature. As far
as we know, our contribution represents the first attempt to define a memetic
methodology designed to generate a (hopefully) optimal feasible solution for
the semi-supervised MSSC problem. The proposal is compared with some
state-of-the-art algorithms from the literature on a set of well-known
datasets, highlighting its effectiveness and efficiency in finding good quality
clustering solutions.</div><div><a href='http://arxiv.org/abs/2403.04322v1'>2403.04322v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.16814v2")'>Cut Facets and Cube Facets of Lifted Multicut Polytopes</div>
<div id='2402.16814v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T18:37:16Z</div><div>Authors: Lucas Fabian Naumann, Jannik Irmai, Shengxian Zhao, Bjoern Andres</div><div style='padding-top: 10px; width: 80ex'>The lifted multicut problem has diverse applications in the field of computer
vision. Exact algorithms based on linear programming require an understanding
of lifted multicut polytopes. Despite recent progress, two fundamental
questions about these polytopes have remained open: Which lower cube
inequalities define facets, and which cut inequalities define facets? In this
article, we answer the first question by establishing conditions that are
necessary, sufficient and efficiently decidable. Toward the second question, we
show that deciding facet-definingness of cut inequalities is NP-hard. This
completes the analysis of canonical facets of lifted multicut polytopes.</div><div><a href='http://arxiv.org/abs/2402.16814v2'>2402.16814v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.15679v1")'>Scalable Density-based Clustering with Random Projections</div>
<div id='2402.15679v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-24T01:45:51Z</div><div>Authors: Haochuan Xu, Ninh Pham</div><div style='padding-top: 10px; width: 80ex'>We present sDBSCAN, a scalable density-based clustering algorithm in high
dimensions with cosine distance. Utilizing the neighborhood-preserving property
of random projections, sDBSCAN can quickly identify core points and their
neighborhoods, the primary hurdle of density-based clustering. Theoretically,
sDBSCAN outputs a clustering structure similar to DBSCAN under mild conditions
with high probability. To further facilitate sDBSCAN, we present sOPTICS, a
scalable OPTICS for interactive exploration of the intrinsic clustering
structure. We also extend sDBSCAN and sOPTICS to L2, L1, $\chi^2$, and
Jensen-Shannon distances via random kernel features. Empirically, sDBSCAN is
significantly faster and provides higher accuracy than many other clustering
algorithms on real-world million-point data sets. On these data sets, sDBSCAN
and sOPTICS run in a few minutes, while the scikit-learn's counterparts demand
several hours or cannot run due to memory constraints.</div><div><a href='http://arxiv.org/abs/2402.15679v1'>2402.15679v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.02239v1")'>Distributional Reduction: Unifying Dimensionality Reduction and
  Clustering with Gromov-Wasserstein Projection</div>
<div id='2402.02239v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-03T19:00:19Z</div><div>Authors: Hugues Van Assel, Cédric Vincent-Cuaz, Nicolas Courty, Rémi Flamary, Pascal Frossard, Titouan Vayer</div><div style='padding-top: 10px; width: 80ex'>Unsupervised learning aims to capture the underlying structure of potentially
large and high-dimensional datasets. Traditionally, this involves using
dimensionality reduction methods to project data onto interpretable spaces or
organizing points into meaningful clusters. In practice, these methods are used
sequentially, without guaranteeing that the clustering aligns well with the
conducted dimensionality reduction. In this work, we offer a fresh perspective:
that of distributions. Leveraging tools from optimal transport, particularly
the Gromov-Wasserstein distance, we unify clustering and dimensionality
reduction into a single framework called distributional reduction. This allows
us to jointly address clustering and dimensionality reduction with a single
optimization problem. Through comprehensive experiments, we highlight the
versatility and interpretability of our method and show that it outperforms
existing approaches across a variety of image and genomics datasets.</div><div><a href='http://arxiv.org/abs/2402.02239v1'>2402.02239v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.03198v1")'>Learning-Augmented K-Means Clustering Using Dimensional Reduction</div>
<div id='2401.03198v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-06T12:02:33Z</div><div>Authors: Issam K. O Jabari, Shofiyah, Pradiptya Kahvi S, Novi Nur Putriwijaya, Novanto Yudistira</div><div style='padding-top: 10px; width: 80ex'>Learning augmented is a machine learning concept built to improve the
performance of a method or model, such as enhancing its ability to predict and
generalize data or features, or testing the reliability of the method by
introducing noise and other factors. On the other hand, clustering is a
fundamental aspect of data analysis and has long been used to understand the
structure of large datasets. Despite its long history, the k-means algorithm
still faces challenges. One approach, as suggested by Ergun et al,is to use a
predictor to minimize the sum of squared distances between each data point and
a specified centroid. However, it is known that the computational cost of this
algorithm increases with the value of k, and it often gets stuck in local
minima. In response to these challenges, we propose a solution to reduce the
dimensionality of the dataset using Principal Component Analysis (PCA). It is
worth noting that when using k values of 10 and 25, the proposed algorithm
yields lower cost results compared to running it without PCA. "Principal
component analysis (PCA) is the problem of fitting a low-dimensional affine
subspace to a set of data points in a high-dimensional space. PCA is
well-established in the literature and has become one of the most useful tools
for data modeling, compression, and visualization."</div><div><a href='http://arxiv.org/abs/2401.03198v1'>2401.03198v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14490v1")'>Imbalanced Data Clustering using Equilibrium K-Means</div>
<div id='2402.14490v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T12:27:38Z</div><div>Authors: Yudong He</div><div style='padding-top: 10px; width: 80ex'>Imbalanced data, characterized by an unequal distribution of data points
across different clusters, poses a challenge for traditional hard and fuzzy
clustering algorithms, such as hard K-means (HKM, or Lloyd's algorithm) and
fuzzy K-means (FKM, or Bezdek's algorithm). This paper introduces equilibrium
K-means (EKM), a novel and simple K-means-type algorithm that alternates
between just two steps, yielding significantly improved clustering results for
imbalanced data by reducing the tendency of centroids to crowd together in the
center of large clusters. We also present a unifying perspective for HKM, FKM,
and EKM, showing they are essentially gradient descent algorithms with an
explicit relationship to Newton's method. EKM has the same time and space
complexity as FKM but offers a clearer physical meaning for its membership
definition. We illustrate the performance of EKM on two synthetic and ten real
datasets, comparing it to various clustering algorithms, including HKM, FKM,
maximum-entropy fuzzy clustering, two FKM variations designed for imbalanced
data, and the Gaussian mixture model. The results demonstrate that EKM performs
competitively on balanced data while significantly outperforming other
techniques on imbalanced data. For high-dimensional data clustering, we
demonstrate that a more discriminative representation can be obtained by
mapping high-dimensional data via deep neural networks into a low-dimensional,
EKM-friendly space. Deep clustering with EKM improves clustering accuracy by
35% on an imbalanced dataset derived from MNIST compared to deep clustering
based on HKM.</div><div><a href='http://arxiv.org/abs/2402.14490v1'>2402.14490v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.09117v1")'>Randomized Principal Component Analysis for Hyperspectral Image
  Classification</div>
<div id='2403.09117v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T05:40:23Z</div><div>Authors: Mustafa Ustuner</div><div style='padding-top: 10px; width: 80ex'>The high-dimensional feature space of the hyperspectral imagery poses major
challenges to the processing and analysis of the hyperspectral data sets. In
such a case, dimensionality reduction is necessary to decrease the
computational complexity. The random projections open up new ways of
dimensionality reduction, especially for large data sets. In this paper, the
principal component analysis (PCA) and randomized principal component analysis
(R-PCA) for the classification of hyperspectral images using support vector
machines (SVM) and light gradient boosting machines (LightGBM) have been
investigated. In this experimental research, the number of features was reduced
to 20 and 30 for classification of two hyperspectral datasets (Indian Pines and
Pavia University). The experimental results demonstrated that PCA outperformed
R-PCA for SVM for both datasets, but received close accuracy values for
LightGBM. The highest classification accuracies were obtained as 0.9925 and
0.9639 by LightGBM with original features for the Pavia University and Indian
Pines, respectively.</div><div><a href='http://arxiv.org/abs/2403.09117v1'>2403.09117v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.12924v2")'>Performance Analysis of Support Vector Machine (SVM) on Challenging
  Datasets for Forest Fire Detection</div>
<div id='2401.12924v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-23T17:20:52Z</div><div>Authors: Ankan Kar, Nirjhar Nath, Utpalraj Kemprai, Aman</div><div style='padding-top: 10px; width: 80ex'>This article delves into the analysis of performance and utilization of
Support Vector Machines (SVMs) for the critical task of forest fire detection
using image datasets. With the increasing threat of forest fires to ecosystems
and human settlements, the need for rapid and accurate detection systems is of
utmost importance. SVMs, renowned for their strong classification capabilities,
exhibit proficiency in recognizing patterns associated with fire within images.
By training on labeled data, SVMs acquire the ability to identify distinctive
attributes associated with fire, such as flames, smoke, or alterations in the
visual characteristics of the forest area. The document thoroughly examines the
use of SVMs, covering crucial elements like data preprocessing, feature
extraction, and model training. It rigorously evaluates parameters such as
accuracy, efficiency, and practical applicability. The knowledge gained from
this study aids in the development of efficient forest fire detection systems,
enabling prompt responses and improving disaster management. Moreover, the
correlation between SVM accuracy and the difficulties presented by
high-dimensional datasets is carefully investigated, demonstrated through a
revealing case study. The relationship between accuracy scores and the
different resolutions used for resizing the training datasets has also been
discussed in this article. These comprehensive studies result in a definitive
overview of the difficulties faced and the potential sectors requiring further
improvement and focus.</div><div><a href='http://arxiv.org/abs/2401.12924v2'>2401.12924v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.14359v1")'>Varroa destructor detection on honey bees using hyperspectral imagery</div>
<div id='2403.14359v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T12:40:41Z</div><div>Authors: Zina-Sabrina Duma, Tomas Zemcik, Simon Bilik, Tuomas Sihvonen, Peter Honec, Satu-Pia Reinikainen, Karel Horak</div><div style='padding-top: 10px; width: 80ex'>Hyperspectral (HS) imagery in agriculture is becoming increasingly common.
These images have the advantage of higher spectral resolution. Advanced
spectral processing techniques are required to unlock the information potential
in these HS images. The present paper introduces a method rooted in
multivariate statistics designed to detect parasitic Varroa destructor mites on
the body of western honey bee Apis mellifera, enabling easier and continuous
monitoring of the bee hives. The methodology explores unsupervised (K-means++)
and recently developed supervised (Kernel Flows - Partial Least-Squares,
KF-PLS) methods for parasitic identification. Additionally, in light of the
emergence of custom-band multispectral cameras, the present research outlines a
strategy for identifying the specific wavelengths necessary for effective
bee-mite separation, suitable for implementation in a custom-band camera.
Illustrated with a real-case dataset, our findings demonstrate that as few as
four spectral bands are sufficient for accurate parasite identification.</div><div><a href='http://arxiv.org/abs/2403.14359v1'>2403.14359v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.18751v1")'>Multi-Sensor and Multi-temporal High-Throughput Phenotyping for
  Monitoring and Early Detection of Water-Limiting Stress in Soybean</div>
<div id='2402.18751v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-28T23:18:15Z</div><div>Authors: Sarah E. Jones, Timilehin Ayanlade, Benjamin Fallen, Talukder Z. Jubery, Arti Singh, Baskar Ganapathysubramanian, Soumik Sarkar, Asheesh K. Singh</div><div style='padding-top: 10px; width: 80ex'>Soybean production is susceptible to biotic and abiotic stresses, exacerbated
by extreme weather events. Water limiting stress, i.e. drought, emerges as a
significant risk for soybean production, underscoring the need for advancements
in stress monitoring for crop breeding and production. This project combines
multi-modal information to identify the most effective and efficient automated
methods to investigate drought response. We investigated a set of diverse
soybean accessions using multiple sensors in a time series high-throughput
phenotyping manner to: (1) develop a pipeline for rapid classification of
soybean drought stress symptoms, and (2) investigate methods for early
detection of drought stress. We utilized high-throughput time-series
phenotyping using UAVs and sensors in conjunction with machine learning (ML)
analytics, which offered a swift and efficient means of phenotyping. The
red-edge and green bands were most effective to classify canopy wilting stress.
The Red-Edge Chlorophyll Vegetation Index (RECI) successfully differentiated
susceptible and tolerant soybean accessions prior to visual symptom
development. We report pre-visual detection of soybean wilting using a
combination of different vegetation indices. These results can contribute to
early stress detection methodologies and rapid classification of drought
responses in screening nurseries for breeding and production applications.</div><div><a href='http://arxiv.org/abs/2402.18751v1'>2402.18751v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.07175v1")'>Domain Adaptation for Sustainable Soil Management using Causal and
  Contrastive Constraint Minimization</div>
<div id='2401.07175v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-13T23:51:42Z</div><div>Authors: Somya Sharma, Swati Sharma, Rafael Padilha, Emre Kiciman, Ranveer Chandra</div><div style='padding-top: 10px; width: 80ex'>Monitoring organic matter is pivotal for maintaining soil health and can help
inform sustainable soil management practices. While sensor-based soil
information offers higher-fidelity and reliable insights into organic matter
changes, sampling and measuring sensor data is cost-prohibitive. We propose a
multi-modal, scalable framework that can estimate organic matter from remote
sensing data, a more readily available data source while leveraging sparse soil
information for improving generalization. Using the sensor data, we preserve
underlying causal relations among sensor attributes and organic matter.
Simultaneously we leverage inherent structure in the data and train the model
to discriminate among domains using contrastive learning. This causal and
contrastive constraint minimization ensures improved generalization and
adaptation to other domains. We also shed light on the interpretability of the
framework by identifying attributes that are important for improving
generalization. Identifying these key soil attributes that affect organic
matter will aid in efforts to standardize data collection efforts.</div><div><a href='http://arxiv.org/abs/2401.07175v1'>2401.07175v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.17035v1")'>Robust Kernel Sparse Subspace Clustering</div>
<div id='2401.17035v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T14:12:39Z</div><div>Authors: Ivica Kopriva</div><div style='padding-top: 10px; width: 80ex'>Kernel methods are applied to many problems in pattern recognition, including
subspace clustering (SC). That way, nonlinear problems in the input data space
become linear in mapped high-dimensional feature space. Thereby,
computationally tractable nonlinear algorithms are enabled through implicit
mapping by the virtue of kernel trick. However, kernelization of linear
algorithms is possible only if square of the Froebenious norm of the error term
is used in related optimization problem. That, however, implies normal
distribution of the error. That is not appropriate for non-Gaussian errors such
as gross sparse corruptions that are modeled by -norm. Herein, to the best of
our knowledge, we propose for the first time robust kernel sparse SC (RKSSC)
algorithm for data with gross sparse corruptions. The concept, in principle,
can be applied to other SC algorithms to achieve robustness to the presence of
such type of corruption. We validated proposed approach on two well-known
datasets with linear robust SSC algorithm as a baseline model. According to
Wilcoxon test, clustering performance obtained by the RKSSC algorithm is
statistically significantly better than corresponding performance obtained by
the robust SSC algorithm. MATLAB code of proposed RKSSC algorithm is posted on
https://github.com/ikopriva/RKSSC.</div><div><a href='http://arxiv.org/abs/2401.17035v1'>2401.17035v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.10474v2")'>LDReg: Local Dimensionality Regularized Self-Supervised Learning</div>
<div id='2401.10474v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-19T03:50:19Z</div><div>Authors: Hanxun Huang, Ricardo J. G. B. Campello, Sarah Monazam Erfani, Xingjun Ma, Michael E. Houle, James Bailey</div><div style='padding-top: 10px; width: 80ex'>Representations learned via self-supervised learning (SSL) can be susceptible
to dimensional collapse, where the learned representation subspace is of
extremely low dimensionality and thus fails to represent the full data
distribution and modalities. Dimensional collapse also known as the
"underfilling" phenomenon is one of the major causes of degraded performance on
downstream tasks. Previous work has investigated the dimensional collapse
problem of SSL at a global level. In this paper, we demonstrate that
representations can span over high dimensional space globally, but collapse
locally. To address this, we propose a method called $\textit{local
dimensionality regularization (LDReg)}$. Our formulation is based on the
derivation of the Fisher-Rao metric to compare and optimize local distance
distributions at an asymptotically small radius for each data point. By
increasing the local intrinsic dimensionality, we demonstrate through a range
of experiments that LDReg improves the representation quality of SSL. The
results also show that LDReg can regularize dimensionality at both local and
global levels.</div><div><a href='http://arxiv.org/abs/2401.10474v2'>2401.10474v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16193v2")'>Contributing Dimension Structure of Deep Feature for Coreset Selection</div>
<div id='2401.16193v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T14:47:26Z</div><div>Authors: Zhijing Wan, Zhixiang Wang, Yuran Wang, Zheng Wang, Hongyuan Zhu, Shin'ichi Satoh</div><div style='padding-top: 10px; width: 80ex'>Coreset selection seeks to choose a subset of crucial training samples for
efficient learning. It has gained traction in deep learning, particularly with
the surge in training dataset sizes. Sample selection hinges on two main
aspects: a sample's representation in enhancing performance and the role of
sample diversity in averting overfitting. Existing methods typically measure
both the representation and diversity of data based on similarity metrics, such
as L2-norm. They have capably tackled representation via distribution matching
guided by the similarities of features, gradients, or other information between
data. However, the results of effectively diverse sample selection are mired in
sub-optimality. This is because the similarity metrics usually simply aggregate
dimension similarities without acknowledging disparities among the dimensions
that significantly contribute to the final similarity. As a result, they fall
short of adequately capturing diversity. To address this, we propose a
feature-based diversity constraint, compelling the chosen subset to exhibit
maximum diversity. Our key lies in the introduction of a novel Contributing
Dimension Structure (CDS) metric. Different from similarity metrics that
measure the overall similarity of high-dimensional features, our CDS metric
considers not only the reduction of redundancy in feature dimensions, but also
the difference between dimensions that contribute significantly to the final
similarity. We reveal that existing methods tend to favor samples with similar
CDS, leading to a reduced variety of CDS types within the coreset and
subsequently hindering model performance. In response, we enhance the
performance of five classical selection methods by integrating the CDS
constraint. Our experiments on three datasets demonstrate the general
effectiveness of the proposed method in boosting existing methods.</div><div><a href='http://arxiv.org/abs/2401.16193v2'>2401.16193v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.11223v1")'>HEAL: Brain-inspired Hyperdimensional Efficient Active Learning</div>
<div id='2402.11223v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-17T08:41:37Z</div><div>Authors: Yang Ni, Zhuowen Zou, Wenjun Huang, Hanning Chen, William Youngwoo Chung, Samuel Cho, Ranganath Krishnan, Pietro Mercati, Mohsen Imani</div><div style='padding-top: 10px; width: 80ex'>Drawing inspiration from the outstanding learning capability of our human
brains, Hyperdimensional Computing (HDC) emerges as a novel computing paradigm,
and it leverages high-dimensional vector presentation and operations for
brain-like lightweight Machine Learning (ML). Practical deployments of HDC have
significantly enhanced the learning efficiency compared to current deep ML
methods on a broad spectrum of applications. However, boosting the data
efficiency of HDC classifiers in supervised learning remains an open question.
In this paper, we introduce Hyperdimensional Efficient Active Learning (HEAL),
a novel Active Learning (AL) framework tailored for HDC classification. HEAL
proactively annotates unlabeled data points via uncertainty and
diversity-guided acquisition, leading to a more efficient dataset annotation
and lowering labor costs. Unlike conventional AL methods that only support
classifiers built upon deep neural networks (DNN), HEAL operates without the
need for gradient or probabilistic computations. This allows it to be
effortlessly integrated with any existing HDC classifier architecture. The key
design of HEAL is a novel approach for uncertainty estimation in HDC
classifiers through a lightweight HDC ensemble with prior hypervectors.
Additionally, by exploiting hypervectors as prototypes (i.e., compact
representations), we develop an extra metric for HEAL to select diverse samples
within each batch for annotation. Our evaluation shows that HEAL surpasses a
diverse set of baselines in AL quality and achieves notably faster acquisition
than many BNN-powered or diversity-guided AL methods, recording 11 times to
40,000 times speedup in acquisition runtime per batch.</div><div><a href='http://arxiv.org/abs/2402.11223v1'>2402.11223v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.02051v1")'>Nonlinear subspace clustering by functional link neural networks</div>
<div id='2402.02051v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-03T06:01:21Z</div><div>Authors: Long Shi, Lei Cao, Zhongpu Chen, Badong Chen, Yu Zhao</div><div style='padding-top: 10px; width: 80ex'>Nonlinear subspace clustering based on a feed-forward neural network has been
demonstrated to provide better clustering accuracy than some advanced subspace
clustering algorithms. While this approach demonstrates impressive outcomes, it
involves a balance between effectiveness and computational cost. In this study,
we employ a functional link neural network to transform data samples into a
nonlinear domain. Subsequently, we acquire a self-representation matrix through
a learning mechanism that builds upon the mapped samples. As the functional
link neural network is a single-layer neural network, our proposed method
achieves high computational efficiency while ensuring desirable clustering
performance. By incorporating the local similarity regularization to enhance
the grouping effect, our proposed method further improves the quality of the
clustering results. Additionally, we introduce a convex combination subspace
clustering scheme, which combining a linear subspace clustering method with the
functional link neural network subspace clustering approach. This combination
approach allows for a dynamic balance between linear and nonlinear
representations. Extensive experiments confirm the advancement of our methods.
The source code will be released on https://lshi91.github.io/ soon.</div><div><a href='http://arxiv.org/abs/2402.02051v1'>2402.02051v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.10015v1")'>Linear optimal transport subspaces for point set classification</div>
<div id='2403.10015v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-15T04:39:27Z</div><div>Authors: Mohammad Shifat E Rabbi, Naqib Sad Pathan, Shiying Li, Yan Zhuang, Abu Hasnat Mohammad Rubaiyat, Gustavo K Rohde</div><div style='padding-top: 10px; width: 80ex'>Learning from point sets is an essential component in many computer vision
and machine learning applications. Native, unordered, and permutation invariant
set structure space is challenging to model, particularly for point set
classification under spatial deformations. Here we propose a framework for
classifying point sets experiencing certain types of spatial deformations, with
a particular emphasis on datasets featuring affine deformations. Our approach
employs the Linear Optimal Transport (LOT) transform to obtain a linear
embedding of set-structured data. Utilizing the mathematical properties of the
LOT transform, we demonstrate its capacity to accommodate variations in point
sets by constructing a convex data space, effectively simplifying point set
classification problems. Our method, which employs a nearest-subspace algorithm
in the LOT space, demonstrates label efficiency, non-iterative behavior, and
requires no hyper-parameter tuning. It achieves competitive accuracies compared
to state-of-the-art methods across various point set classification tasks.
Furthermore, our approach exhibits robustness in out-of-distribution scenarios
where training and test distributions vary in terms of deformation magnitudes.</div><div><a href='http://arxiv.org/abs/2403.10015v1'>2403.10015v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.09183v1")'>Generalized Relevance Learning Grassmann Quantization</div>
<div id='2403.09183v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T08:53:01Z</div><div>Authors: M. Mohammadi, M. Babai, M. H. F. Wilkinson</div><div style='padding-top: 10px; width: 80ex'>Due to advancements in digital cameras, it is easy to gather multiple images
(or videos) from an object under different conditions. Therefore, image-set
classification has attracted more attention, and different solutions were
proposed to model them. A popular way to model image sets is subspaces, which
form a manifold called the Grassmann manifold. In this contribution, we extend
the application of Generalized Relevance Learning Vector Quantization to deal
with Grassmann manifold. The proposed model returns a set of prototype
subspaces and a relevance vector. While prototypes model typical behaviours
within classes, the relevance factors specify the most discriminative principal
vectors (or images) for the classification task. They both provide insights
into the model's decisions by highlighting influential images and pixels for
predictions. Moreover, due to learning prototypes, the model complexity of the
new method during inference is independent of dataset size, unlike previous
works. We applied it to several recognition tasks including handwritten digit
recognition, face recognition, activity recognition, and object recognition.
Experiments demonstrate that it outperforms previous works with lower
complexity and can successfully model the variation, such as handwritten style
or lighting conditions. Moreover, the presence of relevances makes the model
robust to the selection of subspaces' dimensionality.</div><div><a href='http://arxiv.org/abs/2403.09183v1'>2403.09183v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12687v1")'>Learning on manifolds without manifold learning</div>
<div id='2402.12687v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T03:27:53Z</div><div>Authors: H. N. Mhaskar, Ryan O'Dowd</div><div style='padding-top: 10px; width: 80ex'>Function approximation based on data drawn randomly from an unknown
distribution is an important problem in machine learning. In contrast to the
prevalent paradigm of solving this problem by minimizing a loss functional, we
have given a direct one-shot construction together with optimal error bounds
under the manifold assumption; i.e., one assumes that the data is sampled from
an unknown sub-manifold of a high dimensional Euclidean space. A great deal of
research deals with obtaining information about this manifold, such as the
eigendecomposition of the Laplace-Beltrami operator or coordinate charts, and
using this information for function approximation. This two step approach
implies some extra errors in the approximation stemming from basic quantities
of the data in addition to the errors inherent in function approximation. In
Neural Networks, 132:253268, 2020, we have proposed a one-shot direct method to
achieve function approximation without requiring the extraction of any
information about the manifold other than its dimension. However, one cannot
pin down the class of approximants used in that paper.
  In this paper, we view the unknown manifold as a sub-manifold of an ambient
hypersphere and study the question of constructing a one-shot approximation
using the spherical polynomials based on the hypersphere. Our approach does not
require preprocessing of the data to obtain information about the manifold
other than its dimension. We give optimal rates of approximation for relatively
"rough" functions.</div><div><a href='http://arxiv.org/abs/2402.12687v1'>2402.12687v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03232v1")'>Smart Flow Matching: On The Theory of Flow Matching Algorithms with
  Applications</div>
<div id='2402.03232v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T17:45:12Z</div><div>Authors: Gleb Ryzhakov, Svetlana Pavlova, Egor Sevriugov, Ivan Oseledets</div><div style='padding-top: 10px; width: 80ex'>The paper presents the exact formula for the vector field that minimizes the
loss for the standard flow. This formula depends analytically on a given
distribution \rho_0 and an unknown one \rho_1. Based on the presented formula,
a new loss and algorithm for training a vector field model in the style of
Conditional Flow Matching are provided. Our loss, in comparison to the standard
Conditional Flow Matching approach, exhibits smaller variance when evaluated
through Monte Carlo sampling methods. Numerical experiments on synthetic models
and models on tabular data of large dimensions demonstrate better learning
results with the use of the presented algorithm.</div><div><a href='http://arxiv.org/abs/2402.03232v1'>2402.03232v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.14813v1")'>Curvature Augmented Manifold Embedding and Learning</div>
<div id='2403.14813v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T19:59:07Z</div><div>Authors: Yongming Liu</div><div style='padding-top: 10px; width: 80ex'>A new dimensional reduction (DR) and data visualization method,
Curvature-Augmented Manifold Embedding and Learning (CAMEL), is proposed. The
key novel contribution is to formulate the DR problem as a mechanistic/physics
model, where the force field among nodes (data points) is used to find an
n-dimensional manifold representation of the data sets. Compared with many
existing attractive-repulsive force-based methods, one unique contribution of
the proposed method is to include a non-pairwise force. A new force field model
is introduced and discussed, inspired by the multi-body potential in
lattice-particle physics and Riemann curvature in topology. A
curvature-augmented force is included in CAMEL. Following this, CAMEL
formulation for unsupervised learning, supervised learning, semi-supervised
learning/metric learning, and inverse learning are provided. Next, CAMEL is
applied to many benchmark datasets by comparing existing models, such as tSNE,
UMAP, TRIMAP, and PacMap. Both visual comparison and metrics-based evaluation
are performed. 14 open literature and self-proposed metrics are employed for a
comprehensive comparison. Conclusions and future work are suggested based on
the current investigation. Related code and demonstration are available on
https://github.com/ymlasu/CAMEL for interested readers to reproduce the results
and other applications.</div><div><a href='http://arxiv.org/abs/2403.14813v1'>2403.14813v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14977v1")'>Piecewise-Linear Manifolds for Deep Metric Learning</div>
<div id='2403.14977v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-22T06:22:20Z</div><div>Authors: Shubhang Bhatnagar, Narendra Ahuja</div><div style='padding-top: 10px; width: 80ex'>Unsupervised deep metric learning (UDML) focuses on learning a semantic
representation space using only unlabeled data. This challenging problem
requires accurately estimating the similarity between data points, which is
used to supervise a deep network. For this purpose, we propose to model the
high-dimensional data manifold using a piecewise-linear approximation, with
each low-dimensional linear piece approximating the data manifold in a small
neighborhood of a point. These neighborhoods are used to estimate similarity
between data points. We empirically show that this similarity estimate
correlates better with the ground truth than the similarity estimates of
current state-of-the-art techniques. We also show that proxies, commonly used
in supervised metric learning, can be used to model the piecewise-linear
manifold in an unsupervised setting, helping improve performance. Our method
outperforms existing unsupervised metric learning approaches on standard
zero-shot image retrieval benchmarks.</div><div><a href='http://arxiv.org/abs/2403.14977v1'>2403.14977v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.06456v1")'>A Survey of Learned Indexes for the Multi-dimensional Space</div>
<div id='2403.06456v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-11T06:32:32Z</div><div>Authors: Abdullah Al-Mamun, Hao Wu, Qiyang He, Jianguo Wang, Walid G. Aref</div><div style='padding-top: 10px; width: 80ex'>A recent research trend involves treating database index structures as
Machine Learning (ML) models. In this domain, single or multiple ML models are
trained to learn the mapping from keys to positions inside a data set. This
class of indexes is known as "Learned Indexes." Learned indexes have
demonstrated improved search performance and reduced space requirements for
one-dimensional data. The concept of one-dimensional learned indexes has
naturally been extended to multi-dimensional (e.g., spatial) data, leading to
the development of "Learned Multi-dimensional Indexes". This survey focuses on
learned multi-dimensional index structures. Specifically, it reviews the
current state of this research area, explains the core concepts behind each
proposed method, and classifies these methods based on several well-defined
criteria. We present a taxonomy that classifies and categorizes each learned
multi-dimensional index, and survey the existing literature on learned
multi-dimensional indexes according to this taxonomy. Additionally, we present
a timeline to illustrate the evolution of research on learned indexes. Finally,
we highlight several open challenges and future research directions in this
emerging and highly active field.</div><div><a href='http://arxiv.org/abs/2403.06456v1'>2403.06456v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.11020v1")'>Accelerating prototype selection with spatial abstraction</div>
<div id='2403.11020v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-16T21:34:24Z</div><div>Authors: Joel Luís Carbonera</div><div style='padding-top: 10px; width: 80ex'>The increasing digitalization in industry and society leads to a growing
abundance of data available to be processed and exploited. However, the high
volume of data requires considerable computational resources for applying
machine learning approaches. Prototype selection techniques have been applied
to reduce the requirements of computational resources that are needed by these
techniques. In this paper, we propose an approach for speeding up existing
prototype selection techniques. It builds an abstract representation of the
dataset, using the notion of spatial partition. The second step uses this
abstract representation to prune the search space efficiently and select a set
of candidate prototypes. After, some conventional prototype selection
algorithms can be applied to the candidates selected by our approach. Our
approach was integrated with five conventional prototype selection algorithms
and tested on 14 widely recognized datasets used in classification tasks. The
performance of the modified algorithms was compared to that of their original
versions in terms of accuracy and reduction rate. The experimental results
demonstrate that, overall, our proposed approach maintains accuracy while
enhancing the reduction rate of the original prototype selection algorithms and
simultaneously reducing their execution times.</div><div><a href='http://arxiv.org/abs/2403.11020v1'>2403.11020v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.05453v1")'>Dimensionality-Aware Outlier Detection: Theoretical and Experimental
  Analysis</div>
<div id='2401.05453v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-10T01:07:35Z</div><div>Authors: Alastair Anderberg, James Bailey, Ricardo J. G. B. Campello, Michael E. Houle, Henrique O. Marques, Miloš Radovanović, Arthur Zimek</div><div style='padding-top: 10px; width: 80ex'>We present a nonparametric method for outlier detection that takes full
account of local variations in intrinsic dimensionality within the dataset.
Using the theory of Local Intrinsic Dimensionality (LID), our
'dimensionality-aware' outlier detection method, DAO, is derived as an
estimator of an asymptotic local expected density ratio involving the query
point and a close neighbor drawn at random. The dimensionality-aware behavior
of DAO is due to its use of local estimation of LID values in a
theoretically-justified way. Through comprehensive experimentation on more than
800 synthetic and real datasets, we show that DAO significantly outperforms
three popular and important benchmark outlier detection methods: Local Outlier
Factor (LOF), Simplified LOF, and kNN.</div><div><a href='http://arxiv.org/abs/2401.05453v1'>2401.05453v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.08027v1")'>McCatch: Scalable Microcluster Detection in Dimensional and
  Nondimensional Datasets</div>
<div id='2403.08027v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T18:55:23Z</div><div>Authors: Braulio V. Sánchez Vinces, Robson L. F. Cordeiro, Christos Faloutsos</div><div style='padding-top: 10px; width: 80ex'>How could we have an outlier detector that works even with nondimensional
data, and ranks together both singleton microclusters ('one-off' outliers) and
nonsingleton microclusters by their anomaly scores? How to obtain scores that
are principled in one scalable and 'hands-off' manner? Microclusters of
outliers indicate coalition or repetition in fraud activities, etc.; their
identification is thus highly desirable. This paper presents McCatch: a new
algorithm that detects microclusters by leveraging our proposed 'Oracle' plot
(1NN Distance versus Group 1NN Distance). We study 31 real and synthetic
datasets with up to 1M data elements to show that McCatch is the only method
that answers both of the questions above; and, it outperforms 11 other methods,
especially when the data has nonsingleton microclusters or is nondimensional.
We also showcase McCatch's ability to detect meaningful microclusters in
graphs, fingerprints, logs of network connections, text data, and satellite
imagery. For example, it found a 30-elements microcluster of confirmed 'Denial
of Service' attacks in the network logs, taking only ~3 minutes for 222K data
elements on a stock desktop.</div><div><a href='http://arxiv.org/abs/2403.08027v1'>2403.08027v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.10802v1")'>Anomaly Detection Based on Isolation Mechanisms: A Survey</div>
<div id='2403.10802v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-16T04:29:21Z</div><div>Authors: Yang Cao, Haolong Xiang, Hang Zhang, Ye Zhu, Kai Ming Ting</div><div style='padding-top: 10px; width: 80ex'>Anomaly detection is a longstanding and active research area that has many
applications in domains such as finance, security, and manufacturing. However,
the efficiency and performance of anomaly detection algorithms are challenged
by the large-scale, high-dimensional, and heterogeneous data that are prevalent
in the era of big data. Isolation-based unsupervised anomaly detection is a
novel and effective approach for identifying anomalies in data. It relies on
the idea that anomalies are few and different from normal instances, and thus
can be easily isolated by random partitioning. Isolation-based methods have
several advantages over existing methods, such as low computational complexity,
low memory usage, high scalability, robustness to noise and irrelevant
features, and no need for prior knowledge or heavy parameter tuning. In this
survey, we review the state-of-the-art isolation-based anomaly detection
methods, including their data partitioning strategies, anomaly score functions,
and algorithmic details. We also discuss some extensions and applications of
isolation-based methods in different scenarios, such as detecting anomalies in
streaming data, time series, trajectory, and image datasets. Finally, we
identify some open challenges and future directions for isolation-based anomaly
detection research.</div><div><a href='http://arxiv.org/abs/2403.10802v1'>2403.10802v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04405v1")'>Signature Isolation Forest</div>
<div id='2403.04405v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T11:00:35Z</div><div>Authors: Guillaume Staerman, Marta Campi, Gareth W. Peters</div><div style='padding-top: 10px; width: 80ex'>Functional Isolation Forest (FIF) is a recent state-of-the-art Anomaly
Detection (AD) algorithm designed for functional data. It relies on a tree
partition procedure where an abnormality score is computed by projecting each
curve observation on a drawn dictionary through a linear inner product. Such
linear inner product and the dictionary are a priori choices that highly
influence the algorithm's performances and might lead to unreliable results,
particularly with complex datasets. This work addresses these challenges by
introducing \textit{Signature Isolation Forest}, a novel AD algorithm class
leveraging the rough path theory's signature transform. Our objective is to
remove the constraints imposed by FIF through the proposition of two algorithms
which specifically target the linearity of the FIF inner product and the choice
of the dictionary. We provide several numerical experiments, including a
real-world applications benchmark showing the relevance of our methods.</div><div><a href='http://arxiv.org/abs/2403.04405v1'>2403.04405v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14892v2")'>Novelty Detection on Radio Astronomy Data using Signatures</div>
<div id='2402.14892v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T14:13:44Z</div><div>Authors: Paola Arrubarrena, Maud Lemercier, Bojan Nikolic, Terry Lyons, Thomas Cass</div><div style='padding-top: 10px; width: 80ex'>We introduce SigNova, a new semi-supervised framework for detecting anomalies
in streamed data. While our initial examples focus on detecting radio-frequency
interference (RFI) in digitized signals within the field of radio astronomy, it
is important to note that SigNova's applicability extends to any type of
streamed data. The framework comprises three primary components. Firstly, we
use the signature transform to extract a canonical collection of summary
statistics from observational sequences. This allows us to represent
variable-length visibility samples as finite-dimensional feature vectors.
Secondly, each feature vector is assigned a novelty score, calculated as the
Mahalanobis distance to its nearest neighbor in an RFI-free training set. By
thresholding these scores we identify observation ranges that deviate from the
expected behavior of RFI-free visibility samples without relying on stringent
distributional assumptions. Thirdly, we integrate this anomaly detector with
Pysegments, a segmentation algorithm, to localize consecutive observations
contaminated with RFI, if any. This approach provides a compelling alternative
to classical windowing techniques commonly used for RFI detection. Importantly,
the complexity of our algorithm depends on the RFI pattern rather than on the
size of the observation window. We demonstrate how SigNova improves the
detection of various types of RFI (e.g., broadband and narrowband) in
time-frequency visibility data. We validate our framework on the Murchison
Widefield Array (MWA) telescope and simulated data and the Hydrogen Epoch of
Reionization Array (HERA).</div><div><a href='http://arxiv.org/abs/2402.14892v2'>2402.14892v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14742v1")'>A Classifier-Based Approach to Multi-Class Anomaly Detection for
  Astronomical Transients</div>
<div id='2403.14742v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T18:00:00Z</div><div>Authors: Rithwik Gupta, Daniel Muthukrishna, Michelle Lochner</div><div style='padding-top: 10px; width: 80ex'>Automating real-time anomaly detection is essential for identifying rare
transients in the era of large-scale astronomical surveys. Modern survey
telescopes are generating tens of thousands of alerts per night, and future
telescopes, such as the Vera C. Rubin Observatory, are projected to increase
this number dramatically. Currently, most anomaly detection algorithms for
astronomical transients rely either on hand-crafted features extracted from
light curves or on features generated through unsupervised representation
learning, which are then coupled with standard machine learning anomaly
detection algorithms. In this work, we introduce an alternative approach to
detecting anomalies: using the penultimate layer of a neural network classifier
as the latent space for anomaly detection. We then propose a novel method,
named Multi-Class Isolation Forests (MCIF), which trains separate isolation
forests for each class to derive an anomaly score for a light curve from the
latent space representation given by the classifier. This approach
significantly outperforms a standard isolation forest. We also use a simpler
input method for real-time transient classifiers which circumvents the need for
interpolation in light curves and helps the neural network model inter-passband
relationships and handle irregular sampling. Our anomaly detection pipeline
identifies rare classes including kilonovae, pair-instability supernovae, and
intermediate luminosity transients shortly after trigger on simulated Zwicky
Transient Facility light curves. Using a sample of our simulations that matched
the population of anomalies expected in nature (54 anomalies and 12,040 common
transients), our method was able to discover $41\pm3$ anomalies (~75% recall)
after following up the top 2000 (~15%) ranked transients. Our novel method
shows that classifiers can be effectively repurposed for real-time anomaly
detection.</div><div><a href='http://arxiv.org/abs/2403.14742v1'>2403.14742v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14131v1")'>Random forests for detecting weak signals and extracting physical
  information: a case study of magnetic navigation</div>
<div id='2402.14131v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-21T21:10:12Z</div><div>Authors: Mohammadamin Moradi, Zheng-Meng Zhai, Aaron Nielsen, Ying-Cheng Lai</div><div style='padding-top: 10px; width: 80ex'>It was recently demonstrated that two machine-learning architectures,
reservoir computing and time-delayed feed-forward neural networks, can be
exploited for detecting the Earth's anomaly magnetic field immersed in
overwhelming complex signals for magnetic navigation in a GPS-denied
environment. The accuracy of the detected anomaly field corresponds to a
positioning accuracy in the range of 10 to 40 meters. To increase the accuracy
and reduce the uncertainty of weak signal detection as well as to directly
obtain the position information, we exploit the machine-learning model of
random forests that combines the output of multiple decision trees to give
optimal values of the physical quantities of interest. In particular, from
time-series data gathered from the cockpit of a flying airplane during various
maneuvering stages, where strong background complex signals are caused by other
elements of the Earth's magnetic field and the fields produced by the
electronic systems in the cockpit, we demonstrate that the random-forest
algorithm performs remarkably well in detecting the weak anomaly field and in
filtering the position of the aircraft. With the aid of the conventional
inertial navigation system, the positioning error can be reduced to less than
10 meters. We also find that, contrary to the conventional wisdom, the classic
Tolles-Lawson model for calibrating and removing the magnetic field generated
by the body of the aircraft is not necessary and may even be detrimental for
the success of the random-forest method.</div><div><a href='http://arxiv.org/abs/2402.14131v1'>2402.14131v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.06653v1")'>Using remotely sensed data for air pollution assessment</div>
<div id='2402.06653v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-04T14:27:28Z</div><div>Authors: Teresa Bernardino, Maria Alexandra Oliveira, João Nuno Silva</div><div style='padding-top: 10px; width: 80ex'>Air pollution constitutes a global problem of paramount importance that
affects not only human health, but also the environment. The existence of
spatial and temporal data regarding the concentrations of pollutants is crucial
for performing air pollution studies and monitor emissions. However, although
observation data presents great temporal coverage, the number of stations is
very limited and they are usually built in more populated areas.
  The main objective of this work is to create models capable of inferring
pollutant concentrations in locations where no observation data exists. A
machine learning model, more specifically the random forest model, was
developed for predicting concentrations in the Iberian Peninsula in 2019 for
five selected pollutants: $NO_2$, $O_3$ $SO_2$, $PM10$, and $PM2.5$. Model
features include satellite measurements, meteorological variables, land use
classification, temporal variables (month, day of year), and spatial variables
(latitude, longitude, altitude).
  The models were evaluated using various methods, including station 10-fold
cross-validation, in which in each fold observations from 10\% of the stations
are used as testing data and the rest as training data. The $R^2$, RMSE and
mean bias were determined for each model. The $NO_2$ and $O_3$ models presented
good values of $R^2$, 0.5524 and 0.7462, respectively. However, the $SO_2$,
$PM10$, and $PM2.5$ models performed very poorly in this regard, with $R^2$
values of -0.0231, 0.3722, and 0.3303, respectively. All models slightly
overestimated the ground concentrations, except the $O_3$ model. All models
presented acceptable cross-validation RMSE, except the $O_3$ and $PM10$ models
where the mean value was a little higher (12.5934 $\mu g/m^3$ and 10.4737 $\mu
g/m^3$, respectively).</div><div><a href='http://arxiv.org/abs/2402.06653v1'>2402.06653v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03664v1")'>Environmental Insights: Democratizing Access to Ambient Air Pollution
  Data and Predictive Analytics with an Open-Source Python Package</div>
<div id='2403.03664v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T12:34:50Z</div><div>Authors: Liam J Berrisford, Ronaldo Menezes</div><div style='padding-top: 10px; width: 80ex'>Ambient air pollution is a pervasive issue with wide-ranging effects on human
health, ecosystem vitality, and economic structures. Utilizing data on ambient
air pollution concentrations, researchers can perform comprehensive analyses to
uncover the multifaceted impacts of air pollution across society. To this end,
we introduce Environmental Insights, an open-source Python package designed to
democratize access to air pollution concentration data. This tool enables users
to easily retrieve historical air pollution data and employ a Machine Learning
model for forecasting potential future conditions. Moreover, Environmental
Insights includes a suite of tools aimed at facilitating the dissemination of
analytical findings and enhancing user engagement through dynamic
visualizations. This comprehensive approach ensures that the package caters to
the diverse needs of individuals looking to explore and understand air
pollution trends and their implications.</div><div><a href='http://arxiv.org/abs/2403.03664v1'>2403.03664v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14228v1")'>Recovering Latent Confounders from High-dimensional Proxy Variables</div>
<div id='2403.14228v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T08:39:13Z</div><div>Authors: Nathan Mankovich, Homer Durand, Emiliano Diaz, Gherardo Varando, Gustau Camps-Valls</div><div style='padding-top: 10px; width: 80ex'>Detecting latent confounders from proxy variables is an essential problem in
causal effect estimation. Previous approaches are limited to low-dimensional
proxies, sorted proxies, and binary treatments. We remove these assumptions and
present a novel Proxy Confounder Factorization (PCF) framework for continuous
treatment effect estimation when latent confounders manifest through
high-dimensional, mixed proxy variables. For specific sample sizes, our
two-step PCF implementation, using Independent Component Analysis (ICA-PCF),
and the end-to-end implementation, using Gradient Descent (GD-PCF), achieve
high correlation with the latent confounder and low absolute error in causal
effect estimation with synthetic datasets in the high sample size regime. Even
when faced with climate data, ICA-PCF recovers four components that explain
$75.9\%$ of the variance in the North Atlantic Oscillation, a known confounder
of precipitation patterns in Europe. Code for our PCF implementations and
experiments can be found here: https://github.com/IPL-UV/confound_it. The
proposed methodology constitutes a stepping stone towards discovering latent
confounders and can be applied to many problems in disciplines dealing with
high-dimensional observed proxies, e.g., spatiotemporal fields.</div><div><a href='http://arxiv.org/abs/2403.14228v1'>2403.14228v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14709v1")'>ClimateQ&amp;A: Bridging the gap between climate scientists and the general
  public</div>
<div id='2403.14709v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-18T08:16:02Z</div><div>Authors: Natalia De La Calzada, Théo Alves Da Costa, Annabelle Blangero, Nicolas Chesneau</div><div style='padding-top: 10px; width: 80ex'>This research paper investigates public views on climate change and
biodiversity loss by analyzing questions asked to the ClimateQ&amp;A platform.
ClimateQ&amp;A is a conversational agent that uses LLMs to respond to queries based
on over 14,000 pages of scientific literature from the IPCC and IPBES reports.
Launched online in March 2023, the tool has gathered over 30,000 questions,
mainly from a French audience. Its chatbot interface allows for the free
formulation of questions related to nature*. While its main goal is to make
nature science more accessible, it also allows for the collection and analysis
of questions and their themes. Unlike traditional surveys involving closed
questions, this novel method offers a fresh perspective on individual
interrogations about nature. Running NLP clustering algorithms on a sample of
3,425 questions, we find that a significant 25.8% inquire about how climate
change and biodiversity loss will affect them personally (e.g., where they live
or vacation, their consumption habits) and the specific impacts of their
actions on nature (e.g., transportation or food choices). This suggests that
traditional methods of surveying may not identify all existing knowledge gaps,
and that relying solely on IPCC and IPBES reports may not address all
individual inquiries about climate and biodiversity, potentially affecting
public understanding and action on these issues. *we use 'nature' as an
umbrella term for 'climate change' and 'biodiversity loss'</div><div><a href='http://arxiv.org/abs/2403.14709v1'>2403.14709v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.10567v1")'>Uncertainty estimation in spatial interpolation of satellite
  precipitation with ensemble learning</div>
<div id='2403.10567v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T17:45:56Z</div><div>Authors: Georgia Papacharalampous, Hristos Tyralis, Nikolaos Doulamis, Anastasios Doulamis</div><div style='padding-top: 10px; width: 80ex'>Predictions in the form of probability distributions are crucial for
decision-making. Quantile regression enables this within spatial interpolation
settings for merging remote sensing and gauge precipitation data. However,
ensemble learning of quantile regression algorithms remains unexplored in this
context. Here, we address this gap by introducing nine quantile-based ensemble
learners and applying them to large precipitation datasets. We employed a novel
feature engineering strategy, reducing predictors to distance-weighted
satellite precipitation at relevant locations, combined with location
elevation. Our ensemble learners include six stacking and three simple methods
(mean, median, best combiner), combining six individual algorithms: quantile
regression (QR), quantile regression forests (QRF), generalized random forests
(GRF), gradient boosting machines (GBM), light gradient boosting machines
(LightGBM), and quantile regression neural networks (QRNN). These algorithms
serve as both base learners and combiners within different stacking methods. We
evaluated performance against QR using quantile scoring functions in a large
dataset comprising 15 years of monthly gauge-measured and satellite
precipitation in contiguous US (CONUS). Stacking with QR and QRNN yielded the
best results across quantile levels of interest (0.025, 0.050, 0.075, 0.100,
0.200, 0.300, 0.400, 0.500, 0.600, 0.700, 0.800, 0.900, 0.925, 0.950, 0.975),
surpassing the reference method by 3.91% to 8.95%. This demonstrates the
potential of stacking to improve probabilistic predictions in spatial
interpolation and beyond.</div><div><a href='http://arxiv.org/abs/2403.10567v1'>2403.10567v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01206v1")'>Comparative Evaluation of Weather Forecasting using Machine Learning
  Models</div>
<div id='2402.01206v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T08:25:28Z</div><div>Authors: Md Saydur Rahman, Farhana Akter Tumpa, Md Shazid Islam, Abul Al Arabi, Md Sanzid Bin Hossain, Md Saad Ul Haque</div><div style='padding-top: 10px; width: 80ex'>Gaining a deeper understanding of weather and being able to predict its
future conduct have always been considered important endeavors for the growth
of our society. This research paper explores the advancements in understanding
and predicting nature's behavior, particularly in the context of weather
forecasting, through the application of machine learning algorithms. By
leveraging the power of machine learning, data mining, and data analysis
techniques, significant progress has been made in this field. This study
focuses on analyzing the contributions of various machine learning algorithms
in predicting precipitation and temperature patterns using a 20-year dataset
from a single weather station in Dhaka city. Algorithms such as Gradient
Boosting, AdaBoosting, Artificial Neural Network, Stacking Random Forest,
Stacking Neural Network, and Stacking KNN are evaluated and compared based on
their performance metrics, including Confusion matrix measurements. The
findings highlight remarkable achievements and provide valuable insights into
their performances and features correlation.</div><div><a href='http://arxiv.org/abs/2402.01206v1'>2402.01206v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.07967v1")'>Feasibility of machine learning-based rice yield prediction in India at
  the district level using climate reanalysis data</div>
<div id='2403.07967v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T13:31:13Z</div><div>Authors: Djavan De Clercq, Adam Mahdi</div><div style='padding-top: 10px; width: 80ex'>Yield forecasting, the science of predicting agricultural productivity before
the crop harvest occurs, helps a wide range of stakeholders make better
decisions around agricultural planning. This study aims to investigate whether
machine learning-based yield prediction models can capably predict Kharif
season rice yields at the district level in India several months before the
rice harvest takes place. The methodology involved training 19 machine learning
models such as CatBoost, LightGBM, Orthogonal Matching Pursuit, and Extremely
Randomized Trees on 20 years of climate, satellite, and rice yield data across
247 of Indian rice-producing districts. In addition to model-building, a
dynamic dashboard was built understand how the reliability of rice yield
predictions varies across districts. The results of the proof-of-concept
machine learning pipeline demonstrated that rice yields can be predicted with a
reasonable degree of accuracy, with out-of-sample R2, MAE, and MAPE performance
of up to 0.82, 0.29, and 0.16 respectively. These results outperformed test set
performance reported in related literature on rice yield modeling in other
contexts and countries. In addition, SHAP value analysis was conducted to infer
both the importance and directional impact of the climate and remote sensing
variables included in the model. Important features driving rice yields
included temperature, soil water volume, and leaf area index. In particular,
higher temperatures in August correlate with increased rice yields,
particularly when the leaf area index in August is also high. Building on the
results, a proof-of-concept dashboard was developed to allow users to easily
explore which districts may experience a rise or fall in yield relative to the
previous year.</div><div><a href='http://arxiv.org/abs/2403.07967v1'>2403.07967v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03406v1")'>An EnKF-LSTM Assimilation Algorithm for Crop Growth Model</div>
<div id='2403.03406v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T02:09:50Z</div><div>Authors: Siqi Zhou, Ling Wang, Jie Liu, Jinshan Tang</div><div style='padding-top: 10px; width: 80ex'>Accurate and timely prediction of crop growth is of great significance to
ensure crop yields and researchers have developed several crop models for the
prediction of crop growth. However, there are large difference between the
simulation results obtained by the crop models and the actual results, thus in
this paper, we proposed to combine the simulation results with the collected
crop data for data assimilation so that the accuracy of prediction will be
improved. In this paper, an EnKF-LSTM data assimilation method for various
crops is proposed by combining ensemble Kalman filter and LSTM neural network,
which effectively avoids the overfitting problem of existing data assimilation
methods and eliminates the uncertainty of the measured data. The verification
of the proposed EnKF-LSTM method and the comparison of the proposed method with
other data assimilation methods were performed using datasets collected by
sensor equipment deployed on a farm.</div><div><a href='http://arxiv.org/abs/2403.03406v1'>2403.03406v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.00659v1")'>Modeling Freight Mode Choice Using Machine Learning Classifiers: A
  Comparative Study Using the Commodity Flow Survey (CFS) Data</div>
<div id='2402.00659v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T15:18:48Z</div><div>Authors: Majbah Uddin, Sabreena Anowar, Naveen Eluru</div><div style='padding-top: 10px; width: 80ex'>This study explores the usefulness of machine learning classifiers for
modeling freight mode choice. We investigate eight commonly used machine
learning classifiers, namely Naive Bayes, Support Vector Machine, Artificial
Neural Network, K-Nearest Neighbors, Classification and Regression Tree, Random
Forest, Boosting and Bagging, along with the classical Multinomial Logit model.
US 2012 Commodity Flow Survey data are used as the primary data source; we
augment it with spatial attributes from secondary data sources. The performance
of the classifiers is compared based on prediction accuracy results. The
current research also examines the role of sample size and training-testing
data split ratios on the predictive ability of the various approaches. In
addition, the importance of variables is estimated to determine how the
variables influence freight mode choice. The results show that the tree-based
ensemble classifiers perform the best. Specifically, Random Forest produces the
most accurate predictions, closely followed by Boosting and Bagging. With
regard to variable importance, shipment characteristics, such as shipment
distance, industry classification of the shipper and shipment size, are the
most significant factors for freight mode choice decisions.</div><div><a href='http://arxiv.org/abs/2402.00659v1'>2402.00659v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00654v2")'>Improving the accuracy of freight mode choice models: A case study using
  the 2017 CFS PUF data set and ensemble learning techniques</div>
<div id='2402.00654v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T15:14:16Z</div><div>Authors: Diyi Liu, Hyeonsup Lim, Majbah Uddin, Yuandong Liu, Lee D. Han, Ho-ling Hwang, Shih-Miao Chin</div><div style='padding-top: 10px; width: 80ex'>The US Census Bureau has collected two rounds of experimental data from the
Commodity Flow Survey, providing shipment-level characteristics of nationwide
commodity movements, published in 2012 (i.e., Public Use Microdata) and in 2017
(i.e., Public Use File). With this information, data-driven methods have become
increasingly valuable for understanding detailed patterns in freight logistics.
In this study, we used the 2017 Commodity Flow Survey Public Use File data set
to explore building a high-performance freight mode choice model, considering
three main improvements: (1) constructing local models for each separate
commodity/industry category; (2) extracting useful geographical features,
particularly the derived distance of each freight mode between
origin/destination zones; and (3) applying additional ensemble learning methods
such as stacking or voting to combine results from local and unified models for
improved performance. The proposed method achieved over 92% accuracy without
incorporating external information, an over 19% increase compared to directly
fitting Random Forests models over 10,000 samples. Furthermore, SHAP (Shapely
Additive Explanations) values were computed to explain the outputs and major
patterns obtained from the proposed model. The model framework could enhance
the performance and interpretability of existing freight mode choice models.</div><div><a href='http://arxiv.org/abs/2402.00654v2'>2402.00654v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13977v1")'>Evaluating the Determinants of Mode Choice Using Statistical and Machine
  Learning Techniques in the Indian Megacity of Bengaluru</div>
<div id='2401.13977v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-25T06:37:48Z</div><div>Authors: Tanmay Ghosh, Nithin Nagaraj</div><div style='padding-top: 10px; width: 80ex'>The decision making involved behind the mode choice is critical for
transportation planning. While statistical learning techniques like discrete
choice models have been used traditionally, machine learning (ML) models have
gained traction recently among the transportation planners due to their higher
predictive performance. However, the black box nature of ML models pose
significant interpretability challenges, limiting their practical application
in decision and policy making. This study utilised a dataset of $1350$
households belonging to low and low-middle income bracket in the city of
Bengaluru to investigate mode choice decision making behaviour using
Multinomial logit model and ML classifiers like decision trees, random forests,
extreme gradient boosting and support vector machines. In terms of accuracy,
random forest model performed the best ($0.788$ on training data and $0.605$ on
testing data) compared to all the other models. This research has adopted
modern interpretability techniques like feature importance and individual
conditional expectation plots to explain the decision making behaviour using ML
models. A higher travel costs significantly reduce the predicted probability of
bus usage compared to other modes (a $0.66\%$ and $0.34\%$ reduction using
Random Forests and XGBoost model for $10\%$ increase in travel cost). However,
reducing travel time by $10\%$ increases the preference for the metro ($0.16\%$
in Random Forests and 0.42% in XGBoost). This research augments the ongoing
research on mode choice analysis using machine learning techniques, which would
help in improving the understanding of the performance of these models with
real-world data in terms of both accuracy and interpretability.</div><div><a href='http://arxiv.org/abs/2401.13977v1'>2401.13977v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.04857v2")'>Transportation Marketplace Rate Forecast Using Signature Transform</div>
<div id='2401.04857v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-10T00:25:57Z</div><div>Authors: Haotian Gu, Xin Guo, Timothy L. Jacobs, Philip Kaminsky, Xinyu Li</div><div style='padding-top: 10px; width: 80ex'>Freight transportation marketplace rates are typically challenging to
forecast accurately. In this work, we have developed a novel statistical
technique based on signature transforms and have built a predictive and
adaptive model to forecast these marketplace rates. Our technique is based on
two key elements of the signature transform: one being its universal
nonlinearity property, which linearizes the feature space and hence translates
the forecasting problem into linear regression, and the other being the
signature kernel, which allows for comparing computationally efficiently
similarities between time series data. Combined, it allows for efficient
feature generation and precise identification of seasonality and regime
switching in the forecasting process.
  An algorithm based on our technique has been deployed by Amazon trucking
operations, with far superior forecast accuracy and better interpretability
versus commercially available industry models, even during the COVID-19
pandemic and the Ukraine conflict. Furthermore, our technique is able to
capture the influence of business cycles and the heterogeneity of the
marketplace, improving prediction accuracy by more than fivefold, with an
estimated annualized saving of \$50MM.</div><div><a href='http://arxiv.org/abs/2401.04857v2'>2401.04857v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.14498v1")'>Predictive Analysis for Optimizing Port Operations</div>
<div id='2401.14498v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-25T20:29:07Z</div><div>Authors: Aniruddha Rajendra Rao, Haiyan Wang, Chetan Gupta</div><div style='padding-top: 10px; width: 80ex'>Maritime transport is a pivotal logistics mode for the long-distance and bulk
transportation of goods. However, the intricate planning involved in this mode
is often hindered by uncertainties, including weather conditions, cargo
diversity, and port dynamics, leading to increased costs. Consequently,
accurately estimating vessel total (stay) time at port and potential delays
becomes imperative for effective planning and scheduling in port operations.
This study aims to develop a port operation solution with competitive
prediction and classification capabilities for estimating vessel Total and
Delay times. This research addresses a significant gap in port analysis models
for vessel Stay and Delay times, offering a valuable contribution to the field
of maritime logistics. The proposed solution is designed to assist
decision-making in port environments and predict service delays. This is
demonstrated through a case study on Brazil ports. Additionally, feature
analysis is used to understand the key factors impacting maritime logistics,
enhancing the overall understanding of the complexities involved in port
operations.</div><div><a href='http://arxiv.org/abs/2401.14498v1'>2401.14498v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.13909v1")'>Sequential Modeling of Complex Marine Navigation: Case Study on a
  Passenger Vessel (Student Abstract)</div>
<div id='2403.13909v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-20T18:29:55Z</div><div>Authors: Yimeng Fan, Pedram Agand, Mo Chen, Edward J. Park, Allison Kennedy, Chanwoo Bae</div><div style='padding-top: 10px; width: 80ex'>The maritime industry's continuous commitment to sustainability has led to a
dedicated exploration of methods to reduce vessel fuel consumption. This paper
undertakes this challenge through a machine learning approach, leveraging a
real-world dataset spanning two years of a ferry in west coast Canada. Our
focus centers on the creation of a time series forecasting model given the
dynamic and static states, actions, and disturbances. This model is designed to
predict dynamic states based on the actions provided, subsequently serving as
an evaluative tool to assess the proficiency of the ferry's operation under the
captain's guidance. Additionally, it lays the foundation for future
optimization algorithms, providing valuable feedback on decision-making
processes. To facilitate future studies, our code is available at
\url{https://github.com/pagand/model_optimze_vessel/tree/AAAI}</div><div><a href='http://arxiv.org/abs/2403.13909v1'>2403.13909v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.07966v1")'>Applying ranking techniques for estimating influence of Earth variables
  on temperature forecast error</div>
<div id='2403.07966v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T12:59:00Z</div><div>Authors: M. Julia Flores, Melissa Ruiz-Vásquez, Ana Bastos, René Orth</div><div style='padding-top: 10px; width: 80ex'>This paper describes how to analyze the influence of Earth system variables
on the errors when providing temperature forecasts. The initial framework to
get the data has been based on previous research work, which resulted in a very
interesting discovery. However, the aforementioned study only worked on
individual correlations of the variables with respect to the error. This
research work is going to re-use the main ideas but introduce three main
novelties: (1) applying a data science approach by a few representative
locations; (2) taking advantage of the rankings created by Spearman correlation
but enriching them with other metrics looking for a more robust ranking of the
variables; (3) evaluation of the methodology by learning random forest models
for regression with the distinct experimental variations. The main contribution
is the framework that shows how to convert correlations into rankings and
combine them into an aggregate ranking. We have carried out experiments on five
chosen locations to analyze the behavior of this ranking-based methodology. The
results show that the specific performance is dependent on the location and
season, which is expected, and that this selection technique works properly
with Random Forest models but can also improve simpler regression models such
as Bayesian Ridge. This work also contributes with an extensive analysis of the
results. We can conclude that this selection based on the top-k ranked
variables seems promising for this real problem, and it could also be applied
in other domains.</div><div><a href='http://arxiv.org/abs/2403.07966v1'>2403.07966v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03328v1")'>An Ensemble Framework for Explainable Geospatial Machine Learning Models</div>
<div id='2403.03328v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-05T21:12:10Z</div><div>Authors: Lingbo Liu</div><div style='padding-top: 10px; width: 80ex'>Analyzing spatial varying effect is pivotal in geographic analysis. Yet,
accurately capturing and interpreting this variability is challenging due to
the complexity and non-linearity of geospatial data. Herein, we introduce an
integrated framework that merges local spatial weighting scheme, Explainable
Artificial Intelligence (XAI), and cutting-edge machine learning technologies
to bridge the gap between traditional geographic analysis models and general
machine learning approaches. Through tests on synthetic datasets, this
framework is verified to enhance the interpretability and accuracy of
predictions in both geographic regression and classification by elucidating
spatial variability. It significantly boosts prediction precision, offering a
novel approach to understanding spatial phenomena.</div><div><a href='http://arxiv.org/abs/2403.03328v1'>2403.03328v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03527v1")'>Consistent Validation for Predictive Methods in Spatial Settings</div>
<div id='2402.03527v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T21:33:22Z</div><div>Authors: David R. Burt, Yunyi Shen, Tamara Broderick</div><div style='padding-top: 10px; width: 80ex'>Spatial prediction tasks are key to weather forecasting, studying air
pollution, and other scientific endeavors. Determining how much to trust
predictions made by statistical or physical methods is essential for the
credibility of scientific conclusions. Unfortunately, classical approaches for
validation fail to handle mismatch between locations available for validation
and (test) locations where we want to make predictions. This mismatch is often
not an instance of covariate shift (as commonly formalized) because the
validation and test locations are fixed (e.g., on a grid or at select points)
rather than i.i.d. from two distributions. In the present work, we formalize a
check on validation methods: that they become arbitrarily accurate as
validation data becomes arbitrarily dense. We show that classical and
covariate-shift methods can fail this check. We instead propose a method that
builds from existing ideas in the covariate-shift literature, but adapts them
to the validation data at hand. We prove that our proposal passes our check.
And we demonstrate its advantages empirically on simulated and real data.</div><div><a href='http://arxiv.org/abs/2402.03527v1'>2402.03527v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16197v1")'>Geospatial Disparities: A Case Study on Real Estate Prices in Paris</div>
<div id='2401.16197v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T14:53:14Z</div><div>Authors: Agathe Fernandes Machado, François Hu, Philipp Ratz, Ewen Gallic, Arthur Charpentier</div><div style='padding-top: 10px; width: 80ex'>Driven by an increasing prevalence of trackers, ever more IoT sensors, and
the declining cost of computing power, geospatial information has come to play
a pivotal role in contemporary predictive models. While enhancing prognostic
performance, geospatial data also has the potential to perpetuate many
historical socio-economic patterns, raising concerns about a resurgence of
biases and exclusionary practices, with their disproportionate impacts on
society. Addressing this, our paper emphasizes the crucial need to identify and
rectify such biases and calibration errors in predictive models, particularly
as algorithms become more intricate and less interpretable. The increasing
granularity of geospatial information further introduces ethical concerns, as
choosing different geographical scales may exacerbate disparities akin to
redlining and exclusionary zoning. To address these issues, we propose a
toolkit for identifying and mitigating biases arising from geospatial data.
Extending classical fairness definitions, we incorporate an ordinal regression
case with spatial attributes, deviating from the binary classification focus.
This extension allows us to gauge disparities stemming from data aggregation
levels and advocates for a less interfering correction approach. Illustrating
our methodology using a Parisian real estate dataset, we showcase practical
applications and scrutinize the implications of choosing geographical
aggregation levels for fairness and calibration measures.</div><div><a href='http://arxiv.org/abs/2401.16197v1'>2401.16197v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.11318v1")'>BiasBuster: a Neural Approach for Accurate Estimation of Population
  Statistics using Biased Location Data</div>
<div id='2402.11318v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-17T16:16:24Z</div><div>Authors: Sepanta Zeighami, Cyrus Shahabi</div><div style='padding-top: 10px; width: 80ex'>While extremely useful (e.g., for COVID-19 forecasting and policy-making,
urban mobility analysis and marketing, and obtaining business insights),
location data collected from mobile devices often contain data from a biased
population subset, with some communities over or underrepresented in the
collected datasets. As a result, aggregate statistics calculated from such
datasets (as is done by various companies including Safegraph, Google, and
Facebook), while ignoring the bias, leads to an inaccurate representation of
population statistics. Such statistics will not only be generally inaccurate,
but the error will disproportionately impact different population subgroups
(e.g., because they ignore the underrepresented communities). This has dire
consequences, as these datasets are used for sensitive decision-making such as
COVID-19 policymaking. This paper tackles the problem of providing accurate
population statistics using such biased datasets. We show that statistical
debiasing, although in some cases useful, often fails to improve accuracy. We
then propose BiasBuster, a neural network approach that utilizes the
correlations between population statistics and location characteristics to
provide accurate estimates of population statistics. Extensive experiments on
real-world data show that BiasBuster improves accuracy by up to 2 times in
general and up to 3 times for underrepresented populations.</div><div><a href='http://arxiv.org/abs/2402.11318v1'>2402.11318v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16440v1")'>Beyond Eviction Prediction: Leveraging Local Spatiotemporal Public
  Records to Inform Action</div>
<div id='2401.16440v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-27T09:29:11Z</div><div>Authors: Tasfia Mashiat, Alex DiChristofano, Patrick J. Fowler, Sanmay Das</div><div style='padding-top: 10px; width: 80ex'>There has been considerable recent interest in scoring properties on the
basis of eviction risk. The success of methods for eviction prediction is
typically evaluated using different measures of predictive accuracy. However,
the underlying goal of such prediction is to direct appropriate assistance to
households that may be at greater risk so they remain stably housed. Thus, we
must ask the question of how useful such predictions are in targeting outreach
efforts - informing action. In this paper, we investigate this question using a
novel dataset that matches information on properties, evictions, and owners. We
perform an eviction prediction task to produce risk scores and then use these
risk scores to plan targeted outreach policies. We show that the risk scores
are, in fact, useful, enabling a theoretical team of caseworkers to reach more
eviction-prone properties in the same amount of time, compared to outreach
policies that are either neighborhood-based or focus on buildings with a recent
history of evictions. We also discuss the importance of neighborhood and
ownership features in both risk prediction and targeted outreach.</div><div><a href='http://arxiv.org/abs/2401.16440v1'>2401.16440v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.12599v1")'>Preventing Eviction-Caused Homelessness through ML-Informed Distribution
  of Rental Assistance</div>
<div id='2403.12599v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-19T10:09:41Z</div><div>Authors: Catalina Vajiac, Arun Frey, Joachim Baumann, Abigail Smith, Kasun Amarasinghe, Alice Lai, Kit Rodolfa, Rayid Ghani</div><div style='padding-top: 10px; width: 80ex'>Rental assistance programs provide individuals with financial assistance to
prevent housing instabilities caused by evictions and avert homelessness. Since
these programs operate under resource constraints, they must decide who to
prioritize. Typically, funding is distributed by a reactive or first-come-first
serve allocation process that does not systematically consider risk of future
homelessness. We partnered with Allegheny County, PA to explore a proactive
allocation approach that prioritizes individuals facing eviction based on their
risk of future homelessness. Our ML system that uses state and county
administrative data to accurately identify individuals in need of support
outperforms simpler prioritization approaches by at least 20% while being fair
and equitable across race and gender. Furthermore, our approach would identify
28% of individuals who are overlooked by the current process and end up
homeless. Beyond improvements to the rental assistance program in Allegheny
County, this study can inform the development of evidence-based decision
support tools in similar contexts, including lessons about data needs, model
design, evaluation, and field validation.</div><div><a href='http://arxiv.org/abs/2403.12599v1'>2403.12599v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.10638v1")'>A resource-constrained stochastic scheduling algorithm for homeless
  street outreach and gleaning edible food</div>
<div id='2403.10638v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-15T19:12:28Z</div><div>Authors: Conor M. Artman, Aditya Mate, Ezinne Nwankwo, Aliza Heching, Tsuyoshi Idé, Jiří Navrátil, Karthikeyan Shanmugam, Wei Sun, Kush R. Varshney, Lauri Goldkind, Gidi Kroch, Jaclyn Sawyer, Ian Watson</div><div style='padding-top: 10px; width: 80ex'>We developed a common algorithmic solution addressing the problem of
resource-constrained outreach encountered by social change organizations with
different missions and operations: Breaking Ground -- an organization that
helps individuals experiencing homelessness in New York transition to permanent
housing and Leket -- the national food bank of Israel that rescues food from
farms and elsewhere to feed the hungry. Specifically, we developed an
estimation and optimization approach for partially-observed episodic restless
bandits under $k$-step transitions. The results show that our Thompson sampling
with Markov chain recovery (via Stein variational gradient descent) algorithm
significantly outperforms baselines for the problems of both organizations. We
carried out this work in a prospective manner with the express goal of devising
a flexible-enough but also useful-enough solution that can help overcome a lack
of sustainable impact in data science for social good.</div><div><a href='http://arxiv.org/abs/2403.10638v1'>2403.10638v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.00705v2")'>Combining the Strengths of Dutch Survey and Register Data in a Data
  Challenge to Predict Fertility (PreFer)</div>
<div id='2402.00705v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T16:00:21Z</div><div>Authors: Elizaveta Sivak, Paulina Pankowska, Adrienne Mendrik, Tom Emery, Javier Garcia-Bernardo, Seyit Hocuk, Kasia Karpinska, Angelica Maineri, Joris Mulder, Malvina Nissim, Gert Stulp</div><div style='padding-top: 10px; width: 80ex'>The social sciences have produced an impressive body of research on
determinants of fertility outcomes, or whether and when people have children.
However, the strength of these determinants and underlying theories are rarely
evaluated on their predictive ability on new data. This prevents us from
systematically comparing studies, hindering the evaluation and accumulation of
knowledge. In this paper, we present two datasets which can be used to study
the predictability of fertility outcomes in the Netherlands. One dataset is
based on the LISS panel, a longitudinal survey which includes thousands of
variables on a wide range of topics, including individual preferences and
values. The other is based on the Dutch register data which lacks attitudinal
data but includes detailed information about the life courses of millions of
Dutch residents. We provide information about the datasets and the samples, and
describe the fertility outcome of interest. We also introduce the fertility
prediction data challenge PreFer which is based on these datasets and will
start in Spring 2024. We outline the ways in which measuring the predictability
of fertility outcomes using these datasets and combining their strengths in the
data challenge can advance our understanding of fertility behaviour and
computational social science. We further provide details for participants on
how to take part in the data challenge.</div><div><a href='http://arxiv.org/abs/2402.00705v2'>2402.00705v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.13791v1")'>Opening the Black-Box: A Systematic Review on Explainable AI in Remote
  Sensing</div>
<div id='2402.13791v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-21T13:19:58Z</div><div>Authors: Adrian Höhl, Ivica Obadic, Miguel Ángel Fernández Torres, Hiba Najjar, Dario Oliveira, Zeynep Akata, Andreas Dengel, Xiao Xiang Zhu</div><div style='padding-top: 10px; width: 80ex'>In recent years, black-box machine learning approaches have become a dominant
modeling paradigm for knowledge extraction in Remote Sensing. Despite the
potential benefits of uncovering the inner workings of these models with
explainable AI, a comprehensive overview summarizing the used explainable AI
methods and their objectives, findings, and challenges in Remote Sensing
applications is still missing. In this paper, we address this issue by
performing a systematic review to identify the key trends of how explainable AI
is used in Remote Sensing and shed light on novel explainable AI approaches and
emerging directions that tackle specific Remote Sensing challenges. We also
reveal the common patterns of explanation interpretation, discuss the extracted
scientific insights in Remote Sensing, and reflect on the approaches used for
explainable AI methods evaluation. Our review provides a complete summary of
the state-of-the-art in the field. Further, we give a detailed outlook on the
challenges and promising research directions, representing a basis for novel
methodological development and a useful starting point for new researchers in
the field of explainable AI in Remote Sensing.</div><div><a href='http://arxiv.org/abs/2402.13791v1'>2402.13791v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01444v1")'>Mission Critical -- Satellite Data is a Distinct Modality in Machine
  Learning</div>
<div id='2402.01444v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T14:36:50Z</div><div>Authors: Esther Rolf, Konstantin Klemmer, Caleb Robinson, Hannah Kerner</div><div style='padding-top: 10px; width: 80ex'>Satellite data has the potential to inspire a seismic shift for machine
learning -- one in which we rethink existing practices designed for traditional
data modalities. As machine learning for satellite data (SatML) gains traction
for its real-world impact, our field is at a crossroads. We can either continue
applying ill-suited approaches, or we can initiate a new research agenda that
centers around the unique characteristics and challenges of satellite data.
This position paper argues that satellite data constitutes a distinct modality
for machine learning research and that we must recognize it as such to advance
the quality and impact of SatML research across theory, methods, and
deployment. We outline critical discussion questions and actionable suggestions
to transform SatML from merely an intriguing application area to a dedicated
research discipline that helps move the needle on big challenges for machine
learning and society.</div><div><a href='http://arxiv.org/abs/2402.01444v1'>2402.01444v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14297v1")'>Impact Assessment of Missing Data in Model Predictions for Earth
  Observation Applications</div>
<div id='2403.14297v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T11:03:56Z</div><div>Authors: Francisco Mena, Diego Arenas, Marcela Charfuelan, Marlon Nuske, Andreas Dengel</div><div style='padding-top: 10px; width: 80ex'>Earth observation (EO) applications involving complex and heterogeneous data
sources are commonly approached with machine learning models. However, there is
a common assumption that data sources will be persistently available. Different
situations could affect the availability of EO sources, like noise, clouds, or
satellite mission failures. In this work, we assess the impact of missing
temporal and static EO sources in trained models across four datasets with
classification and regression tasks. We compare the predictive quality of
different methods and find that some are naturally more robust to missing data.
The Ensemble strategy, in particular, achieves a prediction robustness up to
100%. We evidence that missing scenarios are significantly more challenging in
regression than classification tasks. Finally, we find that the optical view is
the most critical view when it is missing individually.</div><div><a href='http://arxiv.org/abs/2403.14297v1'>2403.14297v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.06421v1")'>Uncertainty quantification for probabilistic machine learning in earth
  observation using conformal prediction</div>
<div id='2401.06421v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-12T07:31:21Z</div><div>Authors: Geethen Singh, Glenn Moncrieff, Zander Venter, Kerry Cawse-Nicholson, Jasper Slingsby, Tamara B Robinson</div><div style='padding-top: 10px; width: 80ex'>Unreliable predictions can occur when using artificial intelligence (AI)
systems with negative consequences for downstream applications, particularly
when employed for decision-making. Conformal prediction provides a
model-agnostic framework for uncertainty quantification that can be applied to
any dataset, irrespective of its distribution, post hoc. In contrast to other
pixel-level uncertainty quantification methods, conformal prediction operates
without requiring access to the underlying model and training dataset,
concurrently offering statistically valid and informative prediction regions,
all while maintaining computational efficiency. In response to the increased
need to report uncertainty alongside point predictions, we bring attention to
the promise of conformal prediction within the domain of Earth Observation (EO)
applications. To accomplish this, we assess the current state of uncertainty
quantification in the EO domain and found that only 20% of the reviewed Google
Earth Engine (GEE) datasets incorporated a degree of uncertainty information,
with unreliable methods prevalent. Next, we introduce modules that seamlessly
integrate into existing GEE predictive modelling workflows and demonstrate the
application of these tools for datasets spanning local to global scales,
including the Dynamic World and Global Ecosystem Dynamics Investigation (GEDI)
datasets. These case studies encompass regression and classification tasks,
featuring both traditional and deep learning-based workflows. Subsequently, we
discuss the opportunities arising from the use of conformal prediction in EO.
We anticipate that the increased availability of easy-to-use implementations of
conformal predictors, such as those provided here, will drive wider adoption of
rigorous uncertainty quantification in EO, thereby enhancing the reliability of
uses such as operational monitoring and decision making.</div><div><a href='http://arxiv.org/abs/2401.06421v1'>2401.06421v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.17342v1")'>A Latent Space Metric for Enhancing Prediction Confidence in Earth
  Observation Data</div>
<div id='2401.17342v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T13:41:12Z</div><div>Authors: Ioannis Pitsiorlas, Argyro Tsantalidou, George Arvanitakis, Marios Kountouris, Charalambos Kontoes</div><div style='padding-top: 10px; width: 80ex'>This study presents a new approach for estimating confidence in machine
learning model predictions, specifically in regression tasks utilizing Earth
Observation (EO) data, with a particular focus on mosquito abundance (MA)
estimation. We take advantage of a Variational AutoEncoder architecture, to
derive a confidence metric by the latent space representations of EO datasets.
This methodology is pivotal in establishing a correlation between the Euclidean
distance in latent representations and the Absolute Error (AE) in individual MA
predictions. Our research focuses on EO datasets from the Veneto region in
Italy and the Upper Rhine Valley in Germany, targeting areas significantly
affected by mosquito populations. A key finding is a notable correlation of
0.46 between the AE of MA predictions and the proposed confidence metric. This
correlation signifies a robust, new metric for quantifying the reliability and
enhancing the trustworthiness of the AI model's predictions in the context of
both EO data analysis and mosquito abundance studies.</div><div><a href='http://arxiv.org/abs/2401.17342v1'>2401.17342v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.11331v1")'>Potential of Domain Adaptation in Machine Learning in Ecology and
  Hydrology to Improve Model Extrapolability</div>
<div id='2403.11331v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-17T20:23:06Z</div><div>Authors: Haiyang Shi</div><div style='padding-top: 10px; width: 80ex'>Due to the heterogeneity of the global distribution of ecological and
hydrological ground-truth observations, machine learning models can have
limited adaptability when applied to unknown locations, which is referred to as
weak extrapolability. Domain adaptation techniques have been widely used in
machine learning domains such as image classification, which can improve the
model generalization ability by adjusting the difference or inconsistency of
the domain distribution between the training and test sets. However, this
approach has rarely been used explicitly in machine learning models in ecology
and hydrology at the global scale, although these models have often been
questioned due to geographic extrapolability issues. This paper briefly
describes the shortcomings of current machine learning models of ecology and
hydrology in terms of the global representativeness of the distribution of
observations and the resulting limitations of the lack of extrapolability and
suggests that future related modelling efforts should consider the use of
domain adaptation techniques to improve extrapolability.</div><div><a href='http://arxiv.org/abs/2403.11331v1'>2403.11331v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.13332v1")'>Double machine learning for causal hybrid modeling -- applications in
  the Earth sciences</div>
<div id='2402.13332v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T19:19:56Z</div><div>Authors: Kai-Hendrik Cohrs, Gherardo Varando, Nuno Carvalhais, Markus Reichstein, Gustau Camps-Valls</div><div style='padding-top: 10px; width: 80ex'>Hybrid modeling integrates machine learning with scientific knowledge with
the goal of enhancing interpretability, generalization, and adherence to
natural laws. Nevertheless, equifinality and regularization biases pose
challenges in hybrid modeling to achieve these purposes. This paper introduces
a novel approach to estimating hybrid models via a causal inference framework,
specifically employing Double Machine Learning (DML) to estimate causal
effects. We showcase its use for the Earth sciences on two problems related to
carbon dioxide fluxes. In the $Q_{10}$ model, we demonstrate that DML-based
hybrid modeling is superior in estimating causal parameters over end-to-end
deep neural network (DNN) approaches, proving efficiency, robustness to bias
from regularization methods, and circumventing equifinality. Our approach,
applied to carbon flux partitioning, exhibits flexibility in accommodating
heterogeneous causal effects. The study emphasizes the necessity of explicitly
defining causal graphs and relationships, advocating for this as a general best
practice. We encourage the continued exploration of causality in hybrid models
for more interpretable and trustworthy results in knowledge-guided machine
learning.</div><div><a href='http://arxiv.org/abs/2402.13332v1'>2402.13332v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.14861v1")'>CloudNine: Analyzing Meteorological Observation Impact on Weather
  Prediction Using Explainable Graph Neural Networks</div>
<div id='2402.14861v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-21T01:29:17Z</div><div>Authors: Hyeon-Ju Jeon, Jeon-Ho Kang, In-Hyuk Kwon, O-Joun Lee</div><div style='padding-top: 10px; width: 80ex'>The impact of meteorological observations on weather forecasting varies with
sensor type, location, time, and other environmental factors. Thus,
quantitative analysis of observation impacts is crucial for effective and
efficient development of weather forecasting systems. However, the existing
impact analysis methods are difficult to be widely applied due to their high
dependencies on specific forecasting systems. Also, they cannot provide
observation impacts at multiple spatio-temporal scales, only global impacts of
observation types. To address these issues, we present a novel system called
``CloudNine,'' which allows analysis of individual observations' impacts on
specific predictions based on explainable graph neural networks (XGNNs).
Combining an XGNN-based atmospheric state estimation model with a numerical
weather prediction model, we provide a web application to search for
observations in the 3D space of the Earth system and to visualize the impact of
individual observations on predictions in specific spatial regions and time
periods.</div><div><a href='http://arxiv.org/abs/2402.14861v1'>2402.14861v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.13081v1")'>IT Intrusion Detection Using Statistical Learning and Testbed
  Measurements</div>
<div id='2402.13081v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T15:25:56Z</div><div>Authors: Xiaoxuan Wang, Rolf Stadler</div><div style='padding-top: 10px; width: 80ex'>We study automated intrusion detection in an IT infrastructure, specifically
the problem of identifying the start of an attack, the type of attack, and the
sequence of actions an attacker takes, based on continuous measurements from
the infrastructure. We apply statistical learning methods, including Hidden
Markov Model (HMM), Long Short-Term Memory (LSTM), and Random Forest Classifier
(RFC) to map sequences of observations to sequences of predicted attack
actions. In contrast to most related research, we have abundant data to train
the models and evaluate their predictive power. The data comes from traces we
generate on an in-house testbed where we run attacks against an emulated IT
infrastructure. Central to our work is a machine-learning pipeline that maps
measurements from a high-dimensional observation space to a space of low
dimensionality or to a small set of observation symbols. Investigating
intrusions in offline as well as online scenarios, we find that both HMM and
LSTM can be effective in predicting attack start time, attack type, and attack
actions. If sufficient training data is available, LSTM achieves higher
prediction accuracy than HMM. HMM, on the other hand, requires less
computational resources and less training data for effective prediction. Also,
we find that the methods we study benefit from data produced by traditional
intrusion detection systems like SNORT.</div><div><a href='http://arxiv.org/abs/2402.13081v1'>2402.13081v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.13277v2")'>MLSTL-WSN: Machine Learning-based Intrusion Detection using SMOTETomek
  in WSNs</div>
<div id='2402.13277v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-17T18:04:08Z</div><div>Authors: Md. Alamin Talukder, Selina Sharmin, Md Ashraf Uddin, Md Manowarul Islam, Sunil Aryal</div><div style='padding-top: 10px; width: 80ex'>Wireless Sensor Networks (WSNs) play a pivotal role as infrastructures,
encompassing both stationary and mobile sensors. These sensors self-organize
and establish multi-hop connections for communication, collectively sensing,
gathering, processing, and transmitting data about their surroundings. Despite
their significance, WSNs face rapid and detrimental attacks that can disrupt
functionality. Existing intrusion detection methods for WSNs encounter
challenges such as low detection rates, computational overhead, and false
alarms. These issues stem from sensor node resource constraints, data
redundancy, and high correlation within the network. To address these
challenges, we propose an innovative intrusion detection approach that
integrates Machine Learning (ML) techniques with the Synthetic Minority
Oversampling Technique Tomek Link (SMOTE-TomekLink) algorithm. This blend
synthesizes minority instances and eliminates Tomek links, resulting in a
balanced dataset that significantly enhances detection accuracy in WSNs.
Additionally, we incorporate feature scaling through standardization to render
input features consistent and scalable, facilitating more precise training and
detection. To counteract imbalanced WSN datasets, we employ the SMOTE-Tomek
resampling technique, mitigating overfitting and underfitting issues. Our
comprehensive evaluation, using the WSN Dataset (WSN-DS) containing 374,661
records, identifies the optimal model for intrusion detection in WSNs. The
standout outcome of our research is the remarkable performance of our model. In
binary, it achieves an accuracy rate of 99.78% and in multiclass, it attains an
exceptional accuracy rate of 99.92%. These findings underscore the efficiency
and superiority of our proposal in the context of WSN intrusion detection,
showcasing its effectiveness in detecting and mitigating intrusions in WSNs.</div><div><a href='http://arxiv.org/abs/2402.13277v2'>2402.13277v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.17808v1")'>AN An ica-ensemble learning approach for prediction of uwb nlos signals
  data classification</div>
<div id='2402.17808v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T11:42:26Z</div><div>Authors: Jiya A. Enoch, Ilesanmi B. Oluwafemi, Francis A. Ibikunle, Olulope K. Paul</div><div style='padding-top: 10px; width: 80ex'>Trapped human detection in search and rescue (SAR) scenarios poses a
significant challenge in pervasive computing. This study addresses this issue
by leveraging machine learning techniques, given their high accuracy. However,
accurate identification of trapped individuals is hindered by the curse of
dimensionality and noisy data. Particularly in non-line-of-sight (NLOS)
situations during catastrophic events, the curse of dimensionality may lead to
blind spots due to noise and uncorrelated values in detections. This research
focuses on harmonizing information through wireless communication and
identifying individuals in NLOS scenarios using ultra-wideband (UWB) radar
signals. Employing independent component analysis (ICA) for feature extraction,
the study evaluates classification performance using ensemble algorithms on
both static and dynamic datasets. The experimental results demonstrate
categorization accuracies of 88.37% for static data and 87.20% for dynamic
data, highlighting the effectiveness of the proposed approach. Finally, this
work can help scientists and engineers make instant decisions during SAR
operations.</div><div><a href='http://arxiv.org/abs/2402.17808v1'>2402.17808v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.08468v1")'>ROSpace: Intrusion Detection Dataset for a ROS2-Based Cyber-Physical
  System</div>
<div id='2402.08468v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T13:54:47Z</div><div>Authors: Tommaso Puccetti, Simone Nardi, Cosimo Cinquilli, Tommaso Zoppi, Andrea Ceccarelli</div><div style='padding-top: 10px; width: 80ex'>Most of the intrusion detection datasets to research machine learning-based
intrusion detection systems (IDSs) are devoted to cyber-only systems, and they
typically collect data from one architectural layer. Additionally, often the
attacks are generated in dedicated attack sessions, without reproducing the
realistic alternation and overlap of normal and attack actions. We present a
dataset for intrusion detection by performing penetration testing on an
embedded cyber-physical system built over Robot Operating System 2 (ROS2).
Features are monitored from three architectural layers: the Linux operating
system, the network, and the ROS2 services. The dataset is structured as a time
series and describes the expected behavior of the system and its response to
ROS2-specific attacks: it repeatedly alternates periods of attack-free
operation with periods when a specific attack is being performed. Noteworthy,
this allows measuring the time to detect an attacker and the number of
malicious activities performed before detection. Also, it allows training an
intrusion detector to minimize both, by taking advantage of the numerous
alternating periods of normal and attack operations.</div><div><a href='http://arxiv.org/abs/2402.08468v1'>2402.08468v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.12338v1")'>An Adversarial Approach to Evaluating the Robustness of Event
  Identification Models</div>
<div id='2402.12338v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-19T18:11:37Z</div><div>Authors: Obai Bahwal, Oliver Kosut, Lalitha Sankar</div><div style='padding-top: 10px; width: 80ex'>Intelligent machine learning approaches are finding active use for event
detection and identification that allow real-time situational awareness. Yet,
such machine learning algorithms have been shown to be susceptible to
adversarial attacks on the incoming telemetry data. This paper considers a
physics-based modal decomposition method to extract features for event
classification and focuses on interpretable classifiers including logistic
regression and gradient boosting to distinguish two types of events: load loss
and generation loss. The resulting classifiers are then tested against an
adversarial algorithm to evaluate their robustness. The adversarial attack is
tested in two settings: the white box setting, wherein the attacker knows
exactly the classification model; and the gray box setting, wherein the
attacker has access to historical data from the same network as was used to
train the classifier, but does not know the classification model. Thorough
experiments on the synthetic South Carolina 500-bus system highlight that a
relatively simpler model such as logistic regression is more susceptible to
adversarial attacks than gradient boosting.</div><div><a href='http://arxiv.org/abs/2402.12338v1'>2402.12338v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.15360v1")'>All Thresholds Barred: Direct Estimation of Call Density in Bioacoustic
  Data</div>
<div id='2402.15360v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-23T14:52:44Z</div><div>Authors: Amanda K. Navine, Tom Denton, Matthew J. Weldy, Patrick J. Hart</div><div style='padding-top: 10px; width: 80ex'>Passive acoustic monitoring (PAM) studies generate thousands of hours of
audio, which may be used to monitor specific animal populations, conduct broad
biodiversity surveys, detect threats such as poachers, and more. Machine
learning classifiers for species identification are increasingly being used to
process the vast amount of audio generated by bioacoustic surveys, expediting
analysis and increasing the utility of PAM as a management tool. In common
practice, a threshold is applied to classifier output scores, and scores above
the threshold are aggregated into a detection count. The choice of threshold
produces biased counts of vocalizations, which are subject to false
positive/negative rates that may vary across subsets of the dataset. In this
work, we advocate for directly estimating call density: The proportion of
detection windows containing the target vocalization, regardless of classifier
score. Our approach targets a desirable ecological estimator and provides a
more rigorous grounding for identifying the core problems caused by
distribution shifts -- when the defining characteristics of the data
distribution change -- and designing strategies to mitigate them. We propose a
validation scheme for estimating call density in a body of data and obtain,
through Bayesian reasoning, probability distributions of confidence scores for
both the positive and negative classes. We use these distributions to predict
site-level densities, which may be subject to distribution shifts. We test our
proposed methods on a real-world study of Hawaiian birds and provide simulation
results leveraging existing fully annotated datasets, demonstrating robustness
to variations in call density and classifier model quality.</div><div><a href='http://arxiv.org/abs/2402.15360v1'>2402.15360v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.05114v1")'>A Light-weight and Unsupervised Method for Near Real-time Behavioral
  Analysis using Operational Data Measurement</div>
<div id='2402.05114v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-10T10:22:25Z</div><div>Authors: Tom Richard Vargis, Siavash Ghiasvand</div><div style='padding-top: 10px; width: 80ex'>Monitoring the status of large computing systems is essential to identify
unexpected behavior and improve their performance and uptime. However, due to
the large-scale and distributed design of such computing systems as well as a
large number of monitoring parameters, automated monitoring methods should be
applied. Such automatic monitoring methods should also have the ability to
adapt themselves to the continuous changes in the computing system. In
addition, they should be able to identify behavioral anomalies in useful time,
to perform appropriate reactions. This work proposes a general lightweight and
unsupervised method for near real-time anomaly detection using operational data
measurement on large computing systems. The proposed model requires as little
as 4 hours of data and 50 epochs for each training process to accurately
resemble the behavioral pattern of computing systems.</div><div><a href='http://arxiv.org/abs/2402.05114v1'>2402.05114v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.06089v1")'>PANDORA: A Parallel Dendrogram Construction Algorithm for Single Linkage
  Clustering on GPU</div>
<div id='2401.06089v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-11T18:08:56Z</div><div>Authors: Piyush Sao, Andrey Prokopenko, Damien Lebrun-Grandié</div><div style='padding-top: 10px; width: 80ex'>This paper presents \pandora, a novel parallel algorithm for efficiently
constructing dendrograms for single-linkage hierarchical clustering, including
\hdbscan. Traditional dendrogram construction methods from a minimum spanning
tree (MST), such as agglomerative or divisive techniques, often fail to
efficiently parallelize, especially with skewed dendrograms common in
real-world data.
  \pandora addresses these challenges through a unique recursive tree
contraction method, which simplifies the tree for initial dendrogram
construction and then progressively reconstructs the complete dendrogram. This
process makes \pandora asymptotically work-optimal, independent of dendrogram
skewness. All steps in \pandora are fully parallel and suitable for massively
threaded accelerators such as GPUs.
  Our implementation is written in Kokkos, providing support for both CPUs and
multi-vendor GPUs (e.g., Nvidia, AMD). The multithreaded version of \pandora is
2.2$\times$ faster than the current best-multithreaded implementation, while
the GPU \pandora implementation achieved 6-20$\times$ on \amdgpu and
10-37$\times$ on \nvidiagpu speed-up over multithreaded \pandora. These
advancements lead to up to a 6-fold speedup for \hdbscan on GPUs over the
current best, which only offload MST construction to GPUs and perform
multithreaded dendrogram construction.</div><div><a href='http://arxiv.org/abs/2401.06089v1'>2401.06089v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.11013v1")'>Improved Algorithm and Bounds for Successive Projection</div>
<div id='2403.11013v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-16T20:42:27Z</div><div>Authors: Jiashun Jin, Zheng Tracy Ke, Gabriel Moryoussef, Jiajun Tang, Jingming Wang</div><div style='padding-top: 10px; width: 80ex'>Given a $K$-vertex simplex in a $d$-dimensional space, suppose we measure $n$
points on the simplex with noise (hence, some of the observed points fall
outside the simplex). Vertex hunting is the problem of estimating the $K$
vertices of the simplex. A popular vertex hunting algorithm is successive
projection algorithm (SPA). However, SPA is observed to perform
unsatisfactorily under strong noise or outliers. We propose pseudo-point SPA
(pp-SPA). It uses a projection step and a denoise step to generate
pseudo-points and feed them into SPA for vertex hunting. We derive error bounds
for pp-SPA, leveraging on extreme value theory of (possibly) high-dimensional
random vectors. The results suggest that pp-SPA has faster rates and better
numerical performances than SPA. Our analysis includes an improved
non-asymptotic bound for the original SPA, which is of independent interest.</div><div><a href='http://arxiv.org/abs/2403.11013v1'>2403.11013v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.17327v1")'>Data-Efficient Learning via Clustering-Based Sensitivity Sampling:
  Foundation Models and Beyond</div>
<div id='2402.17327v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T09:03:43Z</div><div>Authors: Kyriakos Axiotis, Vincent Cohen-Addad, Monika Henzinger, Sammy Jerome, Vahab Mirrokni, David Saulpic, David Woodruff, Michael Wunder</div><div style='padding-top: 10px; width: 80ex'>We study the data selection problem, whose aim is to select a small
representative subset of data that can be used to efficiently train a machine
learning model. We present a new data selection approach based on $k$-means
clustering and sensitivity sampling. Assuming access to an embedding
representation of the data with respect to which the model loss is H\"older
continuous, our approach provably allows selecting a set of ``typical'' $k +
1/\varepsilon^2$ elements whose average loss corresponds to the average loss of
the whole dataset, up to a multiplicative $(1\pm\varepsilon)$ factor and an
additive $\varepsilon \lambda \Phi_k$, where $\Phi_k$ represents the $k$-means
cost for the input embeddings and $\lambda$ is the H\"older constant.
  We furthermore demonstrate the performance and scalability of our approach on
fine-tuning foundation models and show that it outperforms state-of-the-art
methods. We also show how it can be applied on linear regression, leading to a
new sampling strategy that surprisingly matches the performances of leverage
score sampling, while being conceptually simpler and more scalable.</div><div><a href='http://arxiv.org/abs/2402.17327v1'>2402.17327v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.07137v1")'>Exploring Cluster Analysis in Nelore Cattle Visual Score Attribution</div>
<div id='2403.07137v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-11T20:07:05Z</div><div>Authors: Alexandre de Oliveira Bezerra, Rodrigo Goncalves Mateus, Vanessa Ap. de Moraes Weber, Fabricio de Lima Weber, Yasmin Alves de Arruda, Rodrigo da Costa Gomes, Gabriel Toshio Hirokawa Higa, Hemerson Pistori</div><div style='padding-top: 10px; width: 80ex'>Assessing the biotype of cattle through human visual inspection is a very
common and important practice in precision cattle breeding. This paper presents
the results of a correlation analysis between scores produced by humans for
Nelore cattle and a variety of measurements that can be derived from images or
other instruments. It also presents a study using the k-means algorithm to
generate new ways of clustering a batch of cattle using the measurements that
most correlate with the animal's body weight and visual scores.</div><div><a href='http://arxiv.org/abs/2403.07137v1'>2403.07137v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.16407v1")'>Is K-fold cross validation the best model selection method for Machine
  Learning?</div>
<div id='2401.16407v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T18:46:53Z</div><div>Authors: Juan M Gorriz, F Segovia, J Ramirez, A Ortiz, J. Suckling</div><div style='padding-top: 10px; width: 80ex'>As a technique that can compactly represent complex patterns, machine
learning has significant potential for predictive inference. K-fold
cross-validation (CV) is the most common approach to ascertaining the
likelihood that a machine learning outcome is generated by chance and
frequently outperforms conventional hypothesis testing. This improvement uses
measures directly obtained from machine learning classifications, such as
accuracy, that do not have a parametric description. To approach a frequentist
analysis within machine learning pipelines, a permutation test or simple
statistics from data partitions (i.e. folds) can be added to estimate
confidence intervals. Unfortunately, neither parametric nor non-parametric
tests solve the inherent problems around partitioning small sample-size
datasets and learning from heterogeneous data sources. The fact that machine
learning strongly depends on the learning parameters and the distribution of
data across folds recapitulates familiar difficulties around excess false
positives and replication. The origins of this problem are demonstrated by
simulating common experimental circumstances, including small sample sizes, low
numbers of predictors, and heterogeneous data sources. A novel statistical test
based on K-fold CV and the Upper Bound of the actual error (K-fold CUBV) is
composed, where uncertain predictions of machine learning with CV are bounded
by the \emph{worst case} through the evaluation of concentration inequalities.
Probably Approximately Correct-Bayesian upper bounds for linear classifiers in
combination with K-fold CV is used to estimate the empirical error. The
performance with neuroimaging datasets suggests this is a robust criterion for
detecting effects, validating accuracy values obtained from machine learning
whilst avoiding excess false positives.</div><div><a href='http://arxiv.org/abs/2401.16407v1'>2401.16407v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13843v1")'>Enumerating the k-fold configurations in multi-class classification
  problems</div>
<div id='2401.13843v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T22:40:00Z</div><div>Authors: Attila Fazekas, Gyorgy Kovacs</div><div style='padding-top: 10px; width: 80ex'>K-fold cross-validation is a widely used tool for assessing classifier
performance. The reproducibility crisis faced by artificial intelligence partly
results from the irreproducibility of reported k-fold cross-validation-based
performance scores. Recently, we introduced numerical techniques to test the
consistency of claimed performance scores and experimental setups. In a crucial
use case, the method relies on the combinatorial enumeration of all k-fold
configurations, for which we proposed an algorithm in the binary classification
case.</div><div><a href='http://arxiv.org/abs/2401.13843v1'>2401.13843v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.17036v1")'>Intrinsic Data Constraints and Upper Bounds in Binary Classification
  Performance</div>
<div id='2401.17036v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T14:16:02Z</div><div>Authors: Fei Jing, Zi-Ke Zhang, Qingpeng Zhang</div><div style='padding-top: 10px; width: 80ex'>The structure of data organization is widely recognized as having a
substantial influence on the efficacy of machine learning algorithms,
particularly in binary classification tasks. Our research provides a
theoretical framework suggesting that the maximum potential of binary
classifiers on a given dataset is primarily constrained by the inherent
qualities of the data. Through both theoretical reasoning and empirical
examination, we employed standard objective functions, evaluative metrics, and
binary classifiers to arrive at two principal conclusions. Firstly, we show
that the theoretical upper bound of binary classification performance on actual
datasets can be theoretically attained. This upper boundary represents a
calculable equilibrium between the learning loss and the metric of evaluation.
Secondly, we have computed the precise upper bounds for three commonly used
evaluation metrics, uncovering a fundamental uniformity with our overarching
thesis: the upper bound is intricately linked to the dataset's characteristics,
independent of the classifier in use. Additionally, our subsequent analysis
uncovers a detailed relationship between the upper limit of performance and the
level of class overlap within the binary classification data. This relationship
is instrumental for pinpointing the most effective feature subsets for use in
feature engineering.</div><div><a href='http://arxiv.org/abs/2401.17036v1'>2401.17036v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13185v1")'>Shortcutting Cross-Validation: Efficiently Deriving Column-Wise Centered
  and Scaled Training Set $\mathbf{X}^\mathbf{T}\mathbf{X}$ and
  $\mathbf{X}^\mathbf{T}\mathbf{Y}$ Without Full Recomputation of Matrix
  Products or Statistical Moments</div>
<div id='2401.13185v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T02:16:03Z</div><div>Authors: Ole-Christian Galbo Engstrøm</div><div style='padding-top: 10px; width: 80ex'>Cross-validation is a widely used technique for assessing the performance of
predictive models on unseen data. Many predictive models, such as Kernel-Based
Partial Least-Squares (PLS) models, require the computation of
$\mathbf{X}^{\mathbf{T}}\mathbf{X}$ and $\mathbf{X}^{\mathbf{T}}\mathbf{Y}$
using only training set samples from the input and output matrices,
$\mathbf{X}$ and $\mathbf{Y}$, respectively. In this work, we present three
algorithms that efficiently compute these matrices. The first one allows no
column-wise preprocessing. The second one allows column-wise centering around
the training set means. The third one allows column-wise centering and
column-wise scaling around the training set means and standard deviations.
Demonstrating correctness and superior computational complexity, they offer
significant cross-validation speedup compared with straight-forward
cross-validation and previous work on fast cross-validation - all without data
leakage. Their suitability for parallelization is highlighted with an
open-source Python implementation combining our algorithms with Improved Kernel
PLS.</div><div><a href='http://arxiv.org/abs/2401.13185v1'>2401.13185v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15610v1")'>Prevalidated ridge regression is a highly-efficient drop-in replacement
  for logistic regression for high-dimensional data</div>
<div id='2401.15610v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-28T09:38:14Z</div><div>Authors: Angus Dempster, Geoffrey I. Webb, Daniel F. Schmidt</div><div style='padding-top: 10px; width: 80ex'>Logistic regression is a ubiquitous method for probabilistic classification.
However, the effectiveness of logistic regression depends upon careful and
relatively computationally expensive tuning, especially for the regularisation
hyperparameter, and especially in the context of high-dimensional data. We
present a prevalidated ridge regression model that closely matches logistic
regression in terms of classification error and log-loss, particularly for
high-dimensional data, while being significantly more computationally efficient
and having effectively no hyperparameters beyond regularisation. We scale the
coefficients of the model so as to minimise log-loss for a set of prevalidated
predictions derived from the estimated leave-one-out cross-validation error.
This exploits quantities already computed in the course of fitting the ridge
regression model in order to find the scaling parameter with nominal additional
computational expense.</div><div><a href='http://arxiv.org/abs/2401.15610v1'>2401.15610v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.11963v1")'>Imbalance in Regression Datasets</div>
<div id='2402.11963v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-19T09:06:26Z</div><div>Authors: Daniel Kowatsch, Nicolas M. Müller, Kilian Tscharke, Philip Sperl, Konstantin Bötinger</div><div style='padding-top: 10px; width: 80ex'>For classification, the problem of class imbalance is well known and has been
extensively studied. In this paper, we argue that imbalance in regression is an
equally important problem which has so far been overlooked: Due to under- and
over-representations in a data set's target distribution, regressors are prone
to degenerate to naive models, systematically neglecting uncommon training data
and over-representing targets seen often during training. We analyse this
problem theoretically and use resulting insights to develop a first definition
of imbalance in regression, which we show to be a generalisation of the
commonly employed imbalance measure in classification. With this, we hope to
turn the spotlight on the overlooked problem of imbalance in regression and to
provide common ground for future research.</div><div><a href='http://arxiv.org/abs/2402.11963v1'>2402.11963v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.02354v1")'>A Paradigm for Potential Model Performance Improvement in Classification
  and Regression Problems. A Proof of Concept</div>
<div id='2402.02354v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-04T05:37:37Z</div><div>Authors: Francisco Javier Lobo-Cabrera</div><div style='padding-top: 10px; width: 80ex'>A methodology that seeks to enhance model prediction performance is
presented. The method involves generating multiple auxiliary models that
capture relationships between attributes as a function of each other. Such
information serves to generate additional informative columns in the dataset
that can potentially enhance target prediction. A proof of case and related
code is provided.</div><div><a href='http://arxiv.org/abs/2402.02354v1'>2402.02354v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.11363v1")'>IGANN Sparse: Bridging Sparsity and Interpretability with Non-linear
  Insight</div>
<div id='2403.11363v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-17T22:44:36Z</div><div>Authors: Theodor Stoecker, Nico Hambauer, Patrick Zschech, Mathias Kraus</div><div style='padding-top: 10px; width: 80ex'>Feature selection is a critical component in predictive analytics that
significantly affects the prediction accuracy and interpretability of models.
Intrinsic methods for feature selection are built directly into model learning,
providing a fast and attractive option for large amounts of data. Machine
learning algorithms, such as penalized regression models (e.g., lasso) are the
most common choice when it comes to in-built feature selection. However, they
fail to capture non-linear relationships, which ultimately affects their
ability to predict outcomes in intricate datasets. In this paper, we propose
IGANN Sparse, a novel machine learning model from the family of generalized
additive models, which promotes sparsity through a non-linear feature selection
process during training. This ensures interpretability through improved model
sparsity without sacrificing predictive performance. Moreover, IGANN Sparse
serves as an exploratory tool for information systems researchers to unveil
important non-linear relationships in domains that are characterized by complex
patterns. Our ongoing research is directed at a thorough evaluation of the
IGANN Sparse model, including user studies that allow to assess how well users
of the model can benefit from the reduced number of features. This will allow
for a deeper understanding of the interactions between linear vs. non-linear
modeling, number of selected features, and predictive performance.</div><div><a href='http://arxiv.org/abs/2403.11363v1'>2403.11363v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03447v1")'>Challenges in Variable Importance Ranking Under Correlation</div>
<div id='2402.03447v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T19:02:13Z</div><div>Authors: Annie Liang, Thomas Jemielita, Andy Liaw, Vladimir Svetnik, Lingkang Huang, Richard Baumgartner, Jason M. Klusowski</div><div style='padding-top: 10px; width: 80ex'>Variable importance plays a pivotal role in interpretable machine learning as
it helps measure the impact of factors on the output of the prediction model.
Model agnostic methods based on the generation of "null" features via
permutation (or related approaches) can be applied. Such analysis is often
utilized in pharmaceutical applications due to its ability to interpret
black-box models, including tree-based ensembles. A major challenge and
significant confounder in variable importance estimation however is the
presence of between-feature correlation. Recently, several adjustments to
marginal permutation utilizing feature knockoffs were proposed to address this
issue, such as the variable importance measure known as conditional predictive
impact (CPI). Assessment and evaluation of such approaches is the focus of our
work. We first present a comprehensive simulation study investigating the
impact of feature correlation on the assessment of variable importance. We then
theoretically prove the limitation that highly correlated features pose for the
CPI through the knockoff construction. While we expect that there is always no
correlation between knockoff variables and its corresponding predictor
variables, we prove that the correlation increases linearly beyond a certain
correlation threshold between the predictor variables. Our findings emphasize
the absence of free lunch when dealing with high feature correlation, as well
as the necessity of understanding the utility and limitations behind methods in
variable importance estimation.</div><div><a href='http://arxiv.org/abs/2402.03447v1'>2402.03447v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14466v1")'>Universal Feature Selection for Simultaneous Interpretability of
  Multitask Datasets</div>
<div id='2403.14466v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T15:13:54Z</div><div>Authors: Matt Raymond, Jacob Charles Saldinger, Paolo Elvati, Clayton Scott, Angela Violi</div><div style='padding-top: 10px; width: 80ex'>Extracting meaningful features from complex, high-dimensional datasets across
scientific domains remains challenging. Current methods often struggle with
scalability, limiting their applicability to large datasets, or make
restrictive assumptions about feature-property relationships, hindering their
ability to capture complex interactions. BoUTS's general and scalable feature
selection algorithm surpasses these limitations to identify both universal
features relevant to all datasets and task-specific features predictive for
specific subsets. Evaluated on seven diverse chemical regression datasets,
BoUTS achieves state-of-the-art feature sparsity while maintaining prediction
accuracy comparable to specialized methods. Notably, BoUTS's universal features
enable domain-specific knowledge transfer between datasets, and suggest deep
connections in seemingly-disparate chemical datasets. We expect these results
to have important repercussions in manually-guided inverse problems. Beyond its
current application, BoUTS holds immense potential for elucidating data-poor
systems by leveraging information from similar data-rich systems. BoUTS
represents a significant leap in cross-domain feature selection, potentially
leading to advancements in various scientific fields.</div><div><a href='http://arxiv.org/abs/2403.14466v1'>2403.14466v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.17572v1")'>Hyperdimensional computing: a fast, robust and interpretable paradigm
  for biological data</div>
<div id='2402.17572v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T15:09:20Z</div><div>Authors: Michiel Stock, Dimitri Boeckaerts, Pieter Dewulf, Steff Taelman, Maxime Van Haeverbeke, Wim Van Criekinge, Bernard De Baets</div><div style='padding-top: 10px; width: 80ex'>Advances in bioinformatics are primarily due to new algorithms for processing
diverse biological data sources. While sophisticated alignment algorithms have
been pivotal in analyzing biological sequences, deep learning has substantially
transformed bioinformatics, addressing sequence, structure, and functional
analyses. However, these methods are incredibly data-hungry, compute-intensive
and hard to interpret. Hyperdimensional computing (HDC) has recently emerged as
an intriguing alternative. The key idea is that random vectors of high
dimensionality can represent concepts such as sequence identity or phylogeny.
These vectors can then be combined using simple operators for learning,
reasoning or querying by exploiting the peculiar properties of high-dimensional
spaces. Our work reviews and explores the potential of HDC for bioinformatics,
emphasizing its efficiency, interpretability, and adeptness in handling
multimodal and structured data. HDC holds a lot of potential for various omics
data searching, biosignal analysis and health applications.</div><div><a href='http://arxiv.org/abs/2402.17572v1'>2402.17572v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.08117v1")'>A Universal Non-Parametric Approach For Improved Molecular Sequence
  Analysis</div>
<div id='2402.08117v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-12T23:15:16Z</div><div>Authors: Sarwan Ali, Tamkanat E Ali, Prakash Chourasia, Murray Patterson</div><div style='padding-top: 10px; width: 80ex'>In the field of biological research, it is essential to comprehend the
characteristics and functions of molecular sequences. The classification of
molecular sequences has seen widespread use of neural network-based techniques.
Despite their astounding accuracy, these models often require a substantial
number of parameters and more data collection. In this work, we present a novel
approach based on the compression-based Model, motivated from
\cite{jiang2023low}, which combines the simplicity of basic compression
algorithms like Gzip and Bz2, with Normalized Compression Distance (NCD)
algorithm to achieve better performance on classification tasks without relying
on handcrafted features or pre-trained models. Firstly, we compress the
molecular sequence using well-known compression algorithms, such as Gzip and
Bz2. By leveraging the latent structure encoded in compressed files, we compute
the Normalized Compression Distance between each pair of molecular sequences,
which is derived from the Kolmogorov complexity. This gives us a distance
matrix, which is the input for generating a kernel matrix using a Gaussian
kernel. Next, we employ kernel Principal Component Analysis (PCA) to get the
vector representations for the corresponding molecular sequence, capturing
important structural and functional information. The resulting vector
representations provide an efficient yet effective solution for molecular
sequence analysis and can be used in ML-based downstream tasks. The proposed
approach eliminates the need for computationally intensive Deep Neural Networks
(DNNs), with their large parameter counts and data requirements. Instead, it
leverages a lightweight and universally accessible compression-based model.</div><div><a href='http://arxiv.org/abs/2402.08117v1'>2402.08117v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.14025v1")'>DNA Sequence Classification with Compressors</div>
<div id='2401.14025v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-25T09:17:19Z</div><div>Authors: Şükrü Ozan</div><div style='padding-top: 10px; width: 80ex'>Recent studies in DNA sequence classification have leveraged sophisticated
machine learning techniques, achieving notable accuracy in categorizing complex
genomic data. Among these, methods such as k-mer counting have proven effective
in distinguishing sequences from varied species like chimpanzees, dogs, and
humans, becoming a staple in contemporary genomic research. However, these
approaches often demand extensive computational resources, posing a challenge
in terms of scalability and efficiency. Addressing this issue, our study
introduces a novel adaptation of Jiang et al.'s compressor-based,
parameter-free classification method, specifically tailored for DNA sequence
analysis. This innovative approach utilizes a variety of compression
algorithms, such as Gzip, Brotli, and LZMA, to efficiently process and classify
genomic sequences. Not only does this method align with the current
state-of-the-art in terms of accuracy, but it also offers a more
resource-efficient alternative to traditional machine learning methods. Our
comprehensive evaluation demonstrates the proposed method's effectiveness in
accurately classifying DNA sequences from multiple species. We present a
detailed analysis of the performance of each algorithm used, highlighting the
strengths and limitations of our approach in various genomic contexts.
Furthermore, we discuss the broader implications of our findings for
bioinformatics, particularly in genomic data processing and analysis. The
results of our study pave the way for more efficient and scalable DNA sequence
classification methods, offering significant potential for advancements in
genomic research and applications.</div><div><a href='http://arxiv.org/abs/2401.14025v1'>2401.14025v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13219v1")'>TEPI: Taxonomy-aware Embedding and Pseudo-Imaging for Scarcely-labeled
  Zero-shot Genome Classification</div>
<div id='2401.13219v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T04:16:28Z</div><div>Authors: Sathyanarayanan Aakur, Vishalini R. Laguduva, Priyadharsini Ramamurthy, Akhilesh Ramachandran</div><div style='padding-top: 10px; width: 80ex'>A species' genetic code or genome encodes valuable evolutionary, biological,
and phylogenetic information that aids in species recognition, taxonomic
classification, and understanding genetic predispositions like drug resistance
and virulence. However, the vast number of potential species poses significant
challenges in developing a general-purpose whole genome classification tool.
Traditional bioinformatics tools have made notable progress but lack
scalability and are computationally expensive. Machine learning-based
frameworks show promise but must address the issue of large classification
vocabularies with long-tail distributions. In this study, we propose addressing
this problem through zero-shot learning using TEPI, Taxonomy-aware Embedding
and Pseudo-Imaging. We represent each genome as pseudo-images and map them to a
taxonomy-aware embedding space for reasoning and classification. This embedding
space captures compositional and phylogenetic relationships of species,
enabling predictions in extensive search spaces. We evaluate TEPI using two
rigorous zero-shot settings and demonstrate its generalization capabilities
qualitatively on curated, large-scale, publicly sourced data.</div><div><a href='http://arxiv.org/abs/2401.13219v1'>2401.13219v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.09381v1")'>GraSSRep: Graph-Based Self-Supervised Learning for Repeat Detection in
  Metagenomic Assembly</div>
<div id='2402.09381v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T18:26:58Z</div><div>Authors: Ali Azizpour, Advait Balaji, Todd J. Treangen, Santiago Segarra</div><div style='padding-top: 10px; width: 80ex'>Repetitive DNA (repeats) poses significant challenges for accurate and
efficient genome assembly and sequence alignment. This is particularly true for
metagenomic data, where genome dynamics such as horizontal gene transfer, gene
duplication, and gene loss/gain complicate accurate genome assembly from
metagenomic communities. Detecting repeats is a crucial first step in
overcoming these challenges. To address this issue, we propose GraSSRep, a
novel approach that leverages the assembly graph's structure through graph
neural networks (GNNs) within a self-supervised learning framework to classify
DNA sequences into repetitive and non-repetitive categories. Specifically, we
frame this problem as a node classification task within a metagenomic assembly
graph. In a self-supervised fashion, we rely on a high-precision (but
low-recall) heuristic to generate pseudo-labels for a small proportion of the
nodes. We then use those pseudo-labels to train a GNN embedding and a random
forest classifier to propagate the labels to the remaining nodes. In this way,
GraSSRep combines sequencing features with pre-defined and learned graph
features to achieve state-of-the-art performance in repeat detection. We
evaluate our method using simulated and synthetic metagenomic datasets. The
results on the simulated data highlight our GraSSRep's robustness to repeat
attributes, demonstrating its effectiveness in handling the complexity of
repeated sequences. Additionally, our experiments with synthetic metagenomic
datasets reveal that incorporating the graph structure and the GNN enhances our
detection performance. Finally, in comparative analyses, GraSSRep outperforms
existing repeat detection tools with respect to precision and recall.</div><div><a href='http://arxiv.org/abs/2402.09381v1'>2402.09381v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.01053v2")'>Seeing Unseen: Discover Novel Biomedical Concepts via
  Geometry-Constrained Probabilistic Modeling</div>
<div id='2403.01053v2' style='display: none; margin-left: 20px'><div>Date: 2024-03-02T00:56:05Z</div><div>Authors: Jianan Fan, Dongnan Liu, Hang Chang, Heng Huang, Mei Chen, Weidong Cai</div><div style='padding-top: 10px; width: 80ex'>Machine learning holds tremendous promise for transforming the fundamental
practice of scientific discovery by virtue of its data-driven nature. With the
ever-increasing stream of research data collection, it would be appealing to
autonomously explore patterns and insights from observational data for
discovering novel classes of phenotypes and concepts. However, in the
biomedical domain, there are several challenges inherently presented in the
cumulated data which hamper the progress of novel class discovery. The
non-i.i.d. data distribution accompanied by the severe imbalance among
different groups of classes essentially leads to ambiguous and biased semantic
representations. In this work, we present a geometry-constrained probabilistic
modeling treatment to resolve the identified issues. First, we propose to
parameterize the approximated posterior of instance embedding as a marginal von
MisesFisher distribution to account for the interference of distributional
latent bias. Then, we incorporate a suite of critical geometric properties to
impose proper constraints on the layout of constructed embedding space, which
in turn minimizes the uncontrollable risk for unknown class learning and
structuring. Furthermore, a spectral graph-theoretic method is devised to
estimate the number of potential novel classes. It inherits two intriguing
merits compared to existent approaches, namely high computational efficiency
and flexibility for taxonomy-adaptive estimation. Extensive experiments across
various biomedical scenarios substantiate the effectiveness and general
applicability of our method.</div><div><a href='http://arxiv.org/abs/2403.01053v2'>2403.01053v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.03112v1")'>Infrared Spectra Prediction for Diazo Groups Utilizing a Machine
  Learning Approach with Structural Attention Mechanism</div>
<div id='2402.03112v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T15:44:43Z</div><div>Authors: Chengchun Liu, Fanyang Mo</div><div style='padding-top: 10px; width: 80ex'>Infrared (IR) spectroscopy is a pivotal technique in chemical research for
elucidating molecular structures and dynamics through vibrational and
rotational transitions. However, the intricate molecular fingerprints
characterized by unique vibrational and rotational patterns present substantial
analytical challenges. Here, we present a machine learning approach employing a
Structural Attention Mechanism tailored to enhance the prediction and
interpretation of infrared spectra, particularly for diazo compounds. Our model
distinguishes itself by honing in on chemical information proximal to
functional groups, thereby significantly bolstering the accuracy, robustness,
and interpretability of spectral predictions. This method not only demystifies
the correlations between infrared spectral features and molecular structures
but also offers a scalable and efficient paradigm for dissecting complex
molecular interactions.</div><div><a href='http://arxiv.org/abs/2402.03112v1'>2402.03112v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.01158v1")'>A Bayesian Committee Machine Potential for Oxygen-containing Organic
  Compounds</div>
<div id='2403.01158v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-02T10:18:37Z</div><div>Authors: Seungwon Kim, D. ChangMo Yang, Soohaeng Yoo Willow, Chang Woo Myung</div><div style='padding-top: 10px; width: 80ex'>Understanding the pivotal role of oxygen-containing organic compounds in
serving as an energy source for living organisms and contributing to protein
formation is crucial in the field of biochemistry. This study addresses the
challenge of comprehending protein-protein interactions (PPI) and developing
predicitive models for proteins and organic compounds, with a specific focus on
quantifying their binding affinity. Here, we introduce the active Bayesian
Committee Machine (BCM) potential, specifically designed to predict
oxygen-containing organic compounds within eight groups of CHO. The BCM
potential adopts a committee-based approach to tackle scalability issues
associated with kernel regressors, particularly when dealing with large
datasets. Its adaptable structure allows for efficient and cost-effective
expansion, maintaing both transferability and scalability. Through systematic
benchmarking, we position the sparse BCM potential as a promising contender in
the pursuit of a universal machine learning potential.</div><div><a href='http://arxiv.org/abs/2403.01158v1'>2403.01158v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.15139v2")'>FDR-Controlled Portfolio Optimization for Sparse Financial Index
  Tracking</div>
<div id='2401.15139v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-26T18:29:30Z</div><div>Authors: Jasin Machkour, Daniel P. Palomar, Michael Muma</div><div style='padding-top: 10px; width: 80ex'>In high-dimensional data analysis, such as financial index tracking or
biomedical applications, it is crucial to select the few relevant variables
while maintaining control over the false discovery rate (FDR). In these
applications, strong dependencies often exist among the variables (e.g., stock
returns), which can undermine the FDR control property of existing methods like
the model-X knockoff method or the T-Rex selector. To address this issue, we
have expanded the T-Rex framework to accommodate overlapping groups of highly
correlated variables. This is achieved by integrating a nearest neighbors
penalization mechanism into the framework, which provably controls the FDR at
the user-defined target level. A real-world example of sparse index tracking
demonstrates the proposed method's ability to accurately track the S&amp;P 500
index over the past 20 years based on a small number of stocks. An open-source
implementation is provided within the R package TRexSelector on CRAN.</div><div><a href='http://arxiv.org/abs/2401.15139v2'>2401.15139v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16920v1")'>Sparse Portfolio Selection via Topological Data Analysis based
  Clustering</div>
<div id='2401.16920v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T11:42:52Z</div><div>Authors: Anubha Goel, Damir Filipović, Puneet Pasricha</div><div style='padding-top: 10px; width: 80ex'>This paper uses topological data analysis (TDA) tools and introduces a
data-driven clustering-based stock selection strategy tailored for sparse
portfolio construction. Our asset selection strategy exploits the topological
features of stock price movements to select a subset of topologically similar
(different) assets for a sparse index tracking (Markowitz) portfolio. We
introduce new distance measures, which serve as an input to the clustering
algorithm, on the space of persistence diagrams and landscapes that consider
the time component of a time series. We conduct an empirical analysis on the
S\&amp;P index from 2009 to 2020, including a study on the COVID-19 data to
validate the robustness of our methodology. Our strategy to integrate TDA with
the clustering algorithm significantly enhanced the performance of sparse
portfolios across various performance measures in diverse market scenarios.</div><div><a href='http://arxiv.org/abs/2401.16920v1'>2401.16920v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.08978v1")'>Prismatic: Interactive Multi-View Cluster Analysis of Concept Stocks</div>
<div id='2402.08978v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T06:47:30Z</div><div>Authors: Wong Kam-Kwai, Yan Luo, Xuanwu Yue, Wei Chen, Huamin Qu</div><div style='padding-top: 10px; width: 80ex'>Financial cluster analysis allows investors to discover investment
alternatives and avoid undertaking excessive risks. However, this analytical
task faces substantial challenges arising from many pairwise comparisons, the
dynamic correlations across time spans, and the ambiguity in deriving
implications from business relational knowledge. We propose Prismatic, a visual
analytics system that integrates quantitative analysis of historical
performance and qualitative analysis of business relational knowledge to
cluster correlated businesses interactively. Prismatic features three
clustering processes: dynamic cluster generation, knowledge-based cluster
exploration, and correlation-based cluster validation. Utilizing a multi-view
clustering approach, it enriches data-driven clusters with knowledge-driven
similarity, providing a nuanced understanding of business correlations. Through
well-coordinated visual views, Prismatic facilitates a comprehensive
interpretation of intertwined quantitative and qualitative features,
demonstrating its usefulness and effectiveness via case studies on formulating
concept stocks and extensive interviews with domain experts.</div><div><a href='http://arxiv.org/abs/2402.08978v1'>2402.08978v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.11066v1")'>Towards Financially Inclusive Credit Products Through Financial Time
  Series Clustering</div>
<div id='2402.11066v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-16T20:40:30Z</div><div>Authors: Tristan Bester, Benjamin Rosman</div><div style='padding-top: 10px; width: 80ex'>Financial inclusion ensures that individuals have access to financial
products and services that meet their needs. As a key contributing factor to
economic growth and investment opportunity, financial inclusion increases
consumer spending and consequently business development. It has been shown that
institutions are more profitable when they provide marginalised social groups
access to financial services. Customer segmentation based on consumer
transaction data is a well-known strategy used to promote financial inclusion.
While the required data is available to modern institutions, the challenge
remains that segment annotations are usually difficult and/or expensive to
obtain. This prevents the usage of time series classification models for
customer segmentation based on domain expert knowledge. As a result, clustering
is an attractive alternative to partition customers into homogeneous groups
based on the spending behaviour encoded within their transaction data. In this
paper, we present a solution to one of the key challenges preventing modern
financial institutions from providing financially inclusive credit, savings and
insurance products: the inability to understand consumer financial behaviour,
and hence risk, without the introduction of restrictive conventional credit
scoring techniques. We present a novel time series clustering algorithm that
allows institutions to understand the financial behaviour of their customers.
This enables unique product offerings to be provided based on the needs of the
customer, without reliance on restrictive credit practices.</div><div><a href='http://arxiv.org/abs/2402.11066v1'>2402.11066v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.07388v2")'>The Limits of Assumption-free Tests for Algorithm Performance</div>
<div id='2402.07388v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-12T03:19:30Z</div><div>Authors: Yuetian Luo, Rina Foygel Barber</div><div style='padding-top: 10px; width: 80ex'>Algorithm evaluation and comparison are fundamental questions in machine
learning and statistics -- how well does an algorithm perform at a given
modeling task, and which algorithm performs best? Many methods have been
developed to assess algorithm performance, often based around cross-validation
type strategies, retraining the algorithm of interest on different subsets of
the data and assessing its performance on the held-out data points. Despite the
broad use of such procedures, the theoretical properties of these methods are
not yet fully understood. In this work, we explore some fundamental limits for
answering these questions with limited amounts of data. In particular, we make
a distinction between two questions: how good is an algorithm $A$ at the
problem of learning from a training set of size $n$, versus, how good is a
particular fitted model produced by running $A$ on a particular training data
set of size $n$?
  Our main results prove that, for any test that treats the algorithm $A$ as a
``black box'' (i.e., we can only study the behavior of $A$ empirically), there
is a fundamental limit on our ability to carry out inference on the performance
of $A$, unless the number of available data points $N$ is many times larger
than the sample size $n$ of interest. (On the other hand, evaluating the
performance of a particular fitted model is easy as long as a holdout data set
is available -- that is, as long as $N-n$ is not too small.) We also ask
whether an assumption of algorithmic stability might be sufficient to
circumvent this hardness result. Surprisingly, we find that this is not the
case: the same hardness result still holds for the problem of evaluating the
performance of $A$, aside from a high-stability regime where fitted models are
essentially nonrandom. Finally, we also establish similar hardness results for
the problem of comparing multiple algorithms.</div><div><a href='http://arxiv.org/abs/2402.07388v2'>2402.07388v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.16793v1")'>Failures and Successes of Cross-Validation for Early-Stopped Gradient
  Descent</div>
<div id='2402.16793v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T18:07:27Z</div><div>Authors: Pratik Patil, Yuchen Wu, Ryan J. Tibshirani</div><div style='padding-top: 10px; width: 80ex'>We analyze the statistical properties of generalized cross-validation (GCV)
and leave-one-out cross-validation (LOOCV) applied to early-stopped gradient
descent (GD) in high-dimensional least squares regression. We prove that GCV is
generically inconsistent as an estimator of the prediction risk of
early-stopped GD, even for a well-specified linear model with isotropic
features. In contrast, we show that LOOCV converges uniformly along the GD
trajectory to the prediction risk. Our theory requires only mild assumptions on
the data distribution and does not require the underlying regression function
to be linear. Furthermore, by leveraging the individual LOOCV errors, we
construct consistent estimators for the entire prediction error distribution
along the GD trajectory and consistent estimators for a wide class of error
functionals. This in particular enables the construction of pathwise prediction
intervals based on GD iterates that have asymptotically correct nominal
coverage conditional on the training data.</div><div><a href='http://arxiv.org/abs/2402.16793v1'>2402.16793v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00857v1")'>Early Time Classification with Accumulated Accuracy Gap Control</div>
<div id='2402.00857v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T18:54:34Z</div><div>Authors: Liran Ringel, Regev Cohen, Daniel Freedman, Michael Elad, Yaniv Romano</div><div style='padding-top: 10px; width: 80ex'>Early time classification algorithms aim to label a stream of features
without processing the full input stream, while maintaining accuracy comparable
to that achieved by applying the classifier to the entire input. In this paper,
we introduce a statistical framework that can be applied to any sequential
classifier, formulating a calibrated stopping rule. This data-driven rule
attains finite-sample, distribution-free control of the accuracy gap between
full and early-time classification. We start by presenting a novel method that
builds on the Learn-then-Test calibration framework to control this gap
marginally, on average over i.i.d. instances. As this algorithm tends to yield
an excessively high accuracy gap for early halt times, our main contribution is
the proposal of a framework that controls a stronger notion of error, where the
accuracy gap is controlled conditionally on the accumulated halt times.
Numerical experiments demonstrate the effectiveness, applicability, and
usefulness of our method. We show that our proposed early stopping mechanism
reduces up to 94% of timesteps used for classification while achieving rigorous
accuracy gap control.</div><div><a href='http://arxiv.org/abs/2402.00857v1'>2402.00857v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.13187v1")'>Testing Calibration in Subquadratic Time</div>
<div id='2402.13187v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T17:53:24Z</div><div>Authors: Lunjia Hu, Kevin Tian, Chutong Yang</div><div style='padding-top: 10px; width: 80ex'>In the recent literature on machine learning and decision making, calibration
has emerged as a desirable and widely-studied statistical property of the
outputs of binary prediction models. However, the algorithmic aspects of
measuring model calibration have remained relatively less well-explored.
Motivated by [BGHN23], which proposed a rigorous framework for measuring
distances to calibration, we initiate the algorithmic study of calibration
through the lens of property testing. We define the problem of calibration
testing from samples where given $n$ draws from a distribution $\mathcal{D}$ on
(predictions, binary outcomes), our goal is to distinguish between the case
where $\mathcal{D}$ is perfectly calibrated, and the case where $\mathcal{D}$
is $\varepsilon$-far from calibration.
  We design an algorithm based on approximate linear programming, which solves
calibration testing information-theoretically optimally (up to constant
factors) in time $O(n^{1.5} \log(n))$. This improves upon state-of-the-art
black-box linear program solvers requiring $\Omega(n^\omega)$ time, where
$\omega &gt; 2$ is the exponent of matrix multiplication. We also develop
algorithms for tolerant variants of our testing problem, and give sample
complexity lower bounds for alternative calibration distances to the one
considered in this work. Finally, we present preliminary experiments showing
that the testing problem we define faithfully captures standard notions of
calibration, and that our algorithms scale to accommodate moderate sample
sizes.</div><div><a href='http://arxiv.org/abs/2402.13187v1'>2402.13187v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.14645v1")'>Omnipredictors for Regression and the Approximate Rank of Convex
  Functions</div>
<div id='2401.14645v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-26T04:29:53Z</div><div>Authors: Parikshit Gopalan, Princewill Okoroafor, Prasad Raghavendra, Abhishek Shetty, Mihir Singhal</div><div style='padding-top: 10px; width: 80ex'>Consider the supervised learning setting where the goal is to learn to
predict labels $\mathbf y$ given points $\mathbf x$ from a distribution. An
\textit{omnipredictor} for a class $\mathcal L$ of loss functions and a class
$\mathcal C$ of hypotheses is a predictor whose predictions incur less expected
loss than the best hypothesis in $\mathcal C$ for every loss in $\mathcal L$.
Since the work of [GKR+21] that introduced the notion, there has been a large
body of work in the setting of binary labels where $\mathbf y \in \{0, 1\}$,
but much less is known about the regression setting where $\mathbf y \in [0,1]$
can be continuous. Our main conceptual contribution is the notion of
\textit{sufficient statistics} for loss minimization over a family of loss
functions: these are a set of statistics about a distribution such that knowing
them allows one to take actions that minimize the expected loss for any loss in
the family. The notion of sufficient statistics relates directly to the
approximate rank of the family of loss functions.
  Our key technical contribution is a bound of $O(1/\varepsilon^{2/3})$ on the
$\epsilon$-approximate rank of convex, Lipschitz functions on the interval
$[0,1]$, which we show is tight up to a factor of $\mathrm{polylog}
(1/\epsilon)$. This yields improved runtimes for learning omnipredictors for
the class of all convex, Lipschitz loss functions under weak learnability
assumptions about the class $\mathcal C$. We also give efficient omnipredictors
when the loss families have low-degree polynomial approximations, or arise from
generalized linear models (GLMs). This translation from sufficient statistics
to faster omnipredictors is made possible by lifting the technique of loss
outcome indistinguishability introduced by [GKH+23] for Boolean labels to the
regression setting.</div><div><a href='http://arxiv.org/abs/2401.14645v1'>2401.14645v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.08508v1")'>A PAC-Bayesian Link Between Generalisation and Flat Minima</div>
<div id='2402.08508v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T15:03:02Z</div><div>Authors: Maxime Haddouche, Paul Viallard, Umut Simsekli, Benjamin Guedj</div><div style='padding-top: 10px; width: 80ex'>Modern machine learning usually involves predictors in the overparametrised
setting (number of trained parameters greater than dataset size), and their
training yield not only good performances on training data, but also good
generalisation capacity. This phenomenon challenges many theoretical results,
and remains an open problem. To reach a better understanding, we provide novel
generalisation bounds involving gradient terms. To do so, we combine the
PAC-Bayes toolbox with Poincar\'e and Log-Sobolev inequalities, avoiding an
explicit dependency on dimension of the predictor space. Our results highlight
the positive influence of \emph{flat minima} (being minima with a neighbourhood
nearly minimising the learning problem as well) on generalisation performances,
involving directly the benefits of the optimisation phase.</div><div><a href='http://arxiv.org/abs/2402.08508v1'>2402.08508v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.00680v1")'>Scalable Learning of Item Response Theory Models</div>
<div id='2403.00680v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-01T17:12:53Z</div><div>Authors: Susanne Frick, Amer Krivošija, Alexander Munteanu</div><div style='padding-top: 10px; width: 80ex'>Item Response Theory (IRT) models aim to assess latent abilities of $n$
examinees along with latent difficulty characteristics of $m$ test items from
categorical data that indicates the quality of their corresponding answers.
Classical psychometric assessments are based on a relatively small number of
examinees and items, say a class of $200$ students solving an exam comprising
$10$ problems. More recent global large scale assessments such as PISA, or
internet studies, may lead to significantly increased numbers of participants.
Additionally, in the context of Machine Learning where algorithms take the role
of examinees and data analysis problems take the role of items, both $n$ and
$m$ may become very large, challenging the efficiency and scalability of
computations. To learn the latent variables in IRT models from large data, we
leverage the similarity of these models to logistic regression, which can be
approximated accurately using small weighted subsets called coresets. We
develop coresets for their use in alternating IRT training algorithms,
facilitating scalable learning from large data.</div><div><a href='http://arxiv.org/abs/2403.00680v1'>2403.00680v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.08202v1")'>Confronting Discrimination in Classification: Smote Based on
  Marginalized Minorities in the Kernel Space for Imbalanced Data</div>
<div id='2402.08202v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T04:03:09Z</div><div>Authors: Lingyun Zhong</div><div style='padding-top: 10px; width: 80ex'>Financial fraud detection poses a typical challenge characterized by class
imbalance, where instances of fraud are extremely rare but can lead to
unpredictable economic losses if misidentified. Precisely classifying these
critical minority samples represents a challenging task within the
classification. The primary difficulty arises from mainstream classifiers,
which often exhibit "implicit discrimination" against minority samples in
evaluation metrics, which results in frequent misclassifications, and the key
to the problem lies in the overlap of feature spaces between majority and
minority samples. To address these challenges, oversampling is a feasible
solution, yet current classical oversampling methods often lack the necessary
caution in sample selection, exacerbating feature space overlap. In response,
we propose a novel classification oversampling approach based on the decision
boundary and sample proximity relationships. This method carefully considers
the distance between critical samples and the decision hyperplane, as well as
the density of surrounding samples, resulting in an adaptive oversampling
strategy in the kernel space. Finally, we test the proposed method on a classic
financial fraud dataset, and the results show that our proposed method provides
an effective and robust solution that can improve the classification accuracy
of minorities.</div><div><a href='http://arxiv.org/abs/2402.08202v1'>2402.08202v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00201v1")'>An Experiment on Feature Selection using Logistic Regression</div>
<div id='2402.00201v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-31T21:54:13Z</div><div>Authors: Raisa Islam, Subhasish Mazumdar, Rakibul Islam</div><div style='padding-top: 10px; width: 80ex'>In supervised machine learning, feature selection plays a very important role
by potentially enhancing explainability and performance as measured by
computing time and accuracy-related metrics. In this paper, we investigate a
method for feature selection based on the well-known L1 and L2 regularization
strategies associated with logistic regression (LR). It is well known that the
learned coefficients, which serve as weights, can be used to rank the features.
Our approach is to synthesize the findings of L1 and L2 regularization. For our
experiment, we chose the CIC-IDS2018 dataset owing partly to its size and also
to the existence of two problematic classes that are hard to separate. We
report first with the exclusion of one of them and then with its inclusion. We
ranked features first with L1 and then with L2, and then compared logistic
regression with L1 (LR+L1) against that with L2 (LR+L2) by varying the sizes of
the feature sets for each of the two rankings. We found no significant
difference in accuracy between the two methods once the feature set is
selected. We chose a synthesis, i.e., only those features that were present in
both the sets obtained from L1 and that from L2, and experimented with it on
more complex models like Decision Tree and Random Forest and observed that the
accuracy was very close in spite of the small size of the feature set.
Additionally, we also report on the standard metrics: accuracy, precision,
recall, and f1-score.</div><div><a href='http://arxiv.org/abs/2402.00201v1'>2402.00201v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.12683v1")'>LLpowershap: Logistic Loss-based Automated Shapley Values Feature
  Selection Method</div>
<div id='2401.12683v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-23T11:46:52Z</div><div>Authors: Iqbal Madakkatel, Elina Hyppönen</div><div style='padding-top: 10px; width: 80ex'>Shapley values have been used extensively in machine learning, not only to
explain black box machine learning models, but among other tasks, also to
conduct model debugging, sensitivity and fairness analyses and to select
important features for robust modelling and for further follow-up analyses.
Shapley values satisfy certain axioms that promote fairness in distributing
contributions of features toward prediction or reducing error, after accounting
for non-linear relationships and interactions when complex machine learning
models are employed. Recently, a number of feature selection methods utilising
Shapley values have been introduced. Here, we present a novel feature selection
method, LLpowershap, which makes use of loss-based Shapley values to identify
informative features with minimal noise among the selected sets of features.
Our simulation results show that LLpowershap not only identifies higher number
of informative features but outputs fewer noise features compared to other
state-of-the-art feature selection methods. Benchmarking results on four
real-world datasets demonstrate higher or at par predictive performance of
LLpowershap compared to other Shapley based wrapper methods, or filter methods.</div><div><a href='http://arxiv.org/abs/2401.12683v1'>2401.12683v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.11250v1")'>AFS-BM: Enhancing Model Performance through Adaptive Feature Selection
  with Binary Masking</div>
<div id='2401.11250v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-20T15:09:41Z</div><div>Authors: Mehmet Y. Turali, Mehmet E. Lorasdagi, Ali T. Koc, Suleyman S. Kozat</div><div style='padding-top: 10px; width: 80ex'>We study the problem of feature selection in general machine learning (ML)
context, which is one of the most critical subjects in the field. Although,
there exist many feature selection methods, however, these methods face
challenges such as scalability, managing high-dimensional data, dealing with
correlated features, adapting to variable feature importance, and integrating
domain knowledge. To this end, we introduce the ``Adaptive Feature Selection
with Binary Masking" (AFS-BM) which remedies these problems. AFS-BM achieves
this by joint optimization for simultaneous feature selection and model
training. In particular, we do the joint optimization and binary masking to
continuously adapt the set of features and model parameters during the training
process. This approach leads to significant improvements in model accuracy and
a reduction in computational requirements. We provide an extensive set of
experiments where we compare AFS-BM with the established feature selection
methods using well-known datasets from real-life competitions. Our results show
that AFS-BM makes significant improvement in terms of accuracy and requires
significantly less computational complexity. This is due to AFS-BM's ability to
dynamically adjust to the changing importance of features during the training
process, which an important contribution to the field. We openly share our code
for the replicability of our results and to facilitate further research.</div><div><a href='http://arxiv.org/abs/2401.11250v1'>2401.11250v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.12644v1")'>Binary Feature Mask Optimization for Feature Selection</div>
<div id='2401.12644v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-23T10:54:13Z</div><div>Authors: Mehmet E. Lorasdagi, Mehmet Y. Turali, Ali T. Koc, Suleyman S. Kozat</div><div style='padding-top: 10px; width: 80ex'>We investigate feature selection problem for generic machine learning (ML)
models. We introduce a novel framework that selects features considering the
predictions of the model. Our framework innovates by using a novel feature
masking approach to eliminate the features during the selection process,
instead of completely removing them from the dataset. This allows us to use the
same ML model during feature selection, unlike other feature selection methods
where we need to train the ML model again as the dataset has different
dimensions on each iteration. We obtain the mask operator using the predictions
of the ML model, which offers a comprehensive view on the subsets of the
features essential for the predictive performance of the model. A variety of
approaches exist in the feature selection literature. However, no study has
introduced a training-free framework for a generic ML model to select features
while considering the importance of the feature subsets as a whole, instead of
focusing on the individual features. We demonstrate significant performance
improvements on the real-life datasets under different settings using LightGBM
and Multi-Layer Perceptron as our ML models. Additionally, we openly share the
implementation code for our methods to encourage the research and the
contributions in this area.</div><div><a href='http://arxiv.org/abs/2401.12644v1'>2401.12644v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.07482v1")'>A Contrast Based Feature Selection Algorithm for High-dimensional Data
  set in Machine Learning</div>
<div id='2401.07482v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T05:32:35Z</div><div>Authors: Chunxu Cao, Qiang Zhang</div><div style='padding-top: 10px; width: 80ex'>Feature selection is an important process in machine learning and knowledge
discovery. By selecting the most informative features and eliminating
irrelevant ones, the performance of learning algorithms can be improved and the
extraction of meaningful patterns and insights from data can be facilitated.
However, most existing feature selection methods, when applied to large
datasets, encountered the bottleneck of high computation costs. To address this
problem, we propose a novel filter feature selection method, ContrastFS, which
selects discriminative features based on the discrepancies features shown
between different classes. We introduce a dimensionless quantity as a surrogate
representation to summarize the distributional individuality of certain
classes, based on this quantity we evaluate features and study the correlation
among them. We validate effectiveness and efficiency of our approach on several
widely studied benchmark datasets, results show that the new method performs
favorably with negligible computation in comparison with other state-of-the-art
feature selection methods.</div><div><a href='http://arxiv.org/abs/2401.07482v1'>2401.07482v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.07488v1")'>Feature Selection via Maximizing Distances between Class Conditional
  Distributions</div>
<div id='2401.07488v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T06:10:10Z</div><div>Authors: Chunxu Cao, Qiang Zhang</div><div style='padding-top: 10px; width: 80ex'>For many data-intensive tasks, feature selection is an important
preprocessing step. However, most existing methods do not directly and
intuitively explore the intrinsic discriminative information of features. We
propose a novel feature selection framework based on the distance between class
conditional distributions, measured by integral probability metrics (IPMs). Our
framework directly explores the discriminative information of features in the
sense of distributions for supervised classification. We analyze the
theoretical and practical aspects of IPMs for feature selection, construct
criteria based on IPMs. We propose several variant feature selection methods of
our framework based on the 1-Wasserstein distance and implement them on real
datasets from different domains. Experimental results show that our framework
can outperform state-of-the-art methods in terms of classification accuracy and
robustness to perturbations.</div><div><a href='http://arxiv.org/abs/2401.07488v1'>2401.07488v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.07540v1")'>Study Features via Exploring Distribution Structure</div>
<div id='2401.07540v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T09:01:31Z</div><div>Authors: Chunxu Cao, Qiang Zhang</div><div style='padding-top: 10px; width: 80ex'>In this paper, we present a novel framework for data redundancy measurement
based on probabilistic modeling of datasets, and a new criterion for redundancy
detection that is resilient to noise. We also develop new methods for data
redundancy reduction using both deterministic and stochastic optimization
techniques. Our framework is flexible and can handle different types of
features, and our experiments on benchmark datasets demonstrate the
effectiveness of our methods. We provide a new perspective on feature
selection, and propose effective and robust approaches for both supervised and
unsupervised learning problems.</div><div><a href='http://arxiv.org/abs/2401.07540v1'>2401.07540v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12008v1")'>Cluster Metric Sensitivity to Irrelevant Features</div>
<div id='2402.12008v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-19T10:02:00Z</div><div>Authors: Miles McCrory, Spencer A. Thomas</div><div style='padding-top: 10px; width: 80ex'>Clustering algorithms are used extensively in data analysis for data
exploration and discovery. Technological advancements lead to continually
growth of data in terms of volume, dimensionality and complexity. This provides
great opportunities in data analytics as the data can be interrogated for many
different purposes. This however leads challenges, such as identification of
relevant features for a given task. In supervised tasks, one can utilise a
number of methods to optimise the input features for the task objective (e.g.
classification accuracy). In unsupervised problems, such tools are not readily
available, in part due to an inability to quantify feature relevance in
unlabeled tasks. In this paper, we investigate the sensitivity of clustering
performance noisy uncorrelated variables iteratively added to baseline datasets
with well defined clusters. We show how different types of irrelevant variables
can impact the outcome of a clustering result from $k$-means in different ways.
We observe a resilience to very high proportions of irrelevant features for
adjusted rand index (ARI) and normalised mutual information (NMI) when the
irrelevant features are Gaussian distributed. For Uniformly distributed
irrelevant features, we notice the resilience of ARI and NMI is dependent on
the dimensionality of the data and exhibits tipping points between high scores
and near zero. Our results show that the Silhouette Coefficient and the
Davies-Bouldin score are the most sensitive to irrelevant added features
exhibiting large changes in score for comparably low proportions of irrelevant
features regardless of underlying distribution or data scaling. As such the
Silhouette Coefficient and the Davies-Bouldin score are good candidates for
optimising feature selection in unsupervised clustering tasks.</div><div><a href='http://arxiv.org/abs/2402.12008v1'>2402.12008v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.05954v1")'>EasyFS: an Efficient Model-free Feature Selection Framework via Elastic
  Transformation of Features</div>
<div id='2402.05954v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-04T09:25:07Z</div><div>Authors: Jianming Lv, Sijun Xia, Depin Liang, Wei Chen</div><div style='padding-top: 10px; width: 80ex'>Traditional model-free feature selection methods treat each feature
independently while disregarding the interrelationships among features, which
leads to relatively poor performance compared with the model-aware methods. To
address this challenge, we propose an efficient model-free feature selection
framework via elastic expansion and compression of the features, namely EasyFS,
to achieve better performance than state-of-the-art model-aware methods while
sharing the characters of efficiency and flexibility with the existing
model-free methods. In particular, EasyFS expands the feature space by using
the random non-linear projection network to achieve the non-linear combinations
of the original features, so as to model the interrelationships among the
features and discover most correlated features. Meanwhile, a novel redundancy
measurement based on the change of coding rate is proposed for efficient
filtering of redundant features. Comprehensive experiments on 21 different
datasets show that EasyFS outperforms state-of-the art methods up to 10.9\% in
the regression tasks and 5.7\% in the classification tasks while saving more
than 94\% of the time.</div><div><a href='http://arxiv.org/abs/2402.05954v1'>2402.05954v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12616v1")'>Multi-objective Binary Coordinate Search for Feature Selection</div>
<div id='2402.12616v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T00:50:26Z</div><div>Authors: Sevil Zanjani Miyandoab, Shahryar Rahnamayan, Azam Asilian Bidgoli</div><div style='padding-top: 10px; width: 80ex'>A supervised feature selection method selects an appropriate but concise set
of features to differentiate classes, which is highly expensive for large-scale
datasets. Therefore, feature selection should aim at both minimizing the number
of selected features and maximizing the accuracy of classification, or any
other task. However, this crucial task is computationally highly demanding on
many real-world datasets and requires a very efficient algorithm to reach a set
of optimal features with a limited number of fitness evaluations. For this
purpose, we have proposed the binary multi-objective coordinate search (MOCS)
algorithm to solve large-scale feature selection problems. To the best of our
knowledge, the proposed algorithm in this paper is the first multi-objective
coordinate search algorithm. In this method, we generate new individuals by
flipping a variable of the candidate solutions on the Pareto front. This
enables us to investigate the effectiveness of each feature in the
corresponding subset. In fact, this strategy can play the role of crossover and
mutation operators to generate distinct subsets of features. The reported
results indicate the significant superiority of our method over NSGA-II, on
five real-world large-scale datasets, particularly when the computing budget is
limited. Moreover, this simple hyper-parameter-free algorithm can solve feature
selection much faster and more efficiently than NSGA-II.</div><div><a href='http://arxiv.org/abs/2402.12616v1'>2402.12616v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12625v1")'>Compact NSGA-II for Multi-objective Feature Selection</div>
<div id='2402.12625v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T01:10:12Z</div><div>Authors: Sevil Zanjani Miyandoab, Shahryar Rahnamayan, Azam Asilian Bidgoli</div><div style='padding-top: 10px; width: 80ex'>Feature selection is an expensive challenging task in machine learning and
data mining aimed at removing irrelevant and redundant features. This
contributes to an improvement in classification accuracy, as well as the budget
and memory requirements for classification, or any other post-processing task
conducted after feature selection. In this regard, we define feature selection
as a multi-objective binary optimization task with the objectives of maximizing
classification accuracy and minimizing the number of selected features. In
order to select optimal features, we have proposed a binary Compact NSGA-II
(CNSGA-II) algorithm. Compactness represents the population as a probability
distribution to enhance evolutionary algorithms not only to be more
memory-efficient but also to reduce the number of fitness evaluations. Instead
of holding two populations during the optimization process, our proposed method
uses several Probability Vectors (PVs) to generate new individuals. Each PV
efficiently explores a region of the search space to find non-dominated
solutions instead of generating candidate solutions from a small population as
is the common approach in most evolutionary algorithms. To the best of our
knowledge, this is the first compact multi-objective algorithm proposed for
feature selection. The reported results for expensive optimization cases with a
limited budget on five datasets show that the CNSGA-II performs more
efficiently than the well-known NSGA-II method in terms of the hypervolume (HV)
performance metric requiring less memory. The proposed method and experimental
results are explained and analyzed in detail.</div><div><a href='http://arxiv.org/abs/2402.12625v1'>2402.12625v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.08982v1")'>MEL: Efficient Multi-Task Evolutionary Learning for High-Dimensional
  Feature Selection</div>
<div id='2402.08982v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T06:51:49Z</div><div>Authors: Xubin Wang, Haojiong Shangguan, Fengyi Huang, Shangrui Wu, Weijia Jia</div><div style='padding-top: 10px; width: 80ex'>Feature selection is a crucial step in data mining to enhance model
performance by reducing data dimensionality. However, the increasing
dimensionality of collected data exacerbates the challenge known as the "curse
of dimensionality", where computation grows exponentially with the number of
dimensions. To tackle this issue, evolutionary computational (EC) approaches
have gained popularity due to their simplicity and applicability.
Unfortunately, the diverse designs of EC methods result in varying abilities to
handle different data, often underutilizing and not sharing information
effectively. In this paper, we propose a novel approach called PSO-based
Multi-task Evolutionary Learning (MEL) that leverages multi-task learning to
address these challenges. By incorporating information sharing between
different feature selection tasks, MEL achieves enhanced learning ability and
efficiency. We evaluate the effectiveness of MEL through extensive experiments
on 22 high-dimensional datasets. Comparing against 24 EC approaches, our method
exhibits strong competitiveness. Additionally, we have open-sourced our code on
GitHub at https://github.com/wangxb96/MEL.</div><div><a href='http://arxiv.org/abs/2402.08982v1'>2402.08982v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.06251v1")'>Semantic-Preserving Feature Partitioning for Multi-View Ensemble
  Learning</div>
<div id='2401.06251v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-11T20:44:45Z</div><div>Authors: Mohammad Sadegh Khorshidi, Navid Yazdanjue, Hassan Gharoun, Danial Yazdani, Mohammad Reza Nikoo, Fang Chen, Amir H. Gandomi</div><div style='padding-top: 10px; width: 80ex'>In machine learning, the exponential growth of data and the associated
``curse of dimensionality'' pose significant challenges, particularly with
expansive yet sparse datasets. Addressing these challenges, multi-view ensemble
learning (MEL) has emerged as a transformative approach, with feature
partitioning (FP) playing a pivotal role in constructing artificial views for
MEL. Our study introduces the Semantic-Preserving Feature Partitioning (SPFP)
algorithm, a novel method grounded in information theory. The SPFP algorithm
effectively partitions datasets into multiple semantically consistent views,
enhancing the MEL process. Through extensive experiments on eight real-world
datasets, ranging from high-dimensional with limited instances to
low-dimensional with high instances, our method demonstrates notable efficacy.
It maintains model accuracy while significantly improving uncertainty measures
in scenarios where high generalization performance is achievable. Conversely,
it retains uncertainty metrics while enhancing accuracy where high
generalization accuracy is less attainable. An effect size analysis further
reveals that the SPFP algorithm outperforms benchmark models by large effect
size and reduces computational demands through effective dimensionality
reduction. The substantial effect sizes observed in most experiments underscore
the algorithm's significant improvements in model performance.</div><div><a href='http://arxiv.org/abs/2401.06251v1'>2401.06251v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.10549v1")'>Unified View Imputation and Feature Selection Learning for Incomplete
  Multi-view Data</div>
<div id='2401.10549v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-19T08:26:44Z</div><div>Authors: Yanyong Huang, Zongxin Shen, Tianrui Li, Fengmao Lv</div><div style='padding-top: 10px; width: 80ex'>Although multi-view unsupervised feature selection (MUFS) is an effective
technology for reducing dimensionality in machine learning, existing methods
cannot directly deal with incomplete multi-view data where some samples are
missing in certain views. These methods should first apply predetermined values
to impute missing data, then perform feature selection on the complete dataset.
Separating imputation and feature selection processes fails to capitalize on
the potential synergy where local structural information gleaned from feature
selection could guide the imputation, thereby improving the feature selection
performance in turn. Additionally, previous methods only focus on leveraging
samples' local structure information, while ignoring the intrinsic locality of
the feature space. To tackle these problems, a novel MUFS method, called
UNified view Imputation and Feature selectIon lEaRning (UNIFIER), is proposed.
UNIFIER explores the local structure of multi-view data by adaptively learning
similarity-induced graphs from both the sample and feature spaces. Then,
UNIFIER dynamically recovers the missing views, guided by the sample and
feature similarity graphs during the feature selection procedure. Furthermore,
the half-quadratic minimization technique is used to automatically weight
different instances, alleviating the impact of outliers and unreliable restored
data. Comprehensive experimental results demonstrate that UNIFIER outperforms
other state-of-the-art methods.</div><div><a href='http://arxiv.org/abs/2401.10549v1'>2401.10549v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15691v1")'>One for all: A novel Dual-space Co-training baseline for Large-scale
  Multi-View Clustering</div>
<div id='2401.15691v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-28T16:30:13Z</div><div>Authors: Zisen Kong, Zhiqiang Fu, Dongxia Chang, Yiming Wang, Yao Zhao</div><div style='padding-top: 10px; width: 80ex'>In this paper, we propose a novel multi-view clustering model, named
Dual-space Co-training Large-scale Multi-view Clustering (DSCMC). The main
objective of our approach is to enhance the clustering performance by
leveraging co-training in two distinct spaces. In the original space, we learn
a projection matrix to obtain latent consistent anchor graphs from different
views. This process involves capturing the inherent relationships and
structures between data points within each view. Concurrently, we employ a
feature transformation matrix to map samples from various views to a shared
latent space. This transformation facilitates the alignment of information from
multiple views, enabling a comprehensive understanding of the underlying data
distribution. We jointly optimize the construction of the latent consistent
anchor graph and the feature transformation to generate a discriminative anchor
graph. This anchor graph effectively captures the essential characteristics of
the multi-view data and serves as a reliable basis for subsequent clustering
analysis. Moreover, the element-wise method is proposed to avoid the impact of
diverse information between different views. Our algorithm has an approximate
linear computational complexity, which guarantees its successful application on
large-scale datasets. Through experimental validation, we demonstrate that our
method significantly reduces computational complexity while yielding superior
clustering performance compared to existing approaches.</div><div><a href='http://arxiv.org/abs/2401.15691v1'>2401.15691v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.16383v1")'>Self Supervised Correlation-based Permutations for Multi-View Clustering</div>
<div id='2402.16383v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T08:08:30Z</div><div>Authors: Ran Eisenberg, Jonathan Svirsky, Ofir Lindenbaum</div><div style='padding-top: 10px; width: 80ex'>Fusing information from different modalities can enhance data analysis tasks,
including clustering. However, existing multi-view clustering (MVC) solutions
are limited to specific domains or rely on a suboptimal and computationally
demanding two-stage procedure of representation and clustering. We propose an
end-to-end deep learning-based MVC framework for general data (image, tabular,
etc.). Our approach involves learning meaningful fused data representations
with a novel permutation-based canonical correlation objective. Concurrently,
we learn cluster assignments by identifying consistent pseudo-labels across
multiple views. We demonstrate the effectiveness of our model using ten MVC
benchmark datasets. Theoretically, we show that our model approximates the
supervised linear discrimination analysis (LDA) representation. Additionally,
we provide an error bound induced by false-pseudo label annotations.</div><div><a href='http://arxiv.org/abs/2402.16383v1'>2402.16383v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.12648v3")'>Consistency Enhancement-Based Deep Multiview Clustering via Contrastive
  Learning</div>
<div id='2401.12648v3' style='display: none; margin-left: 20px'><div>Date: 2024-01-23T10:56:01Z</div><div>Authors: Hao Yang, Hua Mao, Wai Lok Woo, Jie Chen, Xi Peng</div><div style='padding-top: 10px; width: 80ex'>Multiview clustering (MVC) segregates data samples into meaningful clusters
by synthesizing information across multiple views. Moreover, deep
learning-based methods have demonstrated their strong feature learning
capabilities in MVC scenarios. However, effectively generalizing feature
representations while maintaining consistency is still an intractable problem.
In addition, most existing deep clustering methods based on contrastive
learning overlook the consistency of the clustering representations during the
clustering process. In this paper, we show how the above problems can be
overcome and propose a consistent enhancement-based deep MVC method via
contrastive learning (CCEC). Specifically, semantic connection blocks are
incorporated into a feature representation to preserve the consistent
information among multiple views. Furthermore, the representation process for
clustering is enhanced through spectral clustering, and the consistency across
multiple views is improved. Experiments conducted on five datasets demonstrate
the effectiveness and superiority of our method in comparison with the
state-of-the-art (SOTA) methods. The code for this method can be accessed at
https://anonymous.4open.science/r/CCEC-E84E/.</div><div><a href='http://arxiv.org/abs/2401.12648v3'>2401.12648v3</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00608v1")'>Deep Clustering Using the Soft Silhouette Score: Towards Compact and
  Well-Separated Clusters</div>
<div id='2402.00608v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T14:02:06Z</div><div>Authors: Georgios Vardakas, Ioannis Papakostas, Aristidis Likas</div><div style='padding-top: 10px; width: 80ex'>Unsupervised learning has gained prominence in the big data era, offering a
means to extract valuable insights from unlabeled datasets. Deep clustering has
emerged as an important unsupervised category, aiming to exploit the non-linear
mapping capabilities of neural networks in order to enhance clustering
performance. The majority of deep clustering literature focuses on minimizing
the inner-cluster variability in some embedded space while keeping the learned
representation consistent with the original high-dimensional dataset. In this
work, we propose soft silhoutte, a probabilistic formulation of the silhouette
coefficient. Soft silhouette rewards compact and distinctly separated
clustering solutions like the conventional silhouette coefficient. When
optimized within a deep clustering framework, soft silhouette guides the
learned representations towards forming compact and well-separated clusters. In
addition, we introduce an autoencoder-based deep learning architecture that is
suitable for optimizing the soft silhouette objective function. The proposed
deep clustering method has been tested and compared with several well-studied
deep clustering methods on various benchmark datasets, yielding very
satisfactory clustering results.</div><div><a href='http://arxiv.org/abs/2402.00608v1'>2402.00608v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.15989v1")'>Deep Embedding Clustering Driven by Sample Stability</div>
<div id='2401.15989v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T09:19:49Z</div><div>Authors: Zhanwen Cheng, Feijiang Li, Jieting Wang, Yuhua Qian</div><div style='padding-top: 10px; width: 80ex'>Deep clustering methods improve the performance of clustering tasks by
jointly optimizing deep representation learning and clustering. While numerous
deep clustering algorithms have been proposed, most of them rely on
artificially constructed pseudo targets for performing clustering. This
construction process requires some prior knowledge, and it is challenging to
determine a suitable pseudo target for clustering. To address this issue, we
propose a deep embedding clustering algorithm driven by sample stability
(DECS), which eliminates the requirement of pseudo targets. Specifically, we
start by constructing the initial feature space with an autoencoder and then
learn the cluster-oriented embedding feature constrained by sample stability.
The sample stability aims to explore the deterministic relationship between
samples and all cluster centroids, pulling samples to their respective clusters
and keeping them away from other clusters with high determinacy. We analyzed
the convergence of the loss using Lipschitz continuity in theory, which
verifies the validity of the model. The experimental results on five datasets
illustrate that the proposed method achieves superior performance compared to
state-of-the-art clustering approaches.</div><div><a href='http://arxiv.org/abs/2401.15989v1'>2401.15989v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.14830v1")'>Deep Clustering Evaluation: How to Validate Internal Clustering
  Validation Measures</div>
<div id='2403.14830v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-21T20:43:44Z</div><div>Authors: Zeya Wang, Chenglong Ye</div><div style='padding-top: 10px; width: 80ex'>Deep clustering, a method for partitioning complex, high-dimensional data
using deep neural networks, presents unique evaluation challenges. Traditional
clustering validation measures, designed for low-dimensional spaces, are
problematic for deep clustering, which involves projecting data into
lower-dimensional embeddings before partitioning. Two key issues are
identified: 1) the curse of dimensionality when applying these measures to raw
data, and 2) the unreliable comparison of clustering results across different
embedding spaces stemming from variations in training procedures and parameter
settings in different clustering models. This paper addresses these challenges
in evaluating clustering quality in deep learning. We present a theoretical
framework to highlight ineffectiveness arising from using internal validation
measures on raw and embedded data and propose a systematic approach to applying
clustering validity indices in deep clustering contexts. Experiments show that
this framework aligns better with external validation measures, effectively
reducing the misguidance from the improper use of clustering validity indices
in deep learning.</div><div><a href='http://arxiv.org/abs/2403.14830v1'>2403.14830v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.09167v1")'>Evolving Restricted Boltzmann Machine-Kohonen Network for Online
  Clustering</div>
<div id='2402.09167v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T13:36:20Z</div><div>Authors: J. Senthilnath, Adithya Bhattiprolu, Ankur Singh, Bangjian Zhou, Min Wu, Jón Atli Benediktsson, Xiaoli Li</div><div style='padding-top: 10px; width: 80ex'>A novel online clustering algorithm is presented where an Evolving Restricted
Boltzmann Machine (ERBM) is embedded with a Kohonen Network called ERBM-KNet.
The proposed ERBM-KNet efficiently handles streaming data in a single-pass mode
using the ERBM, employing a bias-variance strategy for neuron growing and
pruning, as well as online clustering based on a cluster update strategy for
cluster prediction and cluster center update using KNet. Initially, ERBM
evolves its architecture while processing unlabeled image data, effectively
disentangling the data distribution in the latent space. Subsequently, the KNet
utilizes the feature extracted from ERBM to predict the number of clusters and
updates the cluster centers. By overcoming the common challenges associated
with clustering algorithms, such as prior initialization of the number of
clusters and subpar clustering accuracy, the proposed ERBM-KNet offers
significant improvements. Extensive experimental evaluations on four benchmarks
and one industry dataset demonstrate the superiority of ERBM-KNet compared to
state-of-the-art approaches.</div><div><a href='http://arxiv.org/abs/2402.09167v1'>2402.09167v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.16544v1")'>Label Learning Method Based on Tensor Projection</div>
<div id='2402.16544v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T13:03:26Z</div><div>Authors: Jing Li, Quanxue Gao, Qianqian Wang, Cheng Deng, Deyan Xie</div><div style='padding-top: 10px; width: 80ex'>Multi-view clustering method based on anchor graph has been widely concerned
due to its high efficiency and effectiveness. In order to avoid
post-processing, most of the existing anchor graph-based methods learn
bipartite graphs with connected components. However, such methods have high
requirements on parameters, and in some cases it may not be possible to obtain
bipartite graphs with clear connected components. To end this, we propose a
label learning method based on tensor projection (LLMTP). Specifically, we
project anchor graph into the label space through an orthogonal projection
matrix to obtain cluster labels directly. Considering that the spatial
structure information of multi-view data may be ignored to a certain extent
when projected in different views separately, we extend the matrix projection
transformation to tensor projection, so that the spatial structure information
between views can be fully utilized. In addition, we introduce the tensor
Schatten $p$-norm regularization to make the clustering label matrices of
different views as consistent as possible. Extensive experiments have proved
the effectiveness of the proposed method.</div><div><a href='http://arxiv.org/abs/2402.16544v1'>2402.16544v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.09107v1")'>S^2MVTC: a Simple yet Efficient Scalable Multi-View Tensor Clustering</div>
<div id='2403.09107v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T05:00:29Z</div><div>Authors: Zhen Long, Qiyuan Wang, Yazhou Ren, Yipeng Liu, Ce Zhu</div><div style='padding-top: 10px; width: 80ex'>Anchor-based large-scale multi-view clustering has attracted considerable
attention for its effectiveness in handling massive datasets. However, current
methods mainly seek the consensus embedding feature for clustering by exploring
global correlations between anchor graphs or projection matrices.In this paper,
we propose a simple yet efficient scalable multi-view tensor clustering
(S^2MVTC) approach, where our focus is on learning correlations of embedding
features within and across views. Specifically, we first construct the
embedding feature tensor by stacking the embedding features of different views
into a tensor and rotating it. Additionally, we build a novel tensor
low-frequency approximation (TLFA) operator, which incorporates graph
similarity into embedding feature learning, efficiently achieving smooth
representation of embedding features within different views. Furthermore,
consensus constraints are applied to embedding features to ensure inter-view
semantic consistency. Experimental results on six large-scale multi-view
datasets demonstrate that S^2MVTC significantly outperforms state-of-the-art
algorithms in terms of clustering performance and CPU execution time,
especially when handling massive data. The code of S^2MVTC is publicly
available at https://github.com/longzhen520/S2MVTC.</div><div><a href='http://arxiv.org/abs/2403.09107v1'>2403.09107v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07189v1")'>Improving LSH via Tensorized Random Projection</div>
<div id='2402.07189v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-11T12:54:07Z</div><div>Authors: Bhisham Dev Verma, Rameshwar Pratap</div><div style='padding-top: 10px; width: 80ex'>Locality sensitive hashing (LSH) is a fundamental algorithmic toolkit used by
data scientists for approximate nearest neighbour search problems that have
been used extensively in many large scale data processing applications such as
near duplicate detection, nearest neighbour search, clustering, etc. In this
work, we aim to propose faster and space efficient locality sensitive hash
functions for Euclidean distance and cosine similarity for tensor data.
Typically, the naive approach for obtaining LSH for tensor data involves first
reshaping the tensor into vectors, followed by applying existing LSH methods
for vector data $E2LSH$ and $SRP$. However, this approach becomes impractical
for higher order tensors because the size of the reshaped vector becomes
exponential in the order of the tensor. Consequently, the size of LSH
parameters increases exponentially. To address this problem, we suggest two
methods for LSH for Euclidean distance and cosine similarity, namely
$CP-E2LSH$, $TT-E2LSH$, and $CP-SRP$, $TT-SRP$, respectively, building on $CP$
and tensor train $(TT)$ decompositions techniques. Our approaches are space
efficient and can be efficiently applied to low rank $CP$ or $TT$ tensors. We
provide a rigorous theoretical analysis of our proposal on their correctness
and efficacy.</div><div><a href='http://arxiv.org/abs/2402.07189v1'>2402.07189v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00943v1")'>Approximate Nearest Neighbor Search with Window Filters</div>
<div id='2402.00943v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T19:00:40Z</div><div>Authors: Joshua Engels, Benjamin Landrum, Shangdi Yu, Laxman Dhulipala, Julian Shun</div><div style='padding-top: 10px; width: 80ex'>We define and investigate the problem of $\textit{c-approximate window
search}$: approximate nearest neighbor search where each point in the dataset
has a numeric label, and the goal is to find nearest neighbors to queries
within arbitrary label ranges. Many semantic search problems, such as image and
document search with timestamp filters, or product search with cost filters,
are natural examples of this problem. We propose and theoretically analyze a
modular tree-based framework for transforming an index that solves the
traditional c-approximate nearest neighbor problem into a data structure that
solves window search. On standard nearest neighbor benchmark datasets equipped
with random label values, adversarially constructed embeddings, and image
search embeddings with real timestamps, we obtain up to a $75\times$ speedup
over existing solutions at the same level of recall.</div><div><a href='http://arxiv.org/abs/2402.00943v1'>2402.00943v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.07119v1")'>Curator: Efficient Indexing for Multi-Tenant Vector Databases</div>
<div id='2401.07119v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-13T17:08:09Z</div><div>Authors: Yicheng Jin, Yongji Wu, Wenjun Hu, Bruce M. Maggs, Xiao Zhang, Danyang Zhuo</div><div style='padding-top: 10px; width: 80ex'>Vector databases have emerged as key enablers for bridging intelligent
applications with unstructured data, providing generic search and management
support for embedding vectors extracted from the raw unstructured data. As
multiple data users can share the same database infrastructure, multi-tenancy
support for vector databases is increasingly desirable. This hinges on an
efficient filtered search operation, i.e., only querying the vectors accessible
to a particular tenant. Multi-tenancy in vector databases is currently achieved
by building either a single, shared index among all tenants, or a per-tenant
index. The former optimizes for memory efficiency at the expense of search
performance, while the latter does the opposite. Instead, this paper presents
Curator, an in-memory vector index design tailored for multi-tenant queries
that simultaneously achieves the two conflicting goals, low memory overhead and
high performance for queries, vector insertion, and deletion. Curator indexes
each tenant's vectors with a tenant-specific clustering tree and encodes these
trees compactly as sub-trees of a shared clustering tree. Each tenant's
clustering tree adapts dynamically to its unique vector distribution, while
maintaining a low per-tenant memory footprint. Our evaluation, based on two
widely used data sets, confirms that Curator delivers search performance on par
with per-tenant indexing, while maintaining memory consumption at the same
level as metadata filtering on a single, shared index.</div><div><a href='http://arxiv.org/abs/2401.07119v1'>2401.07119v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.15688v1")'>Anchor-free Clustering based on Anchor Graph Factorization</div>
<div id='2402.15688v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-24T02:16:42Z</div><div>Authors: Shikun Mei, Fangfang Li, Quanxue Gao, Ming Yang</div><div style='padding-top: 10px; width: 80ex'>Anchor-based methods are a pivotal approach in handling clustering of
large-scale data. However, these methods typically entail two distinct stages:
selecting anchor points and constructing an anchor graph. This bifurcation,
along with the initialization of anchor points, significantly influences the
overall performance of the algorithm. To mitigate these issues, we introduce a
novel method termed Anchor-free Clustering based on Anchor Graph Factorization
(AFCAGF). AFCAGF innovates in learning the anchor graph, requiring only the
computation of pairwise distances between samples. This process, achievable
through straightforward optimization, circumvents the necessity for explicit
selection of anchor points. More concretely, our approach enhances the Fuzzy
k-means clustering algorithm (FKM), introducing a new manifold learning
technique that obviates the need for initializing cluster centers.
Additionally, we evolve the concept of the membership matrix between cluster
centers and samples in FKM into an anchor graph encompassing multiple anchor
points and samples. Employing Non-negative Matrix Factorization (NMF) on this
anchor graph allows for the direct derivation of cluster labels, thereby
eliminating the requirement for further post-processing steps. To solve the
method proposed, we implement an alternating optimization algorithm that
ensures convergence. Empirical evaluations on various real-world datasets
underscore the superior efficacy of our algorithm compared to traditional
approaches.</div><div><a href='http://arxiv.org/abs/2402.15688v1'>2402.15688v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.08787v1")'>Multi-view Subspace Clustering via An Adaptive Consensus Graph Filter</div>
<div id='2403.08787v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T02:03:18Z</div><div>Authors: Lai Wei, Shanshan Song</div><div style='padding-top: 10px; width: 80ex'>Multiview subspace clustering (MVSC) has attracted an increasing amount of
attention in recent years. Most existing MVSC methods first collect
complementary information from different views and consequently derive a
consensus reconstruction coefficient matrix to indicate the subspace structure
of a multi-view data set. In this paper, we initially assume the existence of a
consensus reconstruction coefficient matrix and then use it to build a
consensus graph filter. In each view, the filter is employed for smoothing the
data and designing a regularizer for the reconstruction coefficient matrix.
Finally, the obtained reconstruction coefficient matrices from different views
are used to create constraints for the consensus reconstruction coefficient
matrix. Therefore, in the proposed method, the consensus reconstruction
coefficient matrix, the consensus graph filter, and the reconstruction
coefficient matrices from different views are interdependent. We provide an
optimization algorithm to obtain their optimal values. Extensive experiments on
diverse multi-view data sets demonstrate that our approach outperforms some
state-of-the-art methods.</div><div><a href='http://arxiv.org/abs/2403.08787v1'>2403.08787v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.07431v1")'>Knowledge Transfer across Multiple Principal Component Analysis Studies</div>
<div id='2403.07431v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T09:15:12Z</div><div>Authors: Zeyu Li, Kangxiang Qin, Yong He, Wang Zhou, Xinsheng Zhang</div><div style='padding-top: 10px; width: 80ex'>Transfer learning has aroused great interest in the statistical community. In
this article, we focus on knowledge transfer for unsupervised learning tasks in
contrast to the supervised learning tasks in the literature. Given the
transferable source populations, we propose a two-step transfer learning
algorithm to extract useful information from multiple source principal
component analysis (PCA) studies, thereby enhancing estimation accuracy for the
target PCA task. In the first step, we integrate the shared subspace
information across multiple studies by a proposed method named as Grassmannian
barycenter, instead of directly performing PCA on the pooled dataset. The
proposed Grassmannian barycenter method enjoys robustness and computational
advantages in more general cases. Then the resulting estimator for the shared
subspace from the first step is further utilized to estimate the target private
subspace in the second step. Our theoretical analysis credits the gain of
knowledge transfer between PCA studies to the enlarged eigenvalue gap, which is
different from the existing supervised transfer learning tasks where sparsity
plays the central role. In addition, we prove that the bilinear forms of the
empirical spectral projectors have asymptotic normality under weaker eigenvalue
gap conditions after knowledge transfer. When the set of informativesources is
unknown, we endow our algorithm with the capability of useful dataset selection
by solving a rectified optimization problem on the Grassmann manifold, which in
turn leads to a computationally friendly rectified Grassmannian K-means
procedure. In the end, extensive numerical simulation results and a real data
case concerning activity recognition are reported to support our theoretical
claims and to illustrate the empirical usefulness of the proposed transfer
learning methods.</div><div><a href='http://arxiv.org/abs/2403.07431v1'>2403.07431v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.16897v2")'>Reliable Conflictive Multi-View Learning</div>
<div id='2402.16897v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-24T03:47:06Z</div><div>Authors: Cai Xu, Jiajun Si, Ziyu Guan, Wei Zhao, Yue Wu, Xiyue Gao</div><div style='padding-top: 10px; width: 80ex'>Multi-view learning aims to combine multiple features to achieve more
comprehensive descriptions of data. Most previous works assume that multiple
views are strictly aligned. However, real-world multi-view data may contain
low-quality conflictive instances, which show conflictive information in
different views. Previous methods for this problem mainly focus on eliminating
the conflictive data instances by removing them or replacing conflictive views.
Nevertheless, real-world applications usually require making decisions for
conflictive instances rather than only eliminating them. To solve this, we
point out a new Reliable Conflictive Multi-view Learning (RCML) problem, which
requires the model to provide decision results and attached reliabilities for
conflictive multi-view data. We develop an Evidential Conflictive Multi-view
Learning (ECML) method for this problem. ECML first learns view-specific
evidence, which could be termed as the amount of support to each category
collected from data. Then, we can construct view-specific opinions consisting
of decision results and reliability. In the multi-view fusion stage, we propose
a conflictive opinion aggregation strategy and theoretically prove this
strategy can exactly model the relation of multi-view common and view-specific
reliabilities. Experiments performed on 6 datasets verify the effectiveness of
ECML.</div><div><a href='http://arxiv.org/abs/2402.16897v2'>2402.16897v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.16244v1")'>Employing Iterative Feature Selection in Fuzzy Rule-Based Binary
  Classification</div>
<div id='2401.16244v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-26T09:33:18Z</div><div>Authors: Haoning Li, Cong Wang, Qinghua Huang</div><div style='padding-top: 10px; width: 80ex'>The feature selection in a traditional binary classification algorithm is
always used in the stage of dataset preprocessing, which makes the obtained
features not necessarily the best ones for the classification algorithm, thus
affecting the classification performance. For a traditional rule-based binary
classification algorithm, classification rules are usually deterministic, which
results in the fuzzy information contained in the rules being ignored. To do
so, this paper employs iterative feature selection in fuzzy rule-based binary
classification. The proposed algorithm combines feature selection based on
fuzzy correlation family with rule mining based on biclustering. It first
conducts biclustering on the dataset after feature selection. Then it conducts
feature selection again for the biclusters according to the feedback of
biclusters evaluation. In this way, an iterative feature selection framework is
build. During the iteration process, it stops until the obtained bicluster
meets the requirements. In addition, the rule membership function is introduced
to extract vectorized fuzzy rules from the bicluster and construct weak
classifiers. The weak classifiers with good classification performance are
selected by Adaptive Boosting and the strong classifier is constructed by
"weighted average". Finally, we perform the proposed algorithm on different
datasets and compare it with other peers. Experimental results show that it
achieves good classification performance and outperforms its peers.</div><div><a href='http://arxiv.org/abs/2401.16244v1'>2401.16244v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.11843v1")'>Fuzzy Rough Choquet Distances for Classification</div>
<div id='2403.11843v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-18T14:53:48Z</div><div>Authors: Adnan Theerens, Chris Cornelis</div><div style='padding-top: 10px; width: 80ex'>This paper introduces a novel Choquet distance using fuzzy rough set based
measures. The proposed distance measure combines the attribute information
received from fuzzy rough set theory with the flexibility of the Choquet
integral. This approach is designed to adeptly capture non-linear relationships
within the data, acknowledging the interplay of the conditional attributes
towards the decision attribute and resulting in a more flexible and accurate
distance. We explore its application in the context of machine learning, with a
specific emphasis on distance-based classification approaches (e.g. k-nearest
neighbours). The paper examines two fuzzy rough set based measures that are
based on the positive region. Moreover, we explore two procedures for
monotonizing the measures derived from fuzzy rough set theory, making them
suitable for use with the Choquet integral, and investigate their differences.</div><div><a href='http://arxiv.org/abs/2403.11843v1'>2403.11843v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.05290v1")'>Foundational propositions of hesitant fuzzy soft $β$-covering
  approximation spaces</div>
<div id='2403.05290v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-08T13:16:17Z</div><div>Authors: Shizhan Lu</div><div style='padding-top: 10px; width: 80ex'>Soft set theory serves as a mathematical framework for handling uncertain
information, and hesitant fuzzy sets find extensive application in scenarios
involving uncertainty and hesitation. Hesitant fuzzy sets exhibit diverse
membership degrees, giving rise to various forms of inclusion relationships
among them. This article introduces the notions of hesitant fuzzy soft
$\beta$-coverings and hesitant fuzzy soft $\beta$-neighborhoods, which are
formulated based on distinct forms of inclusion relationships among hesitancy
fuzzy sets. Subsequently, several associated properties are investigated.
Additionally, specific variations of hesitant fuzzy soft $\beta$-coverings are
introduced by incorporating hesitant fuzzy rough sets, followed by an
exploration of properties pertaining to hesitant fuzzy soft $\beta$-covering
approximation spaces.</div><div><a href='http://arxiv.org/abs/2403.05290v1'>2403.05290v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.05979v1")'>Enhancing Classification Performance via Reinforcement Learning for
  Feature Selection</div>
<div id='2403.05979v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-09T18:34:59Z</div><div>Authors: Younes Ghazagh Jahed, Seyyed Ali Sadat Tavana</div><div style='padding-top: 10px; width: 80ex'>Feature selection plays a crucial role in improving predictive accuracy by
identifying relevant features while filtering out irrelevant ones. This study
investigates the importance of effective feature selection in enhancing the
performance of classification models. By employing reinforcement learning (RL)
algorithms, specifically Q-learning (QL) and SARSA learning, this paper
addresses the feature selection challenge. Using the Breast Cancer Coimbra
dataset (BCCDS) and three normalization methods (Min-Max, l1, and l2), the
study evaluates the performance of these algorithms. Results show that
QL@Min-Max and SARSA@l2 achieve the highest classification accuracies, reaching
87% and 88%, respectively. This highlights the effectiveness of RL-based
feature selection methods in optimizing classification tasks, contributing to
improved model accuracy and efficiency.</div><div><a href='http://arxiv.org/abs/2403.05979v1'>2403.05979v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04015v1")'>Knockoff-Guided Feature Selection via A Single Pre-trained Reinforced
  Agent</div>
<div id='2403.04015v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T19:58:19Z</div><div>Authors: Xinyuan Wang, Dongjie Wang, Wangyang Ying, Rui Xie, Haifeng Chen, Yanjie Fu</div><div style='padding-top: 10px; width: 80ex'>Feature selection prepares the AI-readiness of data by eliminating redundant
features. Prior research falls into two primary categories: i) Supervised
Feature Selection, which identifies the optimal feature subset based on their
relevance to the target variable; ii) Unsupervised Feature Selection, which
reduces the feature space dimensionality by capturing the essential information
within the feature set instead of using target variable. However, SFS
approaches suffer from time-consuming processes and limited generalizability
due to the dependence on the target variable and downstream ML tasks. UFS
methods are constrained by the deducted feature space is latent and
untraceable. To address these challenges, we introduce an innovative framework
for feature selection, which is guided by knockoff features and optimized
through reinforcement learning, to identify the optimal and effective feature
subset. In detail, our method involves generating "knockoff" features that
replicate the distribution and characteristics of the original features but are
independent of the target variable. Each feature is then assigned a pseudo
label based on its correlation with all the knockoff features, serving as a
novel metric for feature evaluation. Our approach utilizes these pseudo labels
to guide the feature selection process in 3 novel ways, optimized by a single
reinforced agent: 1). A deep Q-network, pre-trained with the original features
and their corresponding pseudo labels, is employed to improve the efficacy of
the exploration process in feature selection. 2). We introduce unsupervised
rewards to evaluate the feature subset quality based on the pseudo labels and
the feature space reconstruction loss to reduce dependencies on the target
variable. 3). A new {\epsilon}-greedy strategy is used, incorporating insights
from the pseudo labels to make the feature selection process more effective.</div><div><a href='http://arxiv.org/abs/2403.04015v1'>2403.04015v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03375v1")'>Complexity Matters: Dynamics of Feature Learning in the Presence of
  Spurious Correlations</div>
<div id='2403.03375v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-05T23:54:00Z</div><div>Authors: GuanWen Qiu, Da Kuang, Surbhi Goel</div><div style='padding-top: 10px; width: 80ex'>Existing research often posits spurious features as "easier" to learn than
core features in neural network optimization, but the impact of their relative
simplicity remains under-explored. Moreover they mainly focus on the end
performance intead of the learning dynamics of feature learning. In this paper,
we propose a theoretical framework and associated synthetic dataset grounded in
boolean function analysis which allows for fine-grained control on the relative
complexity (compared to core features) and correlation strength (with respect
to the label) of spurious features to study the dynamics of feature learning
under spurious correlation. Our setup uncovers several interesting phenomenon:
(1) stronger spurious correlations or simpler spurious features slow down the
rate of learning for the core features, (2) learning phases of spurious
features and core features are not always separable, (3) spurious features are
not forgotten even after core features are fully learned. We show that our
findings justify the success of retraining the last layer to remove spurious
correlation and also identifies limitations of popular debiasing algorithms
that exploit early learning of spurious features. We support our empirical
findings with theoretical analyses for the case of learning XOR features with a
one-hidden-layer ReLU network.</div><div><a href='http://arxiv.org/abs/2403.03375v1'>2403.03375v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.10270v1")'>Migrating Birds Optimization-Based Feature Selection for Text
  Classification</div>
<div id='2401.10270v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-04T08:11:03Z</div><div>Authors: Cem Kaya, Zeynep Hilal Kilimci, Mitat Uysal, Murat Kaya</div><div style='padding-top: 10px; width: 80ex'>This research introduces a novel approach, MBO-NB, that leverages Migrating
Birds Optimization (MBO) coupled with Naive Bayes as an internal classifier to
address feature selection challenges in text classification having large number
of features. Focusing on computational efficiency, we preprocess raw data using
the Information Gain algorithm, strategically reducing the feature count from
an average of 62221 to 2089. Our experiments demonstrate MBO-NB's superior
effectiveness in feature reduction compared to other existing techniques,
emphasizing an increased classification accuracy. The successful integration of
Naive Bayes within MBO presents a well-rounded solution. In individual
comparisons with Particle Swarm Optimization (PSO), MBO-NB consistently
outperforms by an average of 6.9% across four setups. This research offers
valuable insights into enhancing feature selection methods, providing a
scalable and effective solution for text classification</div><div><a href='http://arxiv.org/abs/2401.10270v1'>2401.10270v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.11839v1")'>An enhanced Teaching-Learning-Based Optimization (TLBO) with Grey Wolf
  Optimizer (GWO) for text feature selection and clustering</div>
<div id='2402.11839v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-19T05:06:10Z</div><div>Authors: Mahsa Azarshab, Mohammad Fathian, Babak Amiri</div><div style='padding-top: 10px; width: 80ex'>Text document clustering can play a vital role in organizing and handling the
everincreasing number of text documents. Uninformative and redundant features
included in large text documents reduce the effectiveness of the clustering
algorithm. Feature selection (FS) is a well-known technique for removing these
features. Since FS can be formulated as an optimization problem, various
meta-heuristic algorithms have been employed to solve it.
Teaching-Learning-Based Optimization (TLBO) is a novel meta-heuristic algorithm
that benefits from the low number of parameters and fast convergence. A hybrid
method can simultaneously benefit from the advantages of TLBO and tackle the
possible entrapment in the local optimum. By proposing a hybrid of TLBO, Grey
Wolf Optimizer (GWO), and Genetic Algorithm (GA) operators, this paper suggests
a filter-based FS algorithm (TLBO-GWO). Six benchmark datasets are selected,
and TLBO-GWO is compared with three recently proposed FS algorithms with
similar approaches, the main TLBO and GWO. The comparison is conducted based on
clustering evaluation measures, convergence behavior, and dimension reduction,
and is validated using statistical tests. The results reveal that TLBO-GWO can
significantly enhance the effectiveness of the text clustering technique
(K-means).</div><div><a href='http://arxiv.org/abs/2402.11839v1'>2402.11839v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.14867v1")'>Effects of term weighting approach with and without stop words removing
  on Arabic text classification</div>
<div id='2402.14867v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-21T11:31:04Z</div><div>Authors: Esra'a Alhenawi, Ruba Abu Khurma, Pedro A. Castillo, Maribel G. Arenas</div><div style='padding-top: 10px; width: 80ex'>Classifying text is a method for categorizing documents into pre-established
groups. Text documents must be prepared and represented in a way that is
appropriate for the algorithms used for data mining prior to classification. As
a result, a number of term weighting strategies have been created in the
literature to enhance text categorization algorithms' functionality. This study
compares the effects of Binary and Term frequency weighting feature
methodologies on the text's classification method when stop words are
eliminated once and when they are not. In recognition of assessing the effects
of prior weighting of features approaches on classification results in terms of
accuracy, recall, precision, and F-measure values, we used an Arabic data set
made up of 322 documents divided into six main topics (agriculture, economy,
health, politics, science, and sport), each of which contains 50 documents,
with the exception of the health category, which contains 61 documents. The
results demonstrate that for all metrics, the term frequency feature weighting
approach with stop word removal outperforms the binary approach, while for
accuracy, recall, and F-Measure, the binary approach outperforms the TF
approach without stop word removal. However, for precision, the two approaches
produce results that are very similar. Additionally, it is clear from the data
that, using the same phrase weighting approach, stop word removing increases
classification accuracy.</div><div><a href='http://arxiv.org/abs/2402.14867v1'>2402.14867v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.17120v1")'>LCEN: A Novel Feature Selection Algorithm for Nonlinear, Interpretable
  Machine Learning Models</div>
<div id='2402.17120v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T01:26:48Z</div><div>Authors: Pedro Seber, Richard D. Braatz</div><div style='padding-top: 10px; width: 80ex'>Interpretable architectures can have advantages over black-box architectures,
and interpretability is essential for the application of machine learning in
critical settings, such as aviation or medicine. However, the simplest, most
commonly used interpretable architectures (such as LASSO or EN) are limited to
linear predictions and have poor feature selection capabilities. In this work,
we introduce the LASSO-Clip-EN (LCEN) algorithm for the creation of nonlinear,
interpretable machine learning models. LCEN is tested on a wide variety of
artificial and empirical datasets, creating more accurate, sparser models than
other commonly used architectures. These experiments reveal that LCEN is robust
against many issues typically present in datasets and modeling, including
noise, multicollinearity, data scarcity, and hyperparameter variance. LCEN is
also able to rediscover multiple physical laws from empirical data and, for
processes with no known physical laws, LCEN achieves better results than many
other dense and sparse methods -- including using 10.8 times fewer features
than dense methods and 8.1 times fewer features than EN on one dataset, and is
comparable to an ANN on another dataset.</div><div><a href='http://arxiv.org/abs/2402.17120v1'>2402.17120v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.14254v1")'>A hierarchical decomposition for explaining ML performance discrepancies</div>
<div id='2402.14254v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-22T03:41:05Z</div><div>Authors: Jean Feng, Harvineet Singh, Fan Xia, Adarsh Subbaswamy, Alexej Gossmann</div><div style='padding-top: 10px; width: 80ex'>Machine learning (ML) algorithms can often differ in performance across
domains. Understanding $\textit{why}$ their performance differs is crucial for
determining what types of interventions (e.g., algorithmic or operational) are
most effective at closing the performance gaps. Existing methods focus on
$\textit{aggregate decompositions}$ of the total performance gap into the
impact of a shift in the distribution of features $p(X)$ versus the impact of a
shift in the conditional distribution of the outcome $p(Y|X)$; however, such
coarse explanations offer only a few options for how one can close the
performance gap. $\textit{Detailed variable-level decompositions}$ that
quantify the importance of each variable to each term in the aggregate
decomposition can provide a much deeper understanding and suggest much more
targeted interventions. However, existing methods assume knowledge of the full
causal graph or make strong parametric assumptions. We introduce a
nonparametric hierarchical framework that provides both aggregate and detailed
decompositions for explaining why the performance of an ML algorithm differs
across domains, without requiring causal knowledge. We derive debiased,
computationally-efficient estimators, and statistical inference procedures for
asymptotically valid confidence intervals.</div><div><a href='http://arxiv.org/abs/2402.14254v1'>2402.14254v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.15250v1")'>Comprehensive Reassessment of Large-Scale Evaluation Outcomes in LLMs: A
  Multifaceted Statistical Approach</div>
<div id='2403.15250v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-22T14:47:35Z</div><div>Authors: Kun Sun, Rong Wang, Haitao Liu, Anders Søgaard</div><div style='padding-top: 10px; width: 80ex'>Amidst the rapid evolution of LLMs, the significance of evaluation in
comprehending and propelling these models forward is increasingly paramount.
Evaluations have revealed that factors such as scaling, training types,
architectures and other factors profoundly impact the performance of LLMs.
However, the extent and nature of these impacts continue to be subjects of
debate because most assessments have been restricted to a limited number of
models and data points. Clarifying the effects of these factors on performance
scores can be more effectively achieved through a statistical lens. Our study
embarks on a thorough re-examination of these LLMs, targeting the inadequacies
in current evaluation methods. With the advent of a uniform evaluation
framework, our research leverages an expansive dataset of evaluation results,
introducing a comprehensive statistical methodology. This includes the
application of ANOVA, Tukey HSD tests, GAMM, and clustering technique, offering
a robust and transparent approach to deciphering LLM performance data. Contrary
to prevailing findings, our results challenge assumptions about emergent
abilities and the influence of given training types and architectures in LLMs.
These findings furnish new perspectives on the characteristics, intrinsic
nature, and developmental trajectories of LLMs. By providing straightforward
and reliable methods to scrutinize and reassess LLM performance data, this
study contributes a nuanced perspective on LLM efficiency and potentials.</div><div><a href='http://arxiv.org/abs/2403.15250v1'>2403.15250v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.04452v1")'>AI Competitions and Benchmarks, Practical issues: Proposals, grant
  money, sponsors, prizes, dissemination, publicity</div>
<div id='2401.04452v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-09T09:33:59Z</div><div>Authors: Magali Richard, Yuna Blum, Justin Guinney, Gustavo Stolovitzky, Adrien Pavão</div><div style='padding-top: 10px; width: 80ex'>This chapter provides a comprehensive overview of the pragmatic aspects
involved in organizing AI competitions. We begin by discussing strategies to
incentivize participation, touching upon effective communication techniques,
aligning with trending topics in the field, structuring awards, potential
recruitment opportunities, and more. We then shift to the essence of community
engagement, and into organizational best practices and effective means of
disseminating challenge outputs. Lastly, the chapter addresses the logistics,
exposing on costs, required manpower, and resource allocation for effectively
managing and executing a challenge. By examining these practical problems,
readers will gain actionable insights to navigate the multifaceted landscape of
AI competition organization, from inception to completion.</div><div><a href='http://arxiv.org/abs/2401.04452v1'>2401.04452v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13782v2")'>Tweets to Citations: Unveiling the Impact of Social Media Influencers on
  AI Research Visibility</div>
<div id='2401.13782v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T20:05:49Z</div><div>Authors: Iain Xie Weissburg, Mehir Arora, Xinyi Wang, Liangming Pan, William Yang Wang</div><div style='padding-top: 10px; width: 80ex'>As the number of accepted papers at AI and ML conferences reaches into the
thousands, it has become unclear how researchers access and read research
publications. In this paper, we investigate the role of social media
influencers in enhancing the visibility of machine learning research,
particularly the citation counts of papers they share. We have compiled a
comprehensive dataset of over 8,000 papers, spanning tweets from December 2018
to October 2023, alongside controls precisely matched by 9 key covariates. Our
statistical and causal inference analysis reveals a significant increase in
citations for papers endorsed by these influencers, with median citation counts
2-3 times higher than those of the control group. Additionally, the study
delves into the geographic, gender, and institutional diversity of highlighted
authors. Given these findings, we advocate for a responsible approach to
curation, encouraging influencers to uphold the journalistic standard that
includes showcasing diverse research topics, authors, and institutions.</div><div><a href='http://arxiv.org/abs/2401.13782v2'>2401.13782v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.13625v1")'>Enhancing Law Enforcement Training: A Gamified Approach to Detecting
  Terrorism Financing</div>
<div id='2403.13625v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-20T14:22:19Z</div><div>Authors: Francesco Zola, Lander Segurola, Erin King, Martin Mullins, Raul Orduna</div><div style='padding-top: 10px; width: 80ex'>Tools for fighting cyber-criminal activities using new technologies are
promoted and deployed every day. However, too often, they are unnecessarily
complex and hard to use, requiring deep domain and technical knowledge. These
characteristics often limit the engagement of law enforcement and end-users in
these technologies that, despite their potential, remain misunderstood. For
this reason, in this study, we describe our experience in combining learning
and training methods and the potential benefits of gamification to enhance
technology transfer and increase adult learning. In fact, in this case,
participants are experienced practitioners in professions/industries that are
exposed to terrorism financing (such as Law Enforcement Officers, Financial
Investigation Officers, private investigators, etc.) We define training
activities on different levels for increasing the exchange of information about
new trends and criminal modus operandi among and within law enforcement
agencies, intensifying cross-border cooperation and supporting efforts to
combat and prevent terrorism funding activities. On the other hand, a game
(hackathon) is designed to address realistic challenges related to the dark
net, crypto assets, new payment systems and dark web marketplaces that could be
used for terrorist activities. The entire methodology was evaluated using
quizzes, contest results, and engagement metrics. In particular, training
events show about 60% of participants complete the 11-week training course,
while the Hackathon results, gathered in two pilot studies (Madrid and The
Hague), show increasing expertise among the participants (progression in the
achieved points on average). At the same time, more than 70% of participants
positively evaluate the use of the gamification approach, and more than 85% of
them consider the implemented Use Cases suitable for their investigations.</div><div><a href='http://arxiv.org/abs/2403.13625v1'>2403.13625v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.01379v1")'>Regularized boosting with an increasing coefficient magnitude stop
  criterion as meta-learner in hyperparameter optimization stacking ensemble</div>
<div id='2402.01379v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T13:03:15Z</div><div>Authors: Laura Fdez-Díaz, José Ramón Quevedo, Elena Montañés</div><div style='padding-top: 10px; width: 80ex'>In Hyperparameter Optimization (HPO), only the hyperparameter configuration
with the best performance is chosen after performing several trials, then,
discarding the effort of training all the models with every hyperparameter
configuration trial and performing an ensemble of all them. This ensemble
consists of simply averaging the model predictions or weighting the models by a
certain probability. Recently, other more sophisticated ensemble strategies,
such as the Caruana method or the stacking strategy has been proposed. On the
one hand, the Caruana method performs well in HPO ensemble, since it is not
affected by the effects of multicollinearity, which is prevalent in HPO. It
just computes the average over a subset of predictions with replacement. But it
does not benefit from the generalization power of a learning process. On the
other hand, stacking methods include a learning procedure since a meta-learner
is required to perform the ensemble. Yet, one hardly finds advice about which
meta-learner is adequate. Besides, some meta-learners may suffer from the
effects of multicollinearity or need to be tuned to reduce them. This paper
explores meta-learners for stacking ensemble in HPO, free of hyperparameter
tuning, able to reduce the effects of multicollinearity and considering the
ensemble learning process generalization power. At this respect, the boosting
strategy seems promising as a stacking meta-learner. In fact, it completely
removes the effects of multicollinearity. This paper also proposes an implicit
regularization in the classical boosting method and a novel non-parametric stop
criterion suitable only for boosting and specifically designed for HPO. The
synergy between these two improvements over boosting exhibits competitive and
promising predictive power performance compared to other existing meta-learners
and ensemble approaches for HPO other than the stacking ensemble.</div><div><a href='http://arxiv.org/abs/2402.01379v1'>2402.01379v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.06829v2")'>Constructing Variables Using Classifiers as an Aid to Regression: An
  Empirical Assessment</div>
<div id='2403.06829v2' style='display: none; margin-left: 20px'><div>Date: 2024-03-11T15:44:40Z</div><div>Authors: Colin Troisemaine, Vincent Lemaire</div><div style='padding-top: 10px; width: 80ex'>This paper proposes a method for the automatic creation of variables (in the
case of regression) that complement the information contained in the initial
input vector. The method works as a pre-processing step in which the continuous
values of the variable to be regressed are discretized into a set of intervals
which are then used to define value thresholds. Then classifiers are trained to
predict whether the value to be regressed is less than or equal to each of
these thresholds. The different outputs of the classifiers are then
concatenated in the form of an additional vector of variables that enriches the
initial vector of the regression problem. The implemented system can thus be
considered as a generic pre-processing tool. We tested the proposed enrichment
method with 5 types of regressors and evaluated it in 33 regression datasets.
Our experimental results confirm the interest of the approach.</div><div><a href='http://arxiv.org/abs/2403.06829v2'>2403.06829v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.05138v1")'>Greedy feature selection: Classifier-dependent feature selection via
  greedy methods</div>
<div id='2403.05138v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-08T08:12:05Z</div><div>Authors: Fabiana Camattari, Sabrina Guastavino, Francesco Marchetti, Michele Piana, Emma Perracchione</div><div style='padding-top: 10px; width: 80ex'>The purpose of this study is to introduce a new approach to feature ranking
for classification tasks, called in what follows greedy feature selection. In
statistical learning, feature selection is usually realized by means of methods
that are independent of the classifier applied to perform the prediction using
that reduced number of features. Instead, greedy feature selection identifies
the most important feature at each step and according to the selected
classifier. In the paper, the benefits of such scheme are investigated
theoretically in terms of model capacity indicators, such as the
Vapnik-Chervonenkis (VC) dimension or the kernel alignment, and tested
numerically by considering its application to the problem of predicting
geo-effective manifestations of the active Sun.</div><div><a href='http://arxiv.org/abs/2403.05138v1'>2403.05138v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.07627v1")'>Cost-sensitive Feature Selection for Support Vector Machines</div>
<div id='2401.07627v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-15T12:07:52Z</div><div>Authors: Sandra Benítez-Peña, Rafael Blanquero, Emilio Carrizosa, Pepa Ramírez-Cobo</div><div style='padding-top: 10px; width: 80ex'>Feature Selection is a crucial procedure in Data Science tasks such as
Classification, since it identifies the relevant variables, making thus the
classification procedures more interpretable, cheaper in terms of measurement
and more effective by reducing noise and data overfit. The relevance of
features in a classification procedure is linked to the fact that
misclassifications costs are frequently asymmetric, since false positive and
false negative cases may have very different consequences. However,
off-the-shelf Feature Selection procedures seldom take into account such
cost-sensitivity of errors.
  In this paper we propose a mathematical-optimization-based Feature Selection
procedure embedded in one of the most popular classification procedures,
namely, Support Vector Machines, accommodating asymmetric misclassification
costs. The key idea is to replace the traditional margin maximization by
minimizing the number of features selected, but imposing upper bounds on the
false positive and negative rates. The problem is written as an integer linear
problem plus a quadratic convex problem for Support Vector Machines with both
linear and radial kernels.
  The reported numerical experience demonstrates the usefulness of the proposed
Feature Selection procedure. Indeed, our results on benchmark data sets show
that a substantial decrease of the number of features is obtained, whilst the
desired trade-off between false positive and false negative rates is achieved.</div><div><a href='http://arxiv.org/abs/2401.07627v1'>2401.07627v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01797v1")'>Robust support vector machines via conic optimization</div>
<div id='2402.01797v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T05:42:50Z</div><div>Authors: Valentina Cepeda, Andrés Gómez, Shaoning Han</div><div style='padding-top: 10px; width: 80ex'>We consider the problem of learning support vector machines robust to
uncertainty. It has been established in the literature that typical loss
functions, including the hinge loss, are sensible to data perturbations and
outliers, thus performing poorly in the setting considered. In contrast, using
the 0-1 loss or a suitable non-convex approximation results in robust
estimators, at the expense of large computational costs. In this paper we use
mixed-integer optimization techniques to derive a new loss function that better
approximates the 0-1 loss compared with existing alternatives, while preserving
the convexity of the learning problem. In our computational results, we show
that the proposed estimator is competitive with the standard SVMs with the
hinge loss in outlier-free regimes and better in the presence of outliers.</div><div><a href='http://arxiv.org/abs/2402.01797v1'>2402.01797v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.12485v1")'>Adiabatic Quantum Support Vector Machines</div>
<div id='2401.12485v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-23T04:50:13Z</div><div>Authors: Prasanna Date, Dong Jun Woun, Kathleen Hamilton, Eduardo A. Coello Perez, Mayanka Chandra Shekhar, Francisco Rios, John Gounley, In-Saeng Suh, Travis Humble, Georgia Tourassi</div><div style='padding-top: 10px; width: 80ex'>Adiabatic quantum computers can solve difficult optimization problems (e.g.,
the quadratic unconstrained binary optimization problem), and they seem well
suited to train machine learning models. In this paper, we describe an
adiabatic quantum approach for training support vector machines. We show that
the time complexity of our quantum approach is an order of magnitude better
than the classical approach. Next, we compare the test accuracy of our quantum
approach against a classical approach that uses the Scikit-learn library in
Python across five benchmark datasets (Iris, Wisconsin Breast Cancer (WBC),
Wine, Digits, and Lambeq). We show that our quantum approach obtains accuracies
on par with the classical approach. Finally, we perform a scalability study in
which we compute the total training times of the quantum approach and the
classical approach with increasing number of features and number of data points
in the training dataset. Our scalability results show that the quantum approach
obtains a 3.5--4.5 times speedup over the classical approach on datasets with
many (millions of) features.</div><div><a href='http://arxiv.org/abs/2401.12485v1'>2401.12485v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.07856v1")'>Quantum Support Vector Machine for Prostate Cancer Detection: A
  Performance Analysis</div>
<div id='2403.07856v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-12T17:46:38Z</div><div>Authors: Walid El Maouaki, Taoufik Said, Mohamed Bennai</div><div style='padding-top: 10px; width: 80ex'>This study addresses the urgent need for improved prostate cancer detection
methods by harnessing the power of advanced technological solutions. We
introduce the application of Quantum Support Vector Machine (QSVM) to this
critical healthcare challenge, showcasing an enhancement in diagnostic
performance over the classical Support Vector Machine (SVM) approach. Our study
not only outlines the remarkable improvements in diagnostic performance made by
QSVM over the classic SVM technique, but it delves into the advancements
brought about by the quantum feature map architecture, which has been carefully
identified and evaluated, ensuring it aligns seamlessly with the unique
characteristics of our prostate cancer dataset. This architecture succeded in
creating a distinct feature space, enabling the detection of complex,
non-linear patterns in the data. The findings reveal not only a comparable
accuracy with classical SVM ($92\%$) but also a $7.14\%$ increase in
sensitivity and a notably high F1-Score ($93.33\%$). This study's important
combination of quantum computing in medical diagnostics marks a pivotal step
forward in cancer detection, offering promising implications for the future of
healthcare technology.</div><div><a href='http://arxiv.org/abs/2403.07856v1'>2403.07856v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2401.14388v1")'>Smooth Ranking SVM via Cutting-Plane Method</div>
<div id='2401.14388v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-25T18:47:23Z</div><div>Authors: Erhan Can Ozcan, Berk Görgülü, Mustafa G. Baydogan, Ioannis Ch. Paschalidis</div><div style='padding-top: 10px; width: 80ex'>The most popular classification algorithms are designed to maximize
classification accuracy during training. However, this strategy may fail in the
presence of class imbalance since it is possible to train models with high
accuracy by overfitting to the majority class. On the other hand, the Area
Under the Curve (AUC) is a widely used metric to compare classification
performance of different algorithms when there is a class imbalance, and
various approaches focusing on the direct optimization of this metric during
training have been proposed. Among them, SVM-based formulations are especially
popular as this formulation allows incorporating different regularization
strategies easily. In this work, we develop a prototype learning approach that
relies on cutting-plane method, similar to Ranking SVM, to maximize AUC. Our
algorithm learns simpler models by iteratively introducing cutting planes, thus
overfitting is prevented in an unconventional way. Furthermore, it penalizes
the changes in the weights at each iteration to avoid large jumps that might be
observed in the test performance, thus facilitating a smooth learning process.
Based on the experiments conducted on 73 binary classification datasets, our
method yields the best test AUC in 25 datasets among its relevant competitors.</div><div><a href='http://arxiv.org/abs/2401.14388v1'>2401.14388v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.10175v1")'>A Short Survey on Importance Weighting for Machine Learning</div>
<div id='2403.10175v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-15T10:31:46Z</div><div>Authors: Masanari Kimura, Hideitsu Hino</div><div style='padding-top: 10px; width: 80ex'>Importance weighting is a fundamental procedure in statistics and machine
learning that weights the objective function or probability distribution based
on the importance of the instance in some sense. The simplicity and usefulness
of the idea has led to many applications of importance weighting. For example,
it is known that supervised learning under an assumption about the difference
between the training and test distributions, called distribution shift, can
guarantee statistically desirable properties through importance weighting by
their density ratio. This survey summarizes the broad applications of
importance weighting in machine learning and related research.</div><div><a href='http://arxiv.org/abs/2403.10175v1'>2403.10175v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.11594v1")'>Simplifying Hyperparameter Tuning in Online Machine Learning -- The
  spotRiverGUI</div>
<div id='2402.11594v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-18T14:12:15Z</div><div>Authors: Thomas Bartz-Beielstein</div><div style='padding-top: 10px; width: 80ex'>Batch Machine Learning (BML) reaches its limits when dealing with very large
amounts of streaming data. This is especially true for available memory,
handling drift in data streams, and processing new, unknown data. Online
Machine Learning (OML) is an alternative to BML that overcomes the limitations
of BML. OML is able to process data in a sequential manner, which is especially
useful for data streams. The `river` package is a Python OML-library, which
provides a variety of online learning algorithms for classification,
regression, clustering, anomaly detection, and more. The `spotRiver` package
provides a framework for hyperparameter tuning of OML models. The
`spotRiverGUI` is a graphical user interface for the `spotRiver` package. The
`spotRiverGUI` releases the user from the burden of manually searching for the
optimal hyperparameter setting. After the data is provided, users can compare
different OML algorithms from the powerful `river` package in a convenient way
and tune the selected algorithms very efficiently.</div><div><a href='http://arxiv.org/abs/2402.11594v1'>2402.11594v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.03051v1")'>On the Convergence of Semi Unsupervised Calibration through Prior
  Adaptation Algorithm</div>
<div id='2401.03051v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-05T20:04:40Z</div><div>Authors: Lautaro Estienne, Roberta Hansen, Matias Vera, Luciana Ferrer, Pablo Piantanida</div><div style='padding-top: 10px; width: 80ex'>Calibration is an essential key in machine leaning. Semi Unsupervised
Calibration through Prior Adaptation (SUCPA) is a calibration algorithm used in
(but not limited to) large-scale language models defined by a {system of
first-order difference equation. The map derived by this system} has the
peculiarity of being non-hyperbolic {with a non-bounded set of non-isolated
fixed points}. In this work, we prove several convergence properties of this
algorithm from the perspective of dynamical systems. For a binary
classification problem, it can be shown that the algorithm always converges,
{more precisely, the map is globally asymptotically stable, and the orbits
converge} to a single line of fixed points. Finally, we perform numerical
experiments on real-world application to support the presented results.
Experiment codes are available online.</div><div><a href='http://arxiv.org/abs/2401.03051v1'>2401.03051v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.01450v1")'>Improving importance estimation in covariate shift for providing
  accurate prediction error</div>
<div id='2402.01450v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T14:39:39Z</div><div>Authors: Laura Fdez-Díaz, Sara González Tomillo, Elena Montañés, José Ramón Quevedo</div><div style='padding-top: 10px; width: 80ex'>In traditional Machine Learning, the algorithms predictions are based on the
assumption that the data follows the same distribution in both the training and
the test datasets. However, in real world data this condition does not hold
and, for instance, the distribution of the covariates changes whereas the
conditional distribution of the targets remains unchanged. This situation is
called covariate shift problem where standard error estimation may be no longer
accurate. In this context, the importance is a measure commonly used to
alleviate the influence of covariate shift on error estimations. The main
drawback is that it is not easy to compute. The Kullback-Leibler Importance
Estimation Procedure (KLIEP) is capable of estimating importance in a promising
way. Despite its good performance, it fails to ignore target information, since
it only includes the covariates information for computing the importance. In
this direction, this paper explores the potential performance improvement if
target information is considered in the computation of the importance. Then, a
redefinition of the importance arises in order to be generalized in this way.
Besides the potential improvement in performance, including target information
make possible the application to a real application about plankton
classification that motivates this research and characterized by its great
dimensionality, since considering targets rather than covariates reduces the
computation and the noise in the covariates. The impact of taking target
information is also explored when Logistic Regression (LR), Kernel Mean
Matching (KMM), Ensemble Kernel Mean Matching (EKMM) and the naive predecessor
of KLIEP called Kernel Density Estimation (KDE) methods estimate the
importance. The experimental results lead to a more accurate error estimation
using target information, especially in case of the more promising method
KLIEP.</div><div><a href='http://arxiv.org/abs/2402.01450v1'>2402.01450v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.05982v3")'>A tree-based varying coefficient model</div>
<div id='2401.05982v3' style='display: none; margin-left: 20px'><div>Date: 2024-01-11T15:35:32Z</div><div>Authors: Henning Zakrisson, Mathias Lindholm</div><div style='padding-top: 10px; width: 80ex'>The paper introduces a tree-based varying coefficient model (VCM) where the
varying coefficients are modelled using the cyclic gradient boosting machine
(CGBM) from Delong et al. (2023). Modelling the coefficient functions using a
CGBM allows for dimension-wise early stopping and feature importance scores.
The dimension-wise early stopping not only reduces the risk of
dimension-specific overfitting, but also reveals differences in model
complexity across dimensions. The use of feature importance scores allows for
simple feature selection and easy model interpretation. The model is evaluated
on the same simulated and real data examples as those used in Richman and
W\"uthrich (2023), and the results show that it produces results in terms of
out of sample loss that are comparable to those of their neural network-based
VCM called LocalGLMnet.</div><div><a href='http://arxiv.org/abs/2401.05982v3'>2401.05982v3</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.18689v1")'>The VOROS: Lifting ROC curves to 3D</div>
<div id='2402.18689v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-28T20:09:14Z</div><div>Authors: Christopher Ratigan, Lenore Cowen</div><div style='padding-top: 10px; width: 80ex'>The area under the ROC curve is a common measure that is often used to rank
the relative performance of different binary classifiers. However, as has been
also previously noted, it can be a measure that ill-captures the benefits of
different classifiers when either the true class values or misclassification
costs are highly unbalanced between the two classes. We introduce a third
dimension to capture these costs, and lift the ROC curve to a ROC surface in a
natural way. We study both this surface and introduce the VOROS, the volume
over this ROC surface, as a 3D generalization of the 2D area under the ROC
curve. For problems where there are only bounds on the expected costs or class
imbalances, we restrict consideration to the volume of the appropriate
subregion of the ROC surface. We show how the VOROS can better capture the
costs of different classifiers on both a classical and a modern example
dataset.</div><div><a href='http://arxiv.org/abs/2402.18689v1'>2402.18689v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.08405v1")'>A Novel Approach to Regularising 1NN classifier for Improved
  Generalization</div>
<div id='2402.08405v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-13T12:09:15Z</div><div>Authors: Aditya Challa, Sravan Danda, Laurent Najman</div><div style='padding-top: 10px; width: 80ex'>In this paper, we propose a class of non-parametric classifiers, that learn
arbitrary boundaries and generalize well.
  Our approach is based on a novel way to regularize 1NN classifiers using a
greedy approach. We refer to this class of classifiers as Watershed
Classifiers. 1NN classifiers are known to trivially over-fit but have very
large VC dimension, hence do not generalize well. We show that watershed
classifiers can find arbitrary boundaries on any dense enough dataset, and, at
the same time, have very small VC dimension; hence a watershed classifier leads
to good generalization.
  Traditional approaches to regularize 1NN classifiers are to consider $K$
nearest neighbours. Neighbourhood component analysis (NCA) proposes a way to
learn representations consistent with ($n-1$) nearest neighbour classifier,
where $n$ denotes the size of the dataset. In this article, we propose a loss
function which can learn representations consistent with watershed classifiers,
and show that it outperforms the NCA baseline.</div><div><a href='http://arxiv.org/abs/2402.08405v1'>2402.08405v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16785v2")'>HawkEye: Advancing Robust Regression with Bounded, Smooth, and
  Insensitive Loss Function</div>
<div id='2401.16785v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T06:53:59Z</div><div>Authors: Mushir Akhtar, M. Tanveer, Mohd. Arshad</div><div style='padding-top: 10px; width: 80ex'>Support vector regression (SVR) has garnered significant popularity over the
past two decades owing to its wide range of applications across various fields.
Despite its versatility, SVR encounters challenges when confronted with
outliers and noise, primarily due to the use of the $\varepsilon$-insensitive
loss function. To address this limitation, SVR with bounded loss functions has
emerged as an appealing alternative, offering enhanced generalization
performance and robustness. Notably, recent developments focus on designing
bounded loss functions with smooth characteristics, facilitating the adoption
of gradient-based optimization algorithms. However, it's crucial to highlight
that these bounded and smooth loss functions do not possess an insensitive
zone. In this paper, we address the aforementioned constraints by introducing a
novel symmetric loss function named the HawkEye loss function. It is worth
noting that the HawkEye loss function stands out as the first loss function in
SVR literature to be bounded, smooth, and simultaneously possess an insensitive
zone. Leveraging this breakthrough, we integrate the HawkEye loss function into
the least squares framework of SVR and yield a new fast and robust model termed
HE-LSSVR. The optimization problem inherent to HE-LSSVR is addressed by
harnessing the adaptive moment estimation (Adam) algorithm, known for its
adaptive learning rate and efficacy in handling large-scale problems. To our
knowledge, this is the first time Adam has been employed to solve an SVR
problem. To empirically validate the proposed HE-LSSVR model, we evaluate it on
UCI, synthetic, and time series datasets. The experimental outcomes
unequivocally reveal the superiority of the HE-LSSVR model both in terms of its
remarkable generalization performance and its efficiency in training time.</div><div><a href='http://arxiv.org/abs/2401.16785v2'>2401.16785v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.03123v1")'>A least distance estimator for a multivariate regression model using
  deep neural networks</div>
<div id='2401.03123v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-06T04:36:00Z</div><div>Authors: Jungmin Shin, Seung Jun Shin, Sungwan Bang</div><div style='padding-top: 10px; width: 80ex'>We propose a deep neural network (DNN) based least distance (LD) estimator
(DNN-LD) for a multivariate regression problem, addressing the limitations of
the conventional methods. Due to the flexibility of a DNN structure, both
linear and nonlinear conditional mean functions can be easily modeled, and a
multivariate regression model can be realized by simply adding extra nodes at
the output layer. The proposed method is more efficient in capturing the
dependency structure among responses than the least squares loss, and robust to
outliers. In addition, we consider $L_1$-type penalization for variable
selection, crucial in analyzing high-dimensional data. Namely, we propose what
we call (A)GDNN-LD estimator that enjoys variable selection and model
estimation simultaneously, by applying the (adaptive) group Lasso penalty to
weight parameters in the DNN structure. For the computation, we propose a
quadratic smoothing approximation method to facilitate optimizing the
non-smooth objective function based on the least distance loss. The simulation
studies and a real data analysis demonstrate the promising performance of the
proposed method.</div><div><a href='http://arxiv.org/abs/2401.03123v1'>2401.03123v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.13141v1")'>Function Trees: Transparent Machine Learning</div>
<div id='2403.13141v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-19T20:23:31Z</div><div>Authors: Jerome H. Friedman</div><div style='padding-top: 10px; width: 80ex'>The output of a machine learning algorithm can usually be represented by one
or more multivariate functions of its input variables. Knowing the global
properties of such functions can help in understanding the system that produced
the data as well as interpreting and explaining corresponding model
predictions. A method is presented for representing a general multivariate
function as a tree of simpler functions. This tree exposes the global internal
structure of the function by uncovering and describing the combined joint
influences of subsets of its input variables. Given the inputs and
corresponding function values, a function tree is constructed that can be used
to rapidly identify and compute all of the function's main and interaction
effects up to high order. Interaction effects involving up to four variables
are graphically visualized.</div><div><a href='http://arxiv.org/abs/2403.13141v1'>2403.13141v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.08964v1")'>Predicting User Experience on Laptops from Hardware Specifications</div>
<div id='2402.08964v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-14T06:10:44Z</div><div>Authors: Saswat Padhi, Sunil K. Bhasin, Udaya K. Ammu, Alex Bergman, Allan Knies</div><div style='padding-top: 10px; width: 80ex'>Estimating the overall user experience (UX) on a device is a common challenge
faced by manufacturers. Today, device makers primarily rely on microbenchmark
scores, such as Geekbench, that stress test specific hardware components, such
as CPU or RAM, but do not satisfactorily capture consumer workloads. System
designers often rely on domain-specific heuristics and extensive testing of
prototypes to reach a desired UX goal, and yet there is often a mismatch
between the manufacturers' performance claims and the consumers' experience.
  We present our initial results on predicting real-life experience on laptops
from their hardware specifications. We target web applications that run on
Chromebooks (ChromeOS laptops) for a simple and fair aggregation of experience
across applications and workloads. On 54 laptops, we track 9 UX metrics on
common end-user workloads: web browsing, video playback and audio/video calls.
We focus on a subset of high-level metrics exposed by the Chrome browser, that
are part of the Web Vitals initiative for judging the UX on web applications.
  With a dataset of 100K UX data points, we train gradient boosted regression
trees that predict the metric values from device specifications. Across our 9
metrics, we note a mean $R^2$ score (goodness-of-fit on our dataset) of 97.8%
and a mean MAAPE (percentage error in prediction on unseen data) of 10.1%.</div><div><a href='http://arxiv.org/abs/2402.08964v1'>2402.08964v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2402.08056v1")'>MIML library: a Modular and Flexible Library for Multi-instance
  Multi-label Learning</div>
<div id='2402.08056v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-12T20:46:47Z</div><div>Authors: Álvaro Belmonte, Amelia Zafra, Eva Gibaja</div><div style='padding-top: 10px; width: 80ex'>MIML library is a Java software tool to develop, test, and compare
classification algorithms for multi-instance multi-label (MIML) learning. The
library includes 43 algorithms and provides a specific format and facilities
for data managing and partitioning, holdout and cross-validation methods,
standard metrics for performance evaluation, and generation of reports. In
addition, algorithms can be executed through $xml$ configuration files without
needing to program. It is platform-independent, extensible, free, open-source,
and available on GitHub under the GNU General Public License.</div><div><a href='http://arxiv.org/abs/2402.08056v1'>2402.08056v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16594v1")'>Consistent algorithms for multi-label classification with macro-at-$k$
  metrics</div>
<div id='2401.16594v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T21:51:27Z</div><div>Authors: Erik Schultheis, Wojciech Kotłowski, Marek Wydmuch, Rohit Babbar, Strom Borman, Krzysztof Dembczyński</div><div style='padding-top: 10px; width: 80ex'>We consider the optimization of complex performance metrics in multi-label
classification under the population utility framework. We mainly focus on
metrics linearly decomposable into a sum of binary classification utilities
applied separately to each label with an additional requirement of exactly $k$
labels predicted for each instance. These "macro-at-$k$" metrics possess
desired properties for extreme classification problems with long tail labels.
Unfortunately, the at-$k$ constraint couples the otherwise independent binary
classification tasks, leading to a much more challenging optimization problem
than standard macro-averages. We provide a statistical framework to study this
problem, prove the existence and the form of the optimal classifier, and
propose a statistically consistent and practical learning algorithm based on
the Frank-Wolfe method. Interestingly, our main results concern even more
general metrics being non-linear functions of label-wise confusion matrices.
Empirical results provide evidence for the competitive performance of the
proposed approach.</div><div><a href='http://arxiv.org/abs/2401.16594v1'>2401.16594v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.18198v1")'>Automated Machine Learning for Multi-Label Classification</div>
<div id='2402.18198v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-28T09:40:36Z</div><div>Authors: Marcel Wever</div><div style='padding-top: 10px; width: 80ex'>Automated machine learning (AutoML) aims to select and configure machine
learning algorithms and combine them into machine learning pipelines tailored
to a dataset at hand. For supervised learning tasks, most notably binary and
multinomial classification, aka single-label classification (SLC), such AutoML
approaches have shown promising results. However, the task of multi-label
classification (MLC), where data points are associated with a set of class
labels instead of a single class label, has received much less attention so
far. In the context of multi-label classification, the data-specific selection
and configuration of multi-label classifiers are challenging even for experts
in the field, as it is a high-dimensional optimization problem with multi-level
hierarchical dependencies. While for SLC, the space of machine learning
pipelines is already huge, the size of the MLC search space outnumbers the one
of SLC by several orders.
  In the first part of this thesis, we devise a novel AutoML approach for
single-label classification tasks optimizing pipelines of machine learning
algorithms, consisting of two algorithms at most. This approach is then
extended first to optimize pipelines of unlimited length and eventually
configure the complex hierarchical structures of multi-label classification
methods. Furthermore, we investigate how well AutoML approaches that form the
state of the art for single-label classification tasks scale with the increased
problem complexity of AutoML for multi-label classification.
  In the second part, we explore how methods for SLC and MLC could be
configured more flexibly to achieve better generalization performance and how
to increase the efficiency of execution-based AutoML systems.</div><div><a href='http://arxiv.org/abs/2402.18198v1'>2402.18198v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.16133v1")'>BooleanOCT: Optimal Classification Trees based on multivariate Boolean
  Rules</div>
<div id='2401.16133v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T12:58:44Z</div><div>Authors: Jiancheng Tu, Wenqi Fan, Zhibin Wu</div><div style='padding-top: 10px; width: 80ex'>The global optimization of classification trees has demonstrated considerable
promise, notably in enhancing accuracy, optimizing size, and thereby improving
human comprehensibility. While existing optimal classification trees
substantially enhance accuracy over greedy-based tree models like CART, they
still fall short when compared to the more complex black-box models, such as
random forests. To bridge this gap, we introduce a new mixed-integer
programming (MIP) formulation, grounded in multivariate Boolean rules, to
derive the optimal classification tree. Our methodology integrates both linear
metrics, including accuracy, balanced accuracy, and cost-sensitive cost, as
well as nonlinear metrics such as the F1-score. The approach is implemented in
an open-source Python package named BooleanOCT. We comprehensively benchmark
these methods on the 36 datasets from the UCI machine learning repository. The
proposed models demonstrate practical solvability on real-world datasets,
effectively handling sizes in the tens of thousands. Aiming to maximize
accuracy, this model achieves an average absolute improvement of 3.1\% and
1.5\% over random forests in small-scale and medium-sized datasets,
respectively. Experiments targeting various objectives, including balanced
accuracy, cost-sensitive cost, and F1-score, demonstrate the framework's wide
applicability and its superiority over contemporary state-of-the-art optimal
classification tree methods in small to medium-scale datasets.</div><div><a href='http://arxiv.org/abs/2401.16133v1'>2401.16133v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.11228v1")'>Adaptive Split Balancing for Optimal Random Forest</div>
<div id='2402.11228v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-17T09:10:40Z</div><div>Authors: Yuqian Zhang, Weijie Ji, Jelena Bradic</div><div style='padding-top: 10px; width: 80ex'>While random forests are commonly used for regression problems, existing
methods often lack adaptability in complex situations or lose optimality under
simple, smooth scenarios. In this study, we introduce the adaptive split
balancing forest (ASBF), capable of learning tree representations from data
while simultaneously achieving minimax optimality under the Lipschitz class. To
exploit higher-order smoothness levels, we further propose a localized version
that attains the minimax rate under the H\"older class $\mathcal{H}^{q,\beta}$
for any $q\in\mathbb{N}$ and $\beta\in(0,1]$. Rather than relying on the
widely-used random feature selection, we consider a balanced modification to
existing approaches. Our results indicate that an over-reliance on auxiliary
randomness may compromise the approximation power of tree models, leading to
suboptimal results. Conversely, a less random, more balanced approach
demonstrates optimality. Additionally, we establish uniform upper bounds and
explore the application of random forests in average treatment effect
estimation problems. Through simulation studies and real-data applications, we
demonstrate the superior empirical performance of the proposed methods over
existing random forests.</div><div><a href='http://arxiv.org/abs/2402.11228v1'>2402.11228v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.06015v1")'>Grafting: Making Random Forests Consistent</div>
<div id='2403.06015v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-09T21:29:25Z</div><div>Authors: Nicholas Waltz</div><div style='padding-top: 10px; width: 80ex'>Despite their performance and widespread use, little is known about the
theory of Random Forests. A major unanswered question is whether, or when, the
Random Forest algorithm is consistent. The literature explores various variants
of the classic Random Forest algorithm to address this question and known
short-comings of the method. This paper is a contribution to this literature.
Specifically, the suitability of grafting consistent estimators onto a shallow
CART is explored. It is shown that this approach has a consistency guarantee
and performs well in empirical settings.</div><div><a href='http://arxiv.org/abs/2403.06015v1'>2403.06015v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.05535v2")'>Improving the Accuracy and Interpretability of Random Forests via Forest
  Pruning</div>
<div id='2401.05535v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-10T20:02:47Z</div><div>Authors: Albert Dorador</div><div style='padding-top: 10px; width: 80ex'>Decades after their inception, random forests continue to provide
state-of-the-art accuracy in a variety of learning problems, outperforming in
this respect alternative machine learning algorithms such as decision trees or
even neural networks. However, being an ensemble method, the one aspect where
random forests tend to severely underperform decision trees is
interpretability. In the present work, we propose a post-hoc approach that aims
to have the best of both worlds: the accuracy of random forests and the
interpretability of decision trees. To this end, we present two forest-pruning
methods to find an optimal sub-forest within a given random forest, and then,
when applicable, combine the selected trees into one. Our first method relies
on constrained exhaustive search, while our second method is based on an
adaptation of the LASSO methodology. Extensive experiments over synthetic and
real world datasets show that, in the majority of scenarios, at least one of
the two methods proposed is more accurate than the original random forest,
while just using a small fraction of the trees, aiding result interpretability.
Compared to current state-of-the-art forest pruning methods, namely sequential
forward selection and (a variation of) sequential backward selection, our
methods tend to outperform both of them, whether in terms of accuracy, number
of trees employed, or both.</div><div><a href='http://arxiv.org/abs/2401.05535v2'>2401.05535v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04447v1")'>FRRI: a novel algorithm for fuzzy-rough rule induction</div>
<div id='2403.04447v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T12:34:03Z</div><div>Authors: Henri Bollaert, Marko Palangetić, Chris Cornelis, Salvatore Greco, Roman Słowiński</div><div style='padding-top: 10px; width: 80ex'>Interpretability is the next frontier in machine learning research. In the
search for white box models - as opposed to black box models, like random
forests or neural networks - rule induction algorithms are a logical and
promising option, since the rules can easily be understood by humans. Fuzzy and
rough set theory have been successfully applied to this archetype, almost
always separately. As both approaches to rule induction involve granular
computing based on the concept of equivalence classes, it is natural to combine
them. The QuickRules\cite{JensenCornelis2009} algorithm was a first attempt at
using fuzzy rough set theory for rule induction. It is based on QuickReduct, a
greedy algorithm for building decision reducts. QuickRules already showed an
improvement over other rule induction methods. However, to evaluate the full
potential of a fuzzy rough rule induction algorithm, one needs to start from
the foundations. In this paper, we introduce a novel rule induction algorithm
called Fuzzy Rough Rule Induction (FRRI). We provide background and explain the
workings of our algorithm. Furthermore, we perform a computational experiment
to evaluate the performance of our algorithm and compare it to other
state-of-the-art rule induction approaches. We find that our algorithm is more
accurate while creating small rulesets consisting of relatively short rules. We
end the paper by outlining some directions for future work.</div><div><a href='http://arxiv.org/abs/2403.04447v1'>2403.04447v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.12664v1")'>Deciphering AutoML Ensembles: cattleia's Assistance in Decision-Making</div>
<div id='2403.12664v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-19T11:56:21Z</div><div>Authors: Anna Kozak, Dominik Kędzierski, Jakub Piwko, Malwina Wojewoda, Katarzyna Woźnica</div><div style='padding-top: 10px; width: 80ex'>In many applications, model ensembling proves to be better than a single
predictive model. Hence, it is the most common post-processing technique in
Automated Machine Learning (AutoML). The most popular frameworks use ensembles
at the expense of reducing the interpretability of the final models. In our
work, we propose cattleia - an application that deciphers the ensembles for
regression, multiclass, and binary classification tasks. This tool works with
models built by three AutoML packages: auto-sklearn, AutoGluon, and FLAML. The
given ensemble is analyzed from different perspectives. We conduct a predictive
performance investigation through evaluation metrics of the ensemble and its
component models. We extend the validation perspective by introducing new
measures to assess the diversity and complementarity of the model predictions.
Moreover, we apply explainable artificial intelligence (XAI) techniques to
examine the importance of variables. Summarizing obtained insights, we can
investigate and adjust the weights with a modification tool to tune the
ensemble in the desired way. The application provides the aforementioned
aspects through dedicated interactive visualizations, making it accessible to a
diverse audience. We believe the cattleia can support users in decision-making
and deepen the comprehension of AutoML frameworks.</div><div><a href='http://arxiv.org/abs/2403.12664v1'>2403.12664v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.19025v1")'>Combination of Weak Learners eXplanations to Improve Random Forest
  eXplicability Robustness</div>
<div id='2402.19025v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T10:37:40Z</div><div>Authors: Riccardo Pala, Esteban García-Cuesta</div><div style='padding-top: 10px; width: 80ex'>The notion of robustness in XAI refers to the observed variations in the
explanation of the prediction of a learned model with respect to changes in the
input leading to that prediction. Intuitively, if the input being explained is
modified slightly subtly enough so as to not change the prediction of the model
too much, then we would expect that the explanation provided for that new input
does not change much either. We argue that a combination through discriminative
averaging of ensembles weak learners explanations can improve the robustness of
explanations in ensemble methods.This approach has been implemented and tested
with post-hoc SHAP method and Random Forest ensemble with successful results.
The improvements obtained have been measured quantitatively and some insights
into the explicability robustness in ensemble methods are presented.</div><div><a href='http://arxiv.org/abs/2402.19025v1'>2402.19025v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.12668v1")'>Randomization Can Reduce Both Bias and Variance: A Case Study in Random
  Forests</div>
<div id='2402.12668v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-20T02:36:26Z</div><div>Authors: Brian Liu, Rahul Mazumder</div><div style='padding-top: 10px; width: 80ex'>We study the often overlooked phenomenon, first noted in
\cite{breiman2001random}, that random forests appear to reduce bias compared to
bagging. Motivated by an interesting paper by \cite{mentch2020randomization},
where the authors argue that random forests reduce effective degrees of freedom
and only outperform bagging ensembles in low signal-to-noise ratio (SNR)
settings, we explore how random forests can uncover patterns in the data missed
by bagging. We empirically demonstrate that in the presence of such patterns,
random forests reduce bias along with variance and increasingly outperform
bagging ensembles when SNR is high. Our observations offer insights into the
real-world success of random forests across a range of SNRs and enhance our
understanding of the difference between random forests and bagging ensembles
with respect to the randomization injected into each split. Our investigations
also yield practical insights into the importance of tuning $mtry$ in random
forests.</div><div><a href='http://arxiv.org/abs/2402.12668v1'>2402.12668v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01502v1")'>Why do Random Forests Work? Understanding Tree Ensembles as
  Self-Regularizing Adaptive Smoothers</div>
<div id='2402.01502v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-02T15:36:43Z</div><div>Authors: Alicia Curth, Alan Jeffares, Mihaela van der Schaar</div><div style='padding-top: 10px; width: 80ex'>Despite their remarkable effectiveness and broad application, the drivers of
success underlying ensembles of trees are still not fully understood. In this
paper, we highlight how interpreting tree ensembles as adaptive and
self-regularizing smoothers can provide new intuition and deeper insight to
this topic. We use this perspective to show that, when studied as smoothers,
randomized tree ensembles not only make predictions that are quantifiably more
smooth than the predictions of the individual trees they consist of, but also
further regulate their smoothness at test-time based on the dissimilarity
between testing and training inputs. First, we use this insight to revisit,
refine and reconcile two recent explanations of forest success by providing a
new way of quantifying the conjectured behaviors of tree ensembles objectively
by measuring the effective degree of smoothing they imply. Then, we move beyond
existing explanations for the mechanisms by which tree ensembles improve upon
individual trees and challenge the popular wisdom that the superior performance
of forests should be understood as a consequence of variance reduction alone.
We argue that the current high-level dichotomy into bias- and
variance-reduction prevalent in statistics is insufficient to understand tree
ensembles -- because the prevailing definition of bias does not capture
differences in the expressivity of the hypothesis classes formed by trees and
forests. Instead, we show that forests can improve upon trees by three distinct
mechanisms that are usually implicitly entangled. In particular, we demonstrate
that the smoothing effect of ensembling can reduce variance in predictions due
to noise in outcome generation, reduce variability in the quality of the
learned function given fixed input data and reduce potential bias in learnable
functions by enriching the available hypothesis space.</div><div><a href='http://arxiv.org/abs/2402.01502v1'>2402.01502v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07357v2")'>Regression Trees for Fast and Adaptive Prediction Intervals</div>
<div id='2402.07357v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-12T01:17:09Z</div><div>Authors: Luben M. C. Cabezas, Mateus P. Otto, Rafael Izbicki, Rafael B. Stern</div><div style='padding-top: 10px; width: 80ex'>Predictive models make mistakes. Hence, there is a need to quantify the
uncertainty associated with their predictions. Conformal inference has emerged
as a powerful tool to create statistically valid prediction regions around
point predictions, but its naive application to regression problems yields
non-adaptive regions. New conformal scores, often relying upon quantile
regressors or conditional density estimators, aim to address this limitation.
Although they are useful for creating prediction bands, these scores are
detached from the original goal of quantifying the uncertainty around an
arbitrary predictive model. This paper presents a new, model-agnostic family of
methods to calibrate prediction intervals for regression problems with local
coverage guarantees. Our approach is based on pursuing the coarsest partition
of the feature space that approximates conditional coverage. We create this
partition by training regression trees and Random Forests on conformity scores.
Our proposal is versatile, as it applies to various conformity scores and
prediction settings and demonstrates superior scalability and performance
compared to established baselines in simulated and real-world datasets. We
provide a Python package clover that implements our methods using the standard
scikit-learn interface.</div><div><a href='http://arxiv.org/abs/2402.07357v2'>2402.07357v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.16300v1")'>Conformalized Selective Regression</div>
<div id='2402.16300v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-26T04:43:50Z</div><div>Authors: Anna Sokol, Nuno Moniz, Nitesh Chawla</div><div style='padding-top: 10px; width: 80ex'>Should prediction models always deliver a prediction? In the pursuit of
maximum predictive performance, critical considerations of reliability and
fairness are often overshadowed, particularly when it comes to the role of
uncertainty. Selective regression, also known as the "reject option," allows
models to abstain from predictions in cases of considerable uncertainty.
Initially proposed seven decades ago, approaches to selective regression have
mostly focused on distribution-based proxies for measuring uncertainty,
particularly conditional variance. However, this focus neglects the significant
influence of model-specific biases on a model's performance. In this paper, we
propose a novel approach to selective regression by leveraging conformal
prediction, which provides grounded confidence measures for individual
predictions based on model-specific biases. In addition, we propose a
standardized evaluation framework to allow proper comparison of selective
regression approaches. Via an extensive experimental approach, we demonstrate
how our proposed approach, conformalized selective regression, demonstrates an
advantage over multiple state-of-the-art baselines.</div><div><a href='http://arxiv.org/abs/2402.16300v1'>2402.16300v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07307v1")'>Self-Consistent Conformal Prediction</div>
<div id='2402.07307v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-11T21:12:21Z</div><div>Authors: Lars van der Laan, Ahmed M. Alaa</div><div style='padding-top: 10px; width: 80ex'>In decision-making guided by machine learning, decision-makers often take
identical actions in contexts with identical predicted outcomes. Conformal
prediction helps decision-makers quantify outcome uncertainty for actions,
allowing for better risk management. Inspired by this perspective, we introduce
self-consistent conformal prediction, which yields both Venn-Abers calibrated
predictions and conformal prediction intervals that are valid conditional on
actions prompted by model predictions. Our procedure can be applied post-hoc to
any black-box predictor to provide rigorous, action-specific decision-making
guarantees. Numerical experiments show our approach strikes a balance between
interval efficiency and conditional validity.</div><div><a href='http://arxiv.org/abs/2402.07307v1'>2402.07307v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.13744v2")'>Conformal Prediction Sets Improve Human Decision Making</div>
<div id='2401.13744v2' style='display: none; margin-left: 20px'><div>Date: 2024-01-24T19:01:22Z</div><div>Authors: Jesse C. Cresswell, Yi Sui, Bhargava Kumar, Noël Vouitsis</div><div style='padding-top: 10px; width: 80ex'>In response to everyday queries, humans explicitly signal uncertainty and
offer alternative answers when they are unsure. Machine learning models that
output calibrated prediction sets through conformal prediction mimic this human
behaviour; larger sets signal greater uncertainty while providing alternatives.
In this work, we study the usefulness of conformal prediction sets as an aid
for human decision making by conducting a pre-registered randomized controlled
trial with conformal prediction sets provided to human subjects. With
statistical significance, we find that when humans are given conformal
prediction sets their accuracy on tasks improves compared to fixed-size
prediction sets with the same coverage guarantee. The results show that
quantifying model uncertainty with conformal prediction is helpful for
human-in-the-loop decision making and human-AI teams.</div><div><a href='http://arxiv.org/abs/2401.13744v2'>2401.13744v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.04670v1")'>End-to-end Conditional Robust Optimization</div>
<div id='2403.04670v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-07T17:16:59Z</div><div>Authors: Abhilash Chenreddy, Erick Delage</div><div style='padding-top: 10px; width: 80ex'>The field of Contextual Optimization (CO) integrates machine learning and
optimization to solve decision making problems under uncertainty. Recently, a
risk sensitive variant of CO, known as Conditional Robust Optimization (CRO),
combines uncertainty quantification with robust optimization in order to
promote safety and reliability in high stake applications. Exploiting modern
differentiable optimization methods, we propose a novel end-to-end approach to
train a CRO model in a way that accounts for both the empirical risk of the
prescribed decisions and the quality of conditional coverage of the contextual
uncertainty set that supports them. While guarantees of success for the latter
objective are impossible to obtain from the point of view of conformal
prediction theory, high quality conditional coverage is achieved empirically by
ingeniously employing a logistic regression differentiable layer within the
calculation of coverage quality in our training loss. We show that the proposed
training algorithms produce decisions that outperform the traditional estimate
then optimize approaches.</div><div><a href='http://arxiv.org/abs/2403.04670v1'>2403.04670v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03728v1")'>Consistent Joint Decision-Making with Heterogeneous Learning Models</div>
<div id='2402.03728v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-06T05:50:04Z</div><div>Authors: Hossein Rajaby Faghihi, Parisa Kordjamshidi</div><div style='padding-top: 10px; width: 80ex'>This paper introduces a novel decision-making framework that promotes
consistency among decisions made by diverse models while utilizing external
knowledge. Leveraging the Integer Linear Programming (ILP) framework, we map
predictions from various models into globally normalized and comparable values
by incorporating information about decisions' prior probability, confidence
(uncertainty), and the models' expected accuracy. Our empirical study
demonstrates the superiority of our approach over conventional baselines on
multiple datasets.</div><div><a href='http://arxiv.org/abs/2402.03728v1'>2402.03728v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00592v1")'>Uncertainty-Aware Partial-Label Learning</div>
<div id='2402.00592v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T13:41:44Z</div><div>Authors: Tobias Fuchs, Florian Kalinke, Klemens Böhm</div><div style='padding-top: 10px; width: 80ex'>In real-world applications, one often encounters ambiguously labeled data,
where different annotators assign conflicting class labels. Partial-label
learning allows training classifiers in this weakly supervised setting. While
state-of-the-art methods already feature good predictive performance, they
often suffer from miscalibrated uncertainty estimates. However, having
well-calibrated uncertainty estimates is important, especially in
safety-critical domains like medicine and autonomous driving. In this article,
we propose a novel nearest-neighbor-based partial-label-learning algorithm that
leverages Dempster-Shafer theory. Extensive experiments on artificial and
real-world datasets show that the proposed method provides a well-calibrated
uncertainty estimate and achieves competitive prediction performance.
Additionally, we prove that our algorithm is risk-consistent.</div><div><a href='http://arxiv.org/abs/2402.00592v1'>2402.00592v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.05732v1")'>Conservative DDPG -- Pessimistic RL without Ensemble</div>
<div id='2403.05732v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-08T23:59:38Z</div><div>Authors: Nitsan Soffair, Shie Mannor</div><div style='padding-top: 10px; width: 80ex'>DDPG is hindered by the overestimation bias problem, wherein its
$Q$-estimates tend to overstate the actual $Q$-values. Traditional solutions to
this bias involve ensemble-based methods, which require significant
computational resources, or complex log-policy-based approaches, which are
difficult to understand and implement. In contrast, we propose a
straightforward solution using a $Q$-target and incorporating a behavioral
cloning (BC) loss penalty. This solution, acting as an uncertainty measure, can
be easily implemented with minimal code and without the need for an ensemble.
Our empirical findings strongly support the superiority of Conservative DDPG
over DDPG across various MuJoCo and Bullet tasks. We consistently observe
better performance in all evaluated tasks and even competitive or superior
performance compared to TD3 and TD7, all achieved with significantly reduced
computational requirements.</div><div><a href='http://arxiv.org/abs/2403.05732v1'>2403.05732v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.00961v1")'>Automated Model Selection for Tabular Data</div>
<div id='2401.00961v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-01T21:41:20Z</div><div>Authors: Avinash Amballa, Anmol Mekala, Gayathri Akkinapalli, Manas Madine, Naga Pavana Priya Yarrabolu, Przemyslaw A. Grabowicz</div><div style='padding-top: 10px; width: 80ex'>Structured data in the form of tabular datasets contain features that are
distinct and discrete, with varying individual and relative importances to the
target. Combinations of one or more features may be more predictive and
meaningful than simple individual feature contributions. R's mixed effect
linear models library allows users to provide such interactive feature
combinations in the model design. However, given many features and possible
interactions to select from, model selection becomes an exponentially difficult
task. We aim to automate the model selection process for predictions on tabular
datasets incorporating feature interactions while keeping computational costs
small. The framework includes two distinct approaches for feature selection: a
Priority-based Random Grid Search and a Greedy Search method. The
Priority-based approach efficiently explores feature combinations using prior
probabilities to guide the search. The Greedy method builds the solution
iteratively by adding or removing features based on their impact. Experiments
on synthetic demonstrate the ability to effectively capture predictive feature
combinations.</div><div><a href='http://arxiv.org/abs/2401.00961v1'>2401.00961v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.15025v1")'>Robust Conformal Prediction under Distribution Shift via
  Physics-Informed Structural Causal Model</div>
<div id='2403.15025v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-22T08:13:33Z</div><div>Authors: Rui Xu, Yue Sun, Chao Chen, Parv Venkitasubramaniam, Sihong Xie</div><div style='padding-top: 10px; width: 80ex'>Uncertainty is critical to reliable decision-making with machine learning.
Conformal prediction (CP) handles uncertainty by predicting a set on a test
input, hoping the set to cover the true label with at least $(1-\alpha)$
confidence. This coverage can be guaranteed on test data even if the marginal
distributions $P_X$ differ between calibration and test datasets. However, as
it is common in practice, when the conditional distribution $P_{Y|X}$ is
different on calibration and test data, the coverage is not guaranteed and it
is essential to measure and minimize the coverage loss under distributional
shift at \textit{all} possible confidence levels. To address these issues, we
upper bound the coverage difference at all levels using the cumulative density
functions of calibration and test conformal scores and Wasserstein distance.
Inspired by the invariance of physics across data distributions, we propose a
physics-informed structural causal model (PI-SCM) to reduce the upper bound. We
validated that PI-SCM can improve coverage robustness along confidence level
and test domain on a traffic speed prediction task and an epidemic spread task
with multiple real-world datasets.</div><div><a href='http://arxiv.org/abs/2403.15025v1'>2403.15025v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07407v1")'>Conformal Predictive Programming for Chance Constrained Optimization</div>
<div id='2402.07407v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-12T04:59:34Z</div><div>Authors: Yiqi Zhao, Xinyi Yu, Jyotirmoy V. Deshmukh, Lars Lindemann</div><div style='padding-top: 10px; width: 80ex'>Motivated by the advances in conformal prediction (CP), we propose conformal
predictive programming (CPP), an approach to solve chance constrained
optimization (CCO) problems, i.e., optimization problems with nonlinear
constraint functions affected by arbitrary random parameters. CPP utilizes
samples from these random parameters along with the quantile lemma -- which is
central to CP -- to transform the CCO problem into a deterministic optimization
problem. We then present two tractable reformulations of CPP by: (1) writing
the quantile as a linear program along with its KKT conditions (CPP-KKT), and
(2) using mixed integer programming (CPP-MIP). CPP comes with marginal
probabilistic feasibility guarantees for the CCO problem that are conceptually
different from existing approaches, e.g., the sample approximation and the
scenario approach. While we explore algorithmic similarities with the sample
approximation approach, we emphasize that the strength of CPP is that it can
easily be extended to incorporate different variants of CP. To illustrate this,
we present robust conformal predictive programming to deal with distribution
shifts in the uncertain parameters of the CCO problem.</div><div><a href='http://arxiv.org/abs/2402.07407v1'>2402.07407v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.00423v1")'>Validation of ML-UQ calibration statistics using simulated reference
  values: a sensitivity analysis</div>
<div id='2403.00423v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-01T10:19:32Z</div><div>Authors: Pascal Pernot</div><div style='padding-top: 10px; width: 80ex'>Some popular Machine Learning Uncertainty Quantification (ML-UQ) calibration
statistics do not have predefined reference values and are mostly used in
comparative studies. In consequence, calibration is almost never validated and
the diagnostic is left to the appreciation of the reader. Simulated reference
values, based on synthetic calibrated datasets derived from actual
uncertainties, have been proposed to palliate this problem. As the generative
probability distribution for the simulation of synthetic errors is often not
constrained, the sensitivity of simulated reference values to the choice of
generative distribution might be problematic, shedding a doubt on the
calibration diagnostic. This study explores various facets of this problem, and
shows that some statistics are excessively sensitive to the choice of
generative distribution to be used for validation when the generative
distribution is unknown. This is the case, for instance, of the correlation
coefficient between absolute errors and uncertainties (CC) and of the expected
normalized calibration error (ENCE). A robust validation workflow to deal with
simulated reference values is proposed.</div><div><a href='http://arxiv.org/abs/2403.00423v1'>2403.00423v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.06757v2")'>Koopman Ensembles for Probabilistic Time Series Forecasting</div>
<div id='2403.06757v2' style='display: none; margin-left: 20px'><div>Date: 2024-03-11T14:29:56Z</div><div>Authors: Anthony Frion, Lucas Drumetz, Guillaume Tochon, Mauro Dalla Mura, Albdeldjalil Aïssa El Bey</div><div style='padding-top: 10px; width: 80ex'>In the context of an increasing popularity of data-driven models to represent
dynamical systems, many machine learning-based implementations of the Koopman
operator have recently been proposed. However, the vast majority of those works
are limited to deterministic predictions, while the knowledge of uncertainty is
critical in fields like meteorology and climatology. In this work, we
investigate the training of ensembles of models to produce stochastic outputs.
We show through experiments on real remote sensing image time series that
ensembles of independently trained models are highly overconfident and that
using a training criterion that explicitly encourages the members to produce
predictions with high inter-model variances greatly improves the uncertainty
quantification of the ensembles.</div><div><a href='http://arxiv.org/abs/2403.06757v2'>2403.06757v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.12873v1")'>Short-Term Solar Irradiance Forecasting Under Data Transmission
  Constraints</div>
<div id='2403.12873v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-19T16:17:21Z</div><div>Authors: Joshua Edward Hammond, Ricardo A. Lara Orozco, Michael Baldea, Brian A. Korgel</div><div style='padding-top: 10px; width: 80ex'>We report a data-parsimonious machine learning model for short-term
forecasting of solar irradiance. The model inputs include sky camera images
that are reduced to scalar features to meet data transmission constraints. The
output irradiance values are transformed to focus on unknown short-term
dynamics. Inspired by control theory, a noise input is used to reflect
unmeasured variables and is shown to improve model predictions, often
considerably. Five years of data from the NREL Solar Radiation Research
Laboratory were used to create three rolling train-validate sets and determine
the best representations for time, the optimal span of input measurements, and
the most impactful model input data (features). For the chosen test data, the
model achieves a mean absolute error of 74.34 $W/m^2$ compared to a baseline
134.35 $W/m^2$ using the persistence of cloudiness model.</div><div><a href='http://arxiv.org/abs/2403.12873v1'>2403.12873v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.06963v1")'>Tree Ensembles for Contextual Bandits</div>
<div id='2402.06963v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-10T14:36:31Z</div><div>Authors: Hannes Nilsson, Rikard Johansson, Niklas Åkerblom, Morteza Haghir Chehreghani</div><div style='padding-top: 10px; width: 80ex'>We propose a novel framework for contextual multi-armed bandits based on tree
ensembles. Our framework integrates two widely used bandit methods, Upper
Confidence Bound and Thompson Sampling, for both standard and combinatorial
settings. We demonstrate the effectiveness of our framework via several
experimental studies, employing XGBoost, a popular tree ensemble method.
Compared to state-of-the-art methods based on neural networks, our methods
exhibit superior performance in terms of both regret minimization and
computational runtime, when applied to benchmark datasets and the real-world
application of navigation over road networks.</div><div><a href='http://arxiv.org/abs/2402.06963v1'>2402.06963v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.18612v1")'>Understanding random forests and overfitting: a visualization and
  simulation study</div>
<div id='2402.18612v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-28T15:29:02Z</div><div>Authors: Lasai Barreñada, Paula Dhiman, Dirk Timmerman, Anne-Laure Boulesteix, Ben Van Calster</div><div style='padding-top: 10px; width: 80ex'>Random forests have become popular for clinical risk prediction modelling. In
a case study on predicting ovarian malignancy, we observed training
c-statistics close to 1. Although this suggests overfitting, performance was
competitive on test data. We aimed to understand the behaviour of random
forests by (1) visualizing data space in three real world case studies and (2)
a simulation study. For the case studies, risk estimates were visualised using
heatmaps in a 2-dimensional subspace. The simulation study included 48 logistic
data generating mechanisms (DGM), varying the predictor distribution, the
number of predictors, the correlation between predictors, the true c-statistic
and the strength of true predictors. For each DGM, 1000 training datasets of
size 200 or 4000 were simulated and RF models trained with minimum node size 2
or 20 using ranger package, resulting in 192 scenarios in total. The
visualizations suggested that the model learned spikes of probability around
events in the training set. A cluster of events created a bigger peak, isolated
events local peaks. In the simulation study, median training c-statistics were
between 0.97 and 1 unless there were 4 or 16 binary predictors with minimum
node size 20. Median test c-statistics were higher with higher events per
variable, higher minimum node size, and binary predictors. Median training
slopes were always above 1, and were not correlated with median test slopes
across scenarios (correlation -0.11). Median test slopes were higher with
higher true c-statistic, higher minimum node size, and higher sample size.
Random forests learn local probability peaks that often yield near perfect
training c-statistics without strongly affecting c-statistics on test data.
When the aim is probability estimation, the simulation results go against the
common recommendation to use fully grown trees in random forest models.</div><div><a href='http://arxiv.org/abs/2402.18612v1'>2402.18612v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.07790v1")'>From Uncertainty to Precision: Enhancing Binary Classifier Performance
  through Calibration</div>
<div id='2402.07790v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-12T16:55:19Z</div><div>Authors: Agathe Fernandes Machado, Arthur Charpentier, Emmanuel Flachaire, Ewen Gallic, François Hu</div><div style='padding-top: 10px; width: 80ex'>The assessment of binary classifier performance traditionally centers on
discriminative ability using metrics, such as accuracy. However, these metrics
often disregard the model's inherent uncertainty, especially when dealing with
sensitive decision-making domains, such as finance or healthcare. Given that
model-predicted scores are commonly seen as event probabilities, calibration is
crucial for accurate interpretation. In our study, we analyze the sensitivity
of various calibration measures to score distortions and introduce a refined
metric, the Local Calibration Score. Comparing recalibration methods, we
advocate for local regressions, emphasizing their dual role as effective
recalibration tools and facilitators of smoother visualizations. We apply these
findings in a real-world scenario using Random Forest classifier and regressor
to predict credit default while simultaneously measuring calibration during
performance optimization.</div><div><a href='http://arxiv.org/abs/2402.07790v1'>2402.07790v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.11044v1")'>The Significance of Data Abstraction Methods in Machine Learning
  Classification Processes for Critical Decision-Making</div>
<div id='2401.11044v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-19T22:11:54Z</div><div>Authors: Karol Capała, Paulina Tworek, Jose Sousa</div><div style='padding-top: 10px; width: 80ex'>The applicability of widely adopted machine learning (ML) methods to
classification is circumscribed by the imperatives of explicability and
uncertainty, particularly evident in domains such as healthcare, behavioural
sciences, and finances, wherein accountability assumes priority. Recently,
Small and Incomplete Dataset Analyser (SaNDA) has been proposed to enhance the
ability to perform classification in such domains, by developing a data
abstraction protocol using a ROC curve-based method. This paper focuses on
column-wise data transformations called abstractions, which are crucial for
SaNDA's classification process and explores alternative abstractions protocols,
such as constant binning and quantiles. The best-performing methods have been
compared against Random Forest as a baseline for explainable methods. The
results suggests that SaNDA can be a viable substitute for Random Forest when
data is incomplete, even with minimal missing values. It consistently maintains
high accuracy even when half of the dataset is missing, unlike Random Forest
which experiences a significant decline in accuracy under similar conditions.</div><div><a href='http://arxiv.org/abs/2401.11044v1'>2401.11044v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.10250v1")'>Interpretable Machine Learning for Survival Analysis</div>
<div id='2403.10250v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-15T12:38:00Z</div><div>Authors: Sophie Hanna Langbein, Mateusz Krzyziński, Mikołaj Spytek, Hubert Baniecki, Przemysław Biecek, Marvin N. Wright</div><div style='padding-top: 10px; width: 80ex'>With the spread and rapid advancement of black box machine learning models,
the field of interpretable machine learning (IML) or explainable artificial
intelligence (XAI) has become increasingly important over the last decade. This
is particularly relevant for survival analysis, where the adoption of IML
techniques promotes transparency, accountability and fairness in sensitive
areas, such as clinical decision making processes, the development of targeted
therapies, interventions or in other medical or healthcare related contexts.
More specifically, explainability can uncover a survival model's potential
biases and limitations and provide more mathematically sound ways to understand
how and which features are influential for prediction or constitute risk
factors. However, the lack of readily available IML methods may have deterred
medical practitioners and policy makers in public health from leveraging the
full potential of machine learning for predicting time-to-event data. We
present a comprehensive review of the limited existing amount of work on IML
methods for survival analysis within the context of the general IML taxonomy.
In addition, we formally detail how commonly used IML methods, such as such as
individual conditional expectation (ICE), partial dependence plots (PDP),
accumulated local effects (ALE), different feature importance measures or
Friedman's H-interaction statistics can be adapted to survival outcomes. An
application of several IML methods to real data on data on under-5 year
mortality of Ghanaian children from the Demographic and Health Surveys (DHS)
Program serves as a tutorial or guide for researchers, on how to utilize the
techniques in practice to facilitate understanding of model decisions or
predictions.</div><div><a href='http://arxiv.org/abs/2403.10250v1'>2403.10250v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00072v1")'>Explainable AI for survival analysis: a median-SHAP approach</div>
<div id='2402.00072v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-30T20:47:50Z</div><div>Authors: Lucile Ter-Minassian, Sahra Ghalebikesabi, Karla Diaz-Ordaz, Chris Holmes</div><div style='padding-top: 10px; width: 80ex'>With the adoption of machine learning into routine clinical practice comes
the need for Explainable AI methods tailored to medical applications. Shapley
values have sparked wide interest for locally explaining models. Here, we
demonstrate their interpretation strongly depends on both the summary statistic
and the estimator for it, which in turn define what we identify as an 'anchor
point'. We show that the convention of using a mean anchor point may generate
misleading interpretations for survival analysis and introduce median-SHAP, a
method for explaining black-box models predicting individual survival times.</div><div><a href='http://arxiv.org/abs/2402.00072v1'>2402.00072v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.16094v1")'>Federated unsupervised random forest for privacy-preserving patient
  stratification</div>
<div id='2401.16094v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-29T12:04:14Z</div><div>Authors: Bastian Pfeifer, Christel Sirocchi, Marcus D. Bloice, Markus Kreuzthaler, Martin Urschler</div><div style='padding-top: 10px; width: 80ex'>In the realm of precision medicine, effective patient stratification and
disease subtyping demand innovative methodologies tailored for multi-omics
data. Clustering techniques applied to multi-omics data have become
instrumental in identifying distinct subgroups of patients, enabling a
finer-grained understanding of disease variability. This work establishes a
powerful framework for advancing precision medicine through unsupervised
random-forest-based clustering and federated computing. We introduce a novel
multi-omics clustering approach utilizing unsupervised random-forests. The
unsupervised nature of the random forest enables the determination of
cluster-specific feature importance, unraveling key molecular contributors to
distinct patient groups. Moreover, our methodology is designed for federated
execution, a crucial aspect in the medical domain where privacy concerns are
paramount. We have validated our approach on machine learning benchmark data
sets as well as on cancer data from The Cancer Genome Atlas (TCGA). Our method
is competitive with the state-of-the-art in terms of disease subtyping, but at
the same time substantially improves the cluster interpretability. Experiments
indicate that local clustering performance can be improved through federated
computing.</div><div><a href='http://arxiv.org/abs/2401.16094v1'>2401.16094v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.02945v1")'>Unsupervised Learning Approaches for Identifying ICU Patient Subgroups:
  Do Results Generalise?</div>
<div id='2403.02945v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-05T13:16:37Z</div><div>Authors: Harry Mayne, Guy Parsons, Adam Mahdi</div><div style='padding-top: 10px; width: 80ex'>The use of unsupervised learning to identify patient subgroups has emerged as
a potentially promising direction to improve the efficiency of Intensive Care
Units (ICUs). By identifying subgroups of patients with similar levels of
medical resource need, ICUs could be restructured into a collection of smaller
subunits, each catering to a specific group. However, it is unclear whether
common patient subgroups exist across different ICUs, which would determine
whether ICU restructuring could be operationalised in a standardised manner. In
this paper, we tested the hypothesis that common ICU patient subgroups exist by
examining whether the results from one existing study generalise to a different
dataset. We extracted 16 features representing medical resource need and used
consensus clustering to derive patient subgroups, replicating the previous
study. We found limited similarities between our results and those of the
previous study, providing evidence against the hypothesis. Our findings imply
that there is significant variation between ICUs; thus, a standardised
restructuring approach is unlikely to be appropriate. Instead, potential
efficiency gains might be greater when the number and nature of the subunits
are tailored to each ICU individually.</div><div><a href='http://arxiv.org/abs/2403.02945v1'>2403.02945v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.03486v1")'>Early prediction of onset of sepsis in Clinical Setting</div>
<div id='2402.03486v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-05T19:58:40Z</div><div>Authors: Fahim Mohammad, Lakshmi Arunachalam, Samanway Sadhu, Boudewijn Aasman, Shweta Garg, Adil Ahmed, Silvie Colman, Meena Arunachalam, Sudhir Kulkarni, Parsa Mirhaji</div><div style='padding-top: 10px; width: 80ex'>This study proposes the use of Machine Learning models to predict the early
onset of sepsis using deidentified clinical data from Montefiore Medical Center
in Bronx, NY, USA. A supervised learning approach was adopted, wherein an
XGBoost model was trained utilizing 80\% of the train dataset, encompassing 107
features (including the original and derived features). Subsequently, the model
was evaluated on the remaining 20\% of the test data. The model was validated
on prospective data that was entirely unseen during the training phase. To
assess the model's performance at the individual patient level and timeliness
of the prediction, a normalized utility score was employed, a widely recognized
scoring methodology for sepsis detection, as outlined in the PhysioNet Sepsis
Challenge paper. Metrics such as F1 Score, Sensitivity, Specificity, and Flag
Rate were also devised. The model achieved a normalized utility score of 0.494
on test data and 0.378 on prospective data at threshold 0.3. The F1 scores were
80.8\% and 67.1\% respectively for the test data and the prospective data for
the same threshold, highlighting its potential to be integrated into clinical
decision-making processes effectively. These results bear testament to the
model's robust predictive capabilities and its potential to substantially
impact clinical decision-making processes.</div><div><a href='http://arxiv.org/abs/2402.03486v1'>2402.03486v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2401.00972v1")'>Robust Meta-Model for Predicting the Need for Blood Transfusion in
  Non-traumatic ICU Patients</div>
<div id='2401.00972v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-01T23:25:48Z</div><div>Authors: Alireza Rafiei, Ronald Moore, Tilendra Choudhary, Curtis Marshall, Geoffrey Smith, John D. Roback, Ravi M. Patel, Cassandra D. Josephson, Rishikesan Kamaleswaran</div><div style='padding-top: 10px; width: 80ex'>Objective: Blood transfusions, crucial in managing anemia and coagulopathy in
ICU settings, require accurate prediction for effective resource allocation and
patient risk assessment. However, existing clinical decision support systems
have primarily targeted a particular patient demographic with unique medical
conditions and focused on a single type of blood transfusion. This study aims
to develop an advanced machine learning-based model to predict the probability
of transfusion necessity over the next 24 hours for a diverse range of
non-traumatic ICU patients.
  Methods: We conducted a retrospective cohort study on 72,072 adult
non-traumatic ICU patients admitted to a high-volume US metropolitan academic
hospital between 2016 and 2020. We developed a meta-learner and various machine
learning models to serve as predictors, training them annually with four-year
data and evaluating on the fifth, unseen year, iteratively over five years.
  Results: The experimental results revealed that the meta-model surpasses the
other models in different development scenarios. It achieved notable
performance metrics, including an Area Under the Receiver Operating
Characteristic (AUROC) curve of 0.97, an accuracy rate of 0.93, and an F1-score
of 0.89 in the best scenario.
  Conclusion: This study pioneers the use of machine learning models for
predicting blood transfusion needs in a diverse cohort of critically ill
patients. The findings of this evaluation confirm that our model not only
predicts transfusion requirements effectively but also identifies key
biomarkers for making transfusion decisions.</div><div><a href='http://arxiv.org/abs/2401.00972v1'>2401.00972v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2402.17398v2")'>A Quantum Approach to Synthetic Minority Oversampling Technique (SMOTE)</div>
<div id='2402.17398v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-27T10:46:36Z</div><div>Authors: Nishikanta Mohanty, Bikash K. Behera, Christopher Ferrie, Pravat Dash</div><div style='padding-top: 10px; width: 80ex'>The paper proposes the Quantum-SMOTE method, a novel solution that uses
quantum computing techniques to solve the prevalent problem of class imbalance
in machine learning datasets. Quantum-SMOTE, inspired by the Synthetic Minority
Oversampling Technique (SMOTE), generates synthetic data points using quantum
processes such as swap tests and quantum rotation. The process varies from the
conventional SMOTE algorithm's usage of K-Nearest Neighbors (KNN) and Euclidean
distances, enabling synthetic instances to be generated from minority class
data points without relying on neighbor proximity. The algorithm asserts
greater control over the synthetic data generation process by introducing
hyperparameters such as rotation angle, minority percentage, and splitting
factor, which allow for customization to specific dataset requirements. The
approach is tested on a public dataset of TelecomChurn and evaluated alongside
two prominent classification algorithms, Random Forest and Logistic Regression,
to determine its impact along with varying proportions of synthetic data.</div><div><a href='http://arxiv.org/abs/2402.17398v2'>2402.17398v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.09867v1")'>iBRF: Improved Balanced Random Forest Classifier</div>
<div id='2403.09867v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-14T20:59:36Z</div><div>Authors: Asif Newaz, Md. Salman Mohosheu, MD. Abdullah al Noman, Dr. Taskeed Jabid</div><div style='padding-top: 10px; width: 80ex'>Class imbalance poses a major challenge in different classification tasks,
which is a frequently occurring scenario in many real-world applications. Data
resampling is considered to be the standard approach to address this issue. The
goal of the technique is to balance the class distribution by generating new
samples or eliminating samples from the data. A wide variety of sampling
techniques have been proposed over the years to tackle this challenging
problem. Sampling techniques can also be incorporated into the ensemble
learning framework to obtain more generalized prediction performance. Balanced
Random Forest (BRF) and SMOTE-Bagging are some of the popular ensemble
approaches. In this study, we propose a modification to the BRF classifier to
enhance the prediction performance. In the original algorithm, the Random
Undersampling (RUS) technique was utilized to balance the bootstrap samples.
However, randomly eliminating too many samples from the data leads to
significant data loss, resulting in a major decline in performance. We propose
to alleviate the scenario by incorporating a novel hybrid sampling approach to
balance the uneven class distribution in each bootstrap sub-sample. Our
proposed hybrid sampling technique, when incorporated into the framework of the
Random Forest classifier, termed as iBRF: improved Balanced Random Forest
classifier, achieves better prediction performance than other sampling
techniques used in imbalanced classification tasks. Experiments were carried
out on 44 imbalanced datasets on which the original BRF classifier produced an
average MCC score of 47.03% and an F1 score of 49.09%. Our proposed algorithm
outperformed the approach by producing a far better MCC score of 53.04% and an
F1 score of 55%. The results obtained signify the superiority of the iBRF
algorithm and its potential to be an effective sampling technique in imbalanced
learning.</div><div><a href='http://arxiv.org/abs/2403.09867v1'>2403.09867v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.19232v1")'>Trained Random Forests Completely Reveal your Dataset</div>
<div id='2402.19232v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-29T15:05:59Z</div><div>Authors: Julien Ferry, Ricardo Fukasawa, Timothée Pascal, Thibaut Vidal</div><div style='padding-top: 10px; width: 80ex'>We introduce an optimization-based reconstruction attack capable of
completely or near-completely reconstructing a dataset utilized for training a
random forest. Notably, our approach relies solely on information readily
available in commonly used libraries such as scikit-learn. To achieve this, we
formulate the reconstruction problem as a combinatorial problem under a maximum
likelihood objective. We demonstrate that this problem is NP-hard, though
solvable at scale using constraint programming -- an approach rooted in
constraint propagation and solution-domain reduction. Through an extensive
computational investigation, we demonstrate that random forests trained without
bootstrap aggregation but with feature randomization are susceptible to a
complete reconstruction. This holds true even with a small number of trees.
Even with bootstrap aggregation, the majority of the data can also be
reconstructed. These findings underscore a critical vulnerability inherent in
widely adopted ensemble methods, warranting attention and mitigation. Although
the potential for such reconstruction attacks has been discussed in privacy
research, our study provides clear empirical evidence of their practicability.</div><div><a href='http://arxiv.org/abs/2402.19232v1'>2402.19232v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2403.00017v1")'>Towards Interpreting Multi-Objective Feature Associations</div>
<div id='2403.00017v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-28T02:24:04Z</div><div>Authors: Nisha Pillai, Ganga Gireesan, Michael J. Rothrock Jr., Bindu Nanduri, Zhiqian Chen, Mahalingam Ramkumar</div><div style='padding-top: 10px; width: 80ex'>Understanding how multiple features are associated and contribute to a
specific objective is as important as understanding how each feature
contributes to a particular outcome. Interpretability of a single feature in a
prediction may be handled in multiple ways; however, in a multi-objective
prediction, it is difficult to obtain interpretability of a combination of
feature values. To address this issue, we propose an objective specific feature
interaction design using multi-labels to find the optimal combination of
features in agricultural settings. One of the novel aspects of this design is
the identification of a method that integrates feature explanations with global
sensitivity analysis in order to ensure combinatorial optimization in
multi-objective settings. We have demonstrated in our preliminary experiments
that an approximate combination of feature values can be found to achieve the
desired outcome using two agricultural datasets: one with pre-harvest poultry
farm practices for multi-drug resistance presence, and one with post-harvest
poultry farm practices for food-borne pathogens. In our combinatorial
optimization approach, all three pathogens are taken into consideration
simultaneously to account for the interaction between conditions that favor
different types of pathogen growth. These results indicate that
explanation-based approaches are capable of identifying combinations of
features that reduce pathogen presence in fewer iterations than a baseline.</div><div><a href='http://arxiv.org/abs/2403.00017v1'>2403.00017v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(50.0%, 50.0%, 50.0%)' onclick='toggle("2403.15167v1")'>Transition Graph Properties of Target Class Classification</div>
<div id='2403.15167v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-22T12:37:14Z</div><div>Authors: Levon Aslanyan, Hasmik Sahakyan</div><div style='padding-top: 10px; width: 80ex'>Target class classification is a mixed classification and transition model
whose integrated goal is to assign objects to a certain, so called target or
normal class. The classification process is iterative, and in each step an
object in a certain class undergoes an action attached to that class,
initiating the transition of the object to one of the classes. The sequence of
transitions, which we call class transitions, must be designed to provide the
final assignment of objects to the target class. The transition process can be
described in the form of a directed graph, and the success of the final
classification is mainly due to the properties of this graph. In our previous
research we showed that the desirable structure of the transition graph is an
oriented rooted tree with orientation towards the root vertex, which
corresponds to the normal class. It is clear that the transition graph of an
arbitrary algorithm (policy) may not have this property. In this paper we study
the structure of realistic transition graphs, which makes it possible to find
classification inconsistencies, helping to transfer it into the desired form.
The medical interpretation of dynamic treatment regime considered in the
article further clarifies the investigated framework.</div><div><a href='http://arxiv.org/abs/2403.15167v1'>2403.15167v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(75.0%, 75.0%, 75.0%)' onclick='toggle("2401.14343v1")'>Class-attribute Priors: Adapting Optimization to Heterogeneity and
  Fairness Objective</div>
<div id='2401.14343v1' style='display: none; margin-left: 20px'><div>Date: 2024-01-25T17:43:39Z</div><div>Authors: Xuechen Zhang, Mingchen Li, Jiasi Chen, Christos Thrampoulidis, Samet Oymak</div><div style='padding-top: 10px; width: 80ex'>Modern classification problems exhibit heterogeneities across individual
classes: Each class may have unique attributes, such as sample size, label
quality, or predictability (easy vs difficult), and variable importance at
test-time. Without care, these heterogeneities impede the learning process,
most notably, when optimizing fairness objectives. Confirming this, under a
gaussian mixture setting, we show that the optimal SVM classifier for balanced
accuracy needs to be adaptive to the class attributes. This motivates us to
propose CAP: An effective and general method that generates a class-specific
learning strategy (e.g. hyperparameter) based on the attributes of that class.
This way, optimization process better adapts to heterogeneities. CAP leads to
substantial improvements over the naive approach of assigning separate
hyperparameters to each class. We instantiate CAP for loss function design and
post-hoc logit adjustment, with emphasis on label-imbalanced problems. We show
that CAP is competitive with prior art and its flexibility unlocks clear
benefits for fairness objectives beyond balanced accuracy. Finally, we evaluate
CAP on problems with label noise as well as weighted test objectives to
showcase how CAP can jointly adapt to different heterogeneities.</div><div><a href='http://arxiv.org/abs/2401.14343v1'>2401.14343v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.01055v2")'>Multiclass Learning from Noisy Labels for Non-decomposable Performance
  Measures</div>
<div id='2402.01055v2' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T23:03:53Z</div><div>Authors: Mingyuan Zhang, Shivani Agarwal</div><div style='padding-top: 10px; width: 80ex'>There has been much interest in recent years in learning good classifiers
from data with noisy labels. Most work on learning from noisy labels has
focused on standard loss-based performance measures. However, many machine
learning problems require using non-decomposable performance measures which
cannot be expressed as the expectation or sum of a loss on individual examples;
these include for example the H-mean, Q-mean and G-mean in class imbalance
settings, and the Micro $F_1$ in information retrieval. In this paper, we
design algorithms to learn from noisy labels for two broad classes of
multiclass non-decomposable performance measures, namely, monotonic convex and
ratio-of-linear, which encompass all the above examples. Our work builds on the
Frank-Wolfe and Bisection based methods of Narasimhan et al. (2015). In both
cases, we develop noise-corrected versions of the algorithms under the widely
studied family of class-conditional noise models. We provide regret (excess
risk) bounds for our algorithms, establishing that even though they are trained
on noisy data, they are Bayes consistent in the sense that their performance
converges to the optimal performance w.r.t. the clean (non-noisy) distribution.
Our experiments demonstrate the effectiveness of our algorithms in handling
label noise.</div><div><a href='http://arxiv.org/abs/2402.01055v2'>2402.01055v2</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.00324v1")'>A Consistent Lebesgue Measure for Multi-label Learning</div>
<div id='2402.00324v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-01T04:17:15Z</div><div>Authors: Kaan Demir, Bach Nguyen, Bing Xue, Mengjie Zhang</div><div style='padding-top: 10px; width: 80ex'>Multi-label loss functions are usually non-differentiable, requiring
surrogate loss functions for gradient-based optimisation. The consistency of
surrogate loss functions is not proven and is exacerbated by the conflicting
nature of multi-label loss functions. To directly learn from multiple related,
yet potentially conflicting multi-label loss functions, we propose a Consistent
Lebesgue Measure-based Multi-label Learner (CLML) and prove that CLML can
achieve theoretical consistency under a Bayes risk framework. Empirical
evidence supports our theory by demonstrating that: (1) CLML can consistently
achieve state-of-the-art results; (2) the primary performance factor is the
Lebesgue measure design, as CLML optimises a simpler feedforward model without
additional label graph, perturbation-based conditioning, or semantic
embeddings; and (3) an analysis of the results not only distinguishes CLML's
effectiveness but also highlights inconsistencies between the surrogate and the
desired loss functions.</div><div><a href='http://arxiv.org/abs/2402.00324v1'>2402.00324v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.10818v1")'>Trading off Consistency and Dimensionality of Convex Surrogates for the
  Mode</div>
<div id='2402.10818v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-16T16:42:09Z</div><div>Authors: Enrique Nueve, Bo Waggoner, Dhamma Kimpara, Jessie Finocchiaro</div><div style='padding-top: 10px; width: 80ex'>In multiclass classification over $n$ outcomes, the outcomes must be embedded
into the reals with dimension at least $n-1$ in order to design a consistent
surrogate loss that leads to the "correct" classification, regardless of the
data distribution. For large $n$, such as in information retrieval and
structured prediction tasks, optimizing a surrogate in $n-1$ dimensions is
often intractable. We investigate ways to trade off surrogate loss dimension,
the number of problem instances, and restricting the region of consistency in
the simplex for multiclass classification. Following past work, we examine an
intuitive embedding procedure that maps outcomes into the vertices of convex
polytopes in a low-dimensional surrogate space. We show that full-dimensional
subsets of the simplex exist around each point mass distribution for which
consistency holds, but also, with less than $n-1$ dimensions, there exist
distributions for which a phenomenon called hallucination occurs, which is when
the optimal report under the surrogate loss is an outcome with zero
probability. Looking towards application, we derive a result to check if
consistency holds under a given polytope embedding and low-noise assumption,
providing insight into when to use a particular embedding. We provide examples
of embedding $n = 2^{d}$ outcomes into the $d$-dimensional unit cube and $n =
d!$ outcomes into the $d$-dimensional permutahedron under low-noise
assumptions. Finally, we demonstrate that with multiple problem instances, we
can learn the mode with $\frac{n}{2}$ dimensions over the whole simplex.</div><div><a href='http://arxiv.org/abs/2402.10818v1'>2402.10818v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2402.13505v1")'>SimPro: A Simple Probabilistic Framework Towards Realistic Long-Tailed
  Semi-Supervised Learning</div>
<div id='2402.13505v1' style='display: none; margin-left: 20px'><div>Date: 2024-02-21T03:39:04Z</div><div>Authors: Chaoqun Du, Yizeng Han, Gao Huang</div><div style='padding-top: 10px; width: 80ex'>Recent advancements in semi-supervised learning have focused on a more
realistic yet challenging task: addressing imbalances in labeled data while the
class distribution of unlabeled data remains both unknown and potentially
mismatched. Current approaches in this sphere often presuppose rigid
assumptions regarding the class distribution of unlabeled data, thereby
limiting the adaptability of models to only certain distribution ranges. In
this study, we propose a novel approach, introducing a highly adaptable
framework, designated as SimPro, which does not rely on any predefined
assumptions about the distribution of unlabeled data. Our framework, grounded
in a probabilistic model, innovatively refines the expectation-maximization
(EM) algorithm by explicitly decoupling the modeling of conditional and
marginal class distributions. This separation facilitates a closed-form
solution for class distribution estimation during the maximization phase,
leading to the formulation of a Bayes classifier. The Bayes classifier, in
turn, enhances the quality of pseudo-labels in the expectation phase.
Remarkably, the SimPro framework not only comes with theoretical guarantees but
also is straightforward to implement. Moreover, we introduce two novel class
distributions broadening the scope of the evaluation. Our method showcases
consistent state-of-the-art performance across diverse benchmarks and data
distribution scenarios. Our code is available at
https://github.com/LeapLabTHU/SimPro.</div><div><a href='http://arxiv.org/abs/2402.13505v1'>2402.13505v1</a></div>
</div></div><div><div style='margin-top: 5px; border-top: 1px solid rgb(100.0%, 100.0%, 100.0%)' onclick='toggle("2403.03741v1")'>SUPClust: Active Learning at the Boundaries</div>
<div id='2403.03741v1' style='display: none; margin-left: 20px'><div>Date: 2024-03-06T14:30:09Z</div><div>Authors: Yuta Ono, Till Aczel, Benjamin Estermann, Roger Wattenhofer</div><div style='padding-top: 10px; width: 80ex'>Active learning is a machine learning paradigm designed to optimize model
performance in a setting where labeled data is expensive to acquire. In this
work, we propose a novel active learning method called SUPClust that seeks to
identify points at the decision boundary between classes. By targeting these
points, SUPClust aims to gather information that is most informative for
refining the model's prediction of complex decision regions. We demonstrate
experimentally that labeling these points leads to strong model performance.
This improvement is observed even in scenarios characterized by strong class
imbalance.</div><div><a href='http://arxiv.org/abs/2403.03741v1'>2403.03741v1</a></div>
</div></div>
    <div><a href="arxiv_3.html">Prev (3)</a></div>
    <div><a href="arxiv_5.html">Next (5)</a></div>
    